/* Generated by Cython 0.25.2 */

/* BEGIN: Cython Metadata
{
    "distutils": {
        "depends": [
            "/home/steb/torch/install/include/TH/THRandom.h", 
            "/home/steb/torch/install/include/TH/THTensor.h", 
            "src/LuaHelper.h", 
            "src/nnWrapper.h"
        ], 
        "extra_compile_args": [
            "-std=c++0x", 
            "-Wno-unused-function", 
            "-Wno-unreachable-code", 
            "-Wno-strict-prototypes"
        ], 
        "include_dirs": [
            "/home/steb/torch/install/include/TH", 
            "thirdparty/lua-5.1.5/src", 
            "/home/steb/torch/install/include"
        ], 
        "language": "c++", 
        "libraries": [
            "PyTorchNative"
        ], 
        "library_dirs": [
            "/home/steb/torch/install/lib"
        ], 
        "runtime_library_dirs": [
            "/home/steb/torch/install/lib"
        ]
    }, 
    "module_name": "PyTorch"
}
END: Cython Metadata */

#define PY_SSIZE_T_CLEAN
#include "Python.h"
#ifndef Py_PYTHON_H
    #error Python headers needed to compile C extensions, please install development version of Python.
#elif PY_VERSION_HEX < 0x02060000 || (0x03000000 <= PY_VERSION_HEX && PY_VERSION_HEX < 0x03020000)
    #error Cython requires Python 2.6+ or Python 3.2+.
#else
#define CYTHON_ABI "0_25_2"
#include <stddef.h>
#ifndef offsetof
  #define offsetof(type, member) ( (size_t) & ((type*)0) -> member )
#endif
#if !defined(WIN32) && !defined(MS_WINDOWS)
  #ifndef __stdcall
    #define __stdcall
  #endif
  #ifndef __cdecl
    #define __cdecl
  #endif
  #ifndef __fastcall
    #define __fastcall
  #endif
#endif
#ifndef DL_IMPORT
  #define DL_IMPORT(t) t
#endif
#ifndef DL_EXPORT
  #define DL_EXPORT(t) t
#endif
#ifndef HAVE_LONG_LONG
  #if PY_VERSION_HEX >= 0x03030000 || (PY_MAJOR_VERSION == 2 && PY_VERSION_HEX >= 0x02070000)
    #define HAVE_LONG_LONG
  #endif
#endif
#ifndef PY_LONG_LONG
  #define PY_LONG_LONG LONG_LONG
#endif
#ifndef Py_HUGE_VAL
  #define Py_HUGE_VAL HUGE_VAL
#endif
#ifdef PYPY_VERSION
  #define CYTHON_COMPILING_IN_PYPY 1
  #define CYTHON_COMPILING_IN_PYSTON 0
  #define CYTHON_COMPILING_IN_CPYTHON 0
  #undef CYTHON_USE_TYPE_SLOTS
  #define CYTHON_USE_TYPE_SLOTS 0
  #undef CYTHON_USE_ASYNC_SLOTS
  #define CYTHON_USE_ASYNC_SLOTS 0
  #undef CYTHON_USE_PYLIST_INTERNALS
  #define CYTHON_USE_PYLIST_INTERNALS 0
  #undef CYTHON_USE_UNICODE_INTERNALS
  #define CYTHON_USE_UNICODE_INTERNALS 0
  #undef CYTHON_USE_UNICODE_WRITER
  #define CYTHON_USE_UNICODE_WRITER 0
  #undef CYTHON_USE_PYLONG_INTERNALS
  #define CYTHON_USE_PYLONG_INTERNALS 0
  #undef CYTHON_AVOID_BORROWED_REFS
  #define CYTHON_AVOID_BORROWED_REFS 1
  #undef CYTHON_ASSUME_SAFE_MACROS
  #define CYTHON_ASSUME_SAFE_MACROS 0
  #undef CYTHON_UNPACK_METHODS
  #define CYTHON_UNPACK_METHODS 0
  #undef CYTHON_FAST_THREAD_STATE
  #define CYTHON_FAST_THREAD_STATE 0
  #undef CYTHON_FAST_PYCALL
  #define CYTHON_FAST_PYCALL 0
#elif defined(PYSTON_VERSION)
  #define CYTHON_COMPILING_IN_PYPY 0
  #define CYTHON_COMPILING_IN_PYSTON 1
  #define CYTHON_COMPILING_IN_CPYTHON 0
  #ifndef CYTHON_USE_TYPE_SLOTS
    #define CYTHON_USE_TYPE_SLOTS 1
  #endif
  #undef CYTHON_USE_ASYNC_SLOTS
  #define CYTHON_USE_ASYNC_SLOTS 0
  #undef CYTHON_USE_PYLIST_INTERNALS
  #define CYTHON_USE_PYLIST_INTERNALS 0
  #ifndef CYTHON_USE_UNICODE_INTERNALS
    #define CYTHON_USE_UNICODE_INTERNALS 1
  #endif
  #undef CYTHON_USE_UNICODE_WRITER
  #define CYTHON_USE_UNICODE_WRITER 0
  #undef CYTHON_USE_PYLONG_INTERNALS
  #define CYTHON_USE_PYLONG_INTERNALS 0
  #ifndef CYTHON_AVOID_BORROWED_REFS
    #define CYTHON_AVOID_BORROWED_REFS 0
  #endif
  #ifndef CYTHON_ASSUME_SAFE_MACROS
    #define CYTHON_ASSUME_SAFE_MACROS 1
  #endif
  #ifndef CYTHON_UNPACK_METHODS
    #define CYTHON_UNPACK_METHODS 1
  #endif
  #undef CYTHON_FAST_THREAD_STATE
  #define CYTHON_FAST_THREAD_STATE 0
  #undef CYTHON_FAST_PYCALL
  #define CYTHON_FAST_PYCALL 0
#else
  #define CYTHON_COMPILING_IN_PYPY 0
  #define CYTHON_COMPILING_IN_PYSTON 0
  #define CYTHON_COMPILING_IN_CPYTHON 1
  #ifndef CYTHON_USE_TYPE_SLOTS
    #define CYTHON_USE_TYPE_SLOTS 1
  #endif
  #if PY_MAJOR_VERSION < 3
    #undef CYTHON_USE_ASYNC_SLOTS
    #define CYTHON_USE_ASYNC_SLOTS 0
  #elif !defined(CYTHON_USE_ASYNC_SLOTS)
    #define CYTHON_USE_ASYNC_SLOTS 1
  #endif
  #if PY_VERSION_HEX < 0x02070000
    #undef CYTHON_USE_PYLONG_INTERNALS
    #define CYTHON_USE_PYLONG_INTERNALS 0
  #elif !defined(CYTHON_USE_PYLONG_INTERNALS)
    #define CYTHON_USE_PYLONG_INTERNALS 1
  #endif
  #ifndef CYTHON_USE_PYLIST_INTERNALS
    #define CYTHON_USE_PYLIST_INTERNALS 1
  #endif
  #ifndef CYTHON_USE_UNICODE_INTERNALS
    #define CYTHON_USE_UNICODE_INTERNALS 1
  #endif
  #if PY_VERSION_HEX < 0x030300F0
    #undef CYTHON_USE_UNICODE_WRITER
    #define CYTHON_USE_UNICODE_WRITER 0
  #elif !defined(CYTHON_USE_UNICODE_WRITER)
    #define CYTHON_USE_UNICODE_WRITER 1
  #endif
  #ifndef CYTHON_AVOID_BORROWED_REFS
    #define CYTHON_AVOID_BORROWED_REFS 0
  #endif
  #ifndef CYTHON_ASSUME_SAFE_MACROS
    #define CYTHON_ASSUME_SAFE_MACROS 1
  #endif
  #ifndef CYTHON_UNPACK_METHODS
    #define CYTHON_UNPACK_METHODS 1
  #endif
  #ifndef CYTHON_FAST_THREAD_STATE
    #define CYTHON_FAST_THREAD_STATE 1
  #endif
  #ifndef CYTHON_FAST_PYCALL
    #define CYTHON_FAST_PYCALL 1
  #endif
#endif
#if !defined(CYTHON_FAST_PYCCALL)
#define CYTHON_FAST_PYCCALL  (CYTHON_FAST_PYCALL && PY_VERSION_HEX >= 0x030600B1)
#endif
#if CYTHON_USE_PYLONG_INTERNALS
  #include "longintrepr.h"
  #undef SHIFT
  #undef BASE
  #undef MASK
#endif
#if CYTHON_COMPILING_IN_PYPY && PY_VERSION_HEX < 0x02070600 && !defined(Py_OptimizeFlag)
  #define Py_OptimizeFlag 0
#endif
#define __PYX_BUILD_PY_SSIZE_T "n"
#define CYTHON_FORMAT_SSIZE_T "z"
#if PY_MAJOR_VERSION < 3
  #define __Pyx_BUILTIN_MODULE_NAME "__builtin__"
  #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)\
          PyCode_New(a+k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
  #define __Pyx_DefaultClassType PyClass_Type
#else
  #define __Pyx_BUILTIN_MODULE_NAME "builtins"
  #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)\
          PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
  #define __Pyx_DefaultClassType PyType_Type
#endif
#ifndef Py_TPFLAGS_CHECKTYPES
  #define Py_TPFLAGS_CHECKTYPES 0
#endif
#ifndef Py_TPFLAGS_HAVE_INDEX
  #define Py_TPFLAGS_HAVE_INDEX 0
#endif
#ifndef Py_TPFLAGS_HAVE_NEWBUFFER
  #define Py_TPFLAGS_HAVE_NEWBUFFER 0
#endif
#ifndef Py_TPFLAGS_HAVE_FINALIZE
  #define Py_TPFLAGS_HAVE_FINALIZE 0
#endif
#ifndef METH_FASTCALL
  #define METH_FASTCALL 0x80
  typedef PyObject *(*__Pyx_PyCFunctionFast) (PyObject *self, PyObject **args,
                                              Py_ssize_t nargs, PyObject *kwnames);
#else
  #define __Pyx_PyCFunctionFast _PyCFunctionFast
#endif
#if CYTHON_FAST_PYCCALL
#define __Pyx_PyFastCFunction_Check(func)\
    ((PyCFunction_Check(func) && (METH_FASTCALL == (PyCFunction_GET_FLAGS(func) & ~(METH_CLASS | METH_STATIC | METH_COEXIST)))))
#else
#define __Pyx_PyFastCFunction_Check(func) 0
#endif
#if PY_VERSION_HEX > 0x03030000 && defined(PyUnicode_KIND)
  #define CYTHON_PEP393_ENABLED 1
  #define __Pyx_PyUnicode_READY(op)       (likely(PyUnicode_IS_READY(op)) ?\
                                              0 : _PyUnicode_Ready((PyObject *)(op)))
  #define __Pyx_PyUnicode_GET_LENGTH(u)   PyUnicode_GET_LENGTH(u)
  #define __Pyx_PyUnicode_READ_CHAR(u, i) PyUnicode_READ_CHAR(u, i)
  #define __Pyx_PyUnicode_MAX_CHAR_VALUE(u)   PyUnicode_MAX_CHAR_VALUE(u)
  #define __Pyx_PyUnicode_KIND(u)         PyUnicode_KIND(u)
  #define __Pyx_PyUnicode_DATA(u)         PyUnicode_DATA(u)
  #define __Pyx_PyUnicode_READ(k, d, i)   PyUnicode_READ(k, d, i)
  #define __Pyx_PyUnicode_WRITE(k, d, i, ch)  PyUnicode_WRITE(k, d, i, ch)
  #define __Pyx_PyUnicode_IS_TRUE(u)      (0 != (likely(PyUnicode_IS_READY(u)) ? PyUnicode_GET_LENGTH(u) : PyUnicode_GET_SIZE(u)))
#else
  #define CYTHON_PEP393_ENABLED 0
  #define PyUnicode_1BYTE_KIND  1
  #define PyUnicode_2BYTE_KIND  2
  #define PyUnicode_4BYTE_KIND  4
  #define __Pyx_PyUnicode_READY(op)       (0)
  #define __Pyx_PyUnicode_GET_LENGTH(u)   PyUnicode_GET_SIZE(u)
  #define __Pyx_PyUnicode_READ_CHAR(u, i) ((Py_UCS4)(PyUnicode_AS_UNICODE(u)[i]))
  #define __Pyx_PyUnicode_MAX_CHAR_VALUE(u)   ((sizeof(Py_UNICODE) == 2) ? 65535 : 1114111)
  #define __Pyx_PyUnicode_KIND(u)         (sizeof(Py_UNICODE))
  #define __Pyx_PyUnicode_DATA(u)         ((void*)PyUnicode_AS_UNICODE(u))
  #define __Pyx_PyUnicode_READ(k, d, i)   ((void)(k), (Py_UCS4)(((Py_UNICODE*)d)[i]))
  #define __Pyx_PyUnicode_WRITE(k, d, i, ch)  (((void)(k)), ((Py_UNICODE*)d)[i] = ch)
  #define __Pyx_PyUnicode_IS_TRUE(u)      (0 != PyUnicode_GET_SIZE(u))
#endif
#if CYTHON_COMPILING_IN_PYPY
  #define __Pyx_PyUnicode_Concat(a, b)      PyNumber_Add(a, b)
  #define __Pyx_PyUnicode_ConcatSafe(a, b)  PyNumber_Add(a, b)
#else
  #define __Pyx_PyUnicode_Concat(a, b)      PyUnicode_Concat(a, b)
  #define __Pyx_PyUnicode_ConcatSafe(a, b)  ((unlikely((a) == Py_None) || unlikely((b) == Py_None)) ?\
      PyNumber_Add(a, b) : __Pyx_PyUnicode_Concat(a, b))
#endif
#if CYTHON_COMPILING_IN_PYPY && !defined(PyUnicode_Contains)
  #define PyUnicode_Contains(u, s)  PySequence_Contains(u, s)
#endif
#if CYTHON_COMPILING_IN_PYPY && !defined(PyByteArray_Check)
  #define PyByteArray_Check(obj)  PyObject_TypeCheck(obj, &PyByteArray_Type)
#endif
#if CYTHON_COMPILING_IN_PYPY && !defined(PyObject_Format)
  #define PyObject_Format(obj, fmt)  PyObject_CallMethod(obj, "__format__", "O", fmt)
#endif
#if CYTHON_COMPILING_IN_PYPY && !defined(PyObject_Malloc)
  #define PyObject_Malloc(s)   PyMem_Malloc(s)
  #define PyObject_Free(p)     PyMem_Free(p)
  #define PyObject_Realloc(p)  PyMem_Realloc(p)
#endif
#if CYTHON_COMPILING_IN_PYSTON
  #define __Pyx_PyCode_HasFreeVars(co)  PyCode_HasFreeVars(co)
  #define __Pyx_PyFrame_SetLineNumber(frame, lineno) PyFrame_SetLineNumber(frame, lineno)
#else
  #define __Pyx_PyCode_HasFreeVars(co)  (PyCode_GetNumFree(co) > 0)
  #define __Pyx_PyFrame_SetLineNumber(frame, lineno)  (frame)->f_lineno = (lineno)
#endif
#define __Pyx_PyString_FormatSafe(a, b)   ((unlikely((a) == Py_None)) ? PyNumber_Remainder(a, b) : __Pyx_PyString_Format(a, b))
#define __Pyx_PyUnicode_FormatSafe(a, b)  ((unlikely((a) == Py_None)) ? PyNumber_Remainder(a, b) : PyUnicode_Format(a, b))
#if PY_MAJOR_VERSION >= 3
  #define __Pyx_PyString_Format(a, b)  PyUnicode_Format(a, b)
#else
  #define __Pyx_PyString_Format(a, b)  PyString_Format(a, b)
#endif
#if PY_MAJOR_VERSION < 3 && !defined(PyObject_ASCII)
  #define PyObject_ASCII(o)            PyObject_Repr(o)
#endif
#if PY_MAJOR_VERSION >= 3
  #define PyBaseString_Type            PyUnicode_Type
  #define PyStringObject               PyUnicodeObject
  #define PyString_Type                PyUnicode_Type
  #define PyString_Check               PyUnicode_Check
  #define PyString_CheckExact          PyUnicode_CheckExact
#endif
#if PY_MAJOR_VERSION >= 3
  #define __Pyx_PyBaseString_Check(obj) PyUnicode_Check(obj)
  #define __Pyx_PyBaseString_CheckExact(obj) PyUnicode_CheckExact(obj)
#else
  #define __Pyx_PyBaseString_Check(obj) (PyString_Check(obj) || PyUnicode_Check(obj))
  #define __Pyx_PyBaseString_CheckExact(obj) (PyString_CheckExact(obj) || PyUnicode_CheckExact(obj))
#endif
#ifndef PySet_CheckExact
  #define PySet_CheckExact(obj)        (Py_TYPE(obj) == &PySet_Type)
#endif
#define __Pyx_TypeCheck(obj, type) PyObject_TypeCheck(obj, (PyTypeObject *)type)
#define __Pyx_PyException_Check(obj) __Pyx_TypeCheck(obj, PyExc_Exception)
#if PY_MAJOR_VERSION >= 3
  #define PyIntObject                  PyLongObject
  #define PyInt_Type                   PyLong_Type
  #define PyInt_Check(op)              PyLong_Check(op)
  #define PyInt_CheckExact(op)         PyLong_CheckExact(op)
  #define PyInt_FromString             PyLong_FromString
  #define PyInt_FromUnicode            PyLong_FromUnicode
  #define PyInt_FromLong               PyLong_FromLong
  #define PyInt_FromSize_t             PyLong_FromSize_t
  #define PyInt_FromSsize_t            PyLong_FromSsize_t
  #define PyInt_AsLong                 PyLong_AsLong
  #define PyInt_AS_LONG                PyLong_AS_LONG
  #define PyInt_AsSsize_t              PyLong_AsSsize_t
  #define PyInt_AsUnsignedLongMask     PyLong_AsUnsignedLongMask
  #define PyInt_AsUnsignedLongLongMask PyLong_AsUnsignedLongLongMask
  #define PyNumber_Int                 PyNumber_Long
#endif
#if PY_MAJOR_VERSION >= 3
  #define PyBoolObject                 PyLongObject
#endif
#if PY_MAJOR_VERSION >= 3 && CYTHON_COMPILING_IN_PYPY
  #ifndef PyUnicode_InternFromString
    #define PyUnicode_InternFromString(s) PyUnicode_FromString(s)
  #endif
#endif
#if PY_VERSION_HEX < 0x030200A4
  typedef long Py_hash_t;
  #define __Pyx_PyInt_FromHash_t PyInt_FromLong
  #define __Pyx_PyInt_AsHash_t   PyInt_AsLong
#else
  #define __Pyx_PyInt_FromHash_t PyInt_FromSsize_t
  #define __Pyx_PyInt_AsHash_t   PyInt_AsSsize_t
#endif
#if PY_MAJOR_VERSION >= 3
  #define __Pyx_PyMethod_New(func, self, klass) ((self) ? PyMethod_New(func, self) : PyInstanceMethod_New(func))
#else
  #define __Pyx_PyMethod_New(func, self, klass) PyMethod_New(func, self, klass)
#endif
#if CYTHON_USE_ASYNC_SLOTS
  #if PY_VERSION_HEX >= 0x030500B1
    #define __Pyx_PyAsyncMethodsStruct PyAsyncMethods
    #define __Pyx_PyType_AsAsync(obj) (Py_TYPE(obj)->tp_as_async)
  #else
    typedef struct {
        unaryfunc am_await;
        unaryfunc am_aiter;
        unaryfunc am_anext;
    } __Pyx_PyAsyncMethodsStruct;
    #define __Pyx_PyType_AsAsync(obj) ((__Pyx_PyAsyncMethodsStruct*) (Py_TYPE(obj)->tp_reserved))
  #endif
#else
  #define __Pyx_PyType_AsAsync(obj) NULL
#endif
#ifndef CYTHON_RESTRICT
  #if defined(__GNUC__)
    #define CYTHON_RESTRICT __restrict__
  #elif defined(_MSC_VER) && _MSC_VER >= 1400
    #define CYTHON_RESTRICT __restrict
  #elif defined (__STDC_VERSION__) && __STDC_VERSION__ >= 199901L
    #define CYTHON_RESTRICT restrict
  #else
    #define CYTHON_RESTRICT
  #endif
#endif
#ifndef CYTHON_UNUSED
# if defined(__GNUC__)
#   if !(defined(__cplusplus)) || (__GNUC__ > 3 || (__GNUC__ == 3 && __GNUC_MINOR__ >= 4))
#     define CYTHON_UNUSED __attribute__ ((__unused__))
#   else
#     define CYTHON_UNUSED
#   endif
# elif defined(__ICC) || (defined(__INTEL_COMPILER) && !defined(_MSC_VER))
#   define CYTHON_UNUSED __attribute__ ((__unused__))
# else
#   define CYTHON_UNUSED
# endif
#endif
#ifndef CYTHON_MAYBE_UNUSED_VAR
#  if defined(__cplusplus)
     template<class T> void CYTHON_MAYBE_UNUSED_VAR( const T& ) { }
#  else
#    define CYTHON_MAYBE_UNUSED_VAR(x) (void)(x)
#  endif
#endif
#ifndef CYTHON_NCP_UNUSED
# if CYTHON_COMPILING_IN_CPYTHON
#  define CYTHON_NCP_UNUSED
# else
#  define CYTHON_NCP_UNUSED CYTHON_UNUSED
# endif
#endif
#define __Pyx_void_to_None(void_result) ((void)(void_result), Py_INCREF(Py_None), Py_None)

#ifndef __cplusplus
  #error "Cython files generated with the C++ option must be compiled with a C++ compiler."
#endif
#ifndef CYTHON_INLINE
  #if defined(__clang__)
    #define CYTHON_INLINE __inline__ __attribute__ ((__unused__))
  #else
    #define CYTHON_INLINE inline
  #endif
#endif
template<typename T>
void __Pyx_call_destructor(T& x) {
    x.~T();
}
template<typename T>
class __Pyx_FakeReference {
  public:
    __Pyx_FakeReference() : ptr(NULL) { }
    __Pyx_FakeReference(const T& ref) : ptr(const_cast<T*>(&ref)) { }
    T *operator->() { return ptr; }
    T *operator&() { return ptr; }
    operator T&() { return *ptr; }
    template<typename U> bool operator ==(U other) { return *ptr == other; }
    template<typename U> bool operator !=(U other) { return *ptr != other; }
  private:
    T *ptr;
};

#if defined(WIN32) || defined(MS_WINDOWS)
  #define _USE_MATH_DEFINES
#endif
#include <math.h>
#ifdef NAN
#define __PYX_NAN() ((float) NAN)
#else
static CYTHON_INLINE float __PYX_NAN() {
  float value;
  memset(&value, 0xFF, sizeof(value));
  return value;
}
#endif
#if defined(__CYGWIN__) && defined(_LDBL_EQ_DBL)
#define __Pyx_truncl trunc
#else
#define __Pyx_truncl truncl
#endif


#define __PYX_ERR(f_index, lineno, Ln_error) \
{ \
  __pyx_filename = __pyx_f[f_index]; __pyx_lineno = lineno; __pyx_clineno = __LINE__; goto Ln_error; \
}

#if PY_MAJOR_VERSION >= 3
  #define __Pyx_PyNumber_Divide(x,y)         PyNumber_TrueDivide(x,y)
  #define __Pyx_PyNumber_InPlaceDivide(x,y)  PyNumber_InPlaceTrueDivide(x,y)
#else
  #define __Pyx_PyNumber_Divide(x,y)         PyNumber_TrueDivide(x,y)
  #define __Pyx_PyNumber_InPlaceDivide(x,y)  PyNumber_InPlaceTrueDivide(x,y)
#endif

#ifndef __PYX_EXTERN_C
  #ifdef __cplusplus
    #define __PYX_EXTERN_C extern "C"
  #else
    #define __PYX_EXTERN_C extern
  #endif
#endif

#define __PYX_HAVE__PyTorch
#define __PYX_HAVE_API__PyTorch
#include "THRandom.h"
#include "nnWrapper.h"
#include "THTensor.h"
#include "LuaHelper.h"
#include <string.h>
#include <stdio.h>
#include "THStorage.h"
#include "lua_externc.h"
#include "pythread.h"
#include <stdlib.h>
#include "pystate.h"
#ifdef _OPENMP
#include <omp.h>
#endif /* _OPENMP */

#ifdef PYREX_WITHOUT_ASSERTIONS
#define CYTHON_WITHOUT_ASSERTIONS
#endif

typedef struct {PyObject **p; const char *s; const Py_ssize_t n; const char* encoding;
                const char is_unicode; const char is_str; const char intern; } __Pyx_StringTabEntry;

#define __PYX_DEFAULT_STRING_ENCODING_IS_ASCII 0
#define __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT 0
#define __PYX_DEFAULT_STRING_ENCODING ""
#define __Pyx_PyObject_FromString __Pyx_PyBytes_FromString
#define __Pyx_PyObject_FromStringAndSize __Pyx_PyBytes_FromStringAndSize
#define __Pyx_uchar_cast(c) ((unsigned char)c)
#define __Pyx_long_cast(x) ((long)x)
#define __Pyx_fits_Py_ssize_t(v, type, is_signed)  (\
    (sizeof(type) < sizeof(Py_ssize_t))  ||\
    (sizeof(type) > sizeof(Py_ssize_t) &&\
          likely(v < (type)PY_SSIZE_T_MAX ||\
                 v == (type)PY_SSIZE_T_MAX)  &&\
          (!is_signed || likely(v > (type)PY_SSIZE_T_MIN ||\
                                v == (type)PY_SSIZE_T_MIN)))  ||\
    (sizeof(type) == sizeof(Py_ssize_t) &&\
          (is_signed || likely(v < (type)PY_SSIZE_T_MAX ||\
                               v == (type)PY_SSIZE_T_MAX)))  )
#if defined (__cplusplus) && __cplusplus >= 201103L
    #include <cstdlib>
    #define __Pyx_sst_abs(value) std::abs(value)
#elif SIZEOF_INT >= SIZEOF_SIZE_T
    #define __Pyx_sst_abs(value) abs(value)
#elif SIZEOF_LONG >= SIZEOF_SIZE_T
    #define __Pyx_sst_abs(value) labs(value)
#elif defined (_MSC_VER) && defined (_M_X64)
    #define __Pyx_sst_abs(value) _abs64(value)
#elif defined (__STDC_VERSION__) && __STDC_VERSION__ >= 199901L
    #define __Pyx_sst_abs(value) llabs(value)
#elif defined (__GNUC__)
    #define __Pyx_sst_abs(value) __builtin_llabs(value)
#else
    #define __Pyx_sst_abs(value) ((value<0) ? -value : value)
#endif
static CYTHON_INLINE char* __Pyx_PyObject_AsString(PyObject*);
static CYTHON_INLINE char* __Pyx_PyObject_AsStringAndSize(PyObject*, Py_ssize_t* length);
#define __Pyx_PyByteArray_FromString(s) PyByteArray_FromStringAndSize((const char*)s, strlen((const char*)s))
#define __Pyx_PyByteArray_FromStringAndSize(s, l) PyByteArray_FromStringAndSize((const char*)s, l)
#define __Pyx_PyBytes_FromString        PyBytes_FromString
#define __Pyx_PyBytes_FromStringAndSize PyBytes_FromStringAndSize
static CYTHON_INLINE PyObject* __Pyx_PyUnicode_FromString(const char*);
#if PY_MAJOR_VERSION < 3
    #define __Pyx_PyStr_FromString        __Pyx_PyBytes_FromString
    #define __Pyx_PyStr_FromStringAndSize __Pyx_PyBytes_FromStringAndSize
#else
    #define __Pyx_PyStr_FromString        __Pyx_PyUnicode_FromString
    #define __Pyx_PyStr_FromStringAndSize __Pyx_PyUnicode_FromStringAndSize
#endif
#define __Pyx_PyObject_AsSString(s)    ((signed char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsUString(s)    ((unsigned char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_FromCString(s)  __Pyx_PyObject_FromString((const char*)s)
#define __Pyx_PyBytes_FromCString(s)   __Pyx_PyBytes_FromString((const char*)s)
#define __Pyx_PyByteArray_FromCString(s)   __Pyx_PyByteArray_FromString((const char*)s)
#define __Pyx_PyStr_FromCString(s)     __Pyx_PyStr_FromString((const char*)s)
#define __Pyx_PyUnicode_FromCString(s) __Pyx_PyUnicode_FromString((const char*)s)
#if PY_MAJOR_VERSION < 3
static CYTHON_INLINE size_t __Pyx_Py_UNICODE_strlen(const Py_UNICODE *u)
{
    const Py_UNICODE *u_end = u;
    while (*u_end++) ;
    return (size_t)(u_end - u - 1);
}
#else
#define __Pyx_Py_UNICODE_strlen Py_UNICODE_strlen
#endif
#define __Pyx_PyUnicode_FromUnicode(u)       PyUnicode_FromUnicode(u, __Pyx_Py_UNICODE_strlen(u))
#define __Pyx_PyUnicode_FromUnicodeAndLength PyUnicode_FromUnicode
#define __Pyx_PyUnicode_AsUnicode            PyUnicode_AsUnicode
#define __Pyx_NewRef(obj) (Py_INCREF(obj), obj)
#define __Pyx_Owned_Py_None(b) __Pyx_NewRef(Py_None)
#define __Pyx_PyBool_FromLong(b) ((b) ? __Pyx_NewRef(Py_True) : __Pyx_NewRef(Py_False))
static CYTHON_INLINE int __Pyx_PyObject_IsTrue(PyObject*);
static CYTHON_INLINE PyObject* __Pyx_PyNumber_IntOrLong(PyObject* x);
static CYTHON_INLINE Py_ssize_t __Pyx_PyIndex_AsSsize_t(PyObject*);
static CYTHON_INLINE PyObject * __Pyx_PyInt_FromSize_t(size_t);
#if CYTHON_ASSUME_SAFE_MACROS
#define __pyx_PyFloat_AsDouble(x) (PyFloat_CheckExact(x) ? PyFloat_AS_DOUBLE(x) : PyFloat_AsDouble(x))
#else
#define __pyx_PyFloat_AsDouble(x) PyFloat_AsDouble(x)
#endif
#define __pyx_PyFloat_AsFloat(x) ((float) __pyx_PyFloat_AsDouble(x))
#if PY_MAJOR_VERSION >= 3
#define __Pyx_PyNumber_Int(x) (PyLong_CheckExact(x) ? __Pyx_NewRef(x) : PyNumber_Long(x))
#else
#define __Pyx_PyNumber_Int(x) (PyInt_CheckExact(x) ? __Pyx_NewRef(x) : PyNumber_Int(x))
#endif
#define __Pyx_PyNumber_Float(x) (PyFloat_CheckExact(x) ? __Pyx_NewRef(x) : PyNumber_Float(x))
#if PY_MAJOR_VERSION < 3 && __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
static int __Pyx_sys_getdefaultencoding_not_ascii;
static int __Pyx_init_sys_getdefaultencoding_params(void) {
    PyObject* sys;
    PyObject* default_encoding = NULL;
    PyObject* ascii_chars_u = NULL;
    PyObject* ascii_chars_b = NULL;
    const char* default_encoding_c;
    sys = PyImport_ImportModule("sys");
    if (!sys) goto bad;
    default_encoding = PyObject_CallMethod(sys, (char*) "getdefaultencoding", NULL);
    Py_DECREF(sys);
    if (!default_encoding) goto bad;
    default_encoding_c = PyBytes_AsString(default_encoding);
    if (!default_encoding_c) goto bad;
    if (strcmp(default_encoding_c, "ascii") == 0) {
        __Pyx_sys_getdefaultencoding_not_ascii = 0;
    } else {
        char ascii_chars[128];
        int c;
        for (c = 0; c < 128; c++) {
            ascii_chars[c] = c;
        }
        __Pyx_sys_getdefaultencoding_not_ascii = 1;
        ascii_chars_u = PyUnicode_DecodeASCII(ascii_chars, 128, NULL);
        if (!ascii_chars_u) goto bad;
        ascii_chars_b = PyUnicode_AsEncodedString(ascii_chars_u, default_encoding_c, NULL);
        if (!ascii_chars_b || !PyBytes_Check(ascii_chars_b) || memcmp(ascii_chars, PyBytes_AS_STRING(ascii_chars_b), 128) != 0) {
            PyErr_Format(
                PyExc_ValueError,
                "This module compiled with c_string_encoding=ascii, but default encoding '%.200s' is not a superset of ascii.",
                default_encoding_c);
            goto bad;
        }
        Py_DECREF(ascii_chars_u);
        Py_DECREF(ascii_chars_b);
    }
    Py_DECREF(default_encoding);
    return 0;
bad:
    Py_XDECREF(default_encoding);
    Py_XDECREF(ascii_chars_u);
    Py_XDECREF(ascii_chars_b);
    return -1;
}
#endif
#if __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT && PY_MAJOR_VERSION >= 3
#define __Pyx_PyUnicode_FromStringAndSize(c_str, size) PyUnicode_DecodeUTF8(c_str, size, NULL)
#else
#define __Pyx_PyUnicode_FromStringAndSize(c_str, size) PyUnicode_Decode(c_str, size, __PYX_DEFAULT_STRING_ENCODING, NULL)
#if __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT
static char* __PYX_DEFAULT_STRING_ENCODING;
static int __Pyx_init_sys_getdefaultencoding_params(void) {
    PyObject* sys;
    PyObject* default_encoding = NULL;
    char* default_encoding_c;
    sys = PyImport_ImportModule("sys");
    if (!sys) goto bad;
    default_encoding = PyObject_CallMethod(sys, (char*) (const char*) "getdefaultencoding", NULL);
    Py_DECREF(sys);
    if (!default_encoding) goto bad;
    default_encoding_c = PyBytes_AsString(default_encoding);
    if (!default_encoding_c) goto bad;
    __PYX_DEFAULT_STRING_ENCODING = (char*) malloc(strlen(default_encoding_c));
    if (!__PYX_DEFAULT_STRING_ENCODING) goto bad;
    strcpy(__PYX_DEFAULT_STRING_ENCODING, default_encoding_c);
    Py_DECREF(default_encoding);
    return 0;
bad:
    Py_XDECREF(default_encoding);
    return -1;
}
#endif
#endif


/* Test for GCC > 2.95 */
#if defined(__GNUC__)     && (__GNUC__ > 2 || (__GNUC__ == 2 && (__GNUC_MINOR__ > 95)))
  #define likely(x)   __builtin_expect(!!(x), 1)
  #define unlikely(x) __builtin_expect(!!(x), 0)
#else /* !__GNUC__ or GCC < 2.95 */
  #define likely(x)   (x)
  #define unlikely(x) (x)
#endif /* __GNUC__ */

static PyObject *__pyx_m;
static PyObject *__pyx_d;
static PyObject *__pyx_b;
static PyObject *__pyx_empty_tuple;
static PyObject *__pyx_empty_bytes;
static PyObject *__pyx_empty_unicode;
static int __pyx_lineno;
static int __pyx_clineno = 0;
static const char * __pyx_cfilenm= __FILE__;
static const char *__pyx_filename;


static const char *__pyx_f[] = {
  "src/PyTorch.pyx",
  "array.pxd",
  "stringsource",
  "type.pxd",
  "src/Storage.pxd",
  "src/lua.pxd",
};
/* MemviewSliceStruct.proto */
struct __pyx_memoryview_obj;
typedef struct {
  struct __pyx_memoryview_obj *memview;
  char *data;
  Py_ssize_t shape[8];
  Py_ssize_t strides[8];
  Py_ssize_t suboffsets[8];
} __Pyx_memviewslice;

/* BufferFormatStructs.proto */
#define IS_UNSIGNED(type) (((type) -1) > 0)
struct __Pyx_StructField_;
#define __PYX_BUF_FLAGS_PACKED_STRUCT (1 << 0)
typedef struct {
  const char* name;
  struct __Pyx_StructField_* fields;
  size_t size;
  size_t arraysize[8];
  int ndim;
  char typegroup;
  char is_unsigned;
  int flags;
} __Pyx_TypeInfo;
typedef struct __Pyx_StructField_ {
  __Pyx_TypeInfo* type;
  const char* name;
  size_t offset;
} __Pyx_StructField;
typedef struct {
  __Pyx_StructField* field;
  size_t parent_offset;
} __Pyx_BufFmt_StackElem;
typedef struct {
  __Pyx_StructField root;
  __Pyx_BufFmt_StackElem* head;
  size_t fmt_offset;
  size_t new_count, enc_count;
  size_t struct_alignment;
  int is_complex;
  char enc_type;
  char new_packmode;
  char enc_packmode;
  char is_valid_array;
} __Pyx_BufFmt_Context;

/* Atomics.proto */
#include <pythread.h>
#ifndef CYTHON_ATOMICS
    #define CYTHON_ATOMICS 1
#endif
#define __pyx_atomic_int_type int
#if CYTHON_ATOMICS && __GNUC__ >= 4 && (__GNUC_MINOR__ > 1 ||\
                    (__GNUC_MINOR__ == 1 && __GNUC_PATCHLEVEL >= 2)) &&\
                    !defined(__i386__)
    #define __pyx_atomic_incr_aligned(value, lock) __sync_fetch_and_add(value, 1)
    #define __pyx_atomic_decr_aligned(value, lock) __sync_fetch_and_sub(value, 1)
    #ifdef __PYX_DEBUG_ATOMICS
        #warning "Using GNU atomics"
    #endif
#elif CYTHON_ATOMICS && defined(_MSC_VER) && 0
    #include <Windows.h>
    #undef __pyx_atomic_int_type
    #define __pyx_atomic_int_type LONG
    #define __pyx_atomic_incr_aligned(value, lock) InterlockedIncrement(value)
    #define __pyx_atomic_decr_aligned(value, lock) InterlockedDecrement(value)
    #ifdef __PYX_DEBUG_ATOMICS
        #pragma message ("Using MSVC atomics")
    #endif
#elif CYTHON_ATOMICS && (defined(__ICC) || defined(__INTEL_COMPILER)) && 0
    #define __pyx_atomic_incr_aligned(value, lock) _InterlockedIncrement(value)
    #define __pyx_atomic_decr_aligned(value, lock) _InterlockedDecrement(value)
    #ifdef __PYX_DEBUG_ATOMICS
        #warning "Using Intel atomics"
    #endif
#else
    #undef CYTHON_ATOMICS
    #define CYTHON_ATOMICS 0
    #ifdef __PYX_DEBUG_ATOMICS
        #warning "Not using atomics"
    #endif
#endif
typedef volatile __pyx_atomic_int_type __pyx_atomic_int;
#if CYTHON_ATOMICS
    #define __pyx_add_acquisition_count(memview)\
             __pyx_atomic_incr_aligned(__pyx_get_slice_count_pointer(memview), memview->lock)
    #define __pyx_sub_acquisition_count(memview)\
            __pyx_atomic_decr_aligned(__pyx_get_slice_count_pointer(memview), memview->lock)
#else
    #define __pyx_add_acquisition_count(memview)\
            __pyx_add_acquisition_count_locked(__pyx_get_slice_count_pointer(memview), memview->lock)
    #define __pyx_sub_acquisition_count(memview)\
            __pyx_sub_acquisition_count_locked(__pyx_get_slice_count_pointer(memview), memview->lock)
#endif


/*--- Type declarations ---*/
#ifndef _ARRAYARRAY_H
struct arrayobject;
typedef struct arrayobject arrayobject;
#endif
struct __pyx_obj_7Storage__LongStorage;
struct __pyx_obj_7Storage__FloatStorage;
struct __pyx_obj_7Storage__DoubleStorage;
struct __pyx_obj_7Storage__ByteStorage;
struct __pyx_obj_3lua_LuaState;
struct __pyx_obj_7PyTorch__LongTensor;
struct __pyx_obj_7PyTorch__FloatTensor;
struct __pyx_obj_7PyTorch__DoubleTensor;
struct __pyx_obj_7PyTorch__ByteTensor;
struct __pyx_obj_7PyTorch_GlobalState;
struct __pyx_obj_7PyTorch_Nn;
struct __pyx_array_obj;
struct __pyx_MemviewEnum_obj;
struct __pyx_memoryview_obj;
struct __pyx_memoryviewslice_obj;
struct __pyx_opt_args_7Storage__LongStorage_fromNative;
struct __pyx_opt_args_7Storage__FloatStorage_fromNative;
struct __pyx_opt_args_7Storage__DoubleStorage_fromNative;
struct __pyx_opt_args_7Storage__ByteStorage_fromNative;

/* "Storage.pxd":95
 *     cpdef long size(self)
 * 
 * cdef _LongStorage_fromNative(THLongStorage *storageC, retain=*)             # <<<<<<<<<<<<<<
 * 
 * 
 */
struct __pyx_opt_args_7Storage__LongStorage_fromNative {
  int __pyx_n;
  PyObject *retain;
};

/* "Storage.pxd":103
 *     cpdef long size(self)
 * 
 * cdef _FloatStorage_fromNative(THFloatStorage *storageC, retain=*)             # <<<<<<<<<<<<<<
 * 
 * 
 */
struct __pyx_opt_args_7Storage__FloatStorage_fromNative {
  int __pyx_n;
  PyObject *retain;
};

/* "Storage.pxd":111
 *     cpdef long size(self)
 * 
 * cdef _DoubleStorage_fromNative(THDoubleStorage *storageC, retain=*)             # <<<<<<<<<<<<<<
 * 
 * 
 */
struct __pyx_opt_args_7Storage__DoubleStorage_fromNative {
  int __pyx_n;
  PyObject *retain;
};

/* "Storage.pxd":119
 *     cpdef long size(self)
 * 
 * cdef _ByteStorage_fromNative(THByteStorage *storageC, retain=*)             # <<<<<<<<<<<<<<
 * 
 */
struct __pyx_opt_args_7Storage__ByteStorage_fromNative {
  int __pyx_n;
  PyObject *retain;
};
struct __pyx_opt_args_7PyTorch__LongTensor_fromNative;
struct __pyx_opt_args_7PyTorch__FloatTensor_fromNative;
struct __pyx_opt_args_7PyTorch__DoubleTensor_fromNative;
struct __pyx_opt_args_7PyTorch__ByteTensor_fromNative;

/* "PyTorch.pyx":839
 * 
 * #    @staticmethod
 * cdef _LongTensor_fromNative(THLongTensor *tensorC, retain=True):             # <<<<<<<<<<<<<<
 *     if retain:
 *         THLongTensor_retain(tensorC)
 */
struct __pyx_opt_args_7PyTorch__LongTensor_fromNative {
  int __pyx_n;
  PyObject *retain;
};

/* "PyTorch.pyx":1382
 * 
 * #    @staticmethod
 * cdef _FloatTensor_fromNative(THFloatTensor *tensorC, retain=True):             # <<<<<<<<<<<<<<
 *     if retain:
 *         THFloatTensor_retain(tensorC)
 */
struct __pyx_opt_args_7PyTorch__FloatTensor_fromNative {
  int __pyx_n;
  PyObject *retain;
};

/* "PyTorch.pyx":1958
 * 
 * #    @staticmethod
 * cdef _DoubleTensor_fromNative(THDoubleTensor *tensorC, retain=True):             # <<<<<<<<<<<<<<
 *     if retain:
 *         THDoubleTensor_retain(tensorC)
 */
struct __pyx_opt_args_7PyTorch__DoubleTensor_fromNative {
  int __pyx_n;
  PyObject *retain;
};

/* "PyTorch.pyx":2458
 * 
 * #    @staticmethod
 * cdef _ByteTensor_fromNative(THByteTensor *tensorC, retain=True):             # <<<<<<<<<<<<<<
 *     if retain:
 *         THByteTensor_retain(tensorC)
 */
struct __pyx_opt_args_7PyTorch__ByteTensor_fromNative {
  int __pyx_n;
  PyObject *retain;
};

/* "Storage.pxd":91
 * 
 * 
 * cdef class _LongStorage(object):             # <<<<<<<<<<<<<<
 *     cdef THLongStorage *native
 *     cpdef long size(self)
 */
struct __pyx_obj_7Storage__LongStorage {
  PyObject_HEAD
  struct __pyx_vtabstruct_7Storage__LongStorage *__pyx_vtab;
  struct THLongStorage *native;
};


/* "Storage.pxd":99
 * 
 * 
 * cdef class _FloatStorage(object):             # <<<<<<<<<<<<<<
 *     cdef THFloatStorage *native
 *     cpdef long size(self)
 */
struct __pyx_obj_7Storage__FloatStorage {
  PyObject_HEAD
  struct __pyx_vtabstruct_7Storage__FloatStorage *__pyx_vtab;
  struct THFloatStorage *native;
};


/* "Storage.pxd":107
 * 
 * 
 * cdef class _DoubleStorage(object):             # <<<<<<<<<<<<<<
 *     cdef THDoubleStorage *native
 *     cpdef long size(self)
 */
struct __pyx_obj_7Storage__DoubleStorage {
  PyObject_HEAD
  struct __pyx_vtabstruct_7Storage__DoubleStorage *__pyx_vtab;
  struct THDoubleStorage *native;
};


/* "Storage.pxd":115
 * 
 * 
 * cdef class _ByteStorage(object):             # <<<<<<<<<<<<<<
 *     cdef THByteStorage *native
 *     cpdef long size(self)
 */
struct __pyx_obj_7Storage__ByteStorage {
  PyObject_HEAD
  struct __pyx_vtabstruct_7Storage__ByteStorage *__pyx_vtab;
  struct THByteStorage *native;
};


/* "lua.pxd":67
 *     int lua_isuserdata(lua_State *L, int index)
 * 
 * cdef class LuaState(object):             # <<<<<<<<<<<<<<
 *     cdef lua_State *L
 * 
 */
struct __pyx_obj_3lua_LuaState {
  PyObject_HEAD
  struct lua_State *L;
};


/* "PyTorch.pxd":20
 *     cdef struct THLongTensor
 * 
 * cdef class _LongTensor(object):             # <<<<<<<<<<<<<<
 *     cdef THLongTensor *native
 *     cdef long *data(self)
 */
struct __pyx_obj_7PyTorch__LongTensor {
  PyObject_HEAD
  struct __pyx_vtabstruct_7PyTorch__LongTensor *__pyx_vtab;
  struct THLongTensor *native;
};


/* "PyTorch.pxd":42
 *     cdef struct THFloatTensor
 * 
 * cdef class _FloatTensor(object):             # <<<<<<<<<<<<<<
 *     cdef THFloatTensor *native
 *     cdef float *data(self)
 */
struct __pyx_obj_7PyTorch__FloatTensor {
  PyObject_HEAD
  struct __pyx_vtabstruct_7PyTorch__FloatTensor *__pyx_vtab;
  struct THFloatTensor *native;
};


/* "PyTorch.pxd":64
 *     cdef struct THDoubleTensor
 * 
 * cdef class _DoubleTensor(object):             # <<<<<<<<<<<<<<
 *     cdef THDoubleTensor *native
 *     cdef double *data(self)
 */
struct __pyx_obj_7PyTorch__DoubleTensor {
  PyObject_HEAD
  struct __pyx_vtabstruct_7PyTorch__DoubleTensor *__pyx_vtab;
  struct THDoubleTensor *native;
};


/* "PyTorch.pxd":86
 *     cdef struct THByteTensor
 * 
 * cdef class _ByteTensor(object):             # <<<<<<<<<<<<<<
 *     cdef THByteTensor *native
 *     cdef unsigned char *data(self)
 */
struct __pyx_obj_7PyTorch__ByteTensor {
  PyObject_HEAD
  struct __pyx_vtabstruct_7PyTorch__ByteTensor *__pyx_vtab;
  struct THByteTensor *native;
};


/* "PyTorch.pxd":103
 * 
 * 
 * cdef class GlobalState:             # <<<<<<<<<<<<<<
 * #    cdef PyTorchState *state
 *     cdef lua_State *L
 */
struct __pyx_obj_7PyTorch_GlobalState {
  PyObject_HEAD
  struct lua_State *L;
  struct THGenerator *generator;
};


/* "PyTorch.pyx":2632
 * 
 * # ==== Nn ==================================
 * cdef class Nn(object):  # just used to provide the `nn.` syntax             # <<<<<<<<<<<<<<
 *     def collectgarbage(self):
 *         collectGarbage(globalState.L)
 */
struct __pyx_obj_7PyTorch_Nn {
  PyObject_HEAD
};


/* "View.MemoryView":103
 * 
 * @cname("__pyx_array")
 * cdef class array:             # <<<<<<<<<<<<<<
 * 
 *     cdef:
 */
struct __pyx_array_obj {
  PyObject_HEAD
  struct __pyx_vtabstruct_array *__pyx_vtab;
  char *data;
  Py_ssize_t len;
  char *format;
  int ndim;
  Py_ssize_t *_shape;
  Py_ssize_t *_strides;
  Py_ssize_t itemsize;
  PyObject *mode;
  PyObject *_format;
  void (*callback_free_data)(void *);
  int free_data;
  int dtype_is_object;
};


/* "View.MemoryView":275
 * 
 * @cname('__pyx_MemviewEnum')
 * cdef class Enum(object):             # <<<<<<<<<<<<<<
 *     cdef object name
 *     def __init__(self, name):
 */
struct __pyx_MemviewEnum_obj {
  PyObject_HEAD
  PyObject *name;
};


/* "View.MemoryView":326
 * 
 * @cname('__pyx_memoryview')
 * cdef class memoryview(object):             # <<<<<<<<<<<<<<
 * 
 *     cdef object obj
 */
struct __pyx_memoryview_obj {
  PyObject_HEAD
  struct __pyx_vtabstruct_memoryview *__pyx_vtab;
  PyObject *obj;
  PyObject *_size;
  PyObject *_array_interface;
  PyThread_type_lock lock;
  __pyx_atomic_int acquisition_count[2];
  __pyx_atomic_int *acquisition_count_aligned_p;
  Py_buffer view;
  int flags;
  int dtype_is_object;
  __Pyx_TypeInfo *typeinfo;
};


/* "View.MemoryView":951
 * 
 * @cname('__pyx_memoryviewslice')
 * cdef class _memoryviewslice(memoryview):             # <<<<<<<<<<<<<<
 *     "Internal class for passing memoryview slices to Python"
 * 
 */
struct __pyx_memoryviewslice_obj {
  struct __pyx_memoryview_obj __pyx_base;
  __Pyx_memviewslice from_slice;
  PyObject *from_object;
  PyObject *(*to_object_func)(char *);
  int (*to_dtype_func)(char *, PyObject *);
};



/* "Storage.pxd":91
 * 
 * 
 * cdef class _LongStorage(object):             # <<<<<<<<<<<<<<
 *     cdef THLongStorage *native
 *     cpdef long size(self)
 */

struct __pyx_vtabstruct_7Storage__LongStorage {
  long (*size)(struct __pyx_obj_7Storage__LongStorage *, int __pyx_skip_dispatch);
};
static struct __pyx_vtabstruct_7Storage__LongStorage *__pyx_vtabptr_7Storage__LongStorage;


/* "Storage.pxd":99
 * 
 * 
 * cdef class _FloatStorage(object):             # <<<<<<<<<<<<<<
 *     cdef THFloatStorage *native
 *     cpdef long size(self)
 */

struct __pyx_vtabstruct_7Storage__FloatStorage {
  long (*size)(struct __pyx_obj_7Storage__FloatStorage *, int __pyx_skip_dispatch);
};
static struct __pyx_vtabstruct_7Storage__FloatStorage *__pyx_vtabptr_7Storage__FloatStorage;


/* "Storage.pxd":107
 * 
 * 
 * cdef class _DoubleStorage(object):             # <<<<<<<<<<<<<<
 *     cdef THDoubleStorage *native
 *     cpdef long size(self)
 */

struct __pyx_vtabstruct_7Storage__DoubleStorage {
  long (*size)(struct __pyx_obj_7Storage__DoubleStorage *, int __pyx_skip_dispatch);
};
static struct __pyx_vtabstruct_7Storage__DoubleStorage *__pyx_vtabptr_7Storage__DoubleStorage;


/* "Storage.pxd":115
 * 
 * 
 * cdef class _ByteStorage(object):             # <<<<<<<<<<<<<<
 *     cdef THByteStorage *native
 *     cpdef long size(self)
 */

struct __pyx_vtabstruct_7Storage__ByteStorage {
  long (*size)(struct __pyx_obj_7Storage__ByteStorage *, int __pyx_skip_dispatch);
};
static struct __pyx_vtabstruct_7Storage__ByteStorage *__pyx_vtabptr_7Storage__ByteStorage;


/* "PyTorch.pyx":374
 * 
 * 
 * cdef class _LongTensor(object):             # <<<<<<<<<<<<<<
 *     # properties are in the PyTorch.pxd file
 * 
 */

struct __pyx_vtabstruct_7PyTorch__LongTensor {
  long *(*data)(struct __pyx_obj_7PyTorch__LongTensor *);
  int (*dims)(struct __pyx_obj_7PyTorch__LongTensor *, int __pyx_skip_dispatch);
  PyObject *(*set1d)(struct __pyx_obj_7PyTorch__LongTensor *, int, long, int __pyx_skip_dispatch);
  PyObject *(*set2d)(struct __pyx_obj_7PyTorch__LongTensor *, int, int, long, int __pyx_skip_dispatch);
  long (*get1d)(struct __pyx_obj_7PyTorch__LongTensor *, int, int __pyx_skip_dispatch);
  long (*get2d)(struct __pyx_obj_7PyTorch__LongTensor *, int, int, int __pyx_skip_dispatch);
  int (*isContiguous)(struct __pyx_obj_7PyTorch__LongTensor *, int __pyx_skip_dispatch);
  long (*max)(struct __pyx_obj_7PyTorch__LongTensor *, int __pyx_skip_dispatch);
  long (*min)(struct __pyx_obj_7PyTorch__LongTensor *, int __pyx_skip_dispatch);
};
static struct __pyx_vtabstruct_7PyTorch__LongTensor *__pyx_vtabptr_7PyTorch__LongTensor;


/* "PyTorch.pyx":851
 * 
 * 
 * cdef class _FloatTensor(object):             # <<<<<<<<<<<<<<
 *     # properties are in the PyTorch.pxd file
 * 
 */

struct __pyx_vtabstruct_7PyTorch__FloatTensor {
  float *(*data)(struct __pyx_obj_7PyTorch__FloatTensor *);
  int (*dims)(struct __pyx_obj_7PyTorch__FloatTensor *, int __pyx_skip_dispatch);
  PyObject *(*set1d)(struct __pyx_obj_7PyTorch__FloatTensor *, int, float, int __pyx_skip_dispatch);
  PyObject *(*set2d)(struct __pyx_obj_7PyTorch__FloatTensor *, int, int, float, int __pyx_skip_dispatch);
  float (*get1d)(struct __pyx_obj_7PyTorch__FloatTensor *, int, int __pyx_skip_dispatch);
  float (*get2d)(struct __pyx_obj_7PyTorch__FloatTensor *, int, int, int __pyx_skip_dispatch);
  int (*isContiguous)(struct __pyx_obj_7PyTorch__FloatTensor *, int __pyx_skip_dispatch);
  float (*max)(struct __pyx_obj_7PyTorch__FloatTensor *, int __pyx_skip_dispatch);
  float (*min)(struct __pyx_obj_7PyTorch__FloatTensor *, int __pyx_skip_dispatch);
};
static struct __pyx_vtabstruct_7PyTorch__FloatTensor *__pyx_vtabptr_7PyTorch__FloatTensor;


/* "PyTorch.pyx":1427
 * 
 * 
 * cdef class _DoubleTensor(object):             # <<<<<<<<<<<<<<
 *     # properties are in the PyTorch.pxd file
 * 
 */

struct __pyx_vtabstruct_7PyTorch__DoubleTensor {
  double *(*data)(struct __pyx_obj_7PyTorch__DoubleTensor *);
  int (*dims)(struct __pyx_obj_7PyTorch__DoubleTensor *, int __pyx_skip_dispatch);
  PyObject *(*set1d)(struct __pyx_obj_7PyTorch__DoubleTensor *, int, double, int __pyx_skip_dispatch);
  PyObject *(*set2d)(struct __pyx_obj_7PyTorch__DoubleTensor *, int, int, double, int __pyx_skip_dispatch);
  double (*get1d)(struct __pyx_obj_7PyTorch__DoubleTensor *, int, int __pyx_skip_dispatch);
  double (*get2d)(struct __pyx_obj_7PyTorch__DoubleTensor *, int, int, int __pyx_skip_dispatch);
  int (*isContiguous)(struct __pyx_obj_7PyTorch__DoubleTensor *, int __pyx_skip_dispatch);
  double (*max)(struct __pyx_obj_7PyTorch__DoubleTensor *, int __pyx_skip_dispatch);
  double (*min)(struct __pyx_obj_7PyTorch__DoubleTensor *, int __pyx_skip_dispatch);
};
static struct __pyx_vtabstruct_7PyTorch__DoubleTensor *__pyx_vtabptr_7PyTorch__DoubleTensor;


/* "PyTorch.pyx":2003
 * 
 * 
 * cdef class _ByteTensor(object):             # <<<<<<<<<<<<<<
 *     # properties are in the PyTorch.pxd file
 * 
 */

struct __pyx_vtabstruct_7PyTorch__ByteTensor {
  unsigned char *(*data)(struct __pyx_obj_7PyTorch__ByteTensor *);
  int (*dims)(struct __pyx_obj_7PyTorch__ByteTensor *, int __pyx_skip_dispatch);
  PyObject *(*set1d)(struct __pyx_obj_7PyTorch__ByteTensor *, int, unsigned char, int __pyx_skip_dispatch);
  PyObject *(*set2d)(struct __pyx_obj_7PyTorch__ByteTensor *, int, int, unsigned char, int __pyx_skip_dispatch);
  unsigned char (*get1d)(struct __pyx_obj_7PyTorch__ByteTensor *, int, int __pyx_skip_dispatch);
  unsigned char (*get2d)(struct __pyx_obj_7PyTorch__ByteTensor *, int, int, int __pyx_skip_dispatch);
  int (*isContiguous)(struct __pyx_obj_7PyTorch__ByteTensor *, int __pyx_skip_dispatch);
  unsigned char (*max)(struct __pyx_obj_7PyTorch__ByteTensor *, int __pyx_skip_dispatch);
  unsigned char (*min)(struct __pyx_obj_7PyTorch__ByteTensor *, int __pyx_skip_dispatch);
};
static struct __pyx_vtabstruct_7PyTorch__ByteTensor *__pyx_vtabptr_7PyTorch__ByteTensor;


/* "View.MemoryView":103
 * 
 * @cname("__pyx_array")
 * cdef class array:             # <<<<<<<<<<<<<<
 * 
 *     cdef:
 */

struct __pyx_vtabstruct_array {
  PyObject *(*get_memview)(struct __pyx_array_obj *);
};
static struct __pyx_vtabstruct_array *__pyx_vtabptr_array;


/* "View.MemoryView":326
 * 
 * @cname('__pyx_memoryview')
 * cdef class memoryview(object):             # <<<<<<<<<<<<<<
 * 
 *     cdef object obj
 */

struct __pyx_vtabstruct_memoryview {
  char *(*get_item_pointer)(struct __pyx_memoryview_obj *, PyObject *);
  PyObject *(*is_slice)(struct __pyx_memoryview_obj *, PyObject *);
  PyObject *(*setitem_slice_assignment)(struct __pyx_memoryview_obj *, PyObject *, PyObject *);
  PyObject *(*setitem_slice_assign_scalar)(struct __pyx_memoryview_obj *, struct __pyx_memoryview_obj *, PyObject *);
  PyObject *(*setitem_indexed)(struct __pyx_memoryview_obj *, PyObject *, PyObject *);
  PyObject *(*convert_item_to_object)(struct __pyx_memoryview_obj *, char *);
  PyObject *(*assign_item_from_object)(struct __pyx_memoryview_obj *, char *, PyObject *);
};
static struct __pyx_vtabstruct_memoryview *__pyx_vtabptr_memoryview;


/* "View.MemoryView":951
 * 
 * @cname('__pyx_memoryviewslice')
 * cdef class _memoryviewslice(memoryview):             # <<<<<<<<<<<<<<
 *     "Internal class for passing memoryview slices to Python"
 * 
 */

struct __pyx_vtabstruct__memoryviewslice {
  struct __pyx_vtabstruct_memoryview __pyx_base;
};
static struct __pyx_vtabstruct__memoryviewslice *__pyx_vtabptr__memoryviewslice;

/* --- Runtime support code (head) --- */
/* Refnanny.proto */
#ifndef CYTHON_REFNANNY
  #define CYTHON_REFNANNY 0
#endif
#if CYTHON_REFNANNY
  typedef struct {
    void (*INCREF)(void*, PyObject*, int);
    void (*DECREF)(void*, PyObject*, int);
    void (*GOTREF)(void*, PyObject*, int);
    void (*GIVEREF)(void*, PyObject*, int);
    void* (*SetupContext)(const char*, int, const char*);
    void (*FinishContext)(void**);
  } __Pyx_RefNannyAPIStruct;
  static __Pyx_RefNannyAPIStruct *__Pyx_RefNanny = NULL;
  static __Pyx_RefNannyAPIStruct *__Pyx_RefNannyImportAPI(const char *modname);
  #define __Pyx_RefNannyDeclarations void *__pyx_refnanny = NULL;
#ifdef WITH_THREAD
  #define __Pyx_RefNannySetupContext(name, acquire_gil)\
          if (acquire_gil) {\
              PyGILState_STATE __pyx_gilstate_save = PyGILState_Ensure();\
              __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), __LINE__, __FILE__);\
              PyGILState_Release(__pyx_gilstate_save);\
          } else {\
              __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), __LINE__, __FILE__);\
          }
#else
  #define __Pyx_RefNannySetupContext(name, acquire_gil)\
          __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), __LINE__, __FILE__)
#endif
  #define __Pyx_RefNannyFinishContext()\
          __Pyx_RefNanny->FinishContext(&__pyx_refnanny)
  #define __Pyx_INCREF(r)  __Pyx_RefNanny->INCREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_DECREF(r)  __Pyx_RefNanny->DECREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_GOTREF(r)  __Pyx_RefNanny->GOTREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_GIVEREF(r) __Pyx_RefNanny->GIVEREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_XINCREF(r)  do { if((r) != NULL) {__Pyx_INCREF(r); }} while(0)
  #define __Pyx_XDECREF(r)  do { if((r) != NULL) {__Pyx_DECREF(r); }} while(0)
  #define __Pyx_XGOTREF(r)  do { if((r) != NULL) {__Pyx_GOTREF(r); }} while(0)
  #define __Pyx_XGIVEREF(r) do { if((r) != NULL) {__Pyx_GIVEREF(r);}} while(0)
#else
  #define __Pyx_RefNannyDeclarations
  #define __Pyx_RefNannySetupContext(name, acquire_gil)
  #define __Pyx_RefNannyFinishContext()
  #define __Pyx_INCREF(r) Py_INCREF(r)
  #define __Pyx_DECREF(r) Py_DECREF(r)
  #define __Pyx_GOTREF(r)
  #define __Pyx_GIVEREF(r)
  #define __Pyx_XINCREF(r) Py_XINCREF(r)
  #define __Pyx_XDECREF(r) Py_XDECREF(r)
  #define __Pyx_XGOTREF(r)
  #define __Pyx_XGIVEREF(r)
#endif
#define __Pyx_XDECREF_SET(r, v) do {\
        PyObject *tmp = (PyObject *) r;\
        r = v; __Pyx_XDECREF(tmp);\
    } while (0)
#define __Pyx_DECREF_SET(r, v) do {\
        PyObject *tmp = (PyObject *) r;\
        r = v; __Pyx_DECREF(tmp);\
    } while (0)
#define __Pyx_CLEAR(r)    do { PyObject* tmp = ((PyObject*)(r)); r = NULL; __Pyx_DECREF(tmp);} while(0)
#define __Pyx_XCLEAR(r)   do { if((r) != NULL) {PyObject* tmp = ((PyObject*)(r)); r = NULL; __Pyx_DECREF(tmp);}} while(0)

/* PyObjectGetAttrStr.proto */
#if CYTHON_USE_TYPE_SLOTS
static CYTHON_INLINE PyObject* __Pyx_PyObject_GetAttrStr(PyObject* obj, PyObject* attr_name) {
    PyTypeObject* tp = Py_TYPE(obj);
    if (likely(tp->tp_getattro))
        return tp->tp_getattro(obj, attr_name);
#if PY_MAJOR_VERSION < 3
    if (likely(tp->tp_getattr))
        return tp->tp_getattr(obj, PyString_AS_STRING(attr_name));
#endif
    return PyObject_GetAttr(obj, attr_name);
}
#else
#define __Pyx_PyObject_GetAttrStr(o,n) PyObject_GetAttr(o,n)
#endif

/* GetBuiltinName.proto */
static PyObject *__Pyx_GetBuiltinName(PyObject *name);

/* RaiseDoubleKeywords.proto */
static void __Pyx_RaiseDoubleKeywordsError(const char* func_name, PyObject* kw_name);

/* ParseKeywords.proto */
static int __Pyx_ParseOptionalKeywords(PyObject *kwds, PyObject **argnames[],\
    PyObject *kwds2, PyObject *values[], Py_ssize_t num_pos_args,\
    const char* function_name);

/* RaiseArgTupleInvalid.proto */
static void __Pyx_RaiseArgtupleInvalid(const char* func_name, int exact,
    Py_ssize_t num_min, Py_ssize_t num_max, Py_ssize_t num_found);

/* PyIntBinop.proto */
#if !CYTHON_COMPILING_IN_PYPY
static PyObject* __Pyx_PyInt_SubtractObjC(PyObject *op1, PyObject *op2, long intval, int inplace);
#else
#define __Pyx_PyInt_SubtractObjC(op1, op2, intval, inplace)\
    (inplace ? PyNumber_InPlaceSubtract(op1, op2) : PyNumber_Subtract(op1, op2))
#endif

/* GetModuleGlobalName.proto */
static CYTHON_INLINE PyObject *__Pyx_GetModuleGlobalName(PyObject *name);

/* PyCFunctionFastCall.proto */
#if CYTHON_FAST_PYCCALL
static CYTHON_INLINE PyObject *__Pyx_PyCFunction_FastCall(PyObject *func, PyObject **args, Py_ssize_t nargs);
#else
#define __Pyx_PyCFunction_FastCall(func, args, nargs)  (assert(0), NULL)
#endif

/* PyFunctionFastCall.proto */
#if CYTHON_FAST_PYCALL
#define __Pyx_PyFunction_FastCall(func, args, nargs)\
    __Pyx_PyFunction_FastCallDict((func), (args), (nargs), NULL)
#if 1 || PY_VERSION_HEX < 0x030600B1
static PyObject *__Pyx_PyFunction_FastCallDict(PyObject *func, PyObject **args, int nargs, PyObject *kwargs);
#else
#define __Pyx_PyFunction_FastCallDict(func, args, nargs, kwargs) _PyFunction_FastCallDict(func, args, nargs, kwargs)
#endif
#endif

/* PyObjectCall.proto */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_Call(PyObject *func, PyObject *arg, PyObject *kw);
#else
#define __Pyx_PyObject_Call(func, arg, kw) PyObject_Call(func, arg, kw)
#endif

/* PyObjectCallMethO.proto */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallMethO(PyObject *func, PyObject *arg);
#endif

/* PyObjectCallOneArg.proto */
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallOneArg(PyObject *func, PyObject *arg);

/* GetItemInt.proto */
#define __Pyx_GetItemInt(o, i, type, is_signed, to_py_func, is_list, wraparound, boundscheck)\
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ?\
    __Pyx_GetItemInt_Fast(o, (Py_ssize_t)i, is_list, wraparound, boundscheck) :\
    (is_list ? (PyErr_SetString(PyExc_IndexError, "list index out of range"), (PyObject*)NULL) :\
               __Pyx_GetItemInt_Generic(o, to_py_func(i))))
#define __Pyx_GetItemInt_List(o, i, type, is_signed, to_py_func, is_list, wraparound, boundscheck)\
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ?\
    __Pyx_GetItemInt_List_Fast(o, (Py_ssize_t)i, wraparound, boundscheck) :\
    (PyErr_SetString(PyExc_IndexError, "list index out of range"), (PyObject*)NULL))
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_List_Fast(PyObject *o, Py_ssize_t i,
                                                              int wraparound, int boundscheck);
#define __Pyx_GetItemInt_Tuple(o, i, type, is_signed, to_py_func, is_list, wraparound, boundscheck)\
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ?\
    __Pyx_GetItemInt_Tuple_Fast(o, (Py_ssize_t)i, wraparound, boundscheck) :\
    (PyErr_SetString(PyExc_IndexError, "tuple index out of range"), (PyObject*)NULL))
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Tuple_Fast(PyObject *o, Py_ssize_t i,
                                                              int wraparound, int boundscheck);
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Generic(PyObject *o, PyObject* j);
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Fast(PyObject *o, Py_ssize_t i,
                                                     int is_list, int wraparound, int boundscheck);

/* ExtTypeTest.proto */
static CYTHON_INLINE int __Pyx_TypeTest(PyObject *obj, PyTypeObject *type);

/* PyThreadStateGet.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_PyThreadState_declare  PyThreadState *__pyx_tstate;
#define __Pyx_PyThreadState_assign  __pyx_tstate = PyThreadState_GET();
#else
#define __Pyx_PyThreadState_declare
#define __Pyx_PyThreadState_assign
#endif

/* PyErrFetchRestore.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_ErrRestoreWithState(type, value, tb)  __Pyx_ErrRestoreInState(PyThreadState_GET(), type, value, tb)
#define __Pyx_ErrFetchWithState(type, value, tb)    __Pyx_ErrFetchInState(PyThreadState_GET(), type, value, tb)
#define __Pyx_ErrRestore(type, value, tb)  __Pyx_ErrRestoreInState(__pyx_tstate, type, value, tb)
#define __Pyx_ErrFetch(type, value, tb)    __Pyx_ErrFetchInState(__pyx_tstate, type, value, tb)
static CYTHON_INLINE void __Pyx_ErrRestoreInState(PyThreadState *tstate, PyObject *type, PyObject *value, PyObject *tb);
static CYTHON_INLINE void __Pyx_ErrFetchInState(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb);
#else
#define __Pyx_ErrRestoreWithState(type, value, tb)  PyErr_Restore(type, value, tb)
#define __Pyx_ErrFetchWithState(type, value, tb)  PyErr_Fetch(type, value, tb)
#define __Pyx_ErrRestore(type, value, tb)  PyErr_Restore(type, value, tb)
#define __Pyx_ErrFetch(type, value, tb)  PyErr_Fetch(type, value, tb)
#endif

/* RaiseException.proto */
static void __Pyx_Raise(PyObject *type, PyObject *value, PyObject *tb, PyObject *cause);

/* WriteUnraisableException.proto */
static void __Pyx_WriteUnraisable(const char *name, int clineno,
                                  int lineno, const char *filename,
                                  int full_traceback, int nogil);

/* PyObjectCallNoArg.proto */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallNoArg(PyObject *func);
#else
#define __Pyx_PyObject_CallNoArg(func) __Pyx_PyObject_Call(func, __pyx_empty_tuple, NULL)
#endif

/* ListAppend.proto */
#if CYTHON_USE_PYLIST_INTERNALS && CYTHON_ASSUME_SAFE_MACROS
static CYTHON_INLINE int __Pyx_PyList_Append(PyObject* list, PyObject* x) {
    PyListObject* L = (PyListObject*) list;
    Py_ssize_t len = Py_SIZE(list);
    if (likely(L->allocated > len) & likely(len > (L->allocated >> 1))) {
        Py_INCREF(x);
        PyList_SET_ITEM(list, len, x);
        Py_SIZE(list) = len+1;
        return 0;
    }
    return PyList_Append(list, x);
}
#else
#define __Pyx_PyList_Append(L,x) PyList_Append(L,x)
#endif

/* SetItemInt.proto */
#define __Pyx_SetItemInt(o, i, v, type, is_signed, to_py_func, is_list, wraparound, boundscheck)\
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ?\
    __Pyx_SetItemInt_Fast(o, (Py_ssize_t)i, v, is_list, wraparound, boundscheck) :\
    (is_list ? (PyErr_SetString(PyExc_IndexError, "list assignment index out of range"), -1) :\
               __Pyx_SetItemInt_Generic(o, to_py_func(i), v)))
static CYTHON_INLINE int __Pyx_SetItemInt_Generic(PyObject *o, PyObject *j, PyObject *v);
static CYTHON_INLINE int __Pyx_SetItemInt_Fast(PyObject *o, Py_ssize_t i, PyObject *v,
                                               int is_list, int wraparound, int boundscheck);

/* KeywordStringCheck.proto */
static CYTHON_INLINE int __Pyx_CheckKeywordStrings(PyObject *kwdict, const char* function_name, int kw_allowed);

/* ArgTypeTest.proto */
static CYTHON_INLINE int __Pyx_ArgTypeTest(PyObject *obj, PyTypeObject *type, int none_allowed,
    const char *name, int exact);

/* IncludeStringH.proto */
#include <string.h>

/* BytesEquals.proto */
static CYTHON_INLINE int __Pyx_PyBytes_Equals(PyObject* s1, PyObject* s2, int equals);

/* UnicodeEquals.proto */
static CYTHON_INLINE int __Pyx_PyUnicode_Equals(PyObject* s1, PyObject* s2, int equals);

/* StrEquals.proto */
#if PY_MAJOR_VERSION >= 3
#define __Pyx_PyString_Equals __Pyx_PyUnicode_Equals
#else
#define __Pyx_PyString_Equals __Pyx_PyBytes_Equals
#endif

/* BufferFormatCheck.proto */
static CYTHON_INLINE int  __Pyx_GetBufferAndValidate(Py_buffer* buf, PyObject* obj,
    __Pyx_TypeInfo* dtype, int flags, int nd, int cast, __Pyx_BufFmt_StackElem* stack);
static CYTHON_INLINE void __Pyx_SafeReleaseBuffer(Py_buffer* info);
static const char* __Pyx_BufFmt_CheckString(__Pyx_BufFmt_Context* ctx, const char* ts);
static void __Pyx_BufFmt_Init(__Pyx_BufFmt_Context* ctx,
                              __Pyx_BufFmt_StackElem* stack,
                              __Pyx_TypeInfo* type); // PROTO

/* MemviewSliceInit.proto */
#define __Pyx_BUF_MAX_NDIMS %(BUF_MAX_NDIMS)d
#define __Pyx_MEMVIEW_DIRECT   1
#define __Pyx_MEMVIEW_PTR      2
#define __Pyx_MEMVIEW_FULL     4
#define __Pyx_MEMVIEW_CONTIG   8
#define __Pyx_MEMVIEW_STRIDED  16
#define __Pyx_MEMVIEW_FOLLOW   32
#define __Pyx_IS_C_CONTIG 1
#define __Pyx_IS_F_CONTIG 2
static int __Pyx_init_memviewslice(
                struct __pyx_memoryview_obj *memview,
                int ndim,
                __Pyx_memviewslice *memviewslice,
                int memview_is_new_reference);
static CYTHON_INLINE int __pyx_add_acquisition_count_locked(
    __pyx_atomic_int *acquisition_count, PyThread_type_lock lock);
static CYTHON_INLINE int __pyx_sub_acquisition_count_locked(
    __pyx_atomic_int *acquisition_count, PyThread_type_lock lock);
#define __pyx_get_slice_count_pointer(memview) (memview->acquisition_count_aligned_p)
#define __pyx_get_slice_count(memview) (*__pyx_get_slice_count_pointer(memview))
#define __PYX_INC_MEMVIEW(slice, have_gil) __Pyx_INC_MEMVIEW(slice, have_gil, __LINE__)
#define __PYX_XDEC_MEMVIEW(slice, have_gil) __Pyx_XDEC_MEMVIEW(slice, have_gil, __LINE__)
static CYTHON_INLINE void __Pyx_INC_MEMVIEW(__Pyx_memviewslice *, int, int);
static CYTHON_INLINE void __Pyx_XDEC_MEMVIEW(__Pyx_memviewslice *, int, int);

/* None.proto */
static CYTHON_INLINE Py_ssize_t __Pyx_div_Py_ssize_t(Py_ssize_t, Py_ssize_t);

/* UnaryNegOverflows.proto */
#define UNARY_NEG_WOULD_OVERFLOW(x)\
        (((x) < 0) & ((unsigned long)(x) == 0-(unsigned long)(x)))

static CYTHON_UNUSED int __pyx_array_getbuffer(PyObject *__pyx_v_self, Py_buffer *__pyx_v_info, int __pyx_v_flags); /*proto*/
static PyObject *__pyx_array_get_memview(struct __pyx_array_obj *); /*proto*/
/* GetAttr.proto */
static CYTHON_INLINE PyObject *__Pyx_GetAttr(PyObject *, PyObject *);

/* decode_c_string.proto */
static CYTHON_INLINE PyObject* __Pyx_decode_c_string(
         const char* cstring, Py_ssize_t start, Py_ssize_t stop,
         const char* encoding, const char* errors,
         PyObject* (*decode_func)(const char *s, Py_ssize_t size, const char *errors));

/* RaiseTooManyValuesToUnpack.proto */
static CYTHON_INLINE void __Pyx_RaiseTooManyValuesError(Py_ssize_t expected);

/* RaiseNeedMoreValuesToUnpack.proto */
static CYTHON_INLINE void __Pyx_RaiseNeedMoreValuesError(Py_ssize_t index);

/* RaiseNoneIterError.proto */
static CYTHON_INLINE void __Pyx_RaiseNoneNotIterableError(void);

/* SaveResetException.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_ExceptionSave(type, value, tb)  __Pyx__ExceptionSave(__pyx_tstate, type, value, tb)
static CYTHON_INLINE void __Pyx__ExceptionSave(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb);
#define __Pyx_ExceptionReset(type, value, tb)  __Pyx__ExceptionReset(__pyx_tstate, type, value, tb)
static CYTHON_INLINE void __Pyx__ExceptionReset(PyThreadState *tstate, PyObject *type, PyObject *value, PyObject *tb);
#else
#define __Pyx_ExceptionSave(type, value, tb)   PyErr_GetExcInfo(type, value, tb)
#define __Pyx_ExceptionReset(type, value, tb)  PyErr_SetExcInfo(type, value, tb)
#endif

/* PyErrExceptionMatches.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_PyErr_ExceptionMatches(err) __Pyx_PyErr_ExceptionMatchesInState(__pyx_tstate, err)
static CYTHON_INLINE int __Pyx_PyErr_ExceptionMatchesInState(PyThreadState* tstate, PyObject* err);
#else
#define __Pyx_PyErr_ExceptionMatches(err)  PyErr_ExceptionMatches(err)
#endif

/* GetException.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_GetException(type, value, tb)  __Pyx__GetException(__pyx_tstate, type, value, tb)
static int __Pyx__GetException(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb);
#else
static int __Pyx_GetException(PyObject **type, PyObject **value, PyObject **tb);
#endif

/* SwapException.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_ExceptionSwap(type, value, tb)  __Pyx__ExceptionSwap(__pyx_tstate, type, value, tb)
static CYTHON_INLINE void __Pyx__ExceptionSwap(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb);
#else
static CYTHON_INLINE void __Pyx_ExceptionSwap(PyObject **type, PyObject **value, PyObject **tb);
#endif

/* Import.proto */
static PyObject *__Pyx_Import(PyObject *name, PyObject *from_list, int level);

static CYTHON_UNUSED int __pyx_memoryview_getbuffer(PyObject *__pyx_v_self, Py_buffer *__pyx_v_info, int __pyx_v_flags); /*proto*/
/* ListCompAppend.proto */
#if CYTHON_USE_PYLIST_INTERNALS && CYTHON_ASSUME_SAFE_MACROS
static CYTHON_INLINE int __Pyx_ListComp_Append(PyObject* list, PyObject* x) {
    PyListObject* L = (PyListObject*) list;
    Py_ssize_t len = Py_SIZE(list);
    if (likely(L->allocated > len)) {
        Py_INCREF(x);
        PyList_SET_ITEM(list, len, x);
        Py_SIZE(list) = len+1;
        return 0;
    }
    return PyList_Append(list, x);
}
#else
#define __Pyx_ListComp_Append(L,x) PyList_Append(L,x)
#endif

/* PyIntBinop.proto */
#if !CYTHON_COMPILING_IN_PYPY
static PyObject* __Pyx_PyInt_AddObjC(PyObject *op1, PyObject *op2, long intval, int inplace);
#else
#define __Pyx_PyInt_AddObjC(op1, op2, intval, inplace)\
    (inplace ? PyNumber_InPlaceAdd(op1, op2) : PyNumber_Add(op1, op2))
#endif

/* ListExtend.proto */
static CYTHON_INLINE int __Pyx_PyList_Extend(PyObject* L, PyObject* v) {
#if CYTHON_COMPILING_IN_CPYTHON
    PyObject* none = _PyList_Extend((PyListObject*)L, v);
    if (unlikely(!none))
        return -1;
    Py_DECREF(none);
    return 0;
#else
    return PyList_SetSlice(L, PY_SSIZE_T_MAX, PY_SSIZE_T_MAX, v);
#endif
}

/* None.proto */
static CYTHON_INLINE void __Pyx_RaiseUnboundLocalError(const char *varname);

/* ForceInitThreads.proto */
#ifndef __PYX_FORCE_INIT_THREADS
  #define __PYX_FORCE_INIT_THREADS 0
#endif

/* None.proto */
static CYTHON_INLINE long __Pyx_div_long(long, long);

/* SetVTable.proto */
static int __Pyx_SetVtable(PyObject *dict, void *vtable);

/* GetVTable.proto */
static void* __Pyx_GetVtable(PyObject *dict);

/* ImportFrom.proto */
static PyObject* __Pyx_ImportFrom(PyObject* module, PyObject* name);

/* GetNameInClass.proto */
static PyObject *__Pyx_GetNameInClass(PyObject *nmspace, PyObject *name);

/* CodeObjectCache.proto */
typedef struct {
    PyCodeObject* code_object;
    int code_line;
} __Pyx_CodeObjectCacheEntry;
struct __Pyx_CodeObjectCache {
    int count;
    int max_count;
    __Pyx_CodeObjectCacheEntry* entries;
};
static struct __Pyx_CodeObjectCache __pyx_code_cache = {0,0,NULL};
static int __pyx_bisect_code_objects(__Pyx_CodeObjectCacheEntry* entries, int count, int code_line);
static PyCodeObject *__pyx_find_code_object(int code_line);
static void __pyx_insert_code_object(int code_line, PyCodeObject* code_object);

/* AddTraceback.proto */
static void __Pyx_AddTraceback(const char *funcname, int c_line,
                               int py_line, const char *filename);

/* ArrayAPI.proto */
#ifndef _ARRAYARRAY_H
#define _ARRAYARRAY_H
typedef struct arraydescr {
    int typecode;
    int itemsize;
    PyObject * (*getitem)(struct arrayobject *, Py_ssize_t);
    int (*setitem)(struct arrayobject *, Py_ssize_t, PyObject *);
#if PY_MAJOR_VERSION >= 3
    char *formats;
#endif
} arraydescr;
struct arrayobject {
    PyObject_HEAD
    Py_ssize_t ob_size;
    union {
        char *ob_item;
        float *as_floats;
        double *as_doubles;
        int *as_ints;
        unsigned int *as_uints;
        unsigned char *as_uchars;
        signed char *as_schars;
        char *as_chars;
        unsigned long *as_ulongs;
        long *as_longs;
        short *as_shorts;
        unsigned short *as_ushorts;
        Py_UNICODE *as_pyunicodes;
        void *as_voidptr;
    } data;
    Py_ssize_t allocated;
    struct arraydescr *ob_descr;
    PyObject *weakreflist;
#if PY_MAJOR_VERSION >= 3
        int ob_exports;
#endif
};
#ifndef NO_NEWARRAY_INLINE
static CYTHON_INLINE PyObject * newarrayobject(PyTypeObject *type, Py_ssize_t size,
    struct arraydescr *descr) {
    arrayobject *op;
    size_t nbytes;
    if (size < 0) {
        PyErr_BadInternalCall();
        return NULL;
    }
    nbytes = size * descr->itemsize;
    if (nbytes / descr->itemsize != (size_t)size) {
        return PyErr_NoMemory();
    }
    op = (arrayobject *) type->tp_alloc(type, 0);
    if (op == NULL) {
        return NULL;
    }
    op->ob_descr = descr;
    op->allocated = size;
    op->weakreflist = NULL;
    op->ob_size = size;
    if (size <= 0) {
        op->data.ob_item = NULL;
    }
    else {
        op->data.ob_item = PyMem_NEW(char, nbytes);
        if (op->data.ob_item == NULL) {
            Py_DECREF(op);
            return PyErr_NoMemory();
        }
    }
    return (PyObject *) op;
}
#else
PyObject* newarrayobject(PyTypeObject *type, Py_ssize_t size,
    struct arraydescr *descr);
#endif
static CYTHON_INLINE int resize(arrayobject *self, Py_ssize_t n) {
    void *items = (void*) self->data.ob_item;
    PyMem_Resize(items, char, (size_t)(n * self->ob_descr->itemsize));
    if (items == NULL) {
        PyErr_NoMemory();
        return -1;
    }
    self->data.ob_item = (char*) items;
    self->ob_size = n;
    self->allocated = n;
    return 0;
}
static CYTHON_INLINE int resize_smart(arrayobject *self, Py_ssize_t n) {
    void *items = (void*) self->data.ob_item;
    Py_ssize_t newsize;
    if (n < self->allocated && n*4 > self->allocated) {
        self->ob_size = n;
        return 0;
    }
    newsize = n + (n / 2) + 1;
    if (newsize <= n) {
        PyErr_NoMemory();
        return -1;
    }
    PyMem_Resize(items, char, (size_t)(newsize * self->ob_descr->itemsize));
    if (items == NULL) {
        PyErr_NoMemory();
        return -1;
    }
    self->data.ob_item = (char*) items;
    self->ob_size = n;
    self->allocated = newsize;
    return 0;
}
#endif

#if PY_MAJOR_VERSION < 3
    static int __Pyx_GetBuffer(PyObject *obj, Py_buffer *view, int flags);
    static void __Pyx_ReleaseBuffer(Py_buffer *view);
#else
    #define __Pyx_GetBuffer PyObject_GetBuffer
    #define __Pyx_ReleaseBuffer PyBuffer_Release
#endif


/* BufferStructDeclare.proto */
typedef struct {
  Py_ssize_t shape, strides, suboffsets;
} __Pyx_Buf_DimInfo;
typedef struct {
  size_t refcount;
  Py_buffer pybuffer;
} __Pyx_Buffer;
typedef struct {
  __Pyx_Buffer *rcbuffer;
  char *data;
  __Pyx_Buf_DimInfo diminfo[8];
} __Pyx_LocalBuf_ND;

/* None.proto */
static Py_ssize_t __Pyx_zeros[] = {0, 0, 0, 0, 0, 0, 0, 0};
static Py_ssize_t __Pyx_minusones[] = {-1, -1, -1, -1, -1, -1, -1, -1};

/* MemviewSliceIsContig.proto */
static int __pyx_memviewslice_is_contig(const __Pyx_memviewslice mvs,
                                        char order, int ndim);

/* OverlappingSlices.proto */
static int __pyx_slices_overlap(__Pyx_memviewslice *slice1,
                                __Pyx_memviewslice *slice2,
                                int ndim, size_t itemsize);

/* Capsule.proto */
static CYTHON_INLINE PyObject *__pyx_capsule_create(void *p, const char *sig);

/* CIntToPy.proto */
static CYTHON_INLINE PyObject* __Pyx_PyInt_From_long(long value);

/* CIntToPy.proto */
static CYTHON_INLINE PyObject* __Pyx_PyInt_From_int(int value);

/* MemviewDtypeToObject.proto */
static CYTHON_INLINE PyObject *__pyx_memview_get_float(const char *itemp);
static CYTHON_INLINE int __pyx_memview_set_float(const char *itemp, PyObject *obj);

/* MemviewDtypeToObject.proto */
static CYTHON_INLINE PyObject *__pyx_memview_get_double(const char *itemp);
static CYTHON_INLINE int __pyx_memview_set_double(const char *itemp, PyObject *obj);

/* CIntToPy.proto */
static CYTHON_INLINE PyObject* __Pyx_PyInt_From_unsigned_char(unsigned char value);

/* MemviewDtypeToObject.proto */
static CYTHON_INLINE PyObject *__pyx_memview_get_unsigned_char(const char *itemp);
static CYTHON_INLINE int __pyx_memview_set_unsigned_char(const char *itemp, PyObject *obj);

/* MemviewSliceCopyTemplate.proto */
static __Pyx_memviewslice
__pyx_memoryview_copy_new_contig(const __Pyx_memviewslice *from_mvs,
                                 const char *mode, int ndim,
                                 size_t sizeof_dtype, int contig_flag,
                                 int dtype_is_object);

/* CIntFromPy.proto */
static CYTHON_INLINE long __Pyx_PyInt_As_long(PyObject *);

/* CIntFromPy.proto */
static CYTHON_INLINE int __Pyx_PyInt_As_int(PyObject *);

/* CIntFromPy.proto */
static CYTHON_INLINE unsigned char __Pyx_PyInt_As_unsigned_char(PyObject *);

/* CIntFromPy.proto */
static CYTHON_INLINE char __Pyx_PyInt_As_char(PyObject *);

/* TypeInfoCompare.proto */
static int __pyx_typeinfo_cmp(__Pyx_TypeInfo *a, __Pyx_TypeInfo *b);

/* MemviewSliceValidateAndInit.proto */
static int __Pyx_ValidateAndInit_memviewslice(
                int *axes_specs,
                int c_or_f_flag,
                int buf_flags,
                int ndim,
                __Pyx_TypeInfo *dtype,
                __Pyx_BufFmt_StackElem stack[],
                __Pyx_memviewslice *memviewslice,
                PyObject *original_obj);

/* ObjectToMemviewSlice.proto */
static CYTHON_INLINE __Pyx_memviewslice __Pyx_PyObject_to_MemoryviewSlice_ds_float(PyObject *);

/* ObjectToMemviewSlice.proto */
static CYTHON_INLINE __Pyx_memviewslice __Pyx_PyObject_to_MemoryviewSlice_ds_double(PyObject *);

/* ObjectToMemviewSlice.proto */
static CYTHON_INLINE __Pyx_memviewslice __Pyx_PyObject_to_MemoryviewSlice_ds_unsigned_char(PyObject *);

/* CStringEquals.proto */
static CYTHON_INLINE int __Pyx_StrEq(const char *, const char *);

/* CheckBinaryVersion.proto */
static int __Pyx_check_binary_version(void);

/* PyIdentifierFromString.proto */
#if !defined(__Pyx_PyIdentifier_FromString)
#if PY_MAJOR_VERSION < 3
  #define __Pyx_PyIdentifier_FromString(s) PyString_FromString(s)
#else
  #define __Pyx_PyIdentifier_FromString(s) PyUnicode_FromString(s)
#endif
#endif

/* ModuleImport.proto */
static PyObject *__Pyx_ImportModule(const char *name);

/* TypeImport.proto */
static PyTypeObject *__Pyx_ImportType(const char *module_name, const char *class_name, size_t size, int strict);

/* FunctionImport.proto */
static int __Pyx_ImportFunction(PyObject *module, const char *funcname, void (**f)(void), const char *sig);

/* InitStrings.proto */
static int __Pyx_InitStrings(__Pyx_StringTabEntry *t);

static long *__pyx_f_7PyTorch_11_LongTensor_data(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self); /* proto*/
static int __pyx_f_7PyTorch_11_LongTensor_dims(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, int __pyx_skip_dispatch); /* proto*/
static PyObject *__pyx_f_7PyTorch_11_LongTensor_set1d(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, int __pyx_v_x0, long __pyx_v_value, int __pyx_skip_dispatch); /* proto*/
static PyObject *__pyx_f_7PyTorch_11_LongTensor_set2d(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_v_x1, long __pyx_v_value, int __pyx_skip_dispatch); /* proto*/
static long __pyx_f_7PyTorch_11_LongTensor_get1d(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_skip_dispatch); /* proto*/
static long __pyx_f_7PyTorch_11_LongTensor_get2d(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_v_x1, int __pyx_skip_dispatch); /* proto*/
static int __pyx_f_7PyTorch_11_LongTensor_isContiguous(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, int __pyx_skip_dispatch); /* proto*/
static long __pyx_f_7PyTorch_11_LongTensor_max(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, int __pyx_skip_dispatch); /* proto*/
static long __pyx_f_7PyTorch_11_LongTensor_min(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, int __pyx_skip_dispatch); /* proto*/
static float *__pyx_f_7PyTorch_12_FloatTensor_data(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self); /* proto*/
static int __pyx_f_7PyTorch_12_FloatTensor_dims(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, int __pyx_skip_dispatch); /* proto*/
static PyObject *__pyx_f_7PyTorch_12_FloatTensor_set1d(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, int __pyx_v_x0, float __pyx_v_value, int __pyx_skip_dispatch); /* proto*/
static PyObject *__pyx_f_7PyTorch_12_FloatTensor_set2d(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_v_x1, float __pyx_v_value, int __pyx_skip_dispatch); /* proto*/
static float __pyx_f_7PyTorch_12_FloatTensor_get1d(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_skip_dispatch); /* proto*/
static float __pyx_f_7PyTorch_12_FloatTensor_get2d(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_v_x1, int __pyx_skip_dispatch); /* proto*/
static int __pyx_f_7PyTorch_12_FloatTensor_isContiguous(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, int __pyx_skip_dispatch); /* proto*/
static float __pyx_f_7PyTorch_12_FloatTensor_max(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, int __pyx_skip_dispatch); /* proto*/
static float __pyx_f_7PyTorch_12_FloatTensor_min(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, int __pyx_skip_dispatch); /* proto*/
static double *__pyx_f_7PyTorch_13_DoubleTensor_data(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self); /* proto*/
static int __pyx_f_7PyTorch_13_DoubleTensor_dims(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, int __pyx_skip_dispatch); /* proto*/
static PyObject *__pyx_f_7PyTorch_13_DoubleTensor_set1d(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, int __pyx_v_x0, double __pyx_v_value, int __pyx_skip_dispatch); /* proto*/
static PyObject *__pyx_f_7PyTorch_13_DoubleTensor_set2d(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_v_x1, double __pyx_v_value, int __pyx_skip_dispatch); /* proto*/
static double __pyx_f_7PyTorch_13_DoubleTensor_get1d(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_skip_dispatch); /* proto*/
static double __pyx_f_7PyTorch_13_DoubleTensor_get2d(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_v_x1, int __pyx_skip_dispatch); /* proto*/
static int __pyx_f_7PyTorch_13_DoubleTensor_isContiguous(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, int __pyx_skip_dispatch); /* proto*/
static double __pyx_f_7PyTorch_13_DoubleTensor_max(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, int __pyx_skip_dispatch); /* proto*/
static double __pyx_f_7PyTorch_13_DoubleTensor_min(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, int __pyx_skip_dispatch); /* proto*/
static unsigned char *__pyx_f_7PyTorch_11_ByteTensor_data(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self); /* proto*/
static int __pyx_f_7PyTorch_11_ByteTensor_dims(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, int __pyx_skip_dispatch); /* proto*/
static PyObject *__pyx_f_7PyTorch_11_ByteTensor_set1d(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, int __pyx_v_x0, unsigned char __pyx_v_value, int __pyx_skip_dispatch); /* proto*/
static PyObject *__pyx_f_7PyTorch_11_ByteTensor_set2d(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_v_x1, unsigned char __pyx_v_value, int __pyx_skip_dispatch); /* proto*/
static unsigned char __pyx_f_7PyTorch_11_ByteTensor_get1d(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_skip_dispatch); /* proto*/
static unsigned char __pyx_f_7PyTorch_11_ByteTensor_get2d(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_v_x1, int __pyx_skip_dispatch); /* proto*/
static int __pyx_f_7PyTorch_11_ByteTensor_isContiguous(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, int __pyx_skip_dispatch); /* proto*/
static unsigned char __pyx_f_7PyTorch_11_ByteTensor_max(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, int __pyx_skip_dispatch); /* proto*/
static unsigned char __pyx_f_7PyTorch_11_ByteTensor_min(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, int __pyx_skip_dispatch); /* proto*/
static PyObject *__pyx_array_get_memview(struct __pyx_array_obj *__pyx_v_self); /* proto*/
static char *__pyx_memoryview_get_item_pointer(struct __pyx_memoryview_obj *__pyx_v_self, PyObject *__pyx_v_index); /* proto*/
static PyObject *__pyx_memoryview_is_slice(struct __pyx_memoryview_obj *__pyx_v_self, PyObject *__pyx_v_obj); /* proto*/
static PyObject *__pyx_memoryview_setitem_slice_assignment(struct __pyx_memoryview_obj *__pyx_v_self, PyObject *__pyx_v_dst, PyObject *__pyx_v_src); /* proto*/
static PyObject *__pyx_memoryview_setitem_slice_assign_scalar(struct __pyx_memoryview_obj *__pyx_v_self, struct __pyx_memoryview_obj *__pyx_v_dst, PyObject *__pyx_v_value); /* proto*/
static PyObject *__pyx_memoryview_setitem_indexed(struct __pyx_memoryview_obj *__pyx_v_self, PyObject *__pyx_v_index, PyObject *__pyx_v_value); /* proto*/
static PyObject *__pyx_memoryview_convert_item_to_object(struct __pyx_memoryview_obj *__pyx_v_self, char *__pyx_v_itemp); /* proto*/
static PyObject *__pyx_memoryview_assign_item_from_object(struct __pyx_memoryview_obj *__pyx_v_self, char *__pyx_v_itemp, PyObject *__pyx_v_value); /* proto*/
static PyObject *__pyx_memoryviewslice_convert_item_to_object(struct __pyx_memoryviewslice_obj *__pyx_v_self, char *__pyx_v_itemp); /* proto*/
static PyObject *__pyx_memoryviewslice_assign_item_from_object(struct __pyx_memoryviewslice_obj *__pyx_v_self, char *__pyx_v_itemp, PyObject *__pyx_v_value); /* proto*/

/* Module declarations from 'cython.view' */

/* Module declarations from 'cython' */

/* Module declarations from 'libc.string' */

/* Module declarations from 'libc.stdio' */

/* Module declarations from '__builtin__' */

/* Module declarations from 'cpython.type' */
static PyTypeObject *__pyx_ptype_7cpython_4type_type = 0;

/* Module declarations from 'cpython.ref' */

/* Module declarations from 'cpython.exc' */

/* Module declarations from 'cpython.mem' */

/* Module declarations from 'array' */

/* Module declarations from 'cpython' */

/* Module declarations from 'cpython.object' */

/* Module declarations from 'cpython.array' */
static PyTypeObject *__pyx_ptype_7cpython_5array_array = 0;
static CYTHON_INLINE int __pyx_f_7cpython_5array_extend_buffer(arrayobject *, char *, Py_ssize_t); /*proto*/

/* Module declarations from 'Storage' */
static PyTypeObject *__pyx_ptype_7Storage__LongStorage = 0;
static PyTypeObject *__pyx_ptype_7Storage__FloatStorage = 0;
static PyTypeObject *__pyx_ptype_7Storage__DoubleStorage = 0;
static PyTypeObject *__pyx_ptype_7Storage__ByteStorage = 0;
static PyObject *(*__pyx_f_7Storage__LongStorage_fromNative)(struct THLongStorage *, struct __pyx_opt_args_7Storage__LongStorage_fromNative *__pyx_optional_args); /*proto*/
static PyObject *(*__pyx_f_7Storage__FloatStorage_fromNative)(struct THFloatStorage *, struct __pyx_opt_args_7Storage__FloatStorage_fromNative *__pyx_optional_args); /*proto*/
static PyObject *(*__pyx_f_7Storage__DoubleStorage_fromNative)(struct THDoubleStorage *, struct __pyx_opt_args_7Storage__DoubleStorage_fromNative *__pyx_optional_args); /*proto*/
static PyObject *(*__pyx_f_7Storage__ByteStorage_fromNative)(struct THByteStorage *, struct __pyx_opt_args_7Storage__ByteStorage_fromNative *__pyx_optional_args); /*proto*/

/* Module declarations from 'lua' */
static PyTypeObject *__pyx_ptype_3lua_LuaState = 0;
static PyObject *(*__pyx_f_3lua_LuaState_fromNative)(struct lua_State *); /*proto*/

/* Module declarations from 'nnWrapper' */

/* Module declarations from 'PyTorch' */
static PyTypeObject *__pyx_ptype_7PyTorch__LongTensor = 0;
static PyTypeObject *__pyx_ptype_7PyTorch__FloatTensor = 0;
static PyTypeObject *__pyx_ptype_7PyTorch__DoubleTensor = 0;
static PyTypeObject *__pyx_ptype_7PyTorch__ByteTensor = 0;
static PyTypeObject *__pyx_ptype_7PyTorch_GlobalState = 0;
static PyTypeObject *__pyx_ptype_7PyTorch_Nn = 0;
static PyTypeObject *__pyx_array_type = 0;
static PyTypeObject *__pyx_MemviewEnum_type = 0;
static PyTypeObject *__pyx_memoryview_type = 0;
static PyTypeObject *__pyx_memoryviewslice_type = 0;
static struct __pyx_obj_7PyTorch_GlobalState *__pyx_v_7PyTorch_globalState = 0;
static PyObject *generic = 0;
static PyObject *strided = 0;
static PyObject *indirect = 0;
static PyObject *contiguous = 0;
static PyObject *indirect_contiguous = 0;
static int __pyx_memoryview_thread_locks_used;
static PyThread_type_lock __pyx_memoryview_thread_locks[8];
static PyObject *__pyx_f_7PyTorch_floatToString(float); /*proto*/
static PyObject *__pyx_f_7PyTorch__LongTensor_fromNative(struct THLongTensor *, struct __pyx_opt_args_7PyTorch__LongTensor_fromNative *__pyx_optional_args); /*proto*/
static PyObject *__pyx_f_7PyTorch__FloatTensor_fromNative(struct THFloatTensor *, struct __pyx_opt_args_7PyTorch__FloatTensor_fromNative *__pyx_optional_args); /*proto*/
static PyObject *__pyx_f_7PyTorch__DoubleTensor_fromNative(struct THDoubleTensor *, struct __pyx_opt_args_7PyTorch__DoubleTensor_fromNative *__pyx_optional_args); /*proto*/
static PyObject *__pyx_f_7PyTorch__ByteTensor_fromNative(struct THByteTensor *, struct __pyx_opt_args_7PyTorch__ByteTensor_fromNative *__pyx_optional_args); /*proto*/
static int __pyx_f_7PyTorch_getFloatPrediction(struct __pyx_obj_7PyTorch__FloatTensor *, int __pyx_skip_dispatch); /*proto*/
static int __pyx_f_7PyTorch_getDoublePrediction(struct __pyx_obj_7PyTorch__DoubleTensor *, int __pyx_skip_dispatch); /*proto*/
static struct __pyx_array_obj *__pyx_array_new(PyObject *, Py_ssize_t, char *, char *, char *); /*proto*/
static void *__pyx_align_pointer(void *, size_t); /*proto*/
static PyObject *__pyx_memoryview_new(PyObject *, int, int, __Pyx_TypeInfo *); /*proto*/
static CYTHON_INLINE int __pyx_memoryview_check(PyObject *); /*proto*/
static PyObject *_unellipsify(PyObject *, int); /*proto*/
static PyObject *assert_direct_dimensions(Py_ssize_t *, int); /*proto*/
static struct __pyx_memoryview_obj *__pyx_memview_slice(struct __pyx_memoryview_obj *, PyObject *); /*proto*/
static int __pyx_memoryview_slice_memviewslice(__Pyx_memviewslice *, Py_ssize_t, Py_ssize_t, Py_ssize_t, int, int, int *, Py_ssize_t, Py_ssize_t, Py_ssize_t, int, int, int, int); /*proto*/
static char *__pyx_pybuffer_index(Py_buffer *, char *, Py_ssize_t, Py_ssize_t); /*proto*/
static int __pyx_memslice_transpose(__Pyx_memviewslice *); /*proto*/
static PyObject *__pyx_memoryview_fromslice(__Pyx_memviewslice, int, PyObject *(*)(char *), int (*)(char *, PyObject *), int); /*proto*/
static __Pyx_memviewslice *__pyx_memoryview_get_slice_from_memoryview(struct __pyx_memoryview_obj *, __Pyx_memviewslice *); /*proto*/
static void __pyx_memoryview_slice_copy(struct __pyx_memoryview_obj *, __Pyx_memviewslice *); /*proto*/
static PyObject *__pyx_memoryview_copy_object(struct __pyx_memoryview_obj *); /*proto*/
static PyObject *__pyx_memoryview_copy_object_from_slice(struct __pyx_memoryview_obj *, __Pyx_memviewslice *); /*proto*/
static Py_ssize_t abs_py_ssize_t(Py_ssize_t); /*proto*/
static char __pyx_get_best_slice_order(__Pyx_memviewslice *, int); /*proto*/
static void _copy_strided_to_strided(char *, Py_ssize_t *, char *, Py_ssize_t *, Py_ssize_t *, Py_ssize_t *, int, size_t); /*proto*/
static void copy_strided_to_strided(__Pyx_memviewslice *, __Pyx_memviewslice *, int, size_t); /*proto*/
static Py_ssize_t __pyx_memoryview_slice_get_size(__Pyx_memviewslice *, int); /*proto*/
static Py_ssize_t __pyx_fill_contig_strides_array(Py_ssize_t *, Py_ssize_t *, Py_ssize_t, int, char); /*proto*/
static void *__pyx_memoryview_copy_data_to_temp(__Pyx_memviewslice *, __Pyx_memviewslice *, char, int); /*proto*/
static int __pyx_memoryview_err_extents(int, Py_ssize_t, Py_ssize_t); /*proto*/
static int __pyx_memoryview_err_dim(PyObject *, char *, int); /*proto*/
static int __pyx_memoryview_err(PyObject *, char *); /*proto*/
static int __pyx_memoryview_copy_contents(__Pyx_memviewslice, __Pyx_memviewslice, int, int, int); /*proto*/
static void __pyx_memoryview_broadcast_leading(__Pyx_memviewslice *, int, int); /*proto*/
static void __pyx_memoryview_refcount_copying(__Pyx_memviewslice *, int, int, int); /*proto*/
static void __pyx_memoryview_refcount_objects_in_slice_with_gil(char *, Py_ssize_t *, Py_ssize_t *, int, int); /*proto*/
static void __pyx_memoryview_refcount_objects_in_slice(char *, Py_ssize_t *, Py_ssize_t *, int, int); /*proto*/
static void __pyx_memoryview_slice_assign_scalar(__Pyx_memviewslice *, int, size_t, void *, int); /*proto*/
static void __pyx_memoryview__slice_assign_scalar(char *, Py_ssize_t *, Py_ssize_t *, int, size_t, void *); /*proto*/
static __Pyx_TypeInfo __Pyx_TypeInfo_float = { "float", NULL, sizeof(float), { 0 }, 0, 'R', 0, 0 };
static __Pyx_TypeInfo __Pyx_TypeInfo_double = { "double", NULL, sizeof(double), { 0 }, 0, 'R', 0, 0 };
static __Pyx_TypeInfo __Pyx_TypeInfo_unsigned_char = { "unsigned char", NULL, sizeof(unsigned char), { 0 }, 0, IS_UNSIGNED(unsigned char) ? 'U' : 'I', IS_UNSIGNED(unsigned char), 0 };
#define __Pyx_MODULE_NAME "PyTorch"
int __pyx_module_is_main_PyTorch = 0;

/* Implementation of 'PyTorch' */
static PyObject *__pyx_builtin_staticmethod;
static PyObject *__pyx_builtin_round;
static PyObject *__pyx_builtin_range;
static PyObject *__pyx_builtin_MemoryError;
static PyObject *__pyx_builtin_ValueError;
static PyObject *__pyx_builtin_enumerate;
static PyObject *__pyx_builtin_Ellipsis;
static PyObject *__pyx_builtin_TypeError;
static PyObject *__pyx_builtin_id;
static PyObject *__pyx_builtin_IndexError;
static const char __pyx_k_L[] = "L";
static const char __pyx_k_O[] = "O";
static const char __pyx_k_a[] = "a";
static const char __pyx_k_b[] = "b";
static const char __pyx_k_c[] = "c";
static const char __pyx_k_d[] = "d";
static const char __pyx_k_p[] = "p";
static const char __pyx_k_x[] = "x";
static const char __pyx_k_0f[] = "%.0f";
static const char __pyx_k_6g[] = "%.6g";
static const char __pyx_k__7[] = "";
static const char __pyx_k__8[] = " ";
static const char __pyx_k__9[] = "\n";
static const char __pyx_k_id[] = "id";
static const char __pyx_k_np[] = "np";
static const char __pyx_k_x0[] = "x0";
static const char __pyx_k_x1[] = "x1";
static const char __pyx_k__10[] = "]\n";
static const char __pyx_k__11[] = "(";
static const char __pyx_k__12[] = ",.,.) =\n";
static const char __pyx_k__13[] = "]";
static const char __pyx_k_max[] = "max";
static const char __pyx_k_min[] = "min";
static const char __pyx_k_new[] = "new";
static const char __pyx_k_obj[] = "obj";
static const char __pyx_k_sig[] = "sig";
static const char __pyx_k__129[] = "*";
static const char __pyx_k_base[] = "base";
static const char __pyx_k_dims[] = "dims";
static const char __pyx_k_init[] = "init";
static const char __pyx_k_main[] = "__main__";
static const char __pyx_k_math[] = "math";
static const char __pyx_k_mean[] = "mean";
static const char __pyx_k_mode[] = "mode";
static const char __pyx_k_name[] = "name";
static const char __pyx_k_ndim[] = "ndim";
static const char __pyx_k_pack[] = "pack";
static const char __pyx_k_seed[] = "seed";
static const char __pyx_k_size[] = "size";
static const char __pyx_k_stdv[] = "stdv";
static const char __pyx_k_step[] = "step";
static const char __pyx_k_stop[] = "stop";
static const char __pyx_k_test[] = "__test__";
static const char __pyx_k_ASCII[] = "ASCII";
static const char __pyx_k_array[] = "array";
static const char __pyx_k_class[] = "__class__";
static const char __pyx_k_debug[] = "debug";
static const char __pyx_k_dtype[] = "dtype";
static const char __pyx_k_error[] = "error";
static const char __pyx_k_flags[] = "flags";
static const char __pyx_k_floor[] = "floor";
static const char __pyx_k_get1d[] = "get1d";
static const char __pyx_k_get2d[] = "get2d";
static const char __pyx_k_log10[] = "log10";
static const char __pyx_k_numpy[] = "numpy";
static const char __pyx_k_range[] = "range";
static const char __pyx_k_round[] = "round";
static const char __pyx_k_set1d[] = "set1d";
static const char __pyx_k_set2d[] = "set2d";
static const char __pyx_k_shape[] = "shape";
static const char __pyx_k_sigma[] = "sigma";
static const char __pyx_k_size0[] = "size0";
static const char __pyx_k_size1[] = "size1";
static const char __pyx_k_size2[] = "size2";
static const char __pyx_k_size3[] = "size3";
static const char __pyx_k_start[] = "start";
static const char __pyx_k_uint8[] = "uint8";
static const char __pyx_k_utf_8[] = "utf-8";
static const char __pyx_k_value[] = "value";
static const char __pyx_k_zeros[] = "zeros";
static const char __pyx_k_Number[] = "Number";
static const char __pyx_k_encode[] = "encode";
static const char __pyx_k_format[] = "format";
static const char __pyx_k_import[] = "__import__";
static const char __pyx_k_lambda[] = "_lambda";
static const char __pyx_k_logger[] = "logger";
static const char __pyx_k_median[] = "median";
static const char __pyx_k_name_2[] = "__name__";
static const char __pyx_k_offset[] = "offset";
static const char __pyx_k_resize[] = "resize";
static const char __pyx_k_stride[] = "stride";
static const char __pyx_k_struct[] = "struct";
static const char __pyx_k_tensor[] = "tensor";
static const char __pyx_k_unpack[] = "unpack";
static const char __pyx_k_PyTorch[] = "PyTorch";
static const char __pyx_k_Storage[] = "Storage";
static const char __pyx_k_float32[] = "float32";
static const char __pyx_k_float64[] = "float64";
static const char __pyx_k_fortran[] = "fortran";
static const char __pyx_k_libName[] = "libName";
static const char __pyx_k_logging[] = "logging";
static const char __pyx_k_memview[] = "memview";
static const char __pyx_k_myarray[] = "myarray";
static const char __pyx_k_numbers[] = "numbers";
static const char __pyx_k_require[] = "require";
static const char __pyx_k_reshape[] = "reshape";
static const char __pyx_k_storage[] = "storage";
static const char __pyx_k_stride0[] = "stride0";
static const char __pyx_k_stride1[] = "stride1";
static const char __pyx_k_stride2[] = "stride2";
static const char __pyx_k_stride3[] = "stride3";
static const char __pyx_k_tensorC[] = "tensorC";
static const char __pyx_k_Ellipsis[] = "Ellipsis";
static const char __pyx_k_allocate[] = "_allocate";
static const char __pyx_k_itemsize[] = "itemsize";
static const char __pyx_k_resize2d[] = "resize2d";
static const char __pyx_k_TypeError[] = "TypeError";
static const char __pyx_k_as_string[] = "as_string";
static const char __pyx_k_dimension[] = "dimension";
static const char __pyx_k_enumerate[] = "enumerate";
static const char __pyx_k_getGlobal[] = "getGlobal";
static const char __pyx_k_getLogger[] = "getLogger";
static const char __pyx_k_myarraymv[] = "myarraymv";
static const char __pyx_k_round_sig[] = "round_sig";
static const char __pyx_k_show_size[] = "show_size";
static const char __pyx_k_totalSize[] = "totalSize";
static const char __pyx_k_IndexError[] = "IndexError";
static const char __pyx_k_ValueError[] = "ValueError";
static const char __pyx_k_contiguous[] = "contiguous";
static const char __pyx_k_firstIndex[] = "firstIndex";
static const char __pyx_k_manualSeed[] = "manualSeed";
static const char __pyx_k_newTensorC[] = "newTensorC";
static const char __pyx_k_pyx_vtable[] = "__pyx_vtable__";
static const char __pyx_k_ByteStorage[] = "_ByteStorage";
static const char __pyx_k_LongStorage[] = "_LongStorage";
static const char __pyx_k_MemoryError[] = "MemoryError";
static const char __pyx_k_basicConfig[] = "basicConfig";
static const char __pyx_k_floattensor[] = "floattensor";
static const char __pyx_k_newWithData[] = "newWithData";
static const char __pyx_k_newWithSize[] = "newWithSize";
static const char __pyx_k_strideSoFar[] = "strideSoFar";
static const char __pyx_k_FloatStorage[] = "_FloatStorage";
static const char __pyx_k_asByteTensor[] = "_asByteTensor";
static const char __pyx_k_isContiguous[] = "isContiguous";
static const char __pyx_k_staticmethod[] = "staticmethod";
static const char __pyx_k_DoubleStorage[] = "_DoubleStorage";
static const char __pyx_k_asFloatTensor[] = "_asFloatTensor";
static const char __pyx_k_popByteTensor[] = "_popByteTensor";
static const char __pyx_k_pyx_getbuffer[] = "__pyx_getbuffer";
static const char __pyx_k_asDoubleTensor[] = "_asDoubleTensor";
static const char __pyx_k_getGlobalState[] = "getGlobalState";
static const char __pyx_k_newWithStorage[] = "newWithStorage";
static const char __pyx_k_popFloatTensor[] = "_popFloatTensor";
static const char __pyx_k_pushByteTensor[] = "_pushByteTensor";
static const char __pyx_k_allocate_buffer[] = "allocate_buffer";
static const char __pyx_k_dtype_is_object[] = "dtype_is_object";
static const char __pyx_k_not_implemented[] = "not implemented";
static const char __pyx_k_popDoubleTensor[] = "_popDoubleTensor";
static const char __pyx_k_pushFloatTensor[] = "_pushFloatTensor";
static const char __pyx_k_newWithStorage1d[] = "newWithStorage1d";
static const char __pyx_k_newWithStorage2d[] = "newWithStorage2d";
static const char __pyx_k_newWithStorage3d[] = "newWithStorage3d";
static const char __pyx_k_newWithStorage4d[] = "newWithStorage4d";
static const char __pyx_k_pushDoubleTensor[] = "_pushDoubleTensor";
static const char __pyx_k_Raising_exception[] = "Raising exception...";
static const char __pyx_k_ByteTensor___cinit[] = "ByteTensor.__cinit__";
static const char __pyx_k_LongTensor___cinit[] = "LongTensor.__cinit__";
static const char __pyx_k_strided_and_direct[] = "<strided and direct>";
static const char __pyx_k_type_numpy_ndarray[] = "<type 'numpy.ndarray'>";
static const char __pyx_k_FloatTensor___cinit[] = "FloatTensor.__cinit__";
static const char __pyx_k_class_numpy_ndarray[] = "<class 'numpy.ndarray'>";
static const char __pyx_k_DoubleTensor___cinit[] = "DoubleTensor.__cinit__";
static const char __pyx_k_strided_and_indirect[] = "<strided and indirect>";
static const char __pyx_k_contiguous_and_direct[] = "<contiguous and direct>";
static const char __pyx_k_MemoryView_of_r_object[] = "<MemoryView of %r object>";
static const char __pyx_k_Not_implemented_dims_2[] = "Not implemented: dims > 2";
static const char __pyx_k_MemoryView_of_r_at_0x_x[] = "<MemoryView of %r at 0x%x>";
static const char __pyx_k_contiguous_and_indirect[] = "<contiguous and indirect>";
static const char __pyx_k_Cannot_index_with_type_s[] = "Cannot index with type '%s'";
static const char __pyx_k_Not_implemented_for_dims[] = "Not implemented for dims=";
static const char __pyx_k_Not_implemented_len_args[] = "Not implemented, len(args)=";
static const char __pyx_k_not_implemented_for_Byte[] = "not implemented for Byte";
static const char __pyx_k_not_implemented_for_Long[] = "not implemented for Long";
static const char __pyx_k_torch_ByteTensor_of_size[] = "[torch.ByteTensor of size ";
static const char __pyx_k_torch_LongTensor_of_size[] = "[torch.LongTensor of size ";
static const char __pyx_k_Invalid_shape_in_axis_d_d[] = "Invalid shape in axis %d: %d.";
static const char __pyx_k_not_implemented_for_Float[] = "not implemented for Float";
static const char __pyx_k_torch_FloatTensor_of_size[] = "[torch.FloatTensor of size ";
static const char __pyx_k_not_implemented_for_Double[] = "not implemented for Double";
static const char __pyx_k_torch_ByteTensor_of_size_2[] = "\ntorch.ByteTensor of size ";
static const char __pyx_k_torch_DoubleTensor_of_size[] = "[torch.DoubleTensor of size ";
static const char __pyx_k_torch_LongTensor_of_size_2[] = "\ntorch.LongTensor of size ";
static const char __pyx_k_Invalid_arg_type_for_second[] = "Invalid arg type for second: ";
static const char __pyx_k_itemsize_0_for_cython_array[] = "itemsize <= 0 for cython.array";
static const char __pyx_k_torch_FloatTensor_of_size_2[] = "\ntorch.FloatTensor of size ";
static const char __pyx_k_torch_DoubleTensor_of_size_2[] = "\ntorch.DoubleTensor of size ";
static const char __pyx_k_Not_implemented_for_dims_dims[] = "Not implemented for dims = {dims}";
static const char __pyx_k_unable_to_allocate_array_data[] = "unable to allocate array data.";
static const char __pyx_k_dealloc___tensor_never_allocat[] = "__dealloc__ tensor never allocated";
static const char __pyx_k_strided_and_direct_or_indirect[] = "<strided and direct or indirect>";
static const char __pyx_k_home_steb_inst_pytorch_src_PyTo[] = "/home/steb/inst/pytorch/src/PyTorch.pyx";
static const char __pyx_k_torch_ByteTensor_with_no_dimens[] = "[torch.ByteTensor with no dimension]\n";
static const char __pyx_k_torch_DoubleTensor_with_no_dime[] = "[torch.DoubleTensor with no dimension]\n";
static const char __pyx_k_torch_FloatTensor_with_no_dimen[] = "[torch.FloatTensor with no dimension]\n";
static const char __pyx_k_torch_LongTensor_with_no_dimens[] = "[torch.LongTensor with no dimension]\n";
static const char __pyx_k_Buffer_view_does_not_expose_stri[] = "Buffer view does not expose strides";
static const char __pyx_k_Can_only_create_a_buffer_that_is[] = "Can only create a buffer that is contiguous in memory.";
static const char __pyx_k_Empty_shape_tuple_for_cython_arr[] = "Empty shape tuple for cython.array";
static const char __pyx_k_Indirect_dimensions_not_supporte[] = "Indirect dimensions not supported";
static const char __pyx_k_Invalid_mode_expected_c_or_fortr[] = "Invalid mode, expected 'c' or 'fortran', got %s";
static const char __pyx_k_Out_of_bounds_on_buffer_access_a[] = "Out of bounds on buffer access (axis %d)";
static const char __pyx_k_Unable_to_convert_item_to_object[] = "Unable to convert item to object";
static const char __pyx_k_Unallocated_an_already_deallocat[] = "Unallocated an already deallocated tensor... :-O";
static const char __pyx_k_cannot_provide_arguments_to_init[] = "cannot provide arguments to initializer";
static const char __pyx_k_dims_dims_not_implemented_please[] = "dims == {dims} not implemented; please raise an issue";
static const char __pyx_k_got_differing_extents_in_dimensi[] = "got differing extents in dimension %d (got %d and %d)";
static const char __pyx_k_unable_to_allocate_shape_and_str[] = "unable to allocate shape and strides.";
static PyObject *__pyx_kp_s_0f;
static PyObject *__pyx_kp_s_6g;
static PyObject *__pyx_n_s_ASCII;
static PyObject *__pyx_kp_s_Buffer_view_does_not_expose_stri;
static PyObject *__pyx_n_s_ByteStorage;
static PyObject *__pyx_kp_s_ByteTensor___cinit;
static PyObject *__pyx_kp_s_Can_only_create_a_buffer_that_is;
static PyObject *__pyx_kp_s_Cannot_index_with_type_s;
static PyObject *__pyx_n_s_DoubleStorage;
static PyObject *__pyx_kp_s_DoubleTensor___cinit;
static PyObject *__pyx_n_s_Ellipsis;
static PyObject *__pyx_kp_s_Empty_shape_tuple_for_cython_arr;
static PyObject *__pyx_n_s_FloatStorage;
static PyObject *__pyx_kp_s_FloatTensor___cinit;
static PyObject *__pyx_n_s_IndexError;
static PyObject *__pyx_kp_s_Indirect_dimensions_not_supporte;
static PyObject *__pyx_kp_s_Invalid_arg_type_for_second;
static PyObject *__pyx_kp_s_Invalid_mode_expected_c_or_fortr;
static PyObject *__pyx_kp_s_Invalid_shape_in_axis_d_d;
static PyObject *__pyx_n_s_L;
static PyObject *__pyx_n_s_LongStorage;
static PyObject *__pyx_kp_s_LongTensor___cinit;
static PyObject *__pyx_n_s_MemoryError;
static PyObject *__pyx_kp_s_MemoryView_of_r_at_0x_x;
static PyObject *__pyx_kp_s_MemoryView_of_r_object;
static PyObject *__pyx_kp_s_Not_implemented_dims_2;
static PyObject *__pyx_kp_s_Not_implemented_for_dims;
static PyObject *__pyx_kp_s_Not_implemented_for_dims_dims;
static PyObject *__pyx_kp_s_Not_implemented_len_args;
static PyObject *__pyx_n_s_Number;
static PyObject *__pyx_n_b_O;
static PyObject *__pyx_kp_s_Out_of_bounds_on_buffer_access_a;
static PyObject *__pyx_n_s_PyTorch;
static PyObject *__pyx_kp_s_Raising_exception;
static PyObject *__pyx_n_s_Storage;
static PyObject *__pyx_n_s_TypeError;
static PyObject *__pyx_kp_s_Unable_to_convert_item_to_object;
static PyObject *__pyx_kp_s_Unallocated_an_already_deallocat;
static PyObject *__pyx_n_s_ValueError;
static PyObject *__pyx_kp_s__10;
static PyObject *__pyx_kp_s__11;
static PyObject *__pyx_kp_s__12;
static PyObject *__pyx_n_s__129;
static PyObject *__pyx_kp_s__13;
static PyObject *__pyx_kp_s__7;
static PyObject *__pyx_kp_s__8;
static PyObject *__pyx_kp_s__9;
static PyObject *__pyx_n_s_a;
static PyObject *__pyx_n_s_allocate;
static PyObject *__pyx_n_s_allocate_buffer;
static PyObject *__pyx_n_s_array;
static PyObject *__pyx_n_s_asByteTensor;
static PyObject *__pyx_n_s_asDoubleTensor;
static PyObject *__pyx_n_s_asFloatTensor;
static PyObject *__pyx_n_s_as_string;
static PyObject *__pyx_n_s_b;
static PyObject *__pyx_n_s_base;
static PyObject *__pyx_n_s_basicConfig;
static PyObject *__pyx_n_s_c;
static PyObject *__pyx_n_u_c;
static PyObject *__pyx_kp_s_cannot_provide_arguments_to_init;
static PyObject *__pyx_n_s_class;
static PyObject *__pyx_kp_s_class_numpy_ndarray;
static PyObject *__pyx_n_s_contiguous;
static PyObject *__pyx_kp_s_contiguous_and_direct;
static PyObject *__pyx_kp_s_contiguous_and_indirect;
static PyObject *__pyx_n_s_d;
static PyObject *__pyx_kp_s_dealloc___tensor_never_allocat;
static PyObject *__pyx_n_s_debug;
static PyObject *__pyx_n_s_dimension;
static PyObject *__pyx_n_s_dims;
static PyObject *__pyx_kp_s_dims_dims_not_implemented_please;
static PyObject *__pyx_n_s_dtype;
static PyObject *__pyx_n_s_dtype_is_object;
static PyObject *__pyx_n_s_encode;
static PyObject *__pyx_n_s_enumerate;
static PyObject *__pyx_n_s_error;
static PyObject *__pyx_n_s_firstIndex;
static PyObject *__pyx_n_s_flags;
static PyObject *__pyx_n_s_float32;
static PyObject *__pyx_n_s_float64;
static PyObject *__pyx_n_s_floattensor;
static PyObject *__pyx_n_s_floor;
static PyObject *__pyx_n_s_format;
static PyObject *__pyx_n_s_fortran;
static PyObject *__pyx_n_u_fortran;
static PyObject *__pyx_n_s_get1d;
static PyObject *__pyx_n_s_get2d;
static PyObject *__pyx_n_s_getGlobal;
static PyObject *__pyx_n_s_getGlobalState;
static PyObject *__pyx_n_s_getLogger;
static PyObject *__pyx_kp_s_got_differing_extents_in_dimensi;
static PyObject *__pyx_kp_s_home_steb_inst_pytorch_src_PyTo;
static PyObject *__pyx_n_s_id;
static PyObject *__pyx_n_s_import;
static PyObject *__pyx_n_s_init;
static PyObject *__pyx_n_s_isContiguous;
static PyObject *__pyx_n_s_itemsize;
static PyObject *__pyx_kp_s_itemsize_0_for_cython_array;
static PyObject *__pyx_n_s_lambda;
static PyObject *__pyx_n_s_libName;
static PyObject *__pyx_n_s_log10;
static PyObject *__pyx_n_s_logger;
static PyObject *__pyx_n_s_logging;
static PyObject *__pyx_n_s_main;
static PyObject *__pyx_n_s_manualSeed;
static PyObject *__pyx_n_s_math;
static PyObject *__pyx_n_s_max;
static PyObject *__pyx_n_s_mean;
static PyObject *__pyx_n_s_median;
static PyObject *__pyx_n_s_memview;
static PyObject *__pyx_n_s_min;
static PyObject *__pyx_n_s_mode;
static PyObject *__pyx_n_s_myarray;
static PyObject *__pyx_n_s_myarraymv;
static PyObject *__pyx_n_s_name;
static PyObject *__pyx_n_s_name_2;
static PyObject *__pyx_n_s_ndim;
static PyObject *__pyx_n_s_new;
static PyObject *__pyx_n_s_newTensorC;
static PyObject *__pyx_n_s_newWithData;
static PyObject *__pyx_n_s_newWithSize;
static PyObject *__pyx_n_s_newWithStorage;
static PyObject *__pyx_n_s_newWithStorage1d;
static PyObject *__pyx_n_s_newWithStorage2d;
static PyObject *__pyx_n_s_newWithStorage3d;
static PyObject *__pyx_n_s_newWithStorage4d;
static PyObject *__pyx_kp_s_not_implemented;
static PyObject *__pyx_kp_s_not_implemented_for_Byte;
static PyObject *__pyx_kp_s_not_implemented_for_Double;
static PyObject *__pyx_kp_s_not_implemented_for_Float;
static PyObject *__pyx_kp_s_not_implemented_for_Long;
static PyObject *__pyx_n_s_np;
static PyObject *__pyx_n_s_numbers;
static PyObject *__pyx_n_s_numpy;
static PyObject *__pyx_n_s_obj;
static PyObject *__pyx_n_s_offset;
static PyObject *__pyx_n_s_p;
static PyObject *__pyx_n_s_pack;
static PyObject *__pyx_n_s_popByteTensor;
static PyObject *__pyx_n_s_popDoubleTensor;
static PyObject *__pyx_n_s_popFloatTensor;
static PyObject *__pyx_n_s_pushByteTensor;
static PyObject *__pyx_n_s_pushDoubleTensor;
static PyObject *__pyx_n_s_pushFloatTensor;
static PyObject *__pyx_n_s_pyx_getbuffer;
static PyObject *__pyx_n_s_pyx_vtable;
static PyObject *__pyx_n_s_range;
static PyObject *__pyx_n_s_require;
static PyObject *__pyx_n_s_reshape;
static PyObject *__pyx_n_s_resize;
static PyObject *__pyx_n_s_resize2d;
static PyObject *__pyx_n_s_round;
static PyObject *__pyx_n_s_round_sig;
static PyObject *__pyx_n_s_seed;
static PyObject *__pyx_n_s_set1d;
static PyObject *__pyx_n_s_set2d;
static PyObject *__pyx_n_s_shape;
static PyObject *__pyx_n_s_show_size;
static PyObject *__pyx_n_s_sig;
static PyObject *__pyx_n_s_sigma;
static PyObject *__pyx_n_s_size;
static PyObject *__pyx_n_s_size0;
static PyObject *__pyx_n_s_size1;
static PyObject *__pyx_n_s_size2;
static PyObject *__pyx_n_s_size3;
static PyObject *__pyx_n_s_start;
static PyObject *__pyx_n_s_staticmethod;
static PyObject *__pyx_n_s_stdv;
static PyObject *__pyx_n_s_step;
static PyObject *__pyx_n_s_stop;
static PyObject *__pyx_n_s_storage;
static PyObject *__pyx_n_s_stride;
static PyObject *__pyx_n_s_stride0;
static PyObject *__pyx_n_s_stride1;
static PyObject *__pyx_n_s_stride2;
static PyObject *__pyx_n_s_stride3;
static PyObject *__pyx_n_s_strideSoFar;
static PyObject *__pyx_kp_s_strided_and_direct;
static PyObject *__pyx_kp_s_strided_and_direct_or_indirect;
static PyObject *__pyx_kp_s_strided_and_indirect;
static PyObject *__pyx_n_s_struct;
static PyObject *__pyx_n_s_tensor;
static PyObject *__pyx_n_s_tensorC;
static PyObject *__pyx_n_s_test;
static PyObject *__pyx_kp_s_torch_ByteTensor_of_size;
static PyObject *__pyx_kp_s_torch_ByteTensor_of_size_2;
static PyObject *__pyx_kp_s_torch_ByteTensor_with_no_dimens;
static PyObject *__pyx_kp_s_torch_DoubleTensor_of_size;
static PyObject *__pyx_kp_s_torch_DoubleTensor_of_size_2;
static PyObject *__pyx_kp_s_torch_DoubleTensor_with_no_dime;
static PyObject *__pyx_kp_s_torch_FloatTensor_of_size;
static PyObject *__pyx_kp_s_torch_FloatTensor_of_size_2;
static PyObject *__pyx_kp_s_torch_FloatTensor_with_no_dimen;
static PyObject *__pyx_kp_s_torch_LongTensor_of_size;
static PyObject *__pyx_kp_s_torch_LongTensor_of_size_2;
static PyObject *__pyx_kp_s_torch_LongTensor_with_no_dimens;
static PyObject *__pyx_n_s_totalSize;
static PyObject *__pyx_kp_s_type_numpy_ndarray;
static PyObject *__pyx_n_s_uint8;
static PyObject *__pyx_kp_s_unable_to_allocate_array_data;
static PyObject *__pyx_kp_s_unable_to_allocate_shape_and_str;
static PyObject *__pyx_n_s_unpack;
static PyObject *__pyx_kp_s_utf_8;
static PyObject *__pyx_n_s_value;
static PyObject *__pyx_n_s_x;
static PyObject *__pyx_n_s_x0;
static PyObject *__pyx_n_s_x1;
static PyObject *__pyx_n_s_zeros;
static PyObject *__pyx_pf_7PyTorch_round_sig(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_x, PyObject *__pyx_v_sig); /* proto */
static PyObject *__pyx_pf_7PyTorch_2manualSeed(CYTHON_UNUSED PyObject *__pyx_self, long __pyx_v_seed); /* proto */
static int __pyx_pf_7PyTorch_11_LongTensor___cinit__(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, PyObject *__pyx_v__allocate, PyObject *__pyx_v_args); /* proto */
static void __pyx_pf_7PyTorch_11_LongTensor_2__dealloc__(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_4nElement(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_6asNumpyTensor(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_8refCount___get__(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_8dims(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_10set1d(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, int __pyx_v_x0, long __pyx_v_value); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_12set2d(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_v_x1, long __pyx_v_value); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_14get1d(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, int __pyx_v_x0); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_16get2d(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_v_x1); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_18isContiguous(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_20max(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_22min(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_24__repr__(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_26as_string(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, PyObject *__pyx_v_show_size); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_28__getitem__(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, int __pyx_v_index); /* proto */
static int __pyx_pf_7PyTorch_11_LongTensor_30__setitem__(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, int __pyx_v_index, long __pyx_v_value); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_32fill(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, long __pyx_v_value); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_34sum(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_36abs(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_38iabs(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_40size(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_42new(); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_44narrow(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, int __pyx_v_dimension, long __pyx_v_firstIndex, long __pyx_v_size); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_46contiguous(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_48resize1d(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, int __pyx_v_size0); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_50resize2d(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, int __pyx_v_size0, int __pyx_v_size1); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_52resize3d(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, int __pyx_v_size0, int __pyx_v_size1, int __pyx_v_size2); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_54resize4d(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, int __pyx_v_size0, int __pyx_v_size1, int __pyx_v_size2, int __pyx_v_size3); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_56resizeAs(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_model); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_58resize(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, struct __pyx_obj_7Storage__LongStorage *__pyx_v_size); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_60newWithStorage(struct __pyx_obj_7Storage__LongStorage *__pyx_v_storage, PyObject *__pyx_v_offset, struct __pyx_obj_7Storage__LongStorage *__pyx_v_size, struct __pyx_obj_7Storage__LongStorage *__pyx_v_stride); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_62newWithStorage1d(struct __pyx_obj_7Storage__LongStorage *__pyx_v_storage, PyObject *__pyx_v_offset, PyObject *__pyx_v_size0, PyObject *__pyx_v_stride0); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_64newWithStorage2d(struct __pyx_obj_7Storage__LongStorage *__pyx_v_storage, PyObject *__pyx_v_offset, PyObject *__pyx_v_size0, PyObject *__pyx_v_stride0, PyObject *__pyx_v_size1, PyObject *__pyx_v_stride1); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_66newWithStorage3d(struct __pyx_obj_7Storage__LongStorage *__pyx_v_storage, PyObject *__pyx_v_offset, PyObject *__pyx_v_size0, PyObject *__pyx_v_stride0, PyObject *__pyx_v_size1, PyObject *__pyx_v_stride1, PyObject *__pyx_v_size2, PyObject *__pyx_v_stride2); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_68newWithStorage4d(struct __pyx_obj_7Storage__LongStorage *__pyx_v_storage, PyObject *__pyx_v_offset, PyObject *__pyx_v_size0, PyObject *__pyx_v_stride0, PyObject *__pyx_v_size1, PyObject *__pyx_v_stride1, PyObject *__pyx_v_size2, PyObject *__pyx_v_stride2, PyObject *__pyx_v_size3, PyObject *__pyx_v_stride3); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_70clone(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_72storage(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_74__add__(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, PyObject *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_76cmul(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, PyObject *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_78__sub__(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, PyObject *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_80eq(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_82icmin(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, PyObject *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_84icmax(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, PyObject *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_86__floordiv__(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, PyObject *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_88__ifloordiv__(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, PyObject *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_90__iadd__(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, PyObject *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_92__isub__(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, PyObject *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_94__imul__(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, long __pyx_v_value); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_96__mul__(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, PyObject *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_98bernoulli(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, float __pyx_v_p); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_LongTensor_100geometric(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, float __pyx_v_p); /* proto */
static int __pyx_pf_7PyTorch_12_FloatTensor___cinit__(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, PyObject *__pyx_v__allocate, PyObject *__pyx_v_args); /* proto */
static void __pyx_pf_7PyTorch_12_FloatTensor_2__dealloc__(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_4nElement(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_6asNumpyTensor(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_8refCount___get__(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_8dims(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_10set1d(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, int __pyx_v_x0, float __pyx_v_value); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_12set2d(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_v_x1, float __pyx_v_value); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_14get1d(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, int __pyx_v_x0); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_16get2d(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_v_x1); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_18isContiguous(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_20max(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_22min(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_24__repr__(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_26as_string(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, PyObject *__pyx_v_show_size); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_28__getitem__(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, int __pyx_v_index); /* proto */
static int __pyx_pf_7PyTorch_12_FloatTensor_30__setitem__(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, int __pyx_v_index, float __pyx_v_value); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_32fill(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, float __pyx_v_value); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_34sum(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_36itanh(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_38isigmoid(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_40icinv(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_42tanh(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_44sigmoid(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_46cinv(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_48neg(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_50ineg(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_52abs(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_54iabs(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_56size(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_58new(); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_60narrow(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, int __pyx_v_dimension, long __pyx_v_firstIndex, long __pyx_v_size); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_62contiguous(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_64resize1d(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, int __pyx_v_size0); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_66resize2d(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, int __pyx_v_size0, int __pyx_v_size1); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_68resize3d(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, int __pyx_v_size0, int __pyx_v_size1, int __pyx_v_size2); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_70resize4d(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, int __pyx_v_size0, int __pyx_v_size1, int __pyx_v_size2, int __pyx_v_size3); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_72resizeAs(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_model); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_74resize(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, struct __pyx_obj_7Storage__LongStorage *__pyx_v_size); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_76newWithStorage(struct __pyx_obj_7Storage__FloatStorage *__pyx_v_storage, PyObject *__pyx_v_offset, struct __pyx_obj_7Storage__LongStorage *__pyx_v_size, struct __pyx_obj_7Storage__LongStorage *__pyx_v_stride); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_78newWithStorage1d(struct __pyx_obj_7Storage__FloatStorage *__pyx_v_storage, PyObject *__pyx_v_offset, PyObject *__pyx_v_size0, PyObject *__pyx_v_stride0); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_80newWithStorage2d(struct __pyx_obj_7Storage__FloatStorage *__pyx_v_storage, PyObject *__pyx_v_offset, PyObject *__pyx_v_size0, PyObject *__pyx_v_stride0, PyObject *__pyx_v_size1, PyObject *__pyx_v_stride1); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_82newWithStorage3d(struct __pyx_obj_7Storage__FloatStorage *__pyx_v_storage, PyObject *__pyx_v_offset, PyObject *__pyx_v_size0, PyObject *__pyx_v_stride0, PyObject *__pyx_v_size1, PyObject *__pyx_v_stride1, PyObject *__pyx_v_size2, PyObject *__pyx_v_stride2); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_84newWithStorage4d(struct __pyx_obj_7Storage__FloatStorage *__pyx_v_storage, PyObject *__pyx_v_offset, PyObject *__pyx_v_size0, PyObject *__pyx_v_stride0, PyObject *__pyx_v_size1, PyObject *__pyx_v_stride1, PyObject *__pyx_v_size2, PyObject *__pyx_v_stride2, PyObject *__pyx_v_size3, PyObject *__pyx_v_stride3); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_86clone(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_88storage(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_90__add__(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, PyObject *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_92cmul(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, PyObject *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_94__sub__(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, PyObject *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_96eq(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_98icmin(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, PyObject *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_100icmax(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, PyObject *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_102__truediv__(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, PyObject *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_104__itruediv__(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, PyObject *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_106__iadd__(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, PyObject *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_108__isub__(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, PyObject *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_110__imul__(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, float __pyx_v_value); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_112__mul__(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, PyObject *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_114bernoulli(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, float __pyx_v_p); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_116geometric(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, float __pyx_v_p); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_118normal(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, float __pyx_v_mean, float __pyx_v_stdv); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_120exponential(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, float __pyx_v__lambda); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_122cauchy(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, float __pyx_v_median, float __pyx_v_sigma); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_124logNormal(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, float __pyx_v_mean, float __pyx_v_stdv); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_126uniform(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, float __pyx_v_a, float __pyx_v_b); /* proto */
static PyObject *__pyx_pf_7PyTorch_4_asFloatTensor(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_myarray); /* proto */
static int __pyx_pf_7PyTorch_13_DoubleTensor___cinit__(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, PyObject *__pyx_v__allocate, PyObject *__pyx_v_args); /* proto */
static void __pyx_pf_7PyTorch_13_DoubleTensor_2__dealloc__(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_4nElement(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_6asNumpyTensor(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_8refCount___get__(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_8dims(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_10set1d(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, int __pyx_v_x0, double __pyx_v_value); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_12set2d(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_v_x1, double __pyx_v_value); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_14get1d(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, int __pyx_v_x0); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_16get2d(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_v_x1); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_18isContiguous(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_20max(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_22min(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_24__repr__(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_26as_string(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, PyObject *__pyx_v_show_size); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_28__getitem__(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, int __pyx_v_index); /* proto */
static int __pyx_pf_7PyTorch_13_DoubleTensor_30__setitem__(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, int __pyx_v_index, double __pyx_v_value); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_32fill(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, double __pyx_v_value); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_34sum(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_36itanh(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_38isigmoid(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_40icinv(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_42tanh(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_44sigmoid(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_46cinv(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_48neg(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_50ineg(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_52abs(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_54iabs(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_56size(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_58new(); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_60narrow(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, int __pyx_v_dimension, long __pyx_v_firstIndex, long __pyx_v_size); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_62contiguous(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_64resize1d(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, int __pyx_v_size0); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_66resize2d(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, int __pyx_v_size0, int __pyx_v_size1); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_68resize3d(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, int __pyx_v_size0, int __pyx_v_size1, int __pyx_v_size2); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_70resize4d(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, int __pyx_v_size0, int __pyx_v_size1, int __pyx_v_size2, int __pyx_v_size3); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_72resizeAs(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_model); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_74resize(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, struct __pyx_obj_7Storage__LongStorage *__pyx_v_size); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_76newWithStorage(struct __pyx_obj_7Storage__DoubleStorage *__pyx_v_storage, PyObject *__pyx_v_offset, struct __pyx_obj_7Storage__LongStorage *__pyx_v_size, struct __pyx_obj_7Storage__LongStorage *__pyx_v_stride); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_78newWithStorage1d(struct __pyx_obj_7Storage__DoubleStorage *__pyx_v_storage, PyObject *__pyx_v_offset, PyObject *__pyx_v_size0, PyObject *__pyx_v_stride0); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_80newWithStorage2d(struct __pyx_obj_7Storage__DoubleStorage *__pyx_v_storage, PyObject *__pyx_v_offset, PyObject *__pyx_v_size0, PyObject *__pyx_v_stride0, PyObject *__pyx_v_size1, PyObject *__pyx_v_stride1); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_82newWithStorage3d(struct __pyx_obj_7Storage__DoubleStorage *__pyx_v_storage, PyObject *__pyx_v_offset, PyObject *__pyx_v_size0, PyObject *__pyx_v_stride0, PyObject *__pyx_v_size1, PyObject *__pyx_v_stride1, PyObject *__pyx_v_size2, PyObject *__pyx_v_stride2); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_84newWithStorage4d(struct __pyx_obj_7Storage__DoubleStorage *__pyx_v_storage, PyObject *__pyx_v_offset, PyObject *__pyx_v_size0, PyObject *__pyx_v_stride0, PyObject *__pyx_v_size1, PyObject *__pyx_v_stride1, PyObject *__pyx_v_size2, PyObject *__pyx_v_stride2, PyObject *__pyx_v_size3, PyObject *__pyx_v_stride3); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_86clone(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_88storage(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_90__add__(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, PyObject *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_92cmul(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, PyObject *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_94__sub__(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, PyObject *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_96eq(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_98icmin(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, PyObject *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_100icmax(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, PyObject *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_102__truediv__(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, PyObject *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_104__itruediv__(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, PyObject *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_106__iadd__(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, PyObject *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_108__isub__(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, PyObject *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_110__imul__(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, double __pyx_v_value); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_112__mul__(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, PyObject *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_114bernoulli(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, float __pyx_v_p); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_116geometric(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, float __pyx_v_p); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_118normal(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, double __pyx_v_mean, double __pyx_v_stdv); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_120exponential(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, double __pyx_v__lambda); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_122cauchy(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, double __pyx_v_median, double __pyx_v_sigma); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_124logNormal(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, double __pyx_v_mean, double __pyx_v_stdv); /* proto */
static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_126uniform(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, double __pyx_v_a, double __pyx_v_b); /* proto */
static PyObject *__pyx_pf_7PyTorch_6_asDoubleTensor(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_myarray); /* proto */
static int __pyx_pf_7PyTorch_11_ByteTensor___cinit__(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, PyObject *__pyx_v__allocate, PyObject *__pyx_v_args); /* proto */
static void __pyx_pf_7PyTorch_11_ByteTensor_2__dealloc__(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_4nElement(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_6asNumpyTensor(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_8refCount___get__(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_8dims(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_10set1d(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, int __pyx_v_x0, unsigned char __pyx_v_value); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_12set2d(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_v_x1, unsigned char __pyx_v_value); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_14get1d(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, int __pyx_v_x0); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_16get2d(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_v_x1); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_18isContiguous(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_20max(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_22min(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_24__repr__(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_26as_string(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, PyObject *__pyx_v_show_size); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_28__getitem__(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, int __pyx_v_index); /* proto */
static int __pyx_pf_7PyTorch_11_ByteTensor_30__setitem__(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, int __pyx_v_index, unsigned char __pyx_v_value); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_32fill(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, unsigned char __pyx_v_value); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_34sum(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_36size(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_38new(); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_40narrow(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, int __pyx_v_dimension, long __pyx_v_firstIndex, long __pyx_v_size); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_42contiguous(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_44resize1d(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, int __pyx_v_size0); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_46resize2d(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, int __pyx_v_size0, int __pyx_v_size1); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_48resize3d(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, int __pyx_v_size0, int __pyx_v_size1, int __pyx_v_size2); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_50resize4d(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, int __pyx_v_size0, int __pyx_v_size1, int __pyx_v_size2, int __pyx_v_size3); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_52resizeAs(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_model); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_54resize(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, struct __pyx_obj_7Storage__LongStorage *__pyx_v_size); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_56newWithStorage(struct __pyx_obj_7Storage__ByteStorage *__pyx_v_storage, PyObject *__pyx_v_offset, struct __pyx_obj_7Storage__LongStorage *__pyx_v_size, struct __pyx_obj_7Storage__LongStorage *__pyx_v_stride); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_58newWithStorage1d(struct __pyx_obj_7Storage__ByteStorage *__pyx_v_storage, PyObject *__pyx_v_offset, PyObject *__pyx_v_size0, PyObject *__pyx_v_stride0); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_60newWithStorage2d(struct __pyx_obj_7Storage__ByteStorage *__pyx_v_storage, PyObject *__pyx_v_offset, PyObject *__pyx_v_size0, PyObject *__pyx_v_stride0, PyObject *__pyx_v_size1, PyObject *__pyx_v_stride1); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_62newWithStorage3d(struct __pyx_obj_7Storage__ByteStorage *__pyx_v_storage, PyObject *__pyx_v_offset, PyObject *__pyx_v_size0, PyObject *__pyx_v_stride0, PyObject *__pyx_v_size1, PyObject *__pyx_v_stride1, PyObject *__pyx_v_size2, PyObject *__pyx_v_stride2); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_64newWithStorage4d(struct __pyx_obj_7Storage__ByteStorage *__pyx_v_storage, PyObject *__pyx_v_offset, PyObject *__pyx_v_size0, PyObject *__pyx_v_stride0, PyObject *__pyx_v_size1, PyObject *__pyx_v_stride1, PyObject *__pyx_v_size2, PyObject *__pyx_v_stride2, PyObject *__pyx_v_size3, PyObject *__pyx_v_stride3); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_66clone(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_68storage(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_70__add__(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, PyObject *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_72cmul(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, PyObject *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_74__sub__(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, PyObject *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_76eq(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_78icmin(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, PyObject *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_80icmax(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, PyObject *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_82__floordiv__(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, PyObject *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_84__ifloordiv__(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, PyObject *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_86__iadd__(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, PyObject *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_88__isub__(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, PyObject *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_90__imul__(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, unsigned char __pyx_v_value); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_92__mul__(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, PyObject *__pyx_v_second); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_94bernoulli(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, float __pyx_v_p); /* proto */
static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_96geometric(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, float __pyx_v_p); /* proto */
static PyObject *__pyx_pf_7PyTorch_8_asByteTensor(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_myarray); /* proto */
static int __pyx_pf_7PyTorch_11GlobalState___cinit__(CYTHON_UNUSED struct __pyx_obj_7PyTorch_GlobalState *__pyx_v_self); /* proto */
static void __pyx_pf_7PyTorch_11GlobalState_2__dealloc__(CYTHON_UNUSED struct __pyx_obj_7PyTorch_GlobalState *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_11GlobalState_4getLua(struct __pyx_obj_7PyTorch_GlobalState *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_10_popFloatTensor(CYTHON_UNUSED PyObject *__pyx_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_12_pushFloatTensor(CYTHON_UNUSED PyObject *__pyx_self, struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_tensor); /* proto */
static PyObject *__pyx_pf_7PyTorch_14_popDoubleTensor(CYTHON_UNUSED PyObject *__pyx_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_16_pushDoubleTensor(CYTHON_UNUSED PyObject *__pyx_self, struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_tensor); /* proto */
static PyObject *__pyx_pf_7PyTorch_18_popByteTensor(CYTHON_UNUSED PyObject *__pyx_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_20_pushByteTensor(CYTHON_UNUSED PyObject *__pyx_self, struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_tensor); /* proto */
static PyObject *__pyx_pf_7PyTorch_22getFloatPrediction(CYTHON_UNUSED PyObject *__pyx_self, struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_output); /* proto */
static PyObject *__pyx_pf_7PyTorch_24getDoublePrediction(CYTHON_UNUSED PyObject *__pyx_self, struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_output); /* proto */
static PyObject *__pyx_pf_7PyTorch_26getGlobalState(CYTHON_UNUSED PyObject *__pyx_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_28require(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_libName); /* proto */
static PyObject *__pyx_pf_7PyTorch_30getGlobal(CYTHON_UNUSED PyObject *__pyx_self, CYTHON_UNUSED PyObject *__pyx_v_name); /* proto */
static PyObject *__pyx_pf_7PyTorch_32init(CYTHON_UNUSED PyObject *__pyx_self); /* proto */
static PyObject *__pyx_pf_7PyTorch_2Nn_collectgarbage(CYTHON_UNUSED struct __pyx_obj_7PyTorch_Nn *__pyx_v_self); /* proto */
static int __pyx_pf_7cpython_5array_5array___getbuffer__(arrayobject *__pyx_v_self, Py_buffer *__pyx_v_info, CYTHON_UNUSED int __pyx_v_flags); /* proto */
static void __pyx_pf_7cpython_5array_5array_2__releasebuffer__(CYTHON_UNUSED arrayobject *__pyx_v_self, Py_buffer *__pyx_v_info); /* proto */
static int __pyx_array___pyx_pf_15View_dot_MemoryView_5array___cinit__(struct __pyx_array_obj *__pyx_v_self, PyObject *__pyx_v_shape, Py_ssize_t __pyx_v_itemsize, PyObject *__pyx_v_format, PyObject *__pyx_v_mode, int __pyx_v_allocate_buffer); /* proto */
static int __pyx_array___pyx_pf_15View_dot_MemoryView_5array_2__getbuffer__(struct __pyx_array_obj *__pyx_v_self, Py_buffer *__pyx_v_info, int __pyx_v_flags); /* proto */
static void __pyx_array___pyx_pf_15View_dot_MemoryView_5array_4__dealloc__(struct __pyx_array_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_15View_dot_MemoryView_5array_7memview___get__(struct __pyx_array_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_array___pyx_pf_15View_dot_MemoryView_5array_6__getattr__(struct __pyx_array_obj *__pyx_v_self, PyObject *__pyx_v_attr); /* proto */
static PyObject *__pyx_array___pyx_pf_15View_dot_MemoryView_5array_8__getitem__(struct __pyx_array_obj *__pyx_v_self, PyObject *__pyx_v_item); /* proto */
static int __pyx_array___pyx_pf_15View_dot_MemoryView_5array_10__setitem__(struct __pyx_array_obj *__pyx_v_self, PyObject *__pyx_v_item, PyObject *__pyx_v_value); /* proto */
static int __pyx_MemviewEnum___pyx_pf_15View_dot_MemoryView_4Enum___init__(struct __pyx_MemviewEnum_obj *__pyx_v_self, PyObject *__pyx_v_name); /* proto */
static PyObject *__pyx_MemviewEnum___pyx_pf_15View_dot_MemoryView_4Enum_2__repr__(struct __pyx_MemviewEnum_obj *__pyx_v_self); /* proto */
static int __pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview___cinit__(struct __pyx_memoryview_obj *__pyx_v_self, PyObject *__pyx_v_obj, int __pyx_v_flags, int __pyx_v_dtype_is_object); /* proto */
static void __pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_2__dealloc__(struct __pyx_memoryview_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_4__getitem__(struct __pyx_memoryview_obj *__pyx_v_self, PyObject *__pyx_v_index); /* proto */
static int __pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_6__setitem__(struct __pyx_memoryview_obj *__pyx_v_self, PyObject *__pyx_v_index, PyObject *__pyx_v_value); /* proto */
static int __pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_8__getbuffer__(struct __pyx_memoryview_obj *__pyx_v_self, Py_buffer *__pyx_v_info, int __pyx_v_flags); /* proto */
static PyObject *__pyx_pf_15View_dot_MemoryView_10memoryview_1T___get__(struct __pyx_memoryview_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_15View_dot_MemoryView_10memoryview_4base___get__(struct __pyx_memoryview_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_15View_dot_MemoryView_10memoryview_5shape___get__(struct __pyx_memoryview_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_15View_dot_MemoryView_10memoryview_7strides___get__(struct __pyx_memoryview_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_15View_dot_MemoryView_10memoryview_10suboffsets___get__(struct __pyx_memoryview_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_15View_dot_MemoryView_10memoryview_4ndim___get__(struct __pyx_memoryview_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_15View_dot_MemoryView_10memoryview_8itemsize___get__(struct __pyx_memoryview_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_15View_dot_MemoryView_10memoryview_6nbytes___get__(struct __pyx_memoryview_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_15View_dot_MemoryView_10memoryview_4size___get__(struct __pyx_memoryview_obj *__pyx_v_self); /* proto */
static Py_ssize_t __pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_10__len__(struct __pyx_memoryview_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_12__repr__(struct __pyx_memoryview_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_14__str__(struct __pyx_memoryview_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_16is_c_contig(struct __pyx_memoryview_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_18is_f_contig(struct __pyx_memoryview_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_20copy(struct __pyx_memoryview_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_22copy_fortran(struct __pyx_memoryview_obj *__pyx_v_self); /* proto */
static void __pyx_memoryviewslice___pyx_pf_15View_dot_MemoryView_16_memoryviewslice___dealloc__(struct __pyx_memoryviewslice_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_15View_dot_MemoryView_16_memoryviewslice_4base___get__(struct __pyx_memoryviewslice_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_tp_new_7PyTorch__LongTensor(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_7PyTorch__FloatTensor(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_7PyTorch__DoubleTensor(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_7PyTorch__ByteTensor(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_7PyTorch_GlobalState(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_7PyTorch_Nn(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_array(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_Enum(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_memoryview(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new__memoryviewslice(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_int_0;
static PyObject *__pyx_int_1;
static PyObject *__pyx_int_2;
static PyObject *__pyx_int_neg_1;
static PyObject *__pyx_tuple_;
static PyObject *__pyx_tuple__2;
static PyObject *__pyx_tuple__3;
static PyObject *__pyx_tuple__4;
static PyObject *__pyx_tuple__5;
static PyObject *__pyx_tuple__6;
static PyObject *__pyx_slice__53;
static PyObject *__pyx_slice__54;
static PyObject *__pyx_slice__55;
static PyObject *__pyx_tuple__14;
static PyObject *__pyx_tuple__15;
static PyObject *__pyx_tuple__16;
static PyObject *__pyx_tuple__17;
static PyObject *__pyx_tuple__18;
static PyObject *__pyx_tuple__19;
static PyObject *__pyx_tuple__20;
static PyObject *__pyx_tuple__21;
static PyObject *__pyx_tuple__22;
static PyObject *__pyx_tuple__23;
static PyObject *__pyx_tuple__24;
static PyObject *__pyx_tuple__25;
static PyObject *__pyx_tuple__26;
static PyObject *__pyx_tuple__27;
static PyObject *__pyx_tuple__28;
static PyObject *__pyx_tuple__29;
static PyObject *__pyx_tuple__30;
static PyObject *__pyx_tuple__31;
static PyObject *__pyx_tuple__32;
static PyObject *__pyx_tuple__33;
static PyObject *__pyx_tuple__34;
static PyObject *__pyx_tuple__35;
static PyObject *__pyx_tuple__36;
static PyObject *__pyx_tuple__37;
static PyObject *__pyx_tuple__38;
static PyObject *__pyx_tuple__39;
static PyObject *__pyx_tuple__40;
static PyObject *__pyx_tuple__41;
static PyObject *__pyx_tuple__42;
static PyObject *__pyx_tuple__43;
static PyObject *__pyx_tuple__44;
static PyObject *__pyx_tuple__45;
static PyObject *__pyx_tuple__46;
static PyObject *__pyx_tuple__47;
static PyObject *__pyx_tuple__48;
static PyObject *__pyx_tuple__49;
static PyObject *__pyx_tuple__50;
static PyObject *__pyx_tuple__51;
static PyObject *__pyx_tuple__52;
static PyObject *__pyx_tuple__56;
static PyObject *__pyx_tuple__57;
static PyObject *__pyx_tuple__59;
static PyObject *__pyx_tuple__62;
static PyObject *__pyx_tuple__64;
static PyObject *__pyx_tuple__66;
static PyObject *__pyx_tuple__68;
static PyObject *__pyx_tuple__70;
static PyObject *__pyx_tuple__73;
static PyObject *__pyx_tuple__75;
static PyObject *__pyx_tuple__77;
static PyObject *__pyx_tuple__79;
static PyObject *__pyx_tuple__81;
static PyObject *__pyx_tuple__83;
static PyObject *__pyx_tuple__86;
static PyObject *__pyx_tuple__88;
static PyObject *__pyx_tuple__90;
static PyObject *__pyx_tuple__92;
static PyObject *__pyx_tuple__94;
static PyObject *__pyx_tuple__96;
static PyObject *__pyx_tuple__99;
static PyObject *__pyx_tuple__101;
static PyObject *__pyx_tuple__103;
static PyObject *__pyx_tuple__105;
static PyObject *__pyx_tuple__107;
static PyObject *__pyx_tuple__109;
static PyObject *__pyx_tuple__111;
static PyObject *__pyx_tuple__113;
static PyObject *__pyx_tuple__115;
static PyObject *__pyx_tuple__117;
static PyObject *__pyx_tuple__119;
static PyObject *__pyx_tuple__121;
static PyObject *__pyx_tuple__124;
static PyObject *__pyx_tuple__126;
static PyObject *__pyx_tuple__130;
static PyObject *__pyx_tuple__131;
static PyObject *__pyx_tuple__132;
static PyObject *__pyx_tuple__133;
static PyObject *__pyx_tuple__134;
static PyObject *__pyx_codeobj__58;
static PyObject *__pyx_codeobj__60;
static PyObject *__pyx_codeobj__61;
static PyObject *__pyx_codeobj__63;
static PyObject *__pyx_codeobj__65;
static PyObject *__pyx_codeobj__67;
static PyObject *__pyx_codeobj__69;
static PyObject *__pyx_codeobj__71;
static PyObject *__pyx_codeobj__72;
static PyObject *__pyx_codeobj__74;
static PyObject *__pyx_codeobj__76;
static PyObject *__pyx_codeobj__78;
static PyObject *__pyx_codeobj__80;
static PyObject *__pyx_codeobj__82;
static PyObject *__pyx_codeobj__84;
static PyObject *__pyx_codeobj__85;
static PyObject *__pyx_codeobj__87;
static PyObject *__pyx_codeobj__89;
static PyObject *__pyx_codeobj__91;
static PyObject *__pyx_codeobj__93;
static PyObject *__pyx_codeobj__95;
static PyObject *__pyx_codeobj__97;
static PyObject *__pyx_codeobj__98;
static PyObject *__pyx_codeobj__100;
static PyObject *__pyx_codeobj__102;
static PyObject *__pyx_codeobj__104;
static PyObject *__pyx_codeobj__106;
static PyObject *__pyx_codeobj__108;
static PyObject *__pyx_codeobj__110;
static PyObject *__pyx_codeobj__112;
static PyObject *__pyx_codeobj__114;
static PyObject *__pyx_codeobj__116;
static PyObject *__pyx_codeobj__118;
static PyObject *__pyx_codeobj__120;
static PyObject *__pyx_codeobj__122;
static PyObject *__pyx_codeobj__123;
static PyObject *__pyx_codeobj__125;
static PyObject *__pyx_codeobj__127;
static PyObject *__pyx_codeobj__128;

/* "PyTorch.pyx":30
 * 
 * # from http://stackoverflow.com/questions/3410976/how-to-round-a-number-to-significant-figures-in-python
 * def round_sig(x, sig=2):             # <<<<<<<<<<<<<<
 *     return round(x, sig-int(floor(log10(abs(x))))-1)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_1round_sig(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_7PyTorch_1round_sig = {"round_sig", (PyCFunction)__pyx_pw_7PyTorch_1round_sig, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_7PyTorch_1round_sig(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_x = 0;
  PyObject *__pyx_v_sig = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("round_sig (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_x,&__pyx_n_s_sig,0};
    PyObject* values[2] = {0,0};
    values[1] = ((PyObject *)__pyx_int_2);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_x)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_sig);
          if (value) { values[1] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "round_sig") < 0)) __PYX_ERR(0, 30, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_x = values[0];
    __pyx_v_sig = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("round_sig", 0, 1, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 30, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch.round_sig", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_round_sig(__pyx_self, __pyx_v_x, __pyx_v_sig);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_round_sig(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_x, PyObject *__pyx_v_sig) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  __Pyx_RefNannySetupContext("round_sig", 0);

  /* "PyTorch.pyx":31
 * # from http://stackoverflow.com/questions/3410976/how-to-round-a-number-to-significant-figures-in-python
 * def round_sig(x, sig=2):
 *     return round(x, sig-int(floor(log10(abs(x))))-1)             # <<<<<<<<<<<<<<
 * 
 * cdef extern from "THRandom.h":
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_floor); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 31, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_GetModuleGlobalName(__pyx_n_s_log10); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 31, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = PyNumber_Absolute(__pyx_v_x); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 31, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_6 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_4))) {
    __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_4);
    if (likely(__pyx_t_6)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
      __Pyx_INCREF(__pyx_t_6);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_4, function);
    }
  }
  if (!__pyx_t_6) {
    __pyx_t_3 = __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_t_5); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 31, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_GOTREF(__pyx_t_3);
  } else {
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_4)) {
      PyObject *__pyx_temp[2] = {__pyx_t_6, __pyx_t_5};
      __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_4, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 31, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_4)) {
      PyObject *__pyx_temp[2] = {__pyx_t_6, __pyx_t_5};
      __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_4, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 31, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    } else
    #endif
    {
      __pyx_t_7 = PyTuple_New(1+1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 31, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_GIVEREF(__pyx_t_6); PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_6); __pyx_t_6 = NULL;
      __Pyx_GIVEREF(__pyx_t_5);
      PyTuple_SET_ITEM(__pyx_t_7, 0+1, __pyx_t_5);
      __pyx_t_5 = 0;
      __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_4, __pyx_t_7, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 31, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    }
  }
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (!__pyx_t_4) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 31, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else {
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_2)) {
      PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_t_3};
      __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 31, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
      PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_t_3};
      __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 31, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    } else
    #endif
    {
      __pyx_t_7 = PyTuple_New(1+1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 31, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_4); __pyx_t_4 = NULL;
      __Pyx_GIVEREF(__pyx_t_3);
      PyTuple_SET_ITEM(__pyx_t_7, 0+1, __pyx_t_3);
      __pyx_t_3 = 0;
      __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_7, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 31, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    }
  }
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyNumber_Int(__pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 31, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyNumber_Subtract(__pyx_v_sig, __pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 31, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyInt_SubtractObjC(__pyx_t_1, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 31, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyTuple_New(2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 31, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_INCREF(__pyx_v_x);
  __Pyx_GIVEREF(__pyx_v_x);
  PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_v_x);
  __Pyx_GIVEREF(__pyx_t_2);
  PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_t_2);
  __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_round, __pyx_t_1, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 31, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":30
 * 
 * # from http://stackoverflow.com/questions/3410976/how-to-round-a-number-to-significant-figures-in-python
 * def round_sig(x, sig=2):             # <<<<<<<<<<<<<<
 *     return round(x, sig-int(floor(log10(abs(x))))-1)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("PyTorch.round_sig", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":37
 *     void THRandom_manualSeed(THGenerator *_generator, unsigned long the_seed_)
 * 
 * def manualSeed(long seed):             # <<<<<<<<<<<<<<
 *     THRandom_manualSeed(globalState.generator, seed)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_3manualSeed(PyObject *__pyx_self, PyObject *__pyx_arg_seed); /*proto*/
static PyMethodDef __pyx_mdef_7PyTorch_3manualSeed = {"manualSeed", (PyCFunction)__pyx_pw_7PyTorch_3manualSeed, METH_O, 0};
static PyObject *__pyx_pw_7PyTorch_3manualSeed(PyObject *__pyx_self, PyObject *__pyx_arg_seed) {
  long __pyx_v_seed;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("manualSeed (wrapper)", 0);
  assert(__pyx_arg_seed); {
    __pyx_v_seed = __Pyx_PyInt_As_long(__pyx_arg_seed); if (unlikely((__pyx_v_seed == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 37, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch.manualSeed", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_2manualSeed(__pyx_self, ((long)__pyx_v_seed));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_2manualSeed(CYTHON_UNUSED PyObject *__pyx_self, long __pyx_v_seed) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("manualSeed", 0);

  /* "PyTorch.pyx":38
 * 
 * def manualSeed(long seed):
 *     THRandom_manualSeed(globalState.generator, seed)             # <<<<<<<<<<<<<<
 * 
 * cdef floatToString(float floatValue):
 */
  THRandom_manualSeed(__pyx_v_7PyTorch_globalState->generator, __pyx_v_seed);

  /* "PyTorch.pyx":37
 *     void THRandom_manualSeed(THGenerator *_generator, unsigned long the_seed_)
 * 
 * def manualSeed(long seed):             # <<<<<<<<<<<<<<
 *     THRandom_manualSeed(globalState.generator, seed)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":40
 *     THRandom_manualSeed(globalState.generator, seed)
 * 
 * cdef floatToString(float floatValue):             # <<<<<<<<<<<<<<
 *     return '%.6g'% floatValue
 * 
 */

static PyObject *__pyx_f_7PyTorch_floatToString(float __pyx_v_floatValue) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("floatToString", 0);

  /* "PyTorch.pyx":41
 * 
 * cdef floatToString(float floatValue):
 *     return '%.6g'% floatValue             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyFloat_FromDouble(__pyx_v_floatValue); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 41, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyString_Format(__pyx_kp_s_6g, __pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 41, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":40
 *     THRandom_manualSeed(globalState.generator, seed)
 * 
 * cdef floatToString(float floatValue):             # <<<<<<<<<<<<<<
 *     return '%.6g'% floatValue
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("PyTorch.floatToString", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":380
 * #        self.thFloatTensor = tensorC
 * 
 *     def __cinit__(self, *args, _allocate=True):             # <<<<<<<<<<<<<<
 * #        cdef _LongTensor childobject
 *         cdef THLongTensor *newTensorC
 */

/* Python wrapper */
static int __pyx_pw_7PyTorch_11_LongTensor_1__cinit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static int __pyx_pw_7PyTorch_11_LongTensor_1__cinit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v__allocate = 0;
  PyObject *__pyx_v_args = 0;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__cinit__ (wrapper)", 0);
  if (PyTuple_GET_SIZE(__pyx_args) > 0) {
    __pyx_v_args = PyTuple_GetSlice(__pyx_args, 0, PyTuple_GET_SIZE(__pyx_args));
    if (unlikely(!__pyx_v_args)) {
      __Pyx_RefNannyFinishContext();
      return -1;
    }
    __Pyx_GOTREF(__pyx_v_args);
  } else {
    __pyx_v_args = __pyx_empty_tuple; __Pyx_INCREF(__pyx_empty_tuple);
  }
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_allocate,0};
    PyObject* values[1] = {0};
    values[0] = ((PyObject *)Py_True);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        default:
        case  0: break;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      if (kw_args == 1) {
        const Py_ssize_t index = 0;
        PyObject* value = PyDict_GetItem(__pyx_kwds, *__pyx_pyargnames[index]);
        if (value) { values[index] = value; kw_args--; }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, 0, "__cinit__") < 0)) __PYX_ERR(0, 380, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) < 0) {
      goto __pyx_L5_argtuple_error;
    } else {
    }
    __pyx_v__allocate = values[0];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__cinit__", 0, 0, 0, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 380, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_DECREF(__pyx_v_args); __pyx_v_args = 0;
  __Pyx_AddTraceback("PyTorch._LongTensor.__cinit__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return -1;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor___cinit__(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self), __pyx_v__allocate, __pyx_v_args);

  /* function exit code */
  __Pyx_XDECREF(__pyx_v_args);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_7PyTorch_11_LongTensor___cinit__(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, PyObject *__pyx_v__allocate, PyObject *__pyx_v_args) {
  struct THLongTensor *__pyx_v_newTensorC;
  struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_templateObject = 0;
  PyObject *__pyx_v_arg = NULL;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  Py_ssize_t __pyx_t_4;
  int __pyx_t_5;
  int __pyx_t_6;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  long __pyx_t_10;
  long __pyx_t_11;
  long __pyx_t_12;
  long __pyx_t_13;
  __Pyx_RefNannySetupContext("__cinit__", 0);

  /* "PyTorch.pyx":384
 *         cdef THLongTensor *newTensorC
 *         cdef _LongTensor templateObject
 *         logger.debug('LongTensor.__cinit__')             # <<<<<<<<<<<<<<
 * #        cdef THLongStorage *storageC
 * #        cdef long addr
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_logger); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 384, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_debug); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 384, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_tuple_, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 384, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "PyTorch.pyx":389
 * #        if len(kwargs) > 0:
 * #            raise Exception('cannot provide arguments to initializer')
 *         if _allocate:             # <<<<<<<<<<<<<<
 *             if len(args) == 1 and isinstance(args[0], _LongStorage):  # it's a size tensor
 *                self.native = THLongTensor_new()
 */
  __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_v__allocate); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 389, __pyx_L1_error)
  if (__pyx_t_3) {

    /* "PyTorch.pyx":390
 * #            raise Exception('cannot provide arguments to initializer')
 *         if _allocate:
 *             if len(args) == 1 and isinstance(args[0], _LongStorage):  # it's a size tensor             # <<<<<<<<<<<<<<
 *                self.native = THLongTensor_new()
 *                self.resize(args[0])
 */
    __pyx_t_4 = PyTuple_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 390, __pyx_L1_error)
    __pyx_t_5 = ((__pyx_t_4 == 1) != 0);
    if (__pyx_t_5) {
    } else {
      __pyx_t_3 = __pyx_t_5;
      goto __pyx_L5_bool_binop_done;
    }
    __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 390, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_LongStorage); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 390, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_5 = PyObject_IsInstance(__pyx_t_1, __pyx_t_2); if (unlikely(__pyx_t_5 == -1)) __PYX_ERR(0, 390, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_6 = (__pyx_t_5 != 0);
    __pyx_t_3 = __pyx_t_6;
    __pyx_L5_bool_binop_done:;
    if (__pyx_t_3) {

      /* "PyTorch.pyx":391
 *         if _allocate:
 *             if len(args) == 1 and isinstance(args[0], _LongStorage):  # it's a size tensor
 *                self.native = THLongTensor_new()             # <<<<<<<<<<<<<<
 *                self.resize(args[0])
 *                return
 */
      __pyx_v_self->native = THLongTensor_new();

      /* "PyTorch.pyx":392
 *             if len(args) == 1 and isinstance(args[0], _LongStorage):  # it's a size tensor
 *                self.native = THLongTensor_new()
 *                self.resize(args[0])             # <<<<<<<<<<<<<<
 *                return
 *             if len(args) == 1 and isinstance(args[0], _LongTensor):
 */
      __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_resize); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 392, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_7 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 392, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __pyx_t_8 = NULL;
      if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_1))) {
        __pyx_t_8 = PyMethod_GET_SELF(__pyx_t_1);
        if (likely(__pyx_t_8)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
          __Pyx_INCREF(__pyx_t_8);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_1, function);
        }
      }
      if (!__pyx_t_8) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_t_7); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 392, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        __Pyx_GOTREF(__pyx_t_2);
      } else {
        #if CYTHON_FAST_PYCALL
        if (PyFunction_Check(__pyx_t_1)) {
          PyObject *__pyx_temp[2] = {__pyx_t_8, __pyx_t_7};
          __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_1, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 392, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        } else
        #endif
        #if CYTHON_FAST_PYCCALL
        if (__Pyx_PyFastCFunction_Check(__pyx_t_1)) {
          PyObject *__pyx_temp[2] = {__pyx_t_8, __pyx_t_7};
          __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_1, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 392, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        } else
        #endif
        {
          __pyx_t_9 = PyTuple_New(1+1); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 392, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_9);
          __Pyx_GIVEREF(__pyx_t_8); PyTuple_SET_ITEM(__pyx_t_9, 0, __pyx_t_8); __pyx_t_8 = NULL;
          __Pyx_GIVEREF(__pyx_t_7);
          PyTuple_SET_ITEM(__pyx_t_9, 0+1, __pyx_t_7);
          __pyx_t_7 = 0;
          __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_9, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 392, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
        }
      }
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

      /* "PyTorch.pyx":393
 *                self.native = THLongTensor_new()
 *                self.resize(args[0])
 *                return             # <<<<<<<<<<<<<<
 *             if len(args) == 1 and isinstance(args[0], _LongTensor):
 *                templateObject = args[0]
 */
      __pyx_r = 0;
      goto __pyx_L0;

      /* "PyTorch.pyx":390
 * #            raise Exception('cannot provide arguments to initializer')
 *         if _allocate:
 *             if len(args) == 1 and isinstance(args[0], _LongStorage):  # it's a size tensor             # <<<<<<<<<<<<<<
 *                self.native = THLongTensor_new()
 *                self.resize(args[0])
 */
    }

    /* "PyTorch.pyx":394
 *                self.resize(args[0])
 *                return
 *             if len(args) == 1 and isinstance(args[0], _LongTensor):             # <<<<<<<<<<<<<<
 *                templateObject = args[0]
 *                newTensorC = THLongTensor_newClone(templateObject.native)
 */
    __pyx_t_4 = PyTuple_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 394, __pyx_L1_error)
    __pyx_t_6 = ((__pyx_t_4 == 1) != 0);
    if (__pyx_t_6) {
    } else {
      __pyx_t_3 = __pyx_t_6;
      goto __pyx_L8_bool_binop_done;
    }
    __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 394, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_6 = __Pyx_TypeCheck(__pyx_t_2, __pyx_ptype_7PyTorch__LongTensor); 
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_5 = (__pyx_t_6 != 0);
    __pyx_t_3 = __pyx_t_5;
    __pyx_L8_bool_binop_done:;
    if (__pyx_t_3) {

      /* "PyTorch.pyx":395
 *                return
 *             if len(args) == 1 and isinstance(args[0], _LongTensor):
 *                templateObject = args[0]             # <<<<<<<<<<<<<<
 *                newTensorC = THLongTensor_newClone(templateObject.native)
 *                self.native = newTensorC
 */
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 395, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      if (!(likely(((__pyx_t_2) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_2, __pyx_ptype_7PyTorch__LongTensor))))) __PYX_ERR(0, 395, __pyx_L1_error)
      __pyx_v_templateObject = ((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_t_2);
      __pyx_t_2 = 0;

      /* "PyTorch.pyx":396
 *             if len(args) == 1 and isinstance(args[0], _LongTensor):
 *                templateObject = args[0]
 *                newTensorC = THLongTensor_newClone(templateObject.native)             # <<<<<<<<<<<<<<
 *                self.native = newTensorC
 *                return
 */
      __pyx_v_newTensorC = THLongTensor_newClone(__pyx_v_templateObject->native);

      /* "PyTorch.pyx":397
 *                templateObject = args[0]
 *                newTensorC = THLongTensor_newClone(templateObject.native)
 *                self.native = newTensorC             # <<<<<<<<<<<<<<
 *                return
 *             for arg in args:
 */
      __pyx_v_self->native = __pyx_v_newTensorC;

      /* "PyTorch.pyx":398
 *                newTensorC = THLongTensor_newClone(templateObject.native)
 *                self.native = newTensorC
 *                return             # <<<<<<<<<<<<<<
 *             for arg in args:
 *                 if not isinstance(arg, int):
 */
      __pyx_r = 0;
      goto __pyx_L0;

      /* "PyTorch.pyx":394
 *                self.resize(args[0])
 *                return
 *             if len(args) == 1 and isinstance(args[0], _LongTensor):             # <<<<<<<<<<<<<<
 *                templateObject = args[0]
 *                newTensorC = THLongTensor_newClone(templateObject.native)
 */
    }

    /* "PyTorch.pyx":399
 *                self.native = newTensorC
 *                return
 *             for arg in args:             # <<<<<<<<<<<<<<
 *                 if not isinstance(arg, int):
 *                     raise Exception('cannot provide arguments to initializer')
 */
    __pyx_t_2 = __pyx_v_args; __Pyx_INCREF(__pyx_t_2); __pyx_t_4 = 0;
    for (;;) {
      if (__pyx_t_4 >= PyTuple_GET_SIZE(__pyx_t_2)) break;
      #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
      __pyx_t_1 = PyTuple_GET_ITEM(__pyx_t_2, __pyx_t_4); __Pyx_INCREF(__pyx_t_1); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 399, __pyx_L1_error)
      #else
      __pyx_t_1 = PySequence_ITEM(__pyx_t_2, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 399, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      #endif
      __Pyx_XDECREF_SET(__pyx_v_arg, __pyx_t_1);
      __pyx_t_1 = 0;

      /* "PyTorch.pyx":400
 *                return
 *             for arg in args:
 *                 if not isinstance(arg, int):             # <<<<<<<<<<<<<<
 *                     raise Exception('cannot provide arguments to initializer')
 *             if len(args) == 0:
 */
      __pyx_t_3 = PyInt_Check(__pyx_v_arg); 
      __pyx_t_5 = ((!(__pyx_t_3 != 0)) != 0);
      if (__pyx_t_5) {

        /* "PyTorch.pyx":401
 *             for arg in args:
 *                 if not isinstance(arg, int):
 *                     raise Exception('cannot provide arguments to initializer')             # <<<<<<<<<<<<<<
 *             if len(args) == 0:
 *                 # print('no args, calling THLongTensor_new()')
 */
        __pyx_t_1 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_tuple__2, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 401, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_Raise(__pyx_t_1, 0, 0, 0);
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        __PYX_ERR(0, 401, __pyx_L1_error)

        /* "PyTorch.pyx":400
 *                return
 *             for arg in args:
 *                 if not isinstance(arg, int):             # <<<<<<<<<<<<<<
 *                     raise Exception('cannot provide arguments to initializer')
 *             if len(args) == 0:
 */
      }

      /* "PyTorch.pyx":399
 *                self.native = newTensorC
 *                return
 *             for arg in args:             # <<<<<<<<<<<<<<
 *                 if not isinstance(arg, int):
 *                     raise Exception('cannot provide arguments to initializer')
 */
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

    /* "PyTorch.pyx":402
 *                 if not isinstance(arg, int):
 *                     raise Exception('cannot provide arguments to initializer')
 *             if len(args) == 0:             # <<<<<<<<<<<<<<
 *                 # print('no args, calling THLongTensor_new()')
 *                 self.native = THLongTensor_new()
 */
    __pyx_t_4 = PyTuple_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 402, __pyx_L1_error)
    __pyx_t_5 = ((__pyx_t_4 == 0) != 0);
    if (__pyx_t_5) {

      /* "PyTorch.pyx":404
 *             if len(args) == 0:
 *                 # print('no args, calling THLongTensor_new()')
 *                 self.native = THLongTensor_new()             # <<<<<<<<<<<<<<
 *             elif len(args) == 1:
 *                 # print('new tensor 1d length', args[0])
 */
      __pyx_v_self->native = THLongTensor_new();

      /* "PyTorch.pyx":402
 *                 if not isinstance(arg, int):
 *                     raise Exception('cannot provide arguments to initializer')
 *             if len(args) == 0:             # <<<<<<<<<<<<<<
 *                 # print('no args, calling THLongTensor_new()')
 *                 self.native = THLongTensor_new()
 */
      goto __pyx_L13;
    }

    /* "PyTorch.pyx":405
 *                 # print('no args, calling THLongTensor_new()')
 *                 self.native = THLongTensor_new()
 *             elif len(args) == 1:             # <<<<<<<<<<<<<<
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THLongTensor_newWithSize1d(args[0])
 */
    __pyx_t_4 = PyTuple_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 405, __pyx_L1_error)
    __pyx_t_5 = ((__pyx_t_4 == 1) != 0);
    if (__pyx_t_5) {

      /* "PyTorch.pyx":407
 *             elif len(args) == 1:
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THLongTensor_newWithSize1d(args[0])             # <<<<<<<<<<<<<<
 *             elif len(args) == 2:
 *                 # print('args=2')
 */
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 407, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_10 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_10 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 407, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_v_self->native = THLongTensor_newWithSize1d(__pyx_t_10);

      /* "PyTorch.pyx":405
 *                 # print('no args, calling THLongTensor_new()')
 *                 self.native = THLongTensor_new()
 *             elif len(args) == 1:             # <<<<<<<<<<<<<<
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THLongTensor_newWithSize1d(args[0])
 */
      goto __pyx_L13;
    }

    /* "PyTorch.pyx":408
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THLongTensor_newWithSize1d(args[0])
 *             elif len(args) == 2:             # <<<<<<<<<<<<<<
 *                 # print('args=2')
 *                 self.native = THLongTensor_newWithSize2d(args[0], args[1])
 */
    __pyx_t_4 = PyTuple_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 408, __pyx_L1_error)
    __pyx_t_5 = ((__pyx_t_4 == 2) != 0);
    if (__pyx_t_5) {

      /* "PyTorch.pyx":410
 *             elif len(args) == 2:
 *                 # print('args=2')
 *                 self.native = THLongTensor_newWithSize2d(args[0], args[1])             # <<<<<<<<<<<<<<
 *             elif len(args) == 3:
 *                 # print('new tensor 1d length', args[0])
 */
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 410, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_10 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_10 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 410, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 410, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_11 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_11 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 410, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_v_self->native = THLongTensor_newWithSize2d(__pyx_t_10, __pyx_t_11);

      /* "PyTorch.pyx":408
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THLongTensor_newWithSize1d(args[0])
 *             elif len(args) == 2:             # <<<<<<<<<<<<<<
 *                 # print('args=2')
 *                 self.native = THLongTensor_newWithSize2d(args[0], args[1])
 */
      goto __pyx_L13;
    }

    /* "PyTorch.pyx":411
 *                 # print('args=2')
 *                 self.native = THLongTensor_newWithSize2d(args[0], args[1])
 *             elif len(args) == 3:             # <<<<<<<<<<<<<<
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THLongTensor_newWithSize3d(args[0], args[1], args[2])
 */
    __pyx_t_4 = PyTuple_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 411, __pyx_L1_error)
    __pyx_t_5 = ((__pyx_t_4 == 3) != 0);
    if (__pyx_t_5) {

      /* "PyTorch.pyx":413
 *             elif len(args) == 3:
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THLongTensor_newWithSize3d(args[0], args[1], args[2])             # <<<<<<<<<<<<<<
 *             elif len(args) == 4:
 *                 # print('new tensor 1d length', args[0])
 */
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 413, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_11 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_11 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 413, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 413, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_10 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_10 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 413, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 413, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_12 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_12 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 413, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_v_self->native = THLongTensor_newWithSize3d(__pyx_t_11, __pyx_t_10, __pyx_t_12);

      /* "PyTorch.pyx":411
 *                 # print('args=2')
 *                 self.native = THLongTensor_newWithSize2d(args[0], args[1])
 *             elif len(args) == 3:             # <<<<<<<<<<<<<<
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THLongTensor_newWithSize3d(args[0], args[1], args[2])
 */
      goto __pyx_L13;
    }

    /* "PyTorch.pyx":414
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THLongTensor_newWithSize3d(args[0], args[1], args[2])
 *             elif len(args) == 4:             # <<<<<<<<<<<<<<
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THLongTensor_newWithSize4d(args[0], args[1], args[2], args[3])
 */
    __pyx_t_4 = PyTuple_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 414, __pyx_L1_error)
    __pyx_t_5 = ((__pyx_t_4 == 4) != 0);
    if (__pyx_t_5) {

      /* "PyTorch.pyx":416
 *             elif len(args) == 4:
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THLongTensor_newWithSize4d(args[0], args[1], args[2], args[3])             # <<<<<<<<<<<<<<
 *             else:
 *                 logger.error('Raising exception...')
 */
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 416, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_12 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_12 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 416, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 416, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_10 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_10 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 416, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 416, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_11 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_11 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 416, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 3, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 416, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_13 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_13 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 416, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_v_self->native = THLongTensor_newWithSize4d(__pyx_t_12, __pyx_t_10, __pyx_t_11, __pyx_t_13);

      /* "PyTorch.pyx":414
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THLongTensor_newWithSize3d(args[0], args[1], args[2])
 *             elif len(args) == 4:             # <<<<<<<<<<<<<<
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THLongTensor_newWithSize4d(args[0], args[1], args[2], args[3])
 */
      goto __pyx_L13;
    }

    /* "PyTorch.pyx":418
 *                 self.native = THLongTensor_newWithSize4d(args[0], args[1], args[2], args[3])
 *             else:
 *                 logger.error('Raising exception...')             # <<<<<<<<<<<<<<
 *                 raise Exception('Not implemented, len(args)=' + str(len(args)))
 * #        else:
 */
    /*else*/ {
      __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_logger); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 418, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_error); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 418, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_tuple__3, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 418, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

      /* "PyTorch.pyx":419
 *             else:
 *                 logger.error('Raising exception...')
 *                 raise Exception('Not implemented, len(args)=' + str(len(args)))             # <<<<<<<<<<<<<<
 * #        else:
 * #            if len(args) > 0:
 */
      __pyx_t_4 = PyTuple_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 419, __pyx_L1_error)
      __pyx_t_2 = PyInt_FromSsize_t(__pyx_t_4); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 419, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 419, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_GIVEREF(__pyx_t_2);
      PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_2);
      __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)(&PyString_Type)), __pyx_t_1, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 419, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_t_1 = PyNumber_Add(__pyx_kp_s_Not_implemented_len_args, __pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 419, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = PyTuple_New(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 419, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_GIVEREF(__pyx_t_1);
      PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_1);
      __pyx_t_1 = 0;
      __pyx_t_1 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_t_2, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 419, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_Raise(__pyx_t_1, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __PYX_ERR(0, 419, __pyx_L1_error)
    }
    __pyx_L13:;

    /* "PyTorch.pyx":389
 * #        if len(kwargs) > 0:
 * #            raise Exception('cannot provide arguments to initializer')
 *         if _allocate:             # <<<<<<<<<<<<<<
 *             if len(args) == 1 and isinstance(args[0], _LongStorage):  # it's a size tensor
 *                self.native = THLongTensor_new()
 */
  }

  /* "PyTorch.pyx":380
 * #        self.thFloatTensor = tensorC
 * 
 *     def __cinit__(self, *args, _allocate=True):             # <<<<<<<<<<<<<<
 * #        cdef _LongTensor childobject
 *         cdef THLongTensor *newTensorC
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_AddTraceback("PyTorch._LongTensor.__cinit__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_templateObject);
  __Pyx_XDECREF(__pyx_v_arg);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":438
 * #        self.storage = storage
 * 
 *     def __dealloc__(self):             # <<<<<<<<<<<<<<
 *         cdef int refCount
 * #        cdef int dims
 */

/* Python wrapper */
static void __pyx_pw_7PyTorch_11_LongTensor_3__dealloc__(PyObject *__pyx_v_self); /*proto*/
static void __pyx_pw_7PyTorch_11_LongTensor_3__dealloc__(PyObject *__pyx_v_self) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__dealloc__ (wrapper)", 0);
  __pyx_pf_7PyTorch_11_LongTensor_2__dealloc__(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

static void __pyx_pf_7PyTorch_11_LongTensor_2__dealloc__(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self) {
  int __pyx_v_refCount;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("__dealloc__", 0);

  /* "PyTorch.pyx":445
 * #        cdef THFloatStorage *storage
 * #        logger.debug('__dealloc__ native %s', <long>(self.native) != 0)
 *         if <long>(self.native) != 0:             # <<<<<<<<<<<<<<
 *             refCount = THLongTensor_getRefCount(self.native)
 *    #         print('LongTensor.dealloc old refcount', refCount)
 */
  __pyx_t_1 = ((((long)__pyx_v_self->native) != 0) != 0);
  if (__pyx_t_1) {

    /* "PyTorch.pyx":446
 * #        logger.debug('__dealloc__ native %s', <long>(self.native) != 0)
 *         if <long>(self.native) != 0:
 *             refCount = THLongTensor_getRefCount(self.native)             # <<<<<<<<<<<<<<
 *    #         print('LongTensor.dealloc old refcount', refCount)
 *    #        storage = THFloatTensor_storage(self.thFloatTensor)
 */
    __pyx_v_refCount = THLongTensor_getRefCount(__pyx_v_self->native);

    /* "PyTorch.pyx":457
 *    #        for i in range(dims):
 *    #            # print('   size[', i, ']', THFloatTensor_size(self.thFloatTensor, i))
 *             if refCount < 1:             # <<<<<<<<<<<<<<
 *                 raise Exception('Unallocated an already deallocated tensor... :-O')  # Hmmm, seems this exceptoin wont go anywhere useful... :-P
 *             THLongTensor_free(self.native)
 */
    __pyx_t_1 = ((__pyx_v_refCount < 1) != 0);
    if (__pyx_t_1) {

      /* "PyTorch.pyx":458
 *    #            # print('   size[', i, ']', THFloatTensor_size(self.thFloatTensor, i))
 *             if refCount < 1:
 *                 raise Exception('Unallocated an already deallocated tensor... :-O')  # Hmmm, seems this exceptoin wont go anywhere useful... :-P             # <<<<<<<<<<<<<<
 *             THLongTensor_free(self.native)
 *         else:
 */
      __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_tuple__4, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 458, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_Raise(__pyx_t_2, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __PYX_ERR(0, 458, __pyx_L1_error)

      /* "PyTorch.pyx":457
 *    #        for i in range(dims):
 *    #            # print('   size[', i, ']', THFloatTensor_size(self.thFloatTensor, i))
 *             if refCount < 1:             # <<<<<<<<<<<<<<
 *                 raise Exception('Unallocated an already deallocated tensor... :-O')  # Hmmm, seems this exceptoin wont go anywhere useful... :-P
 *             THLongTensor_free(self.native)
 */
    }

    /* "PyTorch.pyx":459
 *             if refCount < 1:
 *                 raise Exception('Unallocated an already deallocated tensor... :-O')  # Hmmm, seems this exceptoin wont go anywhere useful... :-P
 *             THLongTensor_free(self.native)             # <<<<<<<<<<<<<<
 *         else:
 *             logger.debug('__dealloc__ tensor never allocated')
 */
    THLongTensor_free(__pyx_v_self->native);

    /* "PyTorch.pyx":445
 * #        cdef THFloatStorage *storage
 * #        logger.debug('__dealloc__ native %s', <long>(self.native) != 0)
 *         if <long>(self.native) != 0:             # <<<<<<<<<<<<<<
 *             refCount = THLongTensor_getRefCount(self.native)
 *    #         print('LongTensor.dealloc old refcount', refCount)
 */
    goto __pyx_L3;
  }

  /* "PyTorch.pyx":461
 *             THLongTensor_free(self.native)
 *         else:
 *             logger.debug('__dealloc__ tensor never allocated')             # <<<<<<<<<<<<<<
 * 
 *     def nElement(_LongTensor self):
 */
  /*else*/ {
    __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_logger); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 461, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_debug); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 461, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_tuple__5, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 461, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  }
  __pyx_L3:;

  /* "PyTorch.pyx":438
 * #        self.storage = storage
 * 
 *     def __dealloc__(self):             # <<<<<<<<<<<<<<
 *         cdef int refCount
 * #        cdef int dims
 */

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_WriteUnraisable("PyTorch._LongTensor.__dealloc__", __pyx_clineno, __pyx_lineno, __pyx_filename, 0, 0);
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
}

/* "PyTorch.pyx":463
 *             logger.debug('__dealloc__ tensor never allocated')
 * 
 *     def nElement(_LongTensor self):             # <<<<<<<<<<<<<<
 *         return THLongTensor_nElement(self.native)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_5nElement(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_5nElement(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("nElement (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_4nElement(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_4nElement(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("nElement", 0);

  /* "PyTorch.pyx":464
 * 
 *     def nElement(_LongTensor self):
 *         return THLongTensor_nElement(self.native)             # <<<<<<<<<<<<<<
 * 
 *     def asNumpyTensor(_LongTensor self):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_long(THLongTensor_nElement(__pyx_v_self->native)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 464, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":463
 *             logger.debug('__dealloc__ tensor never allocated')
 * 
 *     def nElement(_LongTensor self):             # <<<<<<<<<<<<<<
 *         return THLongTensor_nElement(self.native)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._LongTensor.nElement", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":466
 *         return THLongTensor_nElement(self.native)
 * 
 *     def asNumpyTensor(_LongTensor self):             # <<<<<<<<<<<<<<
 *         cdef Storage._LongStorage storage
 *         cdef long *data
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_7asNumpyTensor(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_7asNumpyTensor(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("asNumpyTensor (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_6asNumpyTensor(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_6asNumpyTensor(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self) {
  long *__pyx_v_data;
  struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_contig = 0;
  PyObject *__pyx_v_size = NULL;
  PyObject *__pyx_v_dims = NULL;
  PyObject *__pyx_v_dtype = NULL;
  PyObject *__pyx_v_totalSize = NULL;
  PyObject *__pyx_v_d = NULL;
  PyObject *__pyx_v_myarray = NULL;
  PyObject *__pyx_v_i = NULL;
  PyObject *__pyx_v_shape = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  Py_ssize_t __pyx_t_4;
  int __pyx_t_5;
  int __pyx_t_6;
  PyObject *(*__pyx_t_7)(PyObject *);
  PyObject *__pyx_t_8 = NULL;
  Py_ssize_t __pyx_t_9;
  int __pyx_t_10;
  __Pyx_RefNannySetupContext("asNumpyTensor", 0);

  /* "PyTorch.pyx":470
 *         cdef long *data
 *         cdef _LongTensor contig
 *         size = self.size()             # <<<<<<<<<<<<<<
 *         dims = len(size)
 *         dtype = None
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_size); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 470, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 470, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 470, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_size = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":471
 *         cdef _LongTensor contig
 *         size = self.size()
 *         dims = len(size)             # <<<<<<<<<<<<<<
 *         dtype = None
 * 
 */
  __pyx_t_4 = PyObject_Length(__pyx_v_size); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 471, __pyx_L1_error)
  __pyx_t_1 = PyInt_FromSsize_t(__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 471, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_dims = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":472
 *         size = self.size()
 *         dims = len(size)
 *         dtype = None             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_INCREF(Py_None);
  __pyx_v_dtype = Py_None;

  /* "PyTorch.pyx":476
 * 
 * 
 *         if dtype is None:             # <<<<<<<<<<<<<<
 *           raise Exception("not implemented for Long")
 * #        print('dtype', dtype)
 */
  __pyx_t_5 = (__pyx_v_dtype == Py_None);
  __pyx_t_6 = (__pyx_t_5 != 0);
  if (__pyx_t_6) {

    /* "PyTorch.pyx":477
 * 
 *         if dtype is None:
 *           raise Exception("not implemented for Long")             # <<<<<<<<<<<<<<
 * #        print('dtype', dtype)
 *         if dims >= 1:
 */
    __pyx_t_1 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_tuple__6, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 477, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_Raise(__pyx_t_1, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(0, 477, __pyx_L1_error)

    /* "PyTorch.pyx":476
 * 
 * 
 *         if dtype is None:             # <<<<<<<<<<<<<<
 *           raise Exception("not implemented for Long")
 * #        print('dtype', dtype)
 */
  }

  /* "PyTorch.pyx":479
 *           raise Exception("not implemented for Long")
 * #        print('dtype', dtype)
 *         if dims >= 1:             # <<<<<<<<<<<<<<
 *             totalSize = 1
 *             for d in range(dims - 1, -1, -1):
 */
  __pyx_t_1 = PyObject_RichCompare(__pyx_v_dims, __pyx_int_1, Py_GE); __Pyx_XGOTREF(__pyx_t_1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 479, __pyx_L1_error)
  __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely(__pyx_t_6 < 0)) __PYX_ERR(0, 479, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (__pyx_t_6) {

    /* "PyTorch.pyx":480
 * #        print('dtype', dtype)
 *         if dims >= 1:
 *             totalSize = 1             # <<<<<<<<<<<<<<
 *             for d in range(dims - 1, -1, -1):
 *                 totalSize *= size[d]
 */
    __Pyx_INCREF(__pyx_int_1);
    __pyx_v_totalSize = __pyx_int_1;

    /* "PyTorch.pyx":481
 *         if dims >= 1:
 *             totalSize = 1
 *             for d in range(dims - 1, -1, -1):             # <<<<<<<<<<<<<<
 *                 totalSize *= size[d]
 *             myarray = np.zeros(totalSize, dtype=dtype)
 */
    __pyx_t_1 = __Pyx_PyInt_SubtractObjC(__pyx_v_dims, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 481, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_2 = PyTuple_New(3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 481, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_GIVEREF(__pyx_t_1);
    PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_1);
    __Pyx_INCREF(__pyx_int_neg_1);
    __Pyx_GIVEREF(__pyx_int_neg_1);
    PyTuple_SET_ITEM(__pyx_t_2, 1, __pyx_int_neg_1);
    __Pyx_INCREF(__pyx_int_neg_1);
    __Pyx_GIVEREF(__pyx_int_neg_1);
    PyTuple_SET_ITEM(__pyx_t_2, 2, __pyx_int_neg_1);
    __pyx_t_1 = 0;
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_range, __pyx_t_2, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 481, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    if (likely(PyList_CheckExact(__pyx_t_1)) || PyTuple_CheckExact(__pyx_t_1)) {
      __pyx_t_2 = __pyx_t_1; __Pyx_INCREF(__pyx_t_2); __pyx_t_4 = 0;
      __pyx_t_7 = NULL;
    } else {
      __pyx_t_4 = -1; __pyx_t_2 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 481, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_7 = Py_TYPE(__pyx_t_2)->tp_iternext; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 481, __pyx_L1_error)
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    for (;;) {
      if (likely(!__pyx_t_7)) {
        if (likely(PyList_CheckExact(__pyx_t_2))) {
          if (__pyx_t_4 >= PyList_GET_SIZE(__pyx_t_2)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_1 = PyList_GET_ITEM(__pyx_t_2, __pyx_t_4); __Pyx_INCREF(__pyx_t_1); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 481, __pyx_L1_error)
          #else
          __pyx_t_1 = PySequence_ITEM(__pyx_t_2, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 481, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_1);
          #endif
        } else {
          if (__pyx_t_4 >= PyTuple_GET_SIZE(__pyx_t_2)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_1 = PyTuple_GET_ITEM(__pyx_t_2, __pyx_t_4); __Pyx_INCREF(__pyx_t_1); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 481, __pyx_L1_error)
          #else
          __pyx_t_1 = PySequence_ITEM(__pyx_t_2, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 481, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_1);
          #endif
        }
      } else {
        __pyx_t_1 = __pyx_t_7(__pyx_t_2);
        if (unlikely(!__pyx_t_1)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(exc_type == PyExc_StopIteration || PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 481, __pyx_L1_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_1);
      }
      __Pyx_XDECREF_SET(__pyx_v_d, __pyx_t_1);
      __pyx_t_1 = 0;

      /* "PyTorch.pyx":482
 *             totalSize = 1
 *             for d in range(dims - 1, -1, -1):
 *                 totalSize *= size[d]             # <<<<<<<<<<<<<<
 *             myarray = np.zeros(totalSize, dtype=dtype)
 *             contig = self.contiguous()
 */
      __pyx_t_1 = PyObject_GetItem(__pyx_v_size, __pyx_v_d); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 482, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_3 = PyNumber_InPlaceMultiply(__pyx_v_totalSize, __pyx_t_1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 482, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_DECREF_SET(__pyx_v_totalSize, __pyx_t_3);
      __pyx_t_3 = 0;

      /* "PyTorch.pyx":481
 *         if dims >= 1:
 *             totalSize = 1
 *             for d in range(dims - 1, -1, -1):             # <<<<<<<<<<<<<<
 *                 totalSize *= size[d]
 *             myarray = np.zeros(totalSize, dtype=dtype)
 */
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

    /* "PyTorch.pyx":483
 *             for d in range(dims - 1, -1, -1):
 *                 totalSize *= size[d]
 *             myarray = np.zeros(totalSize, dtype=dtype)             # <<<<<<<<<<<<<<
 *             contig = self.contiguous()
 *             data = contig.data()
 */
    __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_np); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 483, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_zeros); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 483, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = PyTuple_New(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 483, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_INCREF(__pyx_v_totalSize);
    __Pyx_GIVEREF(__pyx_v_totalSize);
    PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_v_totalSize);
    __pyx_t_1 = PyDict_New(); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 483, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (PyDict_SetItem(__pyx_t_1, __pyx_n_s_dtype, __pyx_v_dtype) < 0) __PYX_ERR(0, 483, __pyx_L1_error)
    __pyx_t_8 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_2, __pyx_t_1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 483, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_v_myarray = __pyx_t_8;
    __pyx_t_8 = 0;

    /* "PyTorch.pyx":484
 *                 totalSize *= size[d]
 *             myarray = np.zeros(totalSize, dtype=dtype)
 *             contig = self.contiguous()             # <<<<<<<<<<<<<<
 *             data = contig.data()
 *             for i in range(totalSize):
 */
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_contiguous); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 484, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_2 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_1))) {
      __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_1);
      if (likely(__pyx_t_2)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
        __Pyx_INCREF(__pyx_t_2);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_1, function);
      }
    }
    if (__pyx_t_2) {
      __pyx_t_8 = __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_t_2); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 484, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    } else {
      __pyx_t_8 = __Pyx_PyObject_CallNoArg(__pyx_t_1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 484, __pyx_L1_error)
    }
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    if (!(likely(((__pyx_t_8) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_8, __pyx_ptype_7PyTorch__LongTensor))))) __PYX_ERR(0, 484, __pyx_L1_error)
    __pyx_v_contig = ((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_t_8);
    __pyx_t_8 = 0;

    /* "PyTorch.pyx":485
 *             myarray = np.zeros(totalSize, dtype=dtype)
 *             contig = self.contiguous()
 *             data = contig.data()             # <<<<<<<<<<<<<<
 *             for i in range(totalSize):
 *                 myarray[i] = data[i]
 */
    __pyx_v_data = ((struct __pyx_vtabstruct_7PyTorch__LongTensor *)__pyx_v_contig->__pyx_vtab)->data(__pyx_v_contig);

    /* "PyTorch.pyx":486
 *             contig = self.contiguous()
 *             data = contig.data()
 *             for i in range(totalSize):             # <<<<<<<<<<<<<<
 *                 myarray[i] = data[i]
 *             shape = []
 */
    __pyx_t_8 = PyTuple_New(1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 486, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_INCREF(__pyx_v_totalSize);
    __Pyx_GIVEREF(__pyx_v_totalSize);
    PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_v_totalSize);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_range, __pyx_t_8, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 486, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    if (likely(PyList_CheckExact(__pyx_t_1)) || PyTuple_CheckExact(__pyx_t_1)) {
      __pyx_t_8 = __pyx_t_1; __Pyx_INCREF(__pyx_t_8); __pyx_t_4 = 0;
      __pyx_t_7 = NULL;
    } else {
      __pyx_t_4 = -1; __pyx_t_8 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 486, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_7 = Py_TYPE(__pyx_t_8)->tp_iternext; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 486, __pyx_L1_error)
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    for (;;) {
      if (likely(!__pyx_t_7)) {
        if (likely(PyList_CheckExact(__pyx_t_8))) {
          if (__pyx_t_4 >= PyList_GET_SIZE(__pyx_t_8)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_1 = PyList_GET_ITEM(__pyx_t_8, __pyx_t_4); __Pyx_INCREF(__pyx_t_1); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 486, __pyx_L1_error)
          #else
          __pyx_t_1 = PySequence_ITEM(__pyx_t_8, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 486, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_1);
          #endif
        } else {
          if (__pyx_t_4 >= PyTuple_GET_SIZE(__pyx_t_8)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_1 = PyTuple_GET_ITEM(__pyx_t_8, __pyx_t_4); __Pyx_INCREF(__pyx_t_1); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 486, __pyx_L1_error)
          #else
          __pyx_t_1 = PySequence_ITEM(__pyx_t_8, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 486, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_1);
          #endif
        }
      } else {
        __pyx_t_1 = __pyx_t_7(__pyx_t_8);
        if (unlikely(!__pyx_t_1)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(exc_type == PyExc_StopIteration || PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 486, __pyx_L1_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_1);
      }
      __Pyx_XDECREF_SET(__pyx_v_i, __pyx_t_1);
      __pyx_t_1 = 0;

      /* "PyTorch.pyx":487
 *             data = contig.data()
 *             for i in range(totalSize):
 *                 myarray[i] = data[i]             # <<<<<<<<<<<<<<
 *             shape = []
 *             for d in range(dims):
 */
      __pyx_t_9 = __Pyx_PyIndex_AsSsize_t(__pyx_v_i); if (unlikely((__pyx_t_9 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 487, __pyx_L1_error)
      __pyx_t_1 = __Pyx_PyInt_From_long((__pyx_v_data[__pyx_t_9])); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 487, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      if (unlikely(PyObject_SetItem(__pyx_v_myarray, __pyx_v_i, __pyx_t_1) < 0)) __PYX_ERR(0, 487, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

      /* "PyTorch.pyx":486
 *             contig = self.contiguous()
 *             data = contig.data()
 *             for i in range(totalSize):             # <<<<<<<<<<<<<<
 *                 myarray[i] = data[i]
 *             shape = []
 */
    }
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;

    /* "PyTorch.pyx":488
 *             for i in range(totalSize):
 *                 myarray[i] = data[i]
 *             shape = []             # <<<<<<<<<<<<<<
 *             for d in range(dims):
 *                 shape.append(size[d])
 */
    __pyx_t_8 = PyList_New(0); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 488, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_v_shape = ((PyObject*)__pyx_t_8);
    __pyx_t_8 = 0;

    /* "PyTorch.pyx":489
 *                 myarray[i] = data[i]
 *             shape = []
 *             for d in range(dims):             # <<<<<<<<<<<<<<
 *                 shape.append(size[d])
 *             return myarray.reshape(shape)
 */
    __pyx_t_8 = PyTuple_New(1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 489, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_INCREF(__pyx_v_dims);
    __Pyx_GIVEREF(__pyx_v_dims);
    PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_v_dims);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_range, __pyx_t_8, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 489, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    if (likely(PyList_CheckExact(__pyx_t_1)) || PyTuple_CheckExact(__pyx_t_1)) {
      __pyx_t_8 = __pyx_t_1; __Pyx_INCREF(__pyx_t_8); __pyx_t_4 = 0;
      __pyx_t_7 = NULL;
    } else {
      __pyx_t_4 = -1; __pyx_t_8 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 489, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_7 = Py_TYPE(__pyx_t_8)->tp_iternext; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 489, __pyx_L1_error)
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    for (;;) {
      if (likely(!__pyx_t_7)) {
        if (likely(PyList_CheckExact(__pyx_t_8))) {
          if (__pyx_t_4 >= PyList_GET_SIZE(__pyx_t_8)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_1 = PyList_GET_ITEM(__pyx_t_8, __pyx_t_4); __Pyx_INCREF(__pyx_t_1); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 489, __pyx_L1_error)
          #else
          __pyx_t_1 = PySequence_ITEM(__pyx_t_8, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 489, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_1);
          #endif
        } else {
          if (__pyx_t_4 >= PyTuple_GET_SIZE(__pyx_t_8)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_1 = PyTuple_GET_ITEM(__pyx_t_8, __pyx_t_4); __Pyx_INCREF(__pyx_t_1); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 489, __pyx_L1_error)
          #else
          __pyx_t_1 = PySequence_ITEM(__pyx_t_8, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 489, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_1);
          #endif
        }
      } else {
        __pyx_t_1 = __pyx_t_7(__pyx_t_8);
        if (unlikely(!__pyx_t_1)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(exc_type == PyExc_StopIteration || PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 489, __pyx_L1_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_1);
      }
      __Pyx_XDECREF_SET(__pyx_v_d, __pyx_t_1);
      __pyx_t_1 = 0;

      /* "PyTorch.pyx":490
 *             shape = []
 *             for d in range(dims):
 *                 shape.append(size[d])             # <<<<<<<<<<<<<<
 *             return myarray.reshape(shape)
 *         else:
 */
      __pyx_t_1 = PyObject_GetItem(__pyx_v_size, __pyx_v_d); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 490, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_10 = __Pyx_PyList_Append(__pyx_v_shape, __pyx_t_1); if (unlikely(__pyx_t_10 == -1)) __PYX_ERR(0, 490, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

      /* "PyTorch.pyx":489
 *                 myarray[i] = data[i]
 *             shape = []
 *             for d in range(dims):             # <<<<<<<<<<<<<<
 *                 shape.append(size[d])
 *             return myarray.reshape(shape)
 */
    }
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;

    /* "PyTorch.pyx":491
 *             for d in range(dims):
 *                 shape.append(size[d])
 *             return myarray.reshape(shape)             # <<<<<<<<<<<<<<
 *         else:
 *             raise Exception('Not implemented for dims = {dims}'.format(dims=dims))
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_myarray, __pyx_n_s_reshape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 491, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_2 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_1))) {
      __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_1);
      if (likely(__pyx_t_2)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
        __Pyx_INCREF(__pyx_t_2);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_1, function);
      }
    }
    if (!__pyx_t_2) {
      __pyx_t_8 = __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_v_shape); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 491, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_1)) {
        PyObject *__pyx_temp[2] = {__pyx_t_2, __pyx_v_shape};
        __pyx_t_8 = __Pyx_PyFunction_FastCall(__pyx_t_1, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 491, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
        __Pyx_GOTREF(__pyx_t_8);
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_1)) {
        PyObject *__pyx_temp[2] = {__pyx_t_2, __pyx_v_shape};
        __pyx_t_8 = __Pyx_PyCFunction_FastCall(__pyx_t_1, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 491, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
        __Pyx_GOTREF(__pyx_t_8);
      } else
      #endif
      {
        __pyx_t_3 = PyTuple_New(1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 491, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_2); __pyx_t_2 = NULL;
        __Pyx_INCREF(__pyx_v_shape);
        __Pyx_GIVEREF(__pyx_v_shape);
        PyTuple_SET_ITEM(__pyx_t_3, 0+1, __pyx_v_shape);
        __pyx_t_8 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_3, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 491, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_r = __pyx_t_8;
    __pyx_t_8 = 0;
    goto __pyx_L0;

    /* "PyTorch.pyx":479
 *           raise Exception("not implemented for Long")
 * #        print('dtype', dtype)
 *         if dims >= 1:             # <<<<<<<<<<<<<<
 *             totalSize = 1
 *             for d in range(dims - 1, -1, -1):
 */
  }

  /* "PyTorch.pyx":493
 *             return myarray.reshape(shape)
 *         else:
 *             raise Exception('Not implemented for dims = {dims}'.format(dims=dims))             # <<<<<<<<<<<<<<
 * 
 *     @property
 */
  /*else*/ {
    __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_kp_s_Not_implemented_for_dims_dims, __pyx_n_s_format); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 493, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_1 = PyDict_New(); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 493, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (PyDict_SetItem(__pyx_t_1, __pyx_n_s_dims, __pyx_v_dims) < 0) __PYX_ERR(0, 493, __pyx_L1_error)
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_8, __pyx_empty_tuple, __pyx_t_1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 493, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 493, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_GIVEREF(__pyx_t_3);
    PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_3);
    __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_t_1, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 493, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(0, 493, __pyx_L1_error)
  }

  /* "PyTorch.pyx":466
 *         return THLongTensor_nElement(self.native)
 * 
 *     def asNumpyTensor(_LongTensor self):             # <<<<<<<<<<<<<<
 *         cdef Storage._LongStorage storage
 *         cdef long *data
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("PyTorch._LongTensor.asNumpyTensor", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_contig);
  __Pyx_XDECREF(__pyx_v_size);
  __Pyx_XDECREF(__pyx_v_dims);
  __Pyx_XDECREF(__pyx_v_dtype);
  __Pyx_XDECREF(__pyx_v_totalSize);
  __Pyx_XDECREF(__pyx_v_d);
  __Pyx_XDECREF(__pyx_v_myarray);
  __Pyx_XDECREF(__pyx_v_i);
  __Pyx_XDECREF(__pyx_v_shape);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":496
 * 
 *     @property
 *     def refCount(_LongTensor self):             # <<<<<<<<<<<<<<
 *         return THLongTensor_getRefCount(self.native)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_8refCount_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_8refCount_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_8refCount___get__(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_8refCount___get__(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "PyTorch.pyx":497
 *     @property
 *     def refCount(_LongTensor self):
 *         return THLongTensor_getRefCount(self.native)             # <<<<<<<<<<<<<<
 * 
 *     cdef long *data(_LongTensor self):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_int(THLongTensor_getRefCount(__pyx_v_self->native)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 497, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":496
 * 
 *     @property
 *     def refCount(_LongTensor self):             # <<<<<<<<<<<<<<
 *         return THLongTensor_getRefCount(self.native)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._LongTensor.refCount.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":499
 *         return THLongTensor_getRefCount(self.native)
 * 
 *     cdef long *data(_LongTensor self):             # <<<<<<<<<<<<<<
 *         return THLongTensor_data(self.native)
 * 
 */

static long *__pyx_f_7PyTorch_11_LongTensor_data(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self) {
  long *__pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("data", 0);

  /* "PyTorch.pyx":500
 * 
 *     cdef long *data(_LongTensor self):
 *         return THLongTensor_data(self.native)             # <<<<<<<<<<<<<<
 * 
 *     cpdef int dims(self):
 */
  __pyx_r = THLongTensor_data(__pyx_v_self->native);
  goto __pyx_L0;

  /* "PyTorch.pyx":499
 *         return THLongTensor_getRefCount(self.native)
 * 
 *     cdef long *data(_LongTensor self):             # <<<<<<<<<<<<<<
 *         return THLongTensor_data(self.native)
 * 
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":502
 *         return THLongTensor_data(self.native)
 * 
 *     cpdef int dims(self):             # <<<<<<<<<<<<<<
 *         return THLongTensor_nDimension(self.native)
 * 
 */

static PyObject *__pyx_pw_7PyTorch_11_LongTensor_9dims(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static int __pyx_f_7PyTorch_11_LongTensor_dims(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, int __pyx_skip_dispatch) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  int __pyx_t_5;
  __Pyx_RefNannySetupContext("dims", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_dims); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 502, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_9dims)) {
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_3 = __pyx_t_1; __pyx_t_4 = NULL;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
        __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
        if (likely(__pyx_t_4)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
          __Pyx_INCREF(__pyx_t_4);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_3, function);
        }
      }
      if (__pyx_t_4) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_4); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 502, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else {
        __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 502, __pyx_L1_error)
      }
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_5 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_5 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 502, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_r = __pyx_t_5;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "PyTorch.pyx":503
 * 
 *     cpdef int dims(self):
 *         return THLongTensor_nDimension(self.native)             # <<<<<<<<<<<<<<
 * 
 *     cpdef set1d(self, int x0, long value):
 */
  __pyx_r = THLongTensor_nDimension(__pyx_v_self->native);
  goto __pyx_L0;

  /* "PyTorch.pyx":502
 *         return THLongTensor_data(self.native)
 * 
 *     cpdef int dims(self):             # <<<<<<<<<<<<<<
 *         return THLongTensor_nDimension(self.native)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_WriteUnraisable("PyTorch._LongTensor.dims", __pyx_clineno, __pyx_lineno, __pyx_filename, 0, 0);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_9dims(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_9dims(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("dims (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_8dims(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_8dims(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("dims", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_f_7PyTorch_11_LongTensor_dims(__pyx_v_self, 1)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 502, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._LongTensor.dims", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":505
 *         return THLongTensor_nDimension(self.native)
 * 
 *     cpdef set1d(self, int x0, long value):             # <<<<<<<<<<<<<<
 *         THLongTensor_set1d(self.native, x0, value)
 * 
 */

static PyObject *__pyx_pw_7PyTorch_11_LongTensor_11set1d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_f_7PyTorch_11_LongTensor_set1d(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, int __pyx_v_x0, long __pyx_v_value, int __pyx_skip_dispatch) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  int __pyx_t_7;
  PyObject *__pyx_t_8 = NULL;
  __Pyx_RefNannySetupContext("set1d", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_set1d); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 505, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_11set1d)) {
      __Pyx_XDECREF(__pyx_r);
      __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_x0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 505, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_4 = __Pyx_PyInt_From_long(__pyx_v_value); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 505, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_5 = __pyx_t_1; __pyx_t_6 = NULL;
      __pyx_t_7 = 0;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
        __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_5);
        if (likely(__pyx_t_6)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
          __Pyx_INCREF(__pyx_t_6);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_5, function);
          __pyx_t_7 = 1;
        }
      }
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_5)) {
        PyObject *__pyx_temp[3] = {__pyx_t_6, __pyx_t_3, __pyx_t_4};
        __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_7, 2+__pyx_t_7); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 505, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
        PyObject *__pyx_temp[3] = {__pyx_t_6, __pyx_t_3, __pyx_t_4};
        __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_7, 2+__pyx_t_7); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 505, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else
      #endif
      {
        __pyx_t_8 = PyTuple_New(2+__pyx_t_7); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 505, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        if (__pyx_t_6) {
          __Pyx_GIVEREF(__pyx_t_6); PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_t_6); __pyx_t_6 = NULL;
        }
        __Pyx_GIVEREF(__pyx_t_3);
        PyTuple_SET_ITEM(__pyx_t_8, 0+__pyx_t_7, __pyx_t_3);
        __Pyx_GIVEREF(__pyx_t_4);
        PyTuple_SET_ITEM(__pyx_t_8, 1+__pyx_t_7, __pyx_t_4);
        __pyx_t_3 = 0;
        __pyx_t_4 = 0;
        __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_8, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 505, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      }
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __pyx_r = __pyx_t_2;
      __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "PyTorch.pyx":506
 * 
 *     cpdef set1d(self, int x0, long value):
 *         THLongTensor_set1d(self.native, x0, value)             # <<<<<<<<<<<<<<
 * 
 *     cpdef set2d(self, int x0, int x1, long value):
 */
  THLongTensor_set1d(__pyx_v_self->native, __pyx_v_x0, __pyx_v_value);

  /* "PyTorch.pyx":505
 *         return THLongTensor_nDimension(self.native)
 * 
 *     cpdef set1d(self, int x0, long value):             # <<<<<<<<<<<<<<
 *         THLongTensor_set1d(self.native, x0, value)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("PyTorch._LongTensor.set1d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_11set1d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_11set1d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  int __pyx_v_x0;
  long __pyx_v_value;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("set1d (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_x0,&__pyx_n_s_value,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_x0)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_value)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("set1d", 1, 2, 2, 1); __PYX_ERR(0, 505, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "set1d") < 0)) __PYX_ERR(0, 505, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_x0 = __Pyx_PyInt_As_int(values[0]); if (unlikely((__pyx_v_x0 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 505, __pyx_L3_error)
    __pyx_v_value = __Pyx_PyInt_As_long(values[1]); if (unlikely((__pyx_v_value == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 505, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("set1d", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 505, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._LongTensor.set1d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_10set1d(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self), __pyx_v_x0, __pyx_v_value);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_10set1d(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, int __pyx_v_x0, long __pyx_v_value) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("set1d", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_7PyTorch_11_LongTensor_set1d(__pyx_v_self, __pyx_v_x0, __pyx_v_value, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 505, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._LongTensor.set1d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":508
 *         THLongTensor_set1d(self.native, x0, value)
 * 
 *     cpdef set2d(self, int x0, int x1, long value):             # <<<<<<<<<<<<<<
 *         THLongTensor_set2d(self.native, x0, x1, value)
 * 
 */

static PyObject *__pyx_pw_7PyTorch_11_LongTensor_13set2d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_f_7PyTorch_11_LongTensor_set2d(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_v_x1, long __pyx_v_value, int __pyx_skip_dispatch) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  int __pyx_t_8;
  PyObject *__pyx_t_9 = NULL;
  __Pyx_RefNannySetupContext("set2d", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_set2d); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 508, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_13set2d)) {
      __Pyx_XDECREF(__pyx_r);
      __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_x0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 508, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_4 = __Pyx_PyInt_From_int(__pyx_v_x1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 508, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_t_5 = __Pyx_PyInt_From_long(__pyx_v_value); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 508, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_6 = __pyx_t_1; __pyx_t_7 = NULL;
      __pyx_t_8 = 0;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_6))) {
        __pyx_t_7 = PyMethod_GET_SELF(__pyx_t_6);
        if (likely(__pyx_t_7)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
          __Pyx_INCREF(__pyx_t_7);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_6, function);
          __pyx_t_8 = 1;
        }
      }
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_6)) {
        PyObject *__pyx_temp[4] = {__pyx_t_7, __pyx_t_3, __pyx_t_4, __pyx_t_5};
        __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_8, 3+__pyx_t_8); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 508, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_6)) {
        PyObject *__pyx_temp[4] = {__pyx_t_7, __pyx_t_3, __pyx_t_4, __pyx_t_5};
        __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_8, 3+__pyx_t_8); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 508, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      } else
      #endif
      {
        __pyx_t_9 = PyTuple_New(3+__pyx_t_8); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 508, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_9);
        if (__pyx_t_7) {
          __Pyx_GIVEREF(__pyx_t_7); PyTuple_SET_ITEM(__pyx_t_9, 0, __pyx_t_7); __pyx_t_7 = NULL;
        }
        __Pyx_GIVEREF(__pyx_t_3);
        PyTuple_SET_ITEM(__pyx_t_9, 0+__pyx_t_8, __pyx_t_3);
        __Pyx_GIVEREF(__pyx_t_4);
        PyTuple_SET_ITEM(__pyx_t_9, 1+__pyx_t_8, __pyx_t_4);
        __Pyx_GIVEREF(__pyx_t_5);
        PyTuple_SET_ITEM(__pyx_t_9, 2+__pyx_t_8, __pyx_t_5);
        __pyx_t_3 = 0;
        __pyx_t_4 = 0;
        __pyx_t_5 = 0;
        __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_9, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 508, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      }
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_r = __pyx_t_2;
      __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "PyTorch.pyx":509
 * 
 *     cpdef set2d(self, int x0, int x1, long value):
 *         THLongTensor_set2d(self.native, x0, x1, value)             # <<<<<<<<<<<<<<
 * 
 *     cpdef long get1d(self, int x0):
 */
  THLongTensor_set2d(__pyx_v_self->native, __pyx_v_x0, __pyx_v_x1, __pyx_v_value);

  /* "PyTorch.pyx":508
 *         THLongTensor_set1d(self.native, x0, value)
 * 
 *     cpdef set2d(self, int x0, int x1, long value):             # <<<<<<<<<<<<<<
 *         THLongTensor_set2d(self.native, x0, x1, value)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_AddTraceback("PyTorch._LongTensor.set2d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_13set2d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_13set2d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  int __pyx_v_x0;
  int __pyx_v_x1;
  long __pyx_v_value;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("set2d (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_x0,&__pyx_n_s_x1,&__pyx_n_s_value,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_x0)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_x1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("set2d", 1, 3, 3, 1); __PYX_ERR(0, 508, __pyx_L3_error)
        }
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_value)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("set2d", 1, 3, 3, 2); __PYX_ERR(0, 508, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "set2d") < 0)) __PYX_ERR(0, 508, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_x0 = __Pyx_PyInt_As_int(values[0]); if (unlikely((__pyx_v_x0 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 508, __pyx_L3_error)
    __pyx_v_x1 = __Pyx_PyInt_As_int(values[1]); if (unlikely((__pyx_v_x1 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 508, __pyx_L3_error)
    __pyx_v_value = __Pyx_PyInt_As_long(values[2]); if (unlikely((__pyx_v_value == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 508, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("set2d", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 508, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._LongTensor.set2d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_12set2d(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self), __pyx_v_x0, __pyx_v_x1, __pyx_v_value);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_12set2d(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_v_x1, long __pyx_v_value) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("set2d", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_7PyTorch_11_LongTensor_set2d(__pyx_v_self, __pyx_v_x0, __pyx_v_x1, __pyx_v_value, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 508, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._LongTensor.set2d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":511
 *         THLongTensor_set2d(self.native, x0, x1, value)
 * 
 *     cpdef long get1d(self, int x0):             # <<<<<<<<<<<<<<
 *         return THLongTensor_get1d(self.native, x0)
 * 
 */

static PyObject *__pyx_pw_7PyTorch_11_LongTensor_15get1d(PyObject *__pyx_v_self, PyObject *__pyx_arg_x0); /*proto*/
static long __pyx_f_7PyTorch_11_LongTensor_get1d(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_skip_dispatch) {
  long __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  long __pyx_t_7;
  __Pyx_RefNannySetupContext("get1d", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_get1d); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 511, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_15get1d)) {
      __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_x0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 511, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_4 = __pyx_t_1; __pyx_t_5 = NULL;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_4))) {
        __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_4);
        if (likely(__pyx_t_5)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
          __Pyx_INCREF(__pyx_t_5);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_4, function);
        }
      }
      if (!__pyx_t_5) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 511, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_GOTREF(__pyx_t_2);
      } else {
        #if CYTHON_FAST_PYCALL
        if (PyFunction_Check(__pyx_t_4)) {
          PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_t_3};
          __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_4, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 511, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        } else
        #endif
        #if CYTHON_FAST_PYCCALL
        if (__Pyx_PyFastCFunction_Check(__pyx_t_4)) {
          PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_t_3};
          __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_4, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 511, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        } else
        #endif
        {
          __pyx_t_6 = PyTuple_New(1+1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 511, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_6);
          __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_5); __pyx_t_5 = NULL;
          __Pyx_GIVEREF(__pyx_t_3);
          PyTuple_SET_ITEM(__pyx_t_6, 0+1, __pyx_t_3);
          __pyx_t_3 = 0;
          __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_4, __pyx_t_6, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 511, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
        }
      }
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_7 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_7 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 511, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_r = __pyx_t_7;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "PyTorch.pyx":512
 * 
 *     cpdef long get1d(self, int x0):
 *         return THLongTensor_get1d(self.native, x0)             # <<<<<<<<<<<<<<
 * 
 *     cpdef long get2d(self, int x0, int x1):
 */
  __pyx_r = THLongTensor_get1d(__pyx_v_self->native, __pyx_v_x0);
  goto __pyx_L0;

  /* "PyTorch.pyx":511
 *         THLongTensor_set2d(self.native, x0, x1, value)
 * 
 *     cpdef long get1d(self, int x0):             # <<<<<<<<<<<<<<
 *         return THLongTensor_get1d(self.native, x0)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_WriteUnraisable("PyTorch._LongTensor.get1d", __pyx_clineno, __pyx_lineno, __pyx_filename, 0, 0);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_15get1d(PyObject *__pyx_v_self, PyObject *__pyx_arg_x0); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_15get1d(PyObject *__pyx_v_self, PyObject *__pyx_arg_x0) {
  int __pyx_v_x0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("get1d (wrapper)", 0);
  assert(__pyx_arg_x0); {
    __pyx_v_x0 = __Pyx_PyInt_As_int(__pyx_arg_x0); if (unlikely((__pyx_v_x0 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 511, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._LongTensor.get1d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_14get1d(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self), ((int)__pyx_v_x0));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_14get1d(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, int __pyx_v_x0) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("get1d", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_long(__pyx_f_7PyTorch_11_LongTensor_get1d(__pyx_v_self, __pyx_v_x0, 1)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 511, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._LongTensor.get1d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":514
 *         return THLongTensor_get1d(self.native, x0)
 * 
 *     cpdef long get2d(self, int x0, int x1):             # <<<<<<<<<<<<<<
 *         return THLongTensor_get2d(self.native, x0, x1)
 * 
 */

static PyObject *__pyx_pw_7PyTorch_11_LongTensor_17get2d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static long __pyx_f_7PyTorch_11_LongTensor_get2d(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_v_x1, int __pyx_skip_dispatch) {
  long __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  int __pyx_t_7;
  PyObject *__pyx_t_8 = NULL;
  long __pyx_t_9;
  __Pyx_RefNannySetupContext("get2d", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_get2d); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 514, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_17get2d)) {
      __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_x0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 514, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_4 = __Pyx_PyInt_From_int(__pyx_v_x1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 514, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_5 = __pyx_t_1; __pyx_t_6 = NULL;
      __pyx_t_7 = 0;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
        __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_5);
        if (likely(__pyx_t_6)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
          __Pyx_INCREF(__pyx_t_6);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_5, function);
          __pyx_t_7 = 1;
        }
      }
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_5)) {
        PyObject *__pyx_temp[3] = {__pyx_t_6, __pyx_t_3, __pyx_t_4};
        __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_7, 2+__pyx_t_7); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 514, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
        PyObject *__pyx_temp[3] = {__pyx_t_6, __pyx_t_3, __pyx_t_4};
        __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_7, 2+__pyx_t_7); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 514, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else
      #endif
      {
        __pyx_t_8 = PyTuple_New(2+__pyx_t_7); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 514, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        if (__pyx_t_6) {
          __Pyx_GIVEREF(__pyx_t_6); PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_t_6); __pyx_t_6 = NULL;
        }
        __Pyx_GIVEREF(__pyx_t_3);
        PyTuple_SET_ITEM(__pyx_t_8, 0+__pyx_t_7, __pyx_t_3);
        __Pyx_GIVEREF(__pyx_t_4);
        PyTuple_SET_ITEM(__pyx_t_8, 1+__pyx_t_7, __pyx_t_4);
        __pyx_t_3 = 0;
        __pyx_t_4 = 0;
        __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_8, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 514, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      }
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __pyx_t_9 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_9 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 514, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_r = __pyx_t_9;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "PyTorch.pyx":515
 * 
 *     cpdef long get2d(self, int x0, int x1):
 *         return THLongTensor_get2d(self.native, x0, x1)             # <<<<<<<<<<<<<<
 * 
 *     cpdef int isContiguous(_LongTensor self):
 */
  __pyx_r = THLongTensor_get2d(__pyx_v_self->native, __pyx_v_x0, __pyx_v_x1);
  goto __pyx_L0;

  /* "PyTorch.pyx":514
 *         return THLongTensor_get1d(self.native, x0)
 * 
 *     cpdef long get2d(self, int x0, int x1):             # <<<<<<<<<<<<<<
 *         return THLongTensor_get2d(self.native, x0, x1)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_WriteUnraisable("PyTorch._LongTensor.get2d", __pyx_clineno, __pyx_lineno, __pyx_filename, 0, 0);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_17get2d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_17get2d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  int __pyx_v_x0;
  int __pyx_v_x1;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("get2d (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_x0,&__pyx_n_s_x1,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_x0)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_x1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("get2d", 1, 2, 2, 1); __PYX_ERR(0, 514, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "get2d") < 0)) __PYX_ERR(0, 514, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_x0 = __Pyx_PyInt_As_int(values[0]); if (unlikely((__pyx_v_x0 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 514, __pyx_L3_error)
    __pyx_v_x1 = __Pyx_PyInt_As_int(values[1]); if (unlikely((__pyx_v_x1 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 514, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("get2d", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 514, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._LongTensor.get2d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_16get2d(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self), __pyx_v_x0, __pyx_v_x1);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_16get2d(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_v_x1) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("get2d", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_long(__pyx_f_7PyTorch_11_LongTensor_get2d(__pyx_v_self, __pyx_v_x0, __pyx_v_x1, 1)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 514, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._LongTensor.get2d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":517
 *         return THLongTensor_get2d(self.native, x0, x1)
 * 
 *     cpdef int isContiguous(_LongTensor self):             # <<<<<<<<<<<<<<
 *         return THLongTensor_isContiguous(self.native)
 * 
 */

static PyObject *__pyx_pw_7PyTorch_11_LongTensor_19isContiguous(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static int __pyx_f_7PyTorch_11_LongTensor_isContiguous(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, int __pyx_skip_dispatch) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  int __pyx_t_5;
  __Pyx_RefNannySetupContext("isContiguous", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_isContiguous); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 517, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_19isContiguous)) {
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_3 = __pyx_t_1; __pyx_t_4 = NULL;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
        __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
        if (likely(__pyx_t_4)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
          __Pyx_INCREF(__pyx_t_4);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_3, function);
        }
      }
      if (__pyx_t_4) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_4); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 517, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else {
        __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 517, __pyx_L1_error)
      }
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_5 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_5 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 517, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_r = __pyx_t_5;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "PyTorch.pyx":518
 * 
 *     cpdef int isContiguous(_LongTensor self):
 *         return THLongTensor_isContiguous(self.native)             # <<<<<<<<<<<<<<
 * 
 *     cpdef long max(self):
 */
  __pyx_r = THLongTensor_isContiguous(__pyx_v_self->native);
  goto __pyx_L0;

  /* "PyTorch.pyx":517
 *         return THLongTensor_get2d(self.native, x0, x1)
 * 
 *     cpdef int isContiguous(_LongTensor self):             # <<<<<<<<<<<<<<
 *         return THLongTensor_isContiguous(self.native)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_WriteUnraisable("PyTorch._LongTensor.isContiguous", __pyx_clineno, __pyx_lineno, __pyx_filename, 0, 0);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_19isContiguous(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_19isContiguous(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("isContiguous (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_18isContiguous(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_18isContiguous(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("isContiguous", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_f_7PyTorch_11_LongTensor_isContiguous(__pyx_v_self, 1)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 517, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._LongTensor.isContiguous", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":520
 *         return THLongTensor_isContiguous(self.native)
 * 
 *     cpdef long max(self):             # <<<<<<<<<<<<<<
 *         return THLongTensor_maxall(self.native)
 * 
 */

static PyObject *__pyx_pw_7PyTorch_11_LongTensor_21max(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static long __pyx_f_7PyTorch_11_LongTensor_max(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, int __pyx_skip_dispatch) {
  long __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  long __pyx_t_5;
  __Pyx_RefNannySetupContext("max", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_max); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 520, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_21max)) {
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_3 = __pyx_t_1; __pyx_t_4 = NULL;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
        __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
        if (likely(__pyx_t_4)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
          __Pyx_INCREF(__pyx_t_4);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_3, function);
        }
      }
      if (__pyx_t_4) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_4); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 520, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else {
        __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 520, __pyx_L1_error)
      }
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_5 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_5 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 520, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_r = __pyx_t_5;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "PyTorch.pyx":521
 * 
 *     cpdef long max(self):
 *         return THLongTensor_maxall(self.native)             # <<<<<<<<<<<<<<
 * 
 *     cpdef long min(self):
 */
  __pyx_r = THLongTensor_maxall(__pyx_v_self->native);
  goto __pyx_L0;

  /* "PyTorch.pyx":520
 *         return THLongTensor_isContiguous(self.native)
 * 
 *     cpdef long max(self):             # <<<<<<<<<<<<<<
 *         return THLongTensor_maxall(self.native)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_WriteUnraisable("PyTorch._LongTensor.max", __pyx_clineno, __pyx_lineno, __pyx_filename, 0, 0);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_21max(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_21max(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("max (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_20max(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_20max(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("max", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_long(__pyx_f_7PyTorch_11_LongTensor_max(__pyx_v_self, 1)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 520, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._LongTensor.max", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":523
 *         return THLongTensor_maxall(self.native)
 * 
 *     cpdef long min(self):             # <<<<<<<<<<<<<<
 *         return THLongTensor_minall(self.native)
 * 
 */

static PyObject *__pyx_pw_7PyTorch_11_LongTensor_23min(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static long __pyx_f_7PyTorch_11_LongTensor_min(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, int __pyx_skip_dispatch) {
  long __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  long __pyx_t_5;
  __Pyx_RefNannySetupContext("min", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_min); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 523, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_23min)) {
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_3 = __pyx_t_1; __pyx_t_4 = NULL;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
        __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
        if (likely(__pyx_t_4)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
          __Pyx_INCREF(__pyx_t_4);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_3, function);
        }
      }
      if (__pyx_t_4) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_4); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 523, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else {
        __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 523, __pyx_L1_error)
      }
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_5 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_5 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 523, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_r = __pyx_t_5;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "PyTorch.pyx":524
 * 
 *     cpdef long min(self):
 *         return THLongTensor_minall(self.native)             # <<<<<<<<<<<<<<
 * 
 *     def __repr__(_LongTensor self):
 */
  __pyx_r = THLongTensor_minall(__pyx_v_self->native);
  goto __pyx_L0;

  /* "PyTorch.pyx":523
 *         return THLongTensor_maxall(self.native)
 * 
 *     cpdef long min(self):             # <<<<<<<<<<<<<<
 *         return THLongTensor_minall(self.native)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_WriteUnraisable("PyTorch._LongTensor.min", __pyx_clineno, __pyx_lineno, __pyx_filename, 0, 0);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_23min(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_23min(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("min (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_22min(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_22min(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("min", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_long(__pyx_f_7PyTorch_11_LongTensor_min(__pyx_v_self, 1)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 523, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._LongTensor.min", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":526
 *         return THLongTensor_minall(self.native)
 * 
 *     def __repr__(_LongTensor self):             # <<<<<<<<<<<<<<
 *         return self.as_string(self)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_25__repr__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_25__repr__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__repr__ (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_24__repr__(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_24__repr__(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  __Pyx_RefNannySetupContext("__repr__", 0);

  /* "PyTorch.pyx":527
 * 
 *     def __repr__(_LongTensor self):
 *         return self.as_string(self)             # <<<<<<<<<<<<<<
 * 
 *     def as_string(_LongTensor self, show_size=True):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_as_string); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 527, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (!__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, ((PyObject *)__pyx_v_self)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 527, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
  } else {
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_2)) {
      PyObject *__pyx_temp[2] = {__pyx_t_3, ((PyObject *)__pyx_v_self)};
      __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 527, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_GOTREF(__pyx_t_1);
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
      PyObject *__pyx_temp[2] = {__pyx_t_3, ((PyObject *)__pyx_v_self)};
      __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 527, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_GOTREF(__pyx_t_1);
    } else
    #endif
    {
      __pyx_t_4 = PyTuple_New(1+1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 527, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_GIVEREF(__pyx_t_3); PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_3); __pyx_t_3 = NULL;
      __Pyx_INCREF(((PyObject *)__pyx_v_self));
      __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
      PyTuple_SET_ITEM(__pyx_t_4, 0+1, ((PyObject *)__pyx_v_self));
      __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_4, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 527, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    }
  }
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":526
 *         return THLongTensor_minall(self.native)
 * 
 *     def __repr__(_LongTensor self):             # <<<<<<<<<<<<<<
 *         return self.as_string(self)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("PyTorch._LongTensor.__repr__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":529
 *         return self.as_string(self)
 * 
 *     def as_string(_LongTensor self, show_size=True):             # <<<<<<<<<<<<<<
 *         # assume 2d matrix for now
 *         cdef int size0
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_27as_string(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_27as_string(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_show_size = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("as_string (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_show_size,0};
    PyObject* values[1] = {0};
    values[0] = ((PyObject *)Py_True);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_show_size);
          if (value) { values[0] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "as_string") < 0)) __PYX_ERR(0, 529, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_show_size = values[0];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("as_string", 0, 0, 1, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 529, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._LongTensor.as_string", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_26as_string(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self), __pyx_v_show_size);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_26as_string(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, PyObject *__pyx_v_show_size) {
  int __pyx_v_size0;
  int __pyx_v_size1;
  int __pyx_v_dims;
  PyObject *__pyx_v_res = NULL;
  int __pyx_v_r;
  PyObject *__pyx_v_thisline = NULL;
  int __pyx_v_c;
  PyObject *__pyx_v_d = NULL;
  int __pyx_v_first;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  int __pyx_t_3;
  int __pyx_t_4;
  int __pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  Py_ssize_t __pyx_t_9;
  PyObject *(*__pyx_t_10)(PyObject *);
  PyObject *__pyx_t_11 = NULL;
  __Pyx_RefNannySetupContext("as_string", 0);

  /* "PyTorch.pyx":533
 *         cdef int size0
 *         cdef int size1
 *         dims = self.dims()             # <<<<<<<<<<<<<<
 *         if dims == 0:
 *             return '[torch.LongTensor with no dimension]\n'
 */
  __pyx_v_dims = ((struct __pyx_vtabstruct_7PyTorch__LongTensor *)__pyx_v_self->__pyx_vtab)->dims(__pyx_v_self, 0);

  /* "PyTorch.pyx":534
 *         cdef int size1
 *         dims = self.dims()
 *         if dims == 0:             # <<<<<<<<<<<<<<
 *             return '[torch.LongTensor with no dimension]\n'
 *         elif dims == 2:
 */
  switch (__pyx_v_dims) {
    case 0:

    /* "PyTorch.pyx":535
 *         dims = self.dims()
 *         if dims == 0:
 *             return '[torch.LongTensor with no dimension]\n'             # <<<<<<<<<<<<<<
 *         elif dims == 2:
 *             size0 = THLongTensor_size(self.native, 0)
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(__pyx_kp_s_torch_LongTensor_with_no_dimens);
    __pyx_r = __pyx_kp_s_torch_LongTensor_with_no_dimens;
    goto __pyx_L0;

    /* "PyTorch.pyx":534
 *         cdef int size1
 *         dims = self.dims()
 *         if dims == 0:             # <<<<<<<<<<<<<<
 *             return '[torch.LongTensor with no dimension]\n'
 *         elif dims == 2:
 */
    break;

    /* "PyTorch.pyx":536
 *         if dims == 0:
 *             return '[torch.LongTensor with no dimension]\n'
 *         elif dims == 2:             # <<<<<<<<<<<<<<
 *             size0 = THLongTensor_size(self.native, 0)
 *             size1 = THLongTensor_size(self.native, 1)
 */
    case 2:

    /* "PyTorch.pyx":537
 *             return '[torch.LongTensor with no dimension]\n'
 *         elif dims == 2:
 *             size0 = THLongTensor_size(self.native, 0)             # <<<<<<<<<<<<<<
 *             size1 = THLongTensor_size(self.native, 1)
 *             res = ''
 */
    __pyx_v_size0 = THLongTensor_size(__pyx_v_self->native, 0);

    /* "PyTorch.pyx":538
 *         elif dims == 2:
 *             size0 = THLongTensor_size(self.native, 0)
 *             size1 = THLongTensor_size(self.native, 1)             # <<<<<<<<<<<<<<
 *             res = ''
 *             for r in range(size0):
 */
    __pyx_v_size1 = THLongTensor_size(__pyx_v_self->native, 1);

    /* "PyTorch.pyx":539
 *             size0 = THLongTensor_size(self.native, 0)
 *             size1 = THLongTensor_size(self.native, 1)
 *             res = ''             # <<<<<<<<<<<<<<
 *             for r in range(size0):
 *                 thisline = ''
 */
    __Pyx_INCREF(__pyx_kp_s__7);
    __pyx_v_res = __pyx_kp_s__7;

    /* "PyTorch.pyx":540
 *             size1 = THLongTensor_size(self.native, 1)
 *             res = ''
 *             for r in range(size0):             # <<<<<<<<<<<<<<
 *                 thisline = ''
 *                 for c in range(size1):
 */
    __pyx_t_1 = __pyx_v_size0;
    for (__pyx_t_2 = 0; __pyx_t_2 < __pyx_t_1; __pyx_t_2+=1) {
      __pyx_v_r = __pyx_t_2;

      /* "PyTorch.pyx":541
 *             res = ''
 *             for r in range(size0):
 *                 thisline = ''             # <<<<<<<<<<<<<<
 *                 for c in range(size1):
 *                     if c > 0:
 */
      __Pyx_INCREF(__pyx_kp_s__7);
      __Pyx_XDECREF_SET(__pyx_v_thisline, __pyx_kp_s__7);

      /* "PyTorch.pyx":542
 *             for r in range(size0):
 *                 thisline = ''
 *                 for c in range(size1):             # <<<<<<<<<<<<<<
 *                     if c > 0:
 *                         thisline += ' '
 */
      __pyx_t_3 = __pyx_v_size1;
      for (__pyx_t_4 = 0; __pyx_t_4 < __pyx_t_3; __pyx_t_4+=1) {
        __pyx_v_c = __pyx_t_4;

        /* "PyTorch.pyx":543
 *                 thisline = ''
 *                 for c in range(size1):
 *                     if c > 0:             # <<<<<<<<<<<<<<
 *                         thisline += ' '
 * 
 */
        __pyx_t_5 = ((__pyx_v_c > 0) != 0);
        if (__pyx_t_5) {

          /* "PyTorch.pyx":544
 *                 for c in range(size1):
 *                     if c > 0:
 *                         thisline += ' '             # <<<<<<<<<<<<<<
 * 
 *                     thisline += str(self.get2d(r,c),)
 */
          __pyx_t_6 = PyNumber_InPlaceAdd(__pyx_v_thisline, __pyx_kp_s__8); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 544, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_6);
          __Pyx_DECREF_SET(__pyx_v_thisline, __pyx_t_6);
          __pyx_t_6 = 0;

          /* "PyTorch.pyx":543
 *                 thisline = ''
 *                 for c in range(size1):
 *                     if c > 0:             # <<<<<<<<<<<<<<
 *                         thisline += ' '
 * 
 */
        }

        /* "PyTorch.pyx":546
 *                         thisline += ' '
 * 
 *                     thisline += str(self.get2d(r,c),)             # <<<<<<<<<<<<<<
 * 
 *                 res += thisline + '\n'
 */
        __pyx_t_6 = __Pyx_PyInt_From_long(((struct __pyx_vtabstruct_7PyTorch__LongTensor *)__pyx_v_self->__pyx_vtab)->get2d(__pyx_v_self, __pyx_v_r, __pyx_v_c, 0)); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 546, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __pyx_t_7 = PyTuple_New(1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 546, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        __Pyx_GIVEREF(__pyx_t_6);
        PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_6);
        __pyx_t_6 = 0;
        __pyx_t_6 = __Pyx_PyObject_Call(((PyObject *)(&PyString_Type)), __pyx_t_7, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 546, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        __pyx_t_7 = PyNumber_InPlaceAdd(__pyx_v_thisline, __pyx_t_6); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 546, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_DECREF_SET(__pyx_v_thisline, __pyx_t_7);
        __pyx_t_7 = 0;
      }

      /* "PyTorch.pyx":548
 *                     thisline += str(self.get2d(r,c),)
 * 
 *                 res += thisline + '\n'             # <<<<<<<<<<<<<<
 *             if show_size:
 *                 res += '[torch.LongTensor of size ' + ('%.0f' % size0) + 'x' + str(size1) + ']\n'
 */
      __pyx_t_7 = PyNumber_Add(__pyx_v_thisline, __pyx_kp_s__9); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 548, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __pyx_t_6 = PyNumber_InPlaceAdd(__pyx_v_res, __pyx_t_7); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 548, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_DECREF_SET(__pyx_v_res, __pyx_t_6);
      __pyx_t_6 = 0;
    }

    /* "PyTorch.pyx":549
 * 
 *                 res += thisline + '\n'
 *             if show_size:             # <<<<<<<<<<<<<<
 *                 res += '[torch.LongTensor of size ' + ('%.0f' % size0) + 'x' + str(size1) + ']\n'
 *             return res
 */
    __pyx_t_5 = __Pyx_PyObject_IsTrue(__pyx_v_show_size); if (unlikely(__pyx_t_5 < 0)) __PYX_ERR(0, 549, __pyx_L1_error)
    if (__pyx_t_5) {

      /* "PyTorch.pyx":550
 *                 res += thisline + '\n'
 *             if show_size:
 *                 res += '[torch.LongTensor of size ' + ('%.0f' % size0) + 'x' + str(size1) + ']\n'             # <<<<<<<<<<<<<<
 *             return res
 *         elif dims == 1:
 */
      __pyx_t_6 = __Pyx_PyInt_From_int(__pyx_v_size0); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 550, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __pyx_t_7 = __Pyx_PyString_Format(__pyx_kp_s_0f, __pyx_t_6); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 550, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_6 = PyNumber_Add(__pyx_kp_s_torch_LongTensor_of_size, __pyx_t_7); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 550, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __pyx_t_7 = PyNumber_Add(__pyx_t_6, __pyx_n_s_x); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 550, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_6 = __Pyx_PyInt_From_int(__pyx_v_size1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 550, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __pyx_t_8 = PyTuple_New(1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 550, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_GIVEREF(__pyx_t_6);
      PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_t_6);
      __pyx_t_6 = 0;
      __pyx_t_6 = __Pyx_PyObject_Call(((PyObject *)(&PyString_Type)), __pyx_t_8, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 550, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_8 = PyNumber_Add(__pyx_t_7, __pyx_t_6); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 550, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_6 = PyNumber_Add(__pyx_t_8, __pyx_kp_s__10); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 550, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_8 = PyNumber_InPlaceAdd(__pyx_v_res, __pyx_t_6); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 550, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_DECREF_SET(__pyx_v_res, __pyx_t_8);
      __pyx_t_8 = 0;

      /* "PyTorch.pyx":549
 * 
 *                 res += thisline + '\n'
 *             if show_size:             # <<<<<<<<<<<<<<
 *                 res += '[torch.LongTensor of size ' + ('%.0f' % size0) + 'x' + str(size1) + ']\n'
 *             return res
 */
    }

    /* "PyTorch.pyx":551
 *             if show_size:
 *                 res += '[torch.LongTensor of size ' + ('%.0f' % size0) + 'x' + str(size1) + ']\n'
 *             return res             # <<<<<<<<<<<<<<
 *         elif dims == 1:
 *             size0 = THLongTensor_size(self.native, 0)
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(__pyx_v_res);
    __pyx_r = __pyx_v_res;
    goto __pyx_L0;

    /* "PyTorch.pyx":536
 *         if dims == 0:
 *             return '[torch.LongTensor with no dimension]\n'
 *         elif dims == 2:             # <<<<<<<<<<<<<<
 *             size0 = THLongTensor_size(self.native, 0)
 *             size1 = THLongTensor_size(self.native, 1)
 */
    break;

    /* "PyTorch.pyx":552
 *                 res += '[torch.LongTensor of size ' + ('%.0f' % size0) + 'x' + str(size1) + ']\n'
 *             return res
 *         elif dims == 1:             # <<<<<<<<<<<<<<
 *             size0 = THLongTensor_size(self.native, 0)
 *             res = ''
 */
    case 1:

    /* "PyTorch.pyx":553
 *             return res
 *         elif dims == 1:
 *             size0 = THLongTensor_size(self.native, 0)             # <<<<<<<<<<<<<<
 *             res = ''
 *             thisline = ''
 */
    __pyx_v_size0 = THLongTensor_size(__pyx_v_self->native, 0);

    /* "PyTorch.pyx":554
 *         elif dims == 1:
 *             size0 = THLongTensor_size(self.native, 0)
 *             res = ''             # <<<<<<<<<<<<<<
 *             thisline = ''
 *             for c in range(size0):
 */
    __Pyx_INCREF(__pyx_kp_s__7);
    __pyx_v_res = __pyx_kp_s__7;

    /* "PyTorch.pyx":555
 *             size0 = THLongTensor_size(self.native, 0)
 *             res = ''
 *             thisline = ''             # <<<<<<<<<<<<<<
 *             for c in range(size0):
 *                 if c > 0:
 */
    __Pyx_INCREF(__pyx_kp_s__7);
    __pyx_v_thisline = __pyx_kp_s__7;

    /* "PyTorch.pyx":556
 *             res = ''
 *             thisline = ''
 *             for c in range(size0):             # <<<<<<<<<<<<<<
 *                 if c > 0:
 *                     thisline += ' '
 */
    __pyx_t_1 = __pyx_v_size0;
    for (__pyx_t_2 = 0; __pyx_t_2 < __pyx_t_1; __pyx_t_2+=1) {
      __pyx_v_c = __pyx_t_2;

      /* "PyTorch.pyx":557
 *             thisline = ''
 *             for c in range(size0):
 *                 if c > 0:             # <<<<<<<<<<<<<<
 *                     thisline += ' '
 * 
 */
      __pyx_t_5 = ((__pyx_v_c > 0) != 0);
      if (__pyx_t_5) {

        /* "PyTorch.pyx":558
 *             for c in range(size0):
 *                 if c > 0:
 *                     thisline += ' '             # <<<<<<<<<<<<<<
 * 
 *                 thisline += str(self.get1d(c))
 */
        __pyx_t_8 = PyNumber_InPlaceAdd(__pyx_v_thisline, __pyx_kp_s__8); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 558, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        __Pyx_DECREF_SET(__pyx_v_thisline, __pyx_t_8);
        __pyx_t_8 = 0;

        /* "PyTorch.pyx":557
 *             thisline = ''
 *             for c in range(size0):
 *                 if c > 0:             # <<<<<<<<<<<<<<
 *                     thisline += ' '
 * 
 */
      }

      /* "PyTorch.pyx":560
 *                     thisline += ' '
 * 
 *                 thisline += str(self.get1d(c))             # <<<<<<<<<<<<<<
 * 
 *             res += thisline + '\n'
 */
      __pyx_t_8 = __Pyx_PyInt_From_long(((struct __pyx_vtabstruct_7PyTorch__LongTensor *)__pyx_v_self->__pyx_vtab)->get1d(__pyx_v_self, __pyx_v_c, 0)); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 560, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_6 = PyTuple_New(1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 560, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_GIVEREF(__pyx_t_8);
      PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_8);
      __pyx_t_8 = 0;
      __pyx_t_8 = __Pyx_PyObject_Call(((PyObject *)(&PyString_Type)), __pyx_t_6, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 560, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_6 = PyNumber_InPlaceAdd(__pyx_v_thisline, __pyx_t_8); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 560, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_DECREF_SET(__pyx_v_thisline, __pyx_t_6);
      __pyx_t_6 = 0;
    }

    /* "PyTorch.pyx":562
 *                 thisline += str(self.get1d(c))
 * 
 *             res += thisline + '\n'             # <<<<<<<<<<<<<<
 *             if show_size:
 *                 res += '[torch.LongTensor of size ' + str(size0) + ']\n'
 */
    __pyx_t_6 = PyNumber_Add(__pyx_v_thisline, __pyx_kp_s__9); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 562, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_8 = PyNumber_InPlaceAdd(__pyx_v_res, __pyx_t_6); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 562, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_DECREF_SET(__pyx_v_res, __pyx_t_8);
    __pyx_t_8 = 0;

    /* "PyTorch.pyx":563
 * 
 *             res += thisline + '\n'
 *             if show_size:             # <<<<<<<<<<<<<<
 *                 res += '[torch.LongTensor of size ' + str(size0) + ']\n'
 *             return res
 */
    __pyx_t_5 = __Pyx_PyObject_IsTrue(__pyx_v_show_size); if (unlikely(__pyx_t_5 < 0)) __PYX_ERR(0, 563, __pyx_L1_error)
    if (__pyx_t_5) {

      /* "PyTorch.pyx":564
 *             res += thisline + '\n'
 *             if show_size:
 *                 res += '[torch.LongTensor of size ' + str(size0) + ']\n'             # <<<<<<<<<<<<<<
 *             return res
 *         elif dims == 3:
 */
      __pyx_t_8 = __Pyx_PyInt_From_int(__pyx_v_size0); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 564, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_6 = PyTuple_New(1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 564, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_GIVEREF(__pyx_t_8);
      PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_8);
      __pyx_t_8 = 0;
      __pyx_t_8 = __Pyx_PyObject_Call(((PyObject *)(&PyString_Type)), __pyx_t_6, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 564, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_6 = PyNumber_Add(__pyx_kp_s_torch_LongTensor_of_size, __pyx_t_8); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 564, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_8 = PyNumber_Add(__pyx_t_6, __pyx_kp_s__10); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 564, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_6 = PyNumber_InPlaceAdd(__pyx_v_res, __pyx_t_8); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 564, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_DECREF_SET(__pyx_v_res, __pyx_t_6);
      __pyx_t_6 = 0;

      /* "PyTorch.pyx":563
 * 
 *             res += thisline + '\n'
 *             if show_size:             # <<<<<<<<<<<<<<
 *                 res += '[torch.LongTensor of size ' + str(size0) + ']\n'
 *             return res
 */
    }

    /* "PyTorch.pyx":565
 *             if show_size:
 *                 res += '[torch.LongTensor of size ' + str(size0) + ']\n'
 *             return res             # <<<<<<<<<<<<<<
 *         elif dims == 3:
 *             res = ''
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(__pyx_v_res);
    __pyx_r = __pyx_v_res;
    goto __pyx_L0;

    /* "PyTorch.pyx":552
 *                 res += '[torch.LongTensor of size ' + ('%.0f' % size0) + 'x' + str(size1) + ']\n'
 *             return res
 *         elif dims == 1:             # <<<<<<<<<<<<<<
 *             size0 = THLongTensor_size(self.native, 0)
 *             res = ''
 */
    break;

    /* "PyTorch.pyx":566
 *                 res += '[torch.LongTensor of size ' + str(size0) + ']\n'
 *             return res
 *         elif dims == 3:             # <<<<<<<<<<<<<<
 *             res = ''
 *             for d in range(self.size()[0]):
 */
    case 3:

    /* "PyTorch.pyx":567
 *             return res
 *         elif dims == 3:
 *             res = ''             # <<<<<<<<<<<<<<
 *             for d in range(self.size()[0]):
 *                 res += '(' + str(d) + ',.,.) =\n'
 */
    __Pyx_INCREF(__pyx_kp_s__7);
    __pyx_v_res = __pyx_kp_s__7;

    /* "PyTorch.pyx":568
 *         elif dims == 3:
 *             res = ''
 *             for d in range(self.size()[0]):             # <<<<<<<<<<<<<<
 *                 res += '(' + str(d) + ',.,.) =\n'
 *                 res += self[d].as_string(show_size=False)
 */
    __pyx_t_8 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_size); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 568, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_7 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_8))) {
      __pyx_t_7 = PyMethod_GET_SELF(__pyx_t_8);
      if (likely(__pyx_t_7)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_8);
        __Pyx_INCREF(__pyx_t_7);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_8, function);
      }
    }
    if (__pyx_t_7) {
      __pyx_t_6 = __Pyx_PyObject_CallOneArg(__pyx_t_8, __pyx_t_7); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 568, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    } else {
      __pyx_t_6 = __Pyx_PyObject_CallNoArg(__pyx_t_8); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 568, __pyx_L1_error)
    }
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_6, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 568, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_6 = PyTuple_New(1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 568, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_GIVEREF(__pyx_t_8);
    PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_8);
    __pyx_t_8 = 0;
    __pyx_t_8 = __Pyx_PyObject_Call(__pyx_builtin_range, __pyx_t_6, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 568, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    if (likely(PyList_CheckExact(__pyx_t_8)) || PyTuple_CheckExact(__pyx_t_8)) {
      __pyx_t_6 = __pyx_t_8; __Pyx_INCREF(__pyx_t_6); __pyx_t_9 = 0;
      __pyx_t_10 = NULL;
    } else {
      __pyx_t_9 = -1; __pyx_t_6 = PyObject_GetIter(__pyx_t_8); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 568, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __pyx_t_10 = Py_TYPE(__pyx_t_6)->tp_iternext; if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 568, __pyx_L1_error)
    }
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    for (;;) {
      if (likely(!__pyx_t_10)) {
        if (likely(PyList_CheckExact(__pyx_t_6))) {
          if (__pyx_t_9 >= PyList_GET_SIZE(__pyx_t_6)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_8 = PyList_GET_ITEM(__pyx_t_6, __pyx_t_9); __Pyx_INCREF(__pyx_t_8); __pyx_t_9++; if (unlikely(0 < 0)) __PYX_ERR(0, 568, __pyx_L1_error)
          #else
          __pyx_t_8 = PySequence_ITEM(__pyx_t_6, __pyx_t_9); __pyx_t_9++; if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 568, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_8);
          #endif
        } else {
          if (__pyx_t_9 >= PyTuple_GET_SIZE(__pyx_t_6)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_8 = PyTuple_GET_ITEM(__pyx_t_6, __pyx_t_9); __Pyx_INCREF(__pyx_t_8); __pyx_t_9++; if (unlikely(0 < 0)) __PYX_ERR(0, 568, __pyx_L1_error)
          #else
          __pyx_t_8 = PySequence_ITEM(__pyx_t_6, __pyx_t_9); __pyx_t_9++; if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 568, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_8);
          #endif
        }
      } else {
        __pyx_t_8 = __pyx_t_10(__pyx_t_6);
        if (unlikely(!__pyx_t_8)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(exc_type == PyExc_StopIteration || PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 568, __pyx_L1_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_8);
      }
      __Pyx_XDECREF_SET(__pyx_v_d, __pyx_t_8);
      __pyx_t_8 = 0;

      /* "PyTorch.pyx":569
 *             res = ''
 *             for d in range(self.size()[0]):
 *                 res += '(' + str(d) + ',.,.) =\n'             # <<<<<<<<<<<<<<
 *                 res += self[d].as_string(show_size=False)
 *             res += '\ntorch.LongTensor of size '
 */
      __pyx_t_8 = PyTuple_New(1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 569, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_INCREF(__pyx_v_d);
      __Pyx_GIVEREF(__pyx_v_d);
      PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_v_d);
      __pyx_t_7 = __Pyx_PyObject_Call(((PyObject *)(&PyString_Type)), __pyx_t_8, NULL); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 569, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_8 = PyNumber_Add(__pyx_kp_s__11, __pyx_t_7); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 569, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __pyx_t_7 = PyNumber_Add(__pyx_t_8, __pyx_kp_s__12); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 569, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_8 = PyNumber_InPlaceAdd(__pyx_v_res, __pyx_t_7); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 569, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_DECREF_SET(__pyx_v_res, __pyx_t_8);
      __pyx_t_8 = 0;

      /* "PyTorch.pyx":570
 *             for d in range(self.size()[0]):
 *                 res += '(' + str(d) + ',.,.) =\n'
 *                 res += self[d].as_string(show_size=False)             # <<<<<<<<<<<<<<
 *             res += '\ntorch.LongTensor of size '
 *             first = True
 */
      __pyx_t_8 = PyObject_GetItem(((PyObject *)__pyx_v_self), __pyx_v_d); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 570, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_t_8, __pyx_n_s_as_string); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 570, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_8 = PyDict_New(); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 570, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      if (PyDict_SetItem(__pyx_t_8, __pyx_n_s_show_size, Py_False) < 0) __PYX_ERR(0, 570, __pyx_L1_error)
      __pyx_t_11 = __Pyx_PyObject_Call(__pyx_t_7, __pyx_empty_tuple, __pyx_t_8); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 570, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_11);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_8 = PyNumber_InPlaceAdd(__pyx_v_res, __pyx_t_11); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 570, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
      __Pyx_DECREF_SET(__pyx_v_res, __pyx_t_8);
      __pyx_t_8 = 0;

      /* "PyTorch.pyx":568
 *         elif dims == 3:
 *             res = ''
 *             for d in range(self.size()[0]):             # <<<<<<<<<<<<<<
 *                 res += '(' + str(d) + ',.,.) =\n'
 *                 res += self[d].as_string(show_size=False)
 */
    }
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;

    /* "PyTorch.pyx":571
 *                 res += '(' + str(d) + ',.,.) =\n'
 *                 res += self[d].as_string(show_size=False)
 *             res += '\ntorch.LongTensor of size '             # <<<<<<<<<<<<<<
 *             first = True
 *             for d in self.size():
 */
    __pyx_t_6 = PyNumber_InPlaceAdd(__pyx_v_res, __pyx_kp_s_torch_LongTensor_of_size_2); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 571, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF_SET(__pyx_v_res, __pyx_t_6);
    __pyx_t_6 = 0;

    /* "PyTorch.pyx":572
 *                 res += self[d].as_string(show_size=False)
 *             res += '\ntorch.LongTensor of size '
 *             first = True             # <<<<<<<<<<<<<<
 *             for d in self.size():
 *                if not first:
 */
    __pyx_v_first = 1;

    /* "PyTorch.pyx":573
 *             res += '\ntorch.LongTensor of size '
 *             first = True
 *             for d in self.size():             # <<<<<<<<<<<<<<
 *                if not first:
 *                   res += 'x'
 */
    __pyx_t_8 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_size); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 573, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_11 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_8))) {
      __pyx_t_11 = PyMethod_GET_SELF(__pyx_t_8);
      if (likely(__pyx_t_11)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_8);
        __Pyx_INCREF(__pyx_t_11);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_8, function);
      }
    }
    if (__pyx_t_11) {
      __pyx_t_6 = __Pyx_PyObject_CallOneArg(__pyx_t_8, __pyx_t_11); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 573, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
    } else {
      __pyx_t_6 = __Pyx_PyObject_CallNoArg(__pyx_t_8); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 573, __pyx_L1_error)
    }
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    if (likely(PyList_CheckExact(__pyx_t_6)) || PyTuple_CheckExact(__pyx_t_6)) {
      __pyx_t_8 = __pyx_t_6; __Pyx_INCREF(__pyx_t_8); __pyx_t_9 = 0;
      __pyx_t_10 = NULL;
    } else {
      __pyx_t_9 = -1; __pyx_t_8 = PyObject_GetIter(__pyx_t_6); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 573, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_10 = Py_TYPE(__pyx_t_8)->tp_iternext; if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 573, __pyx_L1_error)
    }
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    for (;;) {
      if (likely(!__pyx_t_10)) {
        if (likely(PyList_CheckExact(__pyx_t_8))) {
          if (__pyx_t_9 >= PyList_GET_SIZE(__pyx_t_8)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_6 = PyList_GET_ITEM(__pyx_t_8, __pyx_t_9); __Pyx_INCREF(__pyx_t_6); __pyx_t_9++; if (unlikely(0 < 0)) __PYX_ERR(0, 573, __pyx_L1_error)
          #else
          __pyx_t_6 = PySequence_ITEM(__pyx_t_8, __pyx_t_9); __pyx_t_9++; if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 573, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_6);
          #endif
        } else {
          if (__pyx_t_9 >= PyTuple_GET_SIZE(__pyx_t_8)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_6 = PyTuple_GET_ITEM(__pyx_t_8, __pyx_t_9); __Pyx_INCREF(__pyx_t_6); __pyx_t_9++; if (unlikely(0 < 0)) __PYX_ERR(0, 573, __pyx_L1_error)
          #else
          __pyx_t_6 = PySequence_ITEM(__pyx_t_8, __pyx_t_9); __pyx_t_9++; if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 573, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_6);
          #endif
        }
      } else {
        __pyx_t_6 = __pyx_t_10(__pyx_t_8);
        if (unlikely(!__pyx_t_6)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(exc_type == PyExc_StopIteration || PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 573, __pyx_L1_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_6);
      }
      __Pyx_XDECREF_SET(__pyx_v_d, __pyx_t_6);
      __pyx_t_6 = 0;

      /* "PyTorch.pyx":574
 *             first = True
 *             for d in self.size():
 *                if not first:             # <<<<<<<<<<<<<<
 *                   res += 'x'
 *                res += str(d)
 */
      __pyx_t_5 = ((!(__pyx_v_first != 0)) != 0);
      if (__pyx_t_5) {

        /* "PyTorch.pyx":575
 *             for d in self.size():
 *                if not first:
 *                   res += 'x'             # <<<<<<<<<<<<<<
 *                res += str(d)
 *                first = False
 */
        __pyx_t_6 = PyNumber_InPlaceAdd(__pyx_v_res, __pyx_n_s_x); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 575, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __Pyx_DECREF_SET(__pyx_v_res, __pyx_t_6);
        __pyx_t_6 = 0;

        /* "PyTorch.pyx":574
 *             first = True
 *             for d in self.size():
 *                if not first:             # <<<<<<<<<<<<<<
 *                   res += 'x'
 *                res += str(d)
 */
      }

      /* "PyTorch.pyx":576
 *                if not first:
 *                   res += 'x'
 *                res += str(d)             # <<<<<<<<<<<<<<
 *                first = False
 *             res += ']'
 */
      __pyx_t_6 = PyTuple_New(1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 576, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_INCREF(__pyx_v_d);
      __Pyx_GIVEREF(__pyx_v_d);
      PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_v_d);
      __pyx_t_11 = __Pyx_PyObject_Call(((PyObject *)(&PyString_Type)), __pyx_t_6, NULL); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 576, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_11);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_6 = PyNumber_InPlaceAdd(__pyx_v_res, __pyx_t_11); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 576, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
      __Pyx_DECREF_SET(__pyx_v_res, __pyx_t_6);
      __pyx_t_6 = 0;

      /* "PyTorch.pyx":577
 *                   res += 'x'
 *                res += str(d)
 *                first = False             # <<<<<<<<<<<<<<
 *             res += ']'
 *             return res
 */
      __pyx_v_first = 0;

      /* "PyTorch.pyx":573
 *             res += '\ntorch.LongTensor of size '
 *             first = True
 *             for d in self.size():             # <<<<<<<<<<<<<<
 *                if not first:
 *                   res += 'x'
 */
    }
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;

    /* "PyTorch.pyx":578
 *                res += str(d)
 *                first = False
 *             res += ']'             # <<<<<<<<<<<<<<
 *             return res
 *         else:
 */
    __pyx_t_8 = PyNumber_InPlaceAdd(__pyx_v_res, __pyx_kp_s__13); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 578, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF_SET(__pyx_v_res, __pyx_t_8);
    __pyx_t_8 = 0;

    /* "PyTorch.pyx":579
 *                first = False
 *             res += ']'
 *             return res             # <<<<<<<<<<<<<<
 *         else:
 *             raise Exception("Not implemented: dims > 2")
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(__pyx_v_res);
    __pyx_r = __pyx_v_res;
    goto __pyx_L0;

    /* "PyTorch.pyx":566
 *                 res += '[torch.LongTensor of size ' + str(size0) + ']\n'
 *             return res
 *         elif dims == 3:             # <<<<<<<<<<<<<<
 *             res = ''
 *             for d in range(self.size()[0]):
 */
    break;
    default:

    /* "PyTorch.pyx":581
 *             return res
 *         else:
 *             raise Exception("Not implemented: dims > 2")             # <<<<<<<<<<<<<<
 * 
 *     def __getitem__(_LongTensor self, int index):
 */
    __pyx_t_8 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_tuple__14, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 581, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_Raise(__pyx_t_8, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __PYX_ERR(0, 581, __pyx_L1_error)
    break;
  }

  /* "PyTorch.pyx":529
 *         return self.as_string(self)
 * 
 *     def as_string(_LongTensor self, show_size=True):             # <<<<<<<<<<<<<<
 *         # assume 2d matrix for now
 *         cdef int size0
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_11);
  __Pyx_AddTraceback("PyTorch._LongTensor.as_string", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_res);
  __Pyx_XDECREF(__pyx_v_thisline);
  __Pyx_XDECREF(__pyx_v_d);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":583
 *             raise Exception("Not implemented: dims > 2")
 * 
 *     def __getitem__(_LongTensor self, int index):             # <<<<<<<<<<<<<<
 *         if self.dims() == 1:
 *             return self.get1d(index)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_29__getitem__(PyObject *__pyx_v_self, PyObject *__pyx_arg_index); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_29__getitem__(PyObject *__pyx_v_self, PyObject *__pyx_arg_index) {
  int __pyx_v_index;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__getitem__ (wrapper)", 0);
  assert(__pyx_arg_index); {
    __pyx_v_index = __Pyx_PyInt_As_int(__pyx_arg_index); if (unlikely((__pyx_v_index == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 583, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._LongTensor.__getitem__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_28__getitem__(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self), ((int)__pyx_v_index));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_28__getitem__(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, int __pyx_v_index) {
  struct THLongTensor *__pyx_v_res;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  struct __pyx_opt_args_7PyTorch__LongTensor_fromNative __pyx_t_3;
  __Pyx_RefNannySetupContext("__getitem__", 0);

  /* "PyTorch.pyx":584
 * 
 *     def __getitem__(_LongTensor self, int index):
 *         if self.dims() == 1:             # <<<<<<<<<<<<<<
 *             return self.get1d(index)
 *         cdef THLongTensor *res = THLongTensor_newSelect(self.native, 0, index)
 */
  __pyx_t_1 = ((((struct __pyx_vtabstruct_7PyTorch__LongTensor *)__pyx_v_self->__pyx_vtab)->dims(__pyx_v_self, 0) == 1) != 0);
  if (__pyx_t_1) {

    /* "PyTorch.pyx":585
 *     def __getitem__(_LongTensor self, int index):
 *         if self.dims() == 1:
 *             return self.get1d(index)             # <<<<<<<<<<<<<<
 *         cdef THLongTensor *res = THLongTensor_newSelect(self.native, 0, index)
 *         return _LongTensor_fromNative(res, False)
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_2 = __Pyx_PyInt_From_long(((struct __pyx_vtabstruct_7PyTorch__LongTensor *)__pyx_v_self->__pyx_vtab)->get1d(__pyx_v_self, __pyx_v_index, 0)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 585, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_r = __pyx_t_2;
    __pyx_t_2 = 0;
    goto __pyx_L0;

    /* "PyTorch.pyx":584
 * 
 *     def __getitem__(_LongTensor self, int index):
 *         if self.dims() == 1:             # <<<<<<<<<<<<<<
 *             return self.get1d(index)
 *         cdef THLongTensor *res = THLongTensor_newSelect(self.native, 0, index)
 */
  }

  /* "PyTorch.pyx":586
 *         if self.dims() == 1:
 *             return self.get1d(index)
 *         cdef THLongTensor *res = THLongTensor_newSelect(self.native, 0, index)             # <<<<<<<<<<<<<<
 *         return _LongTensor_fromNative(res, False)
 * 
 */
  __pyx_v_res = THLongTensor_newSelect(__pyx_v_self->native, 0, __pyx_v_index);

  /* "PyTorch.pyx":587
 *             return self.get1d(index)
 *         cdef THLongTensor *res = THLongTensor_newSelect(self.native, 0, index)
 *         return _LongTensor_fromNative(res, False)             # <<<<<<<<<<<<<<
 * 
 *     def __setitem__(_LongTensor self, int index, long value):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_3.__pyx_n = 1;
  __pyx_t_3.retain = Py_False;
  __pyx_t_2 = __pyx_f_7PyTorch__LongTensor_fromNative(__pyx_v_res, &__pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 587, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":583
 *             raise Exception("Not implemented: dims > 2")
 * 
 *     def __getitem__(_LongTensor self, int index):             # <<<<<<<<<<<<<<
 *         if self.dims() == 1:
 *             return self.get1d(index)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("PyTorch._LongTensor.__getitem__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":589
 *         return _LongTensor_fromNative(res, False)
 * 
 *     def __setitem__(_LongTensor self, int index, long value):             # <<<<<<<<<<<<<<
 *         if self.dims() == 1:
 *             self.set1d(index, value)
 */

/* Python wrapper */
static int __pyx_pw_7PyTorch_11_LongTensor_31__setitem__(PyObject *__pyx_v_self, PyObject *__pyx_arg_index, PyObject *__pyx_arg_value); /*proto*/
static int __pyx_pw_7PyTorch_11_LongTensor_31__setitem__(PyObject *__pyx_v_self, PyObject *__pyx_arg_index, PyObject *__pyx_arg_value) {
  int __pyx_v_index;
  long __pyx_v_value;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__setitem__ (wrapper)", 0);
  assert(__pyx_arg_index); {
    __pyx_v_index = __Pyx_PyInt_As_int(__pyx_arg_index); if (unlikely((__pyx_v_index == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 589, __pyx_L3_error)
  }
  assert(__pyx_arg_value); {
    __pyx_v_value = __Pyx_PyInt_As_long(__pyx_arg_value); if (unlikely((__pyx_v_value == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 589, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._LongTensor.__setitem__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return -1;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_30__setitem__(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self), ((int)__pyx_v_index), ((long)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_7PyTorch_11_LongTensor_30__setitem__(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, int __pyx_v_index, long __pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("__setitem__", 0);

  /* "PyTorch.pyx":590
 * 
 *     def __setitem__(_LongTensor self, int index, long value):
 *         if self.dims() == 1:             # <<<<<<<<<<<<<<
 *             self.set1d(index, value)
 *         else:
 */
  __pyx_t_1 = ((((struct __pyx_vtabstruct_7PyTorch__LongTensor *)__pyx_v_self->__pyx_vtab)->dims(__pyx_v_self, 0) == 1) != 0);
  if (__pyx_t_1) {

    /* "PyTorch.pyx":591
 *     def __setitem__(_LongTensor self, int index, long value):
 *         if self.dims() == 1:
 *             self.set1d(index, value)             # <<<<<<<<<<<<<<
 *         else:
 *             raise Exception("not implemented")
 */
    __pyx_t_2 = ((struct __pyx_vtabstruct_7PyTorch__LongTensor *)__pyx_v_self->__pyx_vtab)->set1d(__pyx_v_self, __pyx_v_index, __pyx_v_value, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 591, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

    /* "PyTorch.pyx":590
 * 
 *     def __setitem__(_LongTensor self, int index, long value):
 *         if self.dims() == 1:             # <<<<<<<<<<<<<<
 *             self.set1d(index, value)
 *         else:
 */
    goto __pyx_L3;
  }

  /* "PyTorch.pyx":593
 *             self.set1d(index, value)
 *         else:
 *             raise Exception("not implemented")             # <<<<<<<<<<<<<<
 * 
 *     def fill(_LongTensor self, long value):
 */
  /*else*/ {
    __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_tuple__15, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 593, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(0, 593, __pyx_L1_error)
  }
  __pyx_L3:;

  /* "PyTorch.pyx":589
 *         return _LongTensor_fromNative(res, False)
 * 
 *     def __setitem__(_LongTensor self, int index, long value):             # <<<<<<<<<<<<<<
 *         if self.dims() == 1:
 *             self.set1d(index, value)
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("PyTorch._LongTensor.__setitem__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":595
 *             raise Exception("not implemented")
 * 
 *     def fill(_LongTensor self, long value):             # <<<<<<<<<<<<<<
 *         THLongTensor_fill(self.native, value)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_33fill(PyObject *__pyx_v_self, PyObject *__pyx_arg_value); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_33fill(PyObject *__pyx_v_self, PyObject *__pyx_arg_value) {
  long __pyx_v_value;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("fill (wrapper)", 0);
  assert(__pyx_arg_value); {
    __pyx_v_value = __Pyx_PyInt_As_long(__pyx_arg_value); if (unlikely((__pyx_v_value == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 595, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._LongTensor.fill", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_32fill(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self), ((long)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_32fill(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, long __pyx_v_value) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("fill", 0);

  /* "PyTorch.pyx":596
 * 
 *     def fill(_LongTensor self, long value):
 *         THLongTensor_fill(self.native, value)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THLongTensor_fill(__pyx_v_self->native, __pyx_v_value);

  /* "PyTorch.pyx":597
 *     def fill(_LongTensor self, long value):
 *         THLongTensor_fill(self.native, value)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def sum(_LongTensor self):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":595
 *             raise Exception("not implemented")
 * 
 *     def fill(_LongTensor self, long value):             # <<<<<<<<<<<<<<
 *         THLongTensor_fill(self.native, value)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":599
 *         return self
 * 
 *     def sum(_LongTensor self):             # <<<<<<<<<<<<<<
 *         cdef long result = THLongTensor_sumall(self.native)
 *         return result
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_35sum(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_35sum(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("sum (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_34sum(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_34sum(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self) {
  long __pyx_v_result;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("sum", 0);

  /* "PyTorch.pyx":600
 * 
 *     def sum(_LongTensor self):
 *         cdef long result = THLongTensor_sumall(self.native)             # <<<<<<<<<<<<<<
 *         return result
 * 
 */
  __pyx_v_result = THLongTensor_sumall(__pyx_v_self->native);

  /* "PyTorch.pyx":601
 *     def sum(_LongTensor self):
 *         cdef long result = THLongTensor_sumall(self.native)
 *         return result             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_long(__pyx_v_result); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 601, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":599
 *         return self
 * 
 *     def sum(_LongTensor self):             # <<<<<<<<<<<<<<
 *         cdef long result = THLongTensor_sumall(self.native)
 *         return result
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._LongTensor.sum", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":606
 * 
 * 
 *     def abs(_LongTensor self):             # <<<<<<<<<<<<<<
 *         cdef _LongTensor res = _LongTensor.new()
 *         THLongTensor_abs(res.native, self.native)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_37abs(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_37abs(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("abs (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_36abs(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_36abs(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self) {
  struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_res = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("abs", 0);

  /* "PyTorch.pyx":607
 * 
 *     def abs(_LongTensor self):
 *         cdef _LongTensor res = _LongTensor.new()             # <<<<<<<<<<<<<<
 *         THLongTensor_abs(res.native, self.native)
 *         return res
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7PyTorch__LongTensor), __pyx_n_s_new); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 607, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 607, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 607, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_7PyTorch__LongTensor))))) __PYX_ERR(0, 607, __pyx_L1_error)
  __pyx_v_res = ((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":608
 *     def abs(_LongTensor self):
 *         cdef _LongTensor res = _LongTensor.new()
 *         THLongTensor_abs(res.native, self.native)             # <<<<<<<<<<<<<<
 *         return res
 * 
 */
  THLongTensor_abs(__pyx_v_res->native, __pyx_v_self->native);

  /* "PyTorch.pyx":609
 *         cdef _LongTensor res = _LongTensor.new()
 *         THLongTensor_abs(res.native, self.native)
 *         return res             # <<<<<<<<<<<<<<
 * 
 *     def iabs(_LongTensor self):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = ((PyObject *)__pyx_v_res);
  goto __pyx_L0;

  /* "PyTorch.pyx":606
 * 
 * 
 *     def abs(_LongTensor self):             # <<<<<<<<<<<<<<
 *         cdef _LongTensor res = _LongTensor.new()
 *         THLongTensor_abs(res.native, self.native)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("PyTorch._LongTensor.abs", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":611
 *         return res
 * 
 *     def iabs(_LongTensor self):             # <<<<<<<<<<<<<<
 *         THLongTensor_abs(self.native, self.native)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_39iabs(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_39iabs(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("iabs (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_38iabs(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_38iabs(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("iabs", 0);

  /* "PyTorch.pyx":612
 * 
 *     def iabs(_LongTensor self):
 *         THLongTensor_abs(self.native, self.native)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THLongTensor_abs(__pyx_v_self->native, __pyx_v_self->native);

  /* "PyTorch.pyx":613
 *     def iabs(_LongTensor self):
 *         THLongTensor_abs(self.native, self.native)
 *         return self             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":611
 *         return res
 * 
 *     def iabs(_LongTensor self):             # <<<<<<<<<<<<<<
 *         THLongTensor_abs(self.native, self.native)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":617
 * 
 * 
 *     def size(_LongTensor self):             # <<<<<<<<<<<<<<
 *         cdef int dims = self.dims()
 * #        cdef LongStorage size
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_41size(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_41size(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("size (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_40size(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_40size(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self) {
  int __pyx_v_dims;
  PyObject *__pyx_v_size = NULL;
  int __pyx_v_d;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  int __pyx_t_7;
  int __pyx_t_8;
  __Pyx_RefNannySetupContext("size", 0);

  /* "PyTorch.pyx":618
 * 
 *     def size(_LongTensor self):
 *         cdef int dims = self.dims()             # <<<<<<<<<<<<<<
 * #        cdef LongStorage size
 *         if dims > 0:
 */
  __pyx_v_dims = ((struct __pyx_vtabstruct_7PyTorch__LongTensor *)__pyx_v_self->__pyx_vtab)->dims(__pyx_v_self, 0);

  /* "PyTorch.pyx":620
 *         cdef int dims = self.dims()
 * #        cdef LongStorage size
 *         if dims > 0:             # <<<<<<<<<<<<<<
 *             size = _LongStorage(dims)
 *             for d in range(dims):
 */
  __pyx_t_1 = ((__pyx_v_dims > 0) != 0);
  if (__pyx_t_1) {

    /* "PyTorch.pyx":621
 * #        cdef LongStorage size
 *         if dims > 0:
 *             size = _LongStorage(dims)             # <<<<<<<<<<<<<<
 *             for d in range(dims):
 *                 size[d] = THLongTensor_size(self.native, d)
 */
    __pyx_t_3 = __Pyx_GetModuleGlobalName(__pyx_n_s_LongStorage); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 621, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = __Pyx_PyInt_From_int(__pyx_v_dims); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 621, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_5 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
      __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_3);
      if (likely(__pyx_t_5)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
        __Pyx_INCREF(__pyx_t_5);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_3, function);
      }
    }
    if (!__pyx_t_5) {
      __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_4); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 621, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_GOTREF(__pyx_t_2);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_3)) {
        PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_t_4};
        __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 621, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
        PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_t_4};
        __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 621, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else
      #endif
      {
        __pyx_t_6 = PyTuple_New(1+1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 621, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_5); __pyx_t_5 = NULL;
        __Pyx_GIVEREF(__pyx_t_4);
        PyTuple_SET_ITEM(__pyx_t_6, 0+1, __pyx_t_4);
        __pyx_t_4 = 0;
        __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_6, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 621, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_v_size = __pyx_t_2;
    __pyx_t_2 = 0;

    /* "PyTorch.pyx":622
 *         if dims > 0:
 *             size = _LongStorage(dims)
 *             for d in range(dims):             # <<<<<<<<<<<<<<
 *                 size[d] = THLongTensor_size(self.native, d)
 *             return size
 */
    __pyx_t_7 = __pyx_v_dims;
    for (__pyx_t_8 = 0; __pyx_t_8 < __pyx_t_7; __pyx_t_8+=1) {
      __pyx_v_d = __pyx_t_8;

      /* "PyTorch.pyx":623
 *             size = _LongStorage(dims)
 *             for d in range(dims):
 *                 size[d] = THLongTensor_size(self.native, d)             # <<<<<<<<<<<<<<
 *             return size
 *         else:
 */
      __pyx_t_2 = __Pyx_PyInt_From_long(THLongTensor_size(__pyx_v_self->native, __pyx_v_d)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 623, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      if (unlikely(__Pyx_SetItemInt(__pyx_v_size, __pyx_v_d, __pyx_t_2, int, 1, __Pyx_PyInt_From_int, 0, 1, 1) < 0)) __PYX_ERR(0, 623, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    }

    /* "PyTorch.pyx":624
 *             for d in range(dims):
 *                 size[d] = THLongTensor_size(self.native, d)
 *             return size             # <<<<<<<<<<<<<<
 *         else:
 *             return None  # not sure how to handle this yet
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(__pyx_v_size);
    __pyx_r = __pyx_v_size;
    goto __pyx_L0;

    /* "PyTorch.pyx":620
 *         cdef int dims = self.dims()
 * #        cdef LongStorage size
 *         if dims > 0:             # <<<<<<<<<<<<<<
 *             size = _LongStorage(dims)
 *             for d in range(dims):
 */
  }

  /* "PyTorch.pyx":626
 *             return size
 *         else:
 *             return None  # not sure how to handle this yet             # <<<<<<<<<<<<<<
 * 
 *     @staticmethod
 */
  /*else*/ {
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(Py_None);
    __pyx_r = Py_None;
    goto __pyx_L0;
  }

  /* "PyTorch.pyx":617
 * 
 * 
 *     def size(_LongTensor self):             # <<<<<<<<<<<<<<
 *         cdef int dims = self.dims()
 * #        cdef LongStorage size
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("PyTorch._LongTensor.size", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_size);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":629
 * 
 *     @staticmethod
 *     def new():             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         return _LongTensor()
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_43new(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_7PyTorch_11_LongTensor_43new = {"new", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_43new, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_43new(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("new (wrapper)", 0);
  if (unlikely(PyTuple_GET_SIZE(__pyx_args) > 0)) {
    __Pyx_RaiseArgtupleInvalid("new", 1, 0, 0, PyTuple_GET_SIZE(__pyx_args)); return NULL;}
  if (unlikely(__pyx_kwds) && unlikely(PyDict_Size(__pyx_kwds) > 0) && unlikely(!__Pyx_CheckKeywordStrings(__pyx_kwds, "new", 0))) return NULL;
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_42new();

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_42new() {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("new", 0);

  /* "PyTorch.pyx":631
 *     def new():
 * #        # print('allocate tensor')
 *         return _LongTensor()             # <<<<<<<<<<<<<<
 * #        return _FloatTensor_fromNative(newTensorC, False)
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_7PyTorch__LongTensor), __pyx_empty_tuple, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 631, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":629
 * 
 *     @staticmethod
 *     def new():             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         return _LongTensor()
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._LongTensor.new", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":634
 * #        return _FloatTensor_fromNative(newTensorC, False)
 * 
 *     def narrow(_LongTensor self, int dimension, long firstIndex, long size):             # <<<<<<<<<<<<<<
 *         cdef THLongTensor *narrowedC = THLongTensor_newNarrow(self.native, dimension, firstIndex, size)
 *         return _LongTensor_fromNative(narrowedC, retain=False)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_45narrow(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_45narrow(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  int __pyx_v_dimension;
  long __pyx_v_firstIndex;
  long __pyx_v_size;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("narrow (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_dimension,&__pyx_n_s_firstIndex,&__pyx_n_s_size,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_dimension)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_firstIndex)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("narrow", 1, 3, 3, 1); __PYX_ERR(0, 634, __pyx_L3_error)
        }
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("narrow", 1, 3, 3, 2); __PYX_ERR(0, 634, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "narrow") < 0)) __PYX_ERR(0, 634, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_dimension = __Pyx_PyInt_As_int(values[0]); if (unlikely((__pyx_v_dimension == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 634, __pyx_L3_error)
    __pyx_v_firstIndex = __Pyx_PyInt_As_long(values[1]); if (unlikely((__pyx_v_firstIndex == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 634, __pyx_L3_error)
    __pyx_v_size = __Pyx_PyInt_As_long(values[2]); if (unlikely((__pyx_v_size == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 634, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("narrow", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 634, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._LongTensor.narrow", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_44narrow(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self), __pyx_v_dimension, __pyx_v_firstIndex, __pyx_v_size);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_44narrow(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, int __pyx_v_dimension, long __pyx_v_firstIndex, long __pyx_v_size) {
  struct THLongTensor *__pyx_v_narrowedC;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  struct __pyx_opt_args_7PyTorch__LongTensor_fromNative __pyx_t_2;
  __Pyx_RefNannySetupContext("narrow", 0);

  /* "PyTorch.pyx":635
 * 
 *     def narrow(_LongTensor self, int dimension, long firstIndex, long size):
 *         cdef THLongTensor *narrowedC = THLongTensor_newNarrow(self.native, dimension, firstIndex, size)             # <<<<<<<<<<<<<<
 *         return _LongTensor_fromNative(narrowedC, retain=False)
 * 
 */
  __pyx_v_narrowedC = THLongTensor_newNarrow(__pyx_v_self->native, __pyx_v_dimension, __pyx_v_firstIndex, __pyx_v_size);

  /* "PyTorch.pyx":636
 *     def narrow(_LongTensor self, int dimension, long firstIndex, long size):
 *         cdef THLongTensor *narrowedC = THLongTensor_newNarrow(self.native, dimension, firstIndex, size)
 *         return _LongTensor_fromNative(narrowedC, retain=False)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2.__pyx_n = 1;
  __pyx_t_2.retain = Py_False;
  __pyx_t_1 = __pyx_f_7PyTorch__LongTensor_fromNative(__pyx_v_narrowedC, &__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 636, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":634
 * #        return _FloatTensor_fromNative(newTensorC, False)
 * 
 *     def narrow(_LongTensor self, int dimension, long firstIndex, long size):             # <<<<<<<<<<<<<<
 *         cdef THLongTensor *narrowedC = THLongTensor_newNarrow(self.native, dimension, firstIndex, size)
 *         return _LongTensor_fromNative(narrowedC, retain=False)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._LongTensor.narrow", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":639
 * 
 * 
 *     def contiguous(_LongTensor self):             # <<<<<<<<<<<<<<
 *         cdef THLongTensor *newTensorC = THLongTensor_newContiguous(self.native)
 *         return _LongTensor_fromNative(newTensorC, retain=False)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_47contiguous(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_47contiguous(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("contiguous (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_46contiguous(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_46contiguous(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self) {
  struct THLongTensor *__pyx_v_newTensorC;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  struct __pyx_opt_args_7PyTorch__LongTensor_fromNative __pyx_t_2;
  __Pyx_RefNannySetupContext("contiguous", 0);

  /* "PyTorch.pyx":640
 * 
 *     def contiguous(_LongTensor self):
 *         cdef THLongTensor *newTensorC = THLongTensor_newContiguous(self.native)             # <<<<<<<<<<<<<<
 *         return _LongTensor_fromNative(newTensorC, retain=False)
 * 
 */
  __pyx_v_newTensorC = THLongTensor_newContiguous(__pyx_v_self->native);

  /* "PyTorch.pyx":641
 *     def contiguous(_LongTensor self):
 *         cdef THLongTensor *newTensorC = THLongTensor_newContiguous(self.native)
 *         return _LongTensor_fromNative(newTensorC, retain=False)             # <<<<<<<<<<<<<<
 * 
 *     def resize1d(_LongTensor self, int size0):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2.__pyx_n = 1;
  __pyx_t_2.retain = Py_False;
  __pyx_t_1 = __pyx_f_7PyTorch__LongTensor_fromNative(__pyx_v_newTensorC, &__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 641, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":639
 * 
 * 
 *     def contiguous(_LongTensor self):             # <<<<<<<<<<<<<<
 *         cdef THLongTensor *newTensorC = THLongTensor_newContiguous(self.native)
 *         return _LongTensor_fromNative(newTensorC, retain=False)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._LongTensor.contiguous", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":643
 *         return _LongTensor_fromNative(newTensorC, retain=False)
 * 
 *     def resize1d(_LongTensor self, int size0):             # <<<<<<<<<<<<<<
 *         THLongTensor_resize1d(self.native, size0)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_49resize1d(PyObject *__pyx_v_self, PyObject *__pyx_arg_size0); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_49resize1d(PyObject *__pyx_v_self, PyObject *__pyx_arg_size0) {
  int __pyx_v_size0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resize1d (wrapper)", 0);
  assert(__pyx_arg_size0); {
    __pyx_v_size0 = __Pyx_PyInt_As_int(__pyx_arg_size0); if (unlikely((__pyx_v_size0 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 643, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._LongTensor.resize1d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_48resize1d(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self), ((int)__pyx_v_size0));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_48resize1d(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, int __pyx_v_size0) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resize1d", 0);

  /* "PyTorch.pyx":644
 * 
 *     def resize1d(_LongTensor self, int size0):
 *         THLongTensor_resize1d(self.native, size0)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THLongTensor_resize1d(__pyx_v_self->native, __pyx_v_size0);

  /* "PyTorch.pyx":645
 *     def resize1d(_LongTensor self, int size0):
 *         THLongTensor_resize1d(self.native, size0)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def resize2d(_LongTensor self, int size0, int size1):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":643
 *         return _LongTensor_fromNative(newTensorC, retain=False)
 * 
 *     def resize1d(_LongTensor self, int size0):             # <<<<<<<<<<<<<<
 *         THLongTensor_resize1d(self.native, size0)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":647
 *         return self
 * 
 *     def resize2d(_LongTensor self, int size0, int size1):             # <<<<<<<<<<<<<<
 *         THLongTensor_resize2d(self.native, size0, size1)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_51resize2d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_51resize2d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  int __pyx_v_size0;
  int __pyx_v_size1;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resize2d (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_size0,&__pyx_n_s_size1,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size0)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("resize2d", 1, 2, 2, 1); __PYX_ERR(0, 647, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "resize2d") < 0)) __PYX_ERR(0, 647, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_size0 = __Pyx_PyInt_As_int(values[0]); if (unlikely((__pyx_v_size0 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 647, __pyx_L3_error)
    __pyx_v_size1 = __Pyx_PyInt_As_int(values[1]); if (unlikely((__pyx_v_size1 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 647, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("resize2d", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 647, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._LongTensor.resize2d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_50resize2d(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self), __pyx_v_size0, __pyx_v_size1);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_50resize2d(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, int __pyx_v_size0, int __pyx_v_size1) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resize2d", 0);

  /* "PyTorch.pyx":648
 * 
 *     def resize2d(_LongTensor self, int size0, int size1):
 *         THLongTensor_resize2d(self.native, size0, size1)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THLongTensor_resize2d(__pyx_v_self->native, __pyx_v_size0, __pyx_v_size1);

  /* "PyTorch.pyx":649
 *     def resize2d(_LongTensor self, int size0, int size1):
 *         THLongTensor_resize2d(self.native, size0, size1)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def resize3d(_LongTensor self, int size0, int size1, int size2):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":647
 *         return self
 * 
 *     def resize2d(_LongTensor self, int size0, int size1):             # <<<<<<<<<<<<<<
 *         THLongTensor_resize2d(self.native, size0, size1)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":651
 *         return self
 * 
 *     def resize3d(_LongTensor self, int size0, int size1, int size2):             # <<<<<<<<<<<<<<
 *         THLongTensor_resize3d(self.native, size0, size1, size2)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_53resize3d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_53resize3d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  int __pyx_v_size0;
  int __pyx_v_size1;
  int __pyx_v_size2;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resize3d (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_size0,&__pyx_n_s_size1,&__pyx_n_s_size2,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size0)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("resize3d", 1, 3, 3, 1); __PYX_ERR(0, 651, __pyx_L3_error)
        }
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("resize3d", 1, 3, 3, 2); __PYX_ERR(0, 651, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "resize3d") < 0)) __PYX_ERR(0, 651, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_size0 = __Pyx_PyInt_As_int(values[0]); if (unlikely((__pyx_v_size0 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 651, __pyx_L3_error)
    __pyx_v_size1 = __Pyx_PyInt_As_int(values[1]); if (unlikely((__pyx_v_size1 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 651, __pyx_L3_error)
    __pyx_v_size2 = __Pyx_PyInt_As_int(values[2]); if (unlikely((__pyx_v_size2 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 651, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("resize3d", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 651, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._LongTensor.resize3d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_52resize3d(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self), __pyx_v_size0, __pyx_v_size1, __pyx_v_size2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_52resize3d(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, int __pyx_v_size0, int __pyx_v_size1, int __pyx_v_size2) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resize3d", 0);

  /* "PyTorch.pyx":652
 * 
 *     def resize3d(_LongTensor self, int size0, int size1, int size2):
 *         THLongTensor_resize3d(self.native, size0, size1, size2)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THLongTensor_resize3d(__pyx_v_self->native, __pyx_v_size0, __pyx_v_size1, __pyx_v_size2);

  /* "PyTorch.pyx":653
 *     def resize3d(_LongTensor self, int size0, int size1, int size2):
 *         THLongTensor_resize3d(self.native, size0, size1, size2)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def resize4d(_LongTensor self, int size0, int size1, int size2, int size3):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":651
 *         return self
 * 
 *     def resize3d(_LongTensor self, int size0, int size1, int size2):             # <<<<<<<<<<<<<<
 *         THLongTensor_resize3d(self.native, size0, size1, size2)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":655
 *         return self
 * 
 *     def resize4d(_LongTensor self, int size0, int size1, int size2, int size3):             # <<<<<<<<<<<<<<
 *         THLongTensor_resize4d(self.native, size0, size1, size2, size3)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_55resize4d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_55resize4d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  int __pyx_v_size0;
  int __pyx_v_size1;
  int __pyx_v_size2;
  int __pyx_v_size3;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resize4d (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_size0,&__pyx_n_s_size1,&__pyx_n_s_size2,&__pyx_n_s_size3,0};
    PyObject* values[4] = {0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size0)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("resize4d", 1, 4, 4, 1); __PYX_ERR(0, 655, __pyx_L3_error)
        }
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("resize4d", 1, 4, 4, 2); __PYX_ERR(0, 655, __pyx_L3_error)
        }
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size3)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("resize4d", 1, 4, 4, 3); __PYX_ERR(0, 655, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "resize4d") < 0)) __PYX_ERR(0, 655, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 4) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
    }
    __pyx_v_size0 = __Pyx_PyInt_As_int(values[0]); if (unlikely((__pyx_v_size0 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 655, __pyx_L3_error)
    __pyx_v_size1 = __Pyx_PyInt_As_int(values[1]); if (unlikely((__pyx_v_size1 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 655, __pyx_L3_error)
    __pyx_v_size2 = __Pyx_PyInt_As_int(values[2]); if (unlikely((__pyx_v_size2 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 655, __pyx_L3_error)
    __pyx_v_size3 = __Pyx_PyInt_As_int(values[3]); if (unlikely((__pyx_v_size3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 655, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("resize4d", 1, 4, 4, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 655, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._LongTensor.resize4d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_54resize4d(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self), __pyx_v_size0, __pyx_v_size1, __pyx_v_size2, __pyx_v_size3);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_54resize4d(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, int __pyx_v_size0, int __pyx_v_size1, int __pyx_v_size2, int __pyx_v_size3) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resize4d", 0);

  /* "PyTorch.pyx":656
 * 
 *     def resize4d(_LongTensor self, int size0, int size1, int size2, int size3):
 *         THLongTensor_resize4d(self.native, size0, size1, size2, size3)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THLongTensor_resize4d(__pyx_v_self->native, __pyx_v_size0, __pyx_v_size1, __pyx_v_size2, __pyx_v_size3);

  /* "PyTorch.pyx":657
 *     def resize4d(_LongTensor self, int size0, int size1, int size2, int size3):
 *         THLongTensor_resize4d(self.native, size0, size1, size2, size3)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def resizeAs(_LongTensor self, _LongTensor model):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":655
 *         return self
 * 
 *     def resize4d(_LongTensor self, int size0, int size1, int size2, int size3):             # <<<<<<<<<<<<<<
 *         THLongTensor_resize4d(self.native, size0, size1, size2, size3)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":659
 *         return self
 * 
 *     def resizeAs(_LongTensor self, _LongTensor model):             # <<<<<<<<<<<<<<
 *         THLongTensor_resizeAs(self.native, model.native)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_57resizeAs(PyObject *__pyx_v_self, PyObject *__pyx_v_model); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_57resizeAs(PyObject *__pyx_v_self, PyObject *__pyx_v_model) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resizeAs (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_model), __pyx_ptype_7PyTorch__LongTensor, 1, "model", 0))) __PYX_ERR(0, 659, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_56resizeAs(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self), ((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_model));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_56resizeAs(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_model) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resizeAs", 0);

  /* "PyTorch.pyx":660
 * 
 *     def resizeAs(_LongTensor self, _LongTensor model):
 *         THLongTensor_resizeAs(self.native, model.native)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THLongTensor_resizeAs(__pyx_v_self->native, __pyx_v_model->native);

  /* "PyTorch.pyx":661
 *     def resizeAs(_LongTensor self, _LongTensor model):
 *         THLongTensor_resizeAs(self.native, model.native)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def resize(_LongTensor self, Storage._LongStorage size):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":659
 *         return self
 * 
 *     def resizeAs(_LongTensor self, _LongTensor model):             # <<<<<<<<<<<<<<
 *         THLongTensor_resizeAs(self.native, model.native)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":663
 *         return self
 * 
 *     def resize(_LongTensor self, Storage._LongStorage size):             # <<<<<<<<<<<<<<
 * #        # print('_FloatTensor.resize size:', size)
 *         if len(size) == 0:
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_59resize(PyObject *__pyx_v_self, PyObject *__pyx_v_size); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_59resize(PyObject *__pyx_v_self, PyObject *__pyx_v_size) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resize (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_size), __pyx_ptype_7Storage__LongStorage, 1, "size", 0))) __PYX_ERR(0, 663, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_58resize(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self), ((struct __pyx_obj_7Storage__LongStorage *)__pyx_v_size));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_58resize(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, struct __pyx_obj_7Storage__LongStorage *__pyx_v_size) {
  int __pyx_v_dims;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  Py_ssize_t __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  long __pyx_t_4;
  long __pyx_t_5;
  long __pyx_t_6;
  long __pyx_t_7;
  PyObject *__pyx_t_8 = NULL;
  __Pyx_RefNannySetupContext("resize", 0);

  /* "PyTorch.pyx":665
 *     def resize(_LongTensor self, Storage._LongStorage size):
 * #        # print('_FloatTensor.resize size:', size)
 *         if len(size) == 0:             # <<<<<<<<<<<<<<
 *             return self
 *         cdef int dims = len(size)
 */
  __pyx_t_1 = PyObject_Length(((PyObject *)__pyx_v_size)); if (unlikely(__pyx_t_1 == -1)) __PYX_ERR(0, 665, __pyx_L1_error)
  __pyx_t_2 = ((__pyx_t_1 == 0) != 0);
  if (__pyx_t_2) {

    /* "PyTorch.pyx":666
 * #        # print('_FloatTensor.resize size:', size)
 *         if len(size) == 0:
 *             return self             # <<<<<<<<<<<<<<
 *         cdef int dims = len(size)
 * #        # print('_FloatTensor.resize dims:', dims)
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(((PyObject *)__pyx_v_self));
    __pyx_r = ((PyObject *)__pyx_v_self);
    goto __pyx_L0;

    /* "PyTorch.pyx":665
 *     def resize(_LongTensor self, Storage._LongStorage size):
 * #        # print('_FloatTensor.resize size:', size)
 *         if len(size) == 0:             # <<<<<<<<<<<<<<
 *             return self
 *         cdef int dims = len(size)
 */
  }

  /* "PyTorch.pyx":667
 *         if len(size) == 0:
 *             return self
 *         cdef int dims = len(size)             # <<<<<<<<<<<<<<
 * #        # print('_FloatTensor.resize dims:', dims)
 *         if dims == 1:
 */
  __pyx_t_1 = PyObject_Length(((PyObject *)__pyx_v_size)); if (unlikely(__pyx_t_1 == -1)) __PYX_ERR(0, 667, __pyx_L1_error)
  __pyx_v_dims = __pyx_t_1;

  /* "PyTorch.pyx":669
 *         cdef int dims = len(size)
 * #        # print('_FloatTensor.resize dims:', dims)
 *         if dims == 1:             # <<<<<<<<<<<<<<
 *             THLongTensor_resize1d(self.native, size[0])
 *         elif dims == 2:
 */
  switch (__pyx_v_dims) {
    case 1:

    /* "PyTorch.pyx":670
 * #        # print('_FloatTensor.resize dims:', dims)
 *         if dims == 1:
 *             THLongTensor_resize1d(self.native, size[0])             # <<<<<<<<<<<<<<
 *         elif dims == 2:
 *             THLongTensor_resize2d(self.native, size[0], size[1])
 */
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 670, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_4 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 670, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    THLongTensor_resize1d(__pyx_v_self->native, __pyx_t_4);

    /* "PyTorch.pyx":669
 *         cdef int dims = len(size)
 * #        # print('_FloatTensor.resize dims:', dims)
 *         if dims == 1:             # <<<<<<<<<<<<<<
 *             THLongTensor_resize1d(self.native, size[0])
 *         elif dims == 2:
 */
    break;

    /* "PyTorch.pyx":671
 *         if dims == 1:
 *             THLongTensor_resize1d(self.native, size[0])
 *         elif dims == 2:             # <<<<<<<<<<<<<<
 *             THLongTensor_resize2d(self.native, size[0], size[1])
 *         elif dims == 3:
 */
    case 2:

    /* "PyTorch.pyx":672
 *             THLongTensor_resize1d(self.native, size[0])
 *         elif dims == 2:
 *             THLongTensor_resize2d(self.native, size[0], size[1])             # <<<<<<<<<<<<<<
 *         elif dims == 3:
 *             THLongTensor_resize3d(self.native, size[0], size[1], size[2])
 */
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 672, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_4 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 672, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 672, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_5 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_5 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 672, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    THLongTensor_resize2d(__pyx_v_self->native, __pyx_t_4, __pyx_t_5);

    /* "PyTorch.pyx":671
 *         if dims == 1:
 *             THLongTensor_resize1d(self.native, size[0])
 *         elif dims == 2:             # <<<<<<<<<<<<<<
 *             THLongTensor_resize2d(self.native, size[0], size[1])
 *         elif dims == 3:
 */
    break;

    /* "PyTorch.pyx":673
 *         elif dims == 2:
 *             THLongTensor_resize2d(self.native, size[0], size[1])
 *         elif dims == 3:             # <<<<<<<<<<<<<<
 *             THLongTensor_resize3d(self.native, size[0], size[1], size[2])
 *         elif dims == 4:
 */
    case 3:

    /* "PyTorch.pyx":674
 *             THLongTensor_resize2d(self.native, size[0], size[1])
 *         elif dims == 3:
 *             THLongTensor_resize3d(self.native, size[0], size[1], size[2])             # <<<<<<<<<<<<<<
 *         elif dims == 4:
 *             THLongTensor_resize4d(self.native, size[0], size[1], size[2], size[3])
 */
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 674, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_5 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_5 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 674, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 674, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_4 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 674, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 674, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_6 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_6 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 674, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    THLongTensor_resize3d(__pyx_v_self->native, __pyx_t_5, __pyx_t_4, __pyx_t_6);

    /* "PyTorch.pyx":673
 *         elif dims == 2:
 *             THLongTensor_resize2d(self.native, size[0], size[1])
 *         elif dims == 3:             # <<<<<<<<<<<<<<
 *             THLongTensor_resize3d(self.native, size[0], size[1], size[2])
 *         elif dims == 4:
 */
    break;

    /* "PyTorch.pyx":675
 *         elif dims == 3:
 *             THLongTensor_resize3d(self.native, size[0], size[1], size[2])
 *         elif dims == 4:             # <<<<<<<<<<<<<<
 *             THLongTensor_resize4d(self.native, size[0], size[1], size[2], size[3])
 *         else:
 */
    case 4:

    /* "PyTorch.pyx":676
 *             THLongTensor_resize3d(self.native, size[0], size[1], size[2])
 *         elif dims == 4:
 *             THLongTensor_resize4d(self.native, size[0], size[1], size[2], size[3])             # <<<<<<<<<<<<<<
 *         else:
 *             raise Exception('Not implemented for dims=' + str(dims))
 */
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 676, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_6 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_6 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 676, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 676, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_4 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 676, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 676, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_5 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_5 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 676, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 3, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 676, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_7 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_7 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 676, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    THLongTensor_resize4d(__pyx_v_self->native, __pyx_t_6, __pyx_t_4, __pyx_t_5, __pyx_t_7);

    /* "PyTorch.pyx":675
 *         elif dims == 3:
 *             THLongTensor_resize3d(self.native, size[0], size[1], size[2])
 *         elif dims == 4:             # <<<<<<<<<<<<<<
 *             THLongTensor_resize4d(self.native, size[0], size[1], size[2], size[3])
 *         else:
 */
    break;
    default:

    /* "PyTorch.pyx":678
 *             THLongTensor_resize4d(self.native, size[0], size[1], size[2], size[3])
 *         else:
 *             raise Exception('Not implemented for dims=' + str(dims))             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
    __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_dims); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 678, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_8 = PyTuple_New(1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 678, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_GIVEREF(__pyx_t_3);
    PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_t_3);
    __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_PyObject_Call(((PyObject *)(&PyString_Type)), __pyx_t_8, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 678, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_8 = PyNumber_Add(__pyx_kp_s_Not_implemented_for_dims, __pyx_t_3); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 678, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 678, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_GIVEREF(__pyx_t_8);
    PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_8);
    __pyx_t_8 = 0;
    __pyx_t_8 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_t_3, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 678, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_Raise(__pyx_t_8, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __PYX_ERR(0, 678, __pyx_L1_error)
    break;
  }

  /* "PyTorch.pyx":679
 *         else:
 *             raise Exception('Not implemented for dims=' + str(dims))
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     @staticmethod
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":663
 *         return self
 * 
 *     def resize(_LongTensor self, Storage._LongStorage size):             # <<<<<<<<<<<<<<
 * #        # print('_FloatTensor.resize size:', size)
 *         if len(size) == 0:
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("PyTorch._LongTensor.resize", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":682
 * 
 *     @staticmethod
 *     def newWithStorage(Storage._LongStorage storage, offset, Storage._LongStorage size, Storage._LongStorage stride):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THLongTensor *newTensorC = THLongTensor_newWithStorage(storage.native, offset, size.native, stride.native)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_61newWithStorage(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_7PyTorch_11_LongTensor_61newWithStorage = {"newWithStorage", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_61newWithStorage, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_61newWithStorage(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  struct __pyx_obj_7Storage__LongStorage *__pyx_v_storage = 0;
  PyObject *__pyx_v_offset = 0;
  struct __pyx_obj_7Storage__LongStorage *__pyx_v_size = 0;
  struct __pyx_obj_7Storage__LongStorage *__pyx_v_stride = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("newWithStorage (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_storage,&__pyx_n_s_offset,&__pyx_n_s_size,&__pyx_n_s_stride,0};
    PyObject* values[4] = {0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_storage)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_offset)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage", 1, 4, 4, 1); __PYX_ERR(0, 682, __pyx_L3_error)
        }
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage", 1, 4, 4, 2); __PYX_ERR(0, 682, __pyx_L3_error)
        }
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage", 1, 4, 4, 3); __PYX_ERR(0, 682, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "newWithStorage") < 0)) __PYX_ERR(0, 682, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 4) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
    }
    __pyx_v_storage = ((struct __pyx_obj_7Storage__LongStorage *)values[0]);
    __pyx_v_offset = values[1];
    __pyx_v_size = ((struct __pyx_obj_7Storage__LongStorage *)values[2]);
    __pyx_v_stride = ((struct __pyx_obj_7Storage__LongStorage *)values[3]);
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("newWithStorage", 1, 4, 4, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 682, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._LongTensor.newWithStorage", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_storage), __pyx_ptype_7Storage__LongStorage, 1, "storage", 0))) __PYX_ERR(0, 682, __pyx_L1_error)
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_size), __pyx_ptype_7Storage__LongStorage, 1, "size", 0))) __PYX_ERR(0, 682, __pyx_L1_error)
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_stride), __pyx_ptype_7Storage__LongStorage, 1, "stride", 0))) __PYX_ERR(0, 682, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_60newWithStorage(__pyx_v_storage, __pyx_v_offset, __pyx_v_size, __pyx_v_stride);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_60newWithStorage(struct __pyx_obj_7Storage__LongStorage *__pyx_v_storage, PyObject *__pyx_v_offset, struct __pyx_obj_7Storage__LongStorage *__pyx_v_size, struct __pyx_obj_7Storage__LongStorage *__pyx_v_stride) {
  struct THLongTensor *__pyx_v_newTensorC;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  long __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  struct __pyx_opt_args_7PyTorch__LongTensor_fromNative __pyx_t_3;
  __Pyx_RefNannySetupContext("newWithStorage", 0);

  /* "PyTorch.pyx":684
 *     def newWithStorage(Storage._LongStorage storage, offset, Storage._LongStorage size, Storage._LongStorage stride):
 * #        # print('allocate tensor')
 *         cdef THLongTensor *newTensorC = THLongTensor_newWithStorage(storage.native, offset, size.native, stride.native)             # <<<<<<<<<<<<<<
 *         return _LongTensor_fromNative(newTensorC, False)
 * 
 */
  __pyx_t_1 = __Pyx_PyInt_As_long(__pyx_v_offset); if (unlikely((__pyx_t_1 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 684, __pyx_L1_error)
  __pyx_v_newTensorC = THLongTensor_newWithStorage(__pyx_v_storage->native, __pyx_t_1, __pyx_v_size->native, __pyx_v_stride->native);

  /* "PyTorch.pyx":685
 * #        # print('allocate tensor')
 *         cdef THLongTensor *newTensorC = THLongTensor_newWithStorage(storage.native, offset, size.native, stride.native)
 *         return _LongTensor_fromNative(newTensorC, False)             # <<<<<<<<<<<<<<
 * 
 *     @staticmethod
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_3.__pyx_n = 1;
  __pyx_t_3.retain = Py_False;
  __pyx_t_2 = __pyx_f_7PyTorch__LongTensor_fromNative(__pyx_v_newTensorC, &__pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 685, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":682
 * 
 *     @staticmethod
 *     def newWithStorage(Storage._LongStorage storage, offset, Storage._LongStorage size, Storage._LongStorage stride):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THLongTensor *newTensorC = THLongTensor_newWithStorage(storage.native, offset, size.native, stride.native)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("PyTorch._LongTensor.newWithStorage", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":688
 * 
 *     @staticmethod
 *     def newWithStorage1d(Storage._LongStorage storage, offset, size0, stride0):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THLongTensor *newTensorC = THLongTensor_newWithStorage1d(storage.native, offset, size0, stride0)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_63newWithStorage1d(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_7PyTorch_11_LongTensor_63newWithStorage1d = {"newWithStorage1d", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_63newWithStorage1d, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_63newWithStorage1d(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  struct __pyx_obj_7Storage__LongStorage *__pyx_v_storage = 0;
  PyObject *__pyx_v_offset = 0;
  PyObject *__pyx_v_size0 = 0;
  PyObject *__pyx_v_stride0 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("newWithStorage1d (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_storage,&__pyx_n_s_offset,&__pyx_n_s_size0,&__pyx_n_s_stride0,0};
    PyObject* values[4] = {0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_storage)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_offset)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage1d", 1, 4, 4, 1); __PYX_ERR(0, 688, __pyx_L3_error)
        }
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size0)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage1d", 1, 4, 4, 2); __PYX_ERR(0, 688, __pyx_L3_error)
        }
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride0)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage1d", 1, 4, 4, 3); __PYX_ERR(0, 688, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "newWithStorage1d") < 0)) __PYX_ERR(0, 688, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 4) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
    }
    __pyx_v_storage = ((struct __pyx_obj_7Storage__LongStorage *)values[0]);
    __pyx_v_offset = values[1];
    __pyx_v_size0 = values[2];
    __pyx_v_stride0 = values[3];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("newWithStorage1d", 1, 4, 4, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 688, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._LongTensor.newWithStorage1d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_storage), __pyx_ptype_7Storage__LongStorage, 1, "storage", 0))) __PYX_ERR(0, 688, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_62newWithStorage1d(__pyx_v_storage, __pyx_v_offset, __pyx_v_size0, __pyx_v_stride0);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_62newWithStorage1d(struct __pyx_obj_7Storage__LongStorage *__pyx_v_storage, PyObject *__pyx_v_offset, PyObject *__pyx_v_size0, PyObject *__pyx_v_stride0) {
  struct THLongTensor *__pyx_v_newTensorC;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  long __pyx_t_1;
  long __pyx_t_2;
  long __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  struct __pyx_opt_args_7PyTorch__LongTensor_fromNative __pyx_t_5;
  __Pyx_RefNannySetupContext("newWithStorage1d", 0);

  /* "PyTorch.pyx":690
 *     def newWithStorage1d(Storage._LongStorage storage, offset, size0, stride0):
 * #        # print('allocate tensor')
 *         cdef THLongTensor *newTensorC = THLongTensor_newWithStorage1d(storage.native, offset, size0, stride0)             # <<<<<<<<<<<<<<
 *         return _LongTensor_fromNative(newTensorC, False)
 * 
 */
  __pyx_t_1 = __Pyx_PyInt_As_long(__pyx_v_offset); if (unlikely((__pyx_t_1 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 690, __pyx_L1_error)
  __pyx_t_2 = __Pyx_PyInt_As_long(__pyx_v_size0); if (unlikely((__pyx_t_2 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 690, __pyx_L1_error)
  __pyx_t_3 = __Pyx_PyInt_As_long(__pyx_v_stride0); if (unlikely((__pyx_t_3 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 690, __pyx_L1_error)
  __pyx_v_newTensorC = THLongTensor_newWithStorage1d(__pyx_v_storage->native, __pyx_t_1, __pyx_t_2, __pyx_t_3);

  /* "PyTorch.pyx":691
 * #        # print('allocate tensor')
 *         cdef THLongTensor *newTensorC = THLongTensor_newWithStorage1d(storage.native, offset, size0, stride0)
 *         return _LongTensor_fromNative(newTensorC, False)             # <<<<<<<<<<<<<<
 * 
 *     @staticmethod
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_5.__pyx_n = 1;
  __pyx_t_5.retain = Py_False;
  __pyx_t_4 = __pyx_f_7PyTorch__LongTensor_fromNative(__pyx_v_newTensorC, &__pyx_t_5); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 691, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_r = __pyx_t_4;
  __pyx_t_4 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":688
 * 
 *     @staticmethod
 *     def newWithStorage1d(Storage._LongStorage storage, offset, size0, stride0):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THLongTensor *newTensorC = THLongTensor_newWithStorage1d(storage.native, offset, size0, stride0)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("PyTorch._LongTensor.newWithStorage1d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":694
 * 
 *     @staticmethod
 *     def newWithStorage2d(Storage._LongStorage storage, offset, size0, stride0, size1, stride1):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THLongTensor *newTensorC = THLongTensor_newWithStorage2d(storage.native, offset, size0, stride0, size1, stride1)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_65newWithStorage2d(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_7PyTorch_11_LongTensor_65newWithStorage2d = {"newWithStorage2d", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_65newWithStorage2d, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_65newWithStorage2d(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  struct __pyx_obj_7Storage__LongStorage *__pyx_v_storage = 0;
  PyObject *__pyx_v_offset = 0;
  PyObject *__pyx_v_size0 = 0;
  PyObject *__pyx_v_stride0 = 0;
  PyObject *__pyx_v_size1 = 0;
  PyObject *__pyx_v_stride1 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("newWithStorage2d (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_storage,&__pyx_n_s_offset,&__pyx_n_s_size0,&__pyx_n_s_stride0,&__pyx_n_s_size1,&__pyx_n_s_stride1,0};
    PyObject* values[6] = {0,0,0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_storage)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_offset)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage2d", 1, 6, 6, 1); __PYX_ERR(0, 694, __pyx_L3_error)
        }
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size0)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage2d", 1, 6, 6, 2); __PYX_ERR(0, 694, __pyx_L3_error)
        }
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride0)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage2d", 1, 6, 6, 3); __PYX_ERR(0, 694, __pyx_L3_error)
        }
        case  4:
        if (likely((values[4] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage2d", 1, 6, 6, 4); __PYX_ERR(0, 694, __pyx_L3_error)
        }
        case  5:
        if (likely((values[5] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage2d", 1, 6, 6, 5); __PYX_ERR(0, 694, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "newWithStorage2d") < 0)) __PYX_ERR(0, 694, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 6) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
      values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
      values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
    }
    __pyx_v_storage = ((struct __pyx_obj_7Storage__LongStorage *)values[0]);
    __pyx_v_offset = values[1];
    __pyx_v_size0 = values[2];
    __pyx_v_stride0 = values[3];
    __pyx_v_size1 = values[4];
    __pyx_v_stride1 = values[5];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("newWithStorage2d", 1, 6, 6, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 694, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._LongTensor.newWithStorage2d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_storage), __pyx_ptype_7Storage__LongStorage, 1, "storage", 0))) __PYX_ERR(0, 694, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_64newWithStorage2d(__pyx_v_storage, __pyx_v_offset, __pyx_v_size0, __pyx_v_stride0, __pyx_v_size1, __pyx_v_stride1);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_64newWithStorage2d(struct __pyx_obj_7Storage__LongStorage *__pyx_v_storage, PyObject *__pyx_v_offset, PyObject *__pyx_v_size0, PyObject *__pyx_v_stride0, PyObject *__pyx_v_size1, PyObject *__pyx_v_stride1) {
  struct THLongTensor *__pyx_v_newTensorC;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  long __pyx_t_1;
  long __pyx_t_2;
  long __pyx_t_3;
  long __pyx_t_4;
  long __pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  struct __pyx_opt_args_7PyTorch__LongTensor_fromNative __pyx_t_7;
  __Pyx_RefNannySetupContext("newWithStorage2d", 0);

  /* "PyTorch.pyx":696
 *     def newWithStorage2d(Storage._LongStorage storage, offset, size0, stride0, size1, stride1):
 * #        # print('allocate tensor')
 *         cdef THLongTensor *newTensorC = THLongTensor_newWithStorage2d(storage.native, offset, size0, stride0, size1, stride1)             # <<<<<<<<<<<<<<
 *         return _LongTensor_fromNative(newTensorC, False)
 * 
 */
  __pyx_t_1 = __Pyx_PyInt_As_long(__pyx_v_offset); if (unlikely((__pyx_t_1 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 696, __pyx_L1_error)
  __pyx_t_2 = __Pyx_PyInt_As_long(__pyx_v_size0); if (unlikely((__pyx_t_2 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 696, __pyx_L1_error)
  __pyx_t_3 = __Pyx_PyInt_As_long(__pyx_v_stride0); if (unlikely((__pyx_t_3 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 696, __pyx_L1_error)
  __pyx_t_4 = __Pyx_PyInt_As_long(__pyx_v_size1); if (unlikely((__pyx_t_4 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 696, __pyx_L1_error)
  __pyx_t_5 = __Pyx_PyInt_As_long(__pyx_v_stride1); if (unlikely((__pyx_t_5 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 696, __pyx_L1_error)
  __pyx_v_newTensorC = THLongTensor_newWithStorage2d(__pyx_v_storage->native, __pyx_t_1, __pyx_t_2, __pyx_t_3, __pyx_t_4, __pyx_t_5);

  /* "PyTorch.pyx":697
 * #        # print('allocate tensor')
 *         cdef THLongTensor *newTensorC = THLongTensor_newWithStorage2d(storage.native, offset, size0, stride0, size1, stride1)
 *         return _LongTensor_fromNative(newTensorC, False)             # <<<<<<<<<<<<<<
 * 
 *     @staticmethod
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_7.__pyx_n = 1;
  __pyx_t_7.retain = Py_False;
  __pyx_t_6 = __pyx_f_7PyTorch__LongTensor_fromNative(__pyx_v_newTensorC, &__pyx_t_7); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 697, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_r = __pyx_t_6;
  __pyx_t_6 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":694
 * 
 *     @staticmethod
 *     def newWithStorage2d(Storage._LongStorage storage, offset, size0, stride0, size1, stride1):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THLongTensor *newTensorC = THLongTensor_newWithStorage2d(storage.native, offset, size0, stride0, size1, stride1)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("PyTorch._LongTensor.newWithStorage2d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":700
 * 
 *     @staticmethod
 *     def newWithStorage3d(Storage._LongStorage storage, offset, size0, stride0, size1, stride1, size2, stride2):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THLongTensor *newTensorC = THLongTensor_newWithStorage3d(storage.native, offset, size0, stride0, size1, stride1,
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_67newWithStorage3d(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_7PyTorch_11_LongTensor_67newWithStorage3d = {"newWithStorage3d", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_67newWithStorage3d, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_67newWithStorage3d(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  struct __pyx_obj_7Storage__LongStorage *__pyx_v_storage = 0;
  PyObject *__pyx_v_offset = 0;
  PyObject *__pyx_v_size0 = 0;
  PyObject *__pyx_v_stride0 = 0;
  PyObject *__pyx_v_size1 = 0;
  PyObject *__pyx_v_stride1 = 0;
  PyObject *__pyx_v_size2 = 0;
  PyObject *__pyx_v_stride2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("newWithStorage3d (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_storage,&__pyx_n_s_offset,&__pyx_n_s_size0,&__pyx_n_s_stride0,&__pyx_n_s_size1,&__pyx_n_s_stride1,&__pyx_n_s_size2,&__pyx_n_s_stride2,0};
    PyObject* values[8] = {0,0,0,0,0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  8: values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_storage)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_offset)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage3d", 1, 8, 8, 1); __PYX_ERR(0, 700, __pyx_L3_error)
        }
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size0)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage3d", 1, 8, 8, 2); __PYX_ERR(0, 700, __pyx_L3_error)
        }
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride0)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage3d", 1, 8, 8, 3); __PYX_ERR(0, 700, __pyx_L3_error)
        }
        case  4:
        if (likely((values[4] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage3d", 1, 8, 8, 4); __PYX_ERR(0, 700, __pyx_L3_error)
        }
        case  5:
        if (likely((values[5] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage3d", 1, 8, 8, 5); __PYX_ERR(0, 700, __pyx_L3_error)
        }
        case  6:
        if (likely((values[6] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage3d", 1, 8, 8, 6); __PYX_ERR(0, 700, __pyx_L3_error)
        }
        case  7:
        if (likely((values[7] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage3d", 1, 8, 8, 7); __PYX_ERR(0, 700, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "newWithStorage3d") < 0)) __PYX_ERR(0, 700, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 8) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
      values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
      values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
      values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
      values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
    }
    __pyx_v_storage = ((struct __pyx_obj_7Storage__LongStorage *)values[0]);
    __pyx_v_offset = values[1];
    __pyx_v_size0 = values[2];
    __pyx_v_stride0 = values[3];
    __pyx_v_size1 = values[4];
    __pyx_v_stride1 = values[5];
    __pyx_v_size2 = values[6];
    __pyx_v_stride2 = values[7];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("newWithStorage3d", 1, 8, 8, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 700, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._LongTensor.newWithStorage3d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_storage), __pyx_ptype_7Storage__LongStorage, 1, "storage", 0))) __PYX_ERR(0, 700, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_66newWithStorage3d(__pyx_v_storage, __pyx_v_offset, __pyx_v_size0, __pyx_v_stride0, __pyx_v_size1, __pyx_v_stride1, __pyx_v_size2, __pyx_v_stride2);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_66newWithStorage3d(struct __pyx_obj_7Storage__LongStorage *__pyx_v_storage, PyObject *__pyx_v_offset, PyObject *__pyx_v_size0, PyObject *__pyx_v_stride0, PyObject *__pyx_v_size1, PyObject *__pyx_v_stride1, PyObject *__pyx_v_size2, PyObject *__pyx_v_stride2) {
  struct THLongTensor *__pyx_v_newTensorC;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  long __pyx_t_1;
  long __pyx_t_2;
  long __pyx_t_3;
  long __pyx_t_4;
  long __pyx_t_5;
  long __pyx_t_6;
  long __pyx_t_7;
  PyObject *__pyx_t_8 = NULL;
  struct __pyx_opt_args_7PyTorch__LongTensor_fromNative __pyx_t_9;
  __Pyx_RefNannySetupContext("newWithStorage3d", 0);

  /* "PyTorch.pyx":702
 *     def newWithStorage3d(Storage._LongStorage storage, offset, size0, stride0, size1, stride1, size2, stride2):
 * #        # print('allocate tensor')
 *         cdef THLongTensor *newTensorC = THLongTensor_newWithStorage3d(storage.native, offset, size0, stride0, size1, stride1,             # <<<<<<<<<<<<<<
 *             size2, stride2)
 *         return _LongTensor_fromNative(newTensorC, False)
 */
  __pyx_t_1 = __Pyx_PyInt_As_long(__pyx_v_offset); if (unlikely((__pyx_t_1 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 702, __pyx_L1_error)
  __pyx_t_2 = __Pyx_PyInt_As_long(__pyx_v_size0); if (unlikely((__pyx_t_2 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 702, __pyx_L1_error)
  __pyx_t_3 = __Pyx_PyInt_As_long(__pyx_v_stride0); if (unlikely((__pyx_t_3 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 702, __pyx_L1_error)
  __pyx_t_4 = __Pyx_PyInt_As_long(__pyx_v_size1); if (unlikely((__pyx_t_4 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 702, __pyx_L1_error)
  __pyx_t_5 = __Pyx_PyInt_As_long(__pyx_v_stride1); if (unlikely((__pyx_t_5 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 702, __pyx_L1_error)

  /* "PyTorch.pyx":703
 * #        # print('allocate tensor')
 *         cdef THLongTensor *newTensorC = THLongTensor_newWithStorage3d(storage.native, offset, size0, stride0, size1, stride1,
 *             size2, stride2)             # <<<<<<<<<<<<<<
 *         return _LongTensor_fromNative(newTensorC, False)
 * 
 */
  __pyx_t_6 = __Pyx_PyInt_As_long(__pyx_v_size2); if (unlikely((__pyx_t_6 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 703, __pyx_L1_error)
  __pyx_t_7 = __Pyx_PyInt_As_long(__pyx_v_stride2); if (unlikely((__pyx_t_7 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 703, __pyx_L1_error)

  /* "PyTorch.pyx":702
 *     def newWithStorage3d(Storage._LongStorage storage, offset, size0, stride0, size1, stride1, size2, stride2):
 * #        # print('allocate tensor')
 *         cdef THLongTensor *newTensorC = THLongTensor_newWithStorage3d(storage.native, offset, size0, stride0, size1, stride1,             # <<<<<<<<<<<<<<
 *             size2, stride2)
 *         return _LongTensor_fromNative(newTensorC, False)
 */
  __pyx_v_newTensorC = THLongTensor_newWithStorage3d(__pyx_v_storage->native, __pyx_t_1, __pyx_t_2, __pyx_t_3, __pyx_t_4, __pyx_t_5, __pyx_t_6, __pyx_t_7);

  /* "PyTorch.pyx":704
 *         cdef THLongTensor *newTensorC = THLongTensor_newWithStorage3d(storage.native, offset, size0, stride0, size1, stride1,
 *             size2, stride2)
 *         return _LongTensor_fromNative(newTensorC, False)             # <<<<<<<<<<<<<<
 * 
 *     @staticmethod
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_9.__pyx_n = 1;
  __pyx_t_9.retain = Py_False;
  __pyx_t_8 = __pyx_f_7PyTorch__LongTensor_fromNative(__pyx_v_newTensorC, &__pyx_t_9); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 704, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __pyx_r = __pyx_t_8;
  __pyx_t_8 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":700
 * 
 *     @staticmethod
 *     def newWithStorage3d(Storage._LongStorage storage, offset, size0, stride0, size1, stride1, size2, stride2):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THLongTensor *newTensorC = THLongTensor_newWithStorage3d(storage.native, offset, size0, stride0, size1, stride1,
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("PyTorch._LongTensor.newWithStorage3d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":707
 * 
 *     @staticmethod
 *     def newWithStorage4d(Storage._LongStorage storage, offset, size0, stride0, size1, stride1, size2, stride2,             # <<<<<<<<<<<<<<
 *             size3, stride3):
 * #        # print('allocate tensor')
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_69newWithStorage4d(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_7PyTorch_11_LongTensor_69newWithStorage4d = {"newWithStorage4d", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_69newWithStorage4d, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_69newWithStorage4d(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  struct __pyx_obj_7Storage__LongStorage *__pyx_v_storage = 0;
  PyObject *__pyx_v_offset = 0;
  PyObject *__pyx_v_size0 = 0;
  PyObject *__pyx_v_stride0 = 0;
  PyObject *__pyx_v_size1 = 0;
  PyObject *__pyx_v_stride1 = 0;
  PyObject *__pyx_v_size2 = 0;
  PyObject *__pyx_v_stride2 = 0;
  PyObject *__pyx_v_size3 = 0;
  PyObject *__pyx_v_stride3 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("newWithStorage4d (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_storage,&__pyx_n_s_offset,&__pyx_n_s_size0,&__pyx_n_s_stride0,&__pyx_n_s_size1,&__pyx_n_s_stride1,&__pyx_n_s_size2,&__pyx_n_s_stride2,&__pyx_n_s_size3,&__pyx_n_s_stride3,0};
    PyObject* values[10] = {0,0,0,0,0,0,0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case 10: values[9] = PyTuple_GET_ITEM(__pyx_args, 9);
        case  9: values[8] = PyTuple_GET_ITEM(__pyx_args, 8);
        case  8: values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_storage)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_offset)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage4d", 1, 10, 10, 1); __PYX_ERR(0, 707, __pyx_L3_error)
        }
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size0)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage4d", 1, 10, 10, 2); __PYX_ERR(0, 707, __pyx_L3_error)
        }
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride0)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage4d", 1, 10, 10, 3); __PYX_ERR(0, 707, __pyx_L3_error)
        }
        case  4:
        if (likely((values[4] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage4d", 1, 10, 10, 4); __PYX_ERR(0, 707, __pyx_L3_error)
        }
        case  5:
        if (likely((values[5] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage4d", 1, 10, 10, 5); __PYX_ERR(0, 707, __pyx_L3_error)
        }
        case  6:
        if (likely((values[6] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage4d", 1, 10, 10, 6); __PYX_ERR(0, 707, __pyx_L3_error)
        }
        case  7:
        if (likely((values[7] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage4d", 1, 10, 10, 7); __PYX_ERR(0, 707, __pyx_L3_error)
        }
        case  8:
        if (likely((values[8] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size3)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage4d", 1, 10, 10, 8); __PYX_ERR(0, 707, __pyx_L3_error)
        }
        case  9:
        if (likely((values[9] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride3)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage4d", 1, 10, 10, 9); __PYX_ERR(0, 707, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "newWithStorage4d") < 0)) __PYX_ERR(0, 707, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 10) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
      values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
      values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
      values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
      values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
      values[8] = PyTuple_GET_ITEM(__pyx_args, 8);
      values[9] = PyTuple_GET_ITEM(__pyx_args, 9);
    }
    __pyx_v_storage = ((struct __pyx_obj_7Storage__LongStorage *)values[0]);
    __pyx_v_offset = values[1];
    __pyx_v_size0 = values[2];
    __pyx_v_stride0 = values[3];
    __pyx_v_size1 = values[4];
    __pyx_v_stride1 = values[5];
    __pyx_v_size2 = values[6];
    __pyx_v_stride2 = values[7];
    __pyx_v_size3 = values[8];
    __pyx_v_stride3 = values[9];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("newWithStorage4d", 1, 10, 10, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 707, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._LongTensor.newWithStorage4d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_storage), __pyx_ptype_7Storage__LongStorage, 1, "storage", 0))) __PYX_ERR(0, 707, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_68newWithStorage4d(__pyx_v_storage, __pyx_v_offset, __pyx_v_size0, __pyx_v_stride0, __pyx_v_size1, __pyx_v_stride1, __pyx_v_size2, __pyx_v_stride2, __pyx_v_size3, __pyx_v_stride3);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_68newWithStorage4d(struct __pyx_obj_7Storage__LongStorage *__pyx_v_storage, PyObject *__pyx_v_offset, PyObject *__pyx_v_size0, PyObject *__pyx_v_stride0, PyObject *__pyx_v_size1, PyObject *__pyx_v_stride1, PyObject *__pyx_v_size2, PyObject *__pyx_v_stride2, PyObject *__pyx_v_size3, PyObject *__pyx_v_stride3) {
  struct THLongTensor *__pyx_v_newTensorC;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  long __pyx_t_1;
  long __pyx_t_2;
  long __pyx_t_3;
  long __pyx_t_4;
  long __pyx_t_5;
  long __pyx_t_6;
  long __pyx_t_7;
  long __pyx_t_8;
  long __pyx_t_9;
  PyObject *__pyx_t_10 = NULL;
  struct __pyx_opt_args_7PyTorch__LongTensor_fromNative __pyx_t_11;
  __Pyx_RefNannySetupContext("newWithStorage4d", 0);

  /* "PyTorch.pyx":710
 *             size3, stride3):
 * #        # print('allocate tensor')
 *         cdef THLongTensor *newTensorC = THLongTensor_newWithStorage4d(storage.native, offset, size0, stride0, size1, stride1,             # <<<<<<<<<<<<<<
 *             size2, stride2, size3, stride3)
 *         return _LongTensor_fromNative(newTensorC, False)
 */
  __pyx_t_1 = __Pyx_PyInt_As_long(__pyx_v_offset); if (unlikely((__pyx_t_1 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 710, __pyx_L1_error)
  __pyx_t_2 = __Pyx_PyInt_As_long(__pyx_v_size0); if (unlikely((__pyx_t_2 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 710, __pyx_L1_error)
  __pyx_t_3 = __Pyx_PyInt_As_long(__pyx_v_stride0); if (unlikely((__pyx_t_3 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 710, __pyx_L1_error)
  __pyx_t_4 = __Pyx_PyInt_As_long(__pyx_v_size1); if (unlikely((__pyx_t_4 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 710, __pyx_L1_error)
  __pyx_t_5 = __Pyx_PyInt_As_long(__pyx_v_stride1); if (unlikely((__pyx_t_5 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 710, __pyx_L1_error)

  /* "PyTorch.pyx":711
 * #        # print('allocate tensor')
 *         cdef THLongTensor *newTensorC = THLongTensor_newWithStorage4d(storage.native, offset, size0, stride0, size1, stride1,
 *             size2, stride2, size3, stride3)             # <<<<<<<<<<<<<<
 *         return _LongTensor_fromNative(newTensorC, False)
 * 
 */
  __pyx_t_6 = __Pyx_PyInt_As_long(__pyx_v_size2); if (unlikely((__pyx_t_6 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 711, __pyx_L1_error)
  __pyx_t_7 = __Pyx_PyInt_As_long(__pyx_v_stride2); if (unlikely((__pyx_t_7 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 711, __pyx_L1_error)
  __pyx_t_8 = __Pyx_PyInt_As_long(__pyx_v_size3); if (unlikely((__pyx_t_8 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 711, __pyx_L1_error)
  __pyx_t_9 = __Pyx_PyInt_As_long(__pyx_v_stride3); if (unlikely((__pyx_t_9 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 711, __pyx_L1_error)

  /* "PyTorch.pyx":710
 *             size3, stride3):
 * #        # print('allocate tensor')
 *         cdef THLongTensor *newTensorC = THLongTensor_newWithStorage4d(storage.native, offset, size0, stride0, size1, stride1,             # <<<<<<<<<<<<<<
 *             size2, stride2, size3, stride3)
 *         return _LongTensor_fromNative(newTensorC, False)
 */
  __pyx_v_newTensorC = THLongTensor_newWithStorage4d(__pyx_v_storage->native, __pyx_t_1, __pyx_t_2, __pyx_t_3, __pyx_t_4, __pyx_t_5, __pyx_t_6, __pyx_t_7, __pyx_t_8, __pyx_t_9);

  /* "PyTorch.pyx":712
 *         cdef THLongTensor *newTensorC = THLongTensor_newWithStorage4d(storage.native, offset, size0, stride0, size1, stride1,
 *             size2, stride2, size3, stride3)
 *         return _LongTensor_fromNative(newTensorC, False)             # <<<<<<<<<<<<<<
 * 
 *     def clone(_LongTensor self):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_11.__pyx_n = 1;
  __pyx_t_11.retain = Py_False;
  __pyx_t_10 = __pyx_f_7PyTorch__LongTensor_fromNative(__pyx_v_newTensorC, &__pyx_t_11); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 712, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __pyx_r = __pyx_t_10;
  __pyx_t_10 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":707
 * 
 *     @staticmethod
 *     def newWithStorage4d(Storage._LongStorage storage, offset, size0, stride0, size1, stride1, size2, stride2,             # <<<<<<<<<<<<<<
 *             size3, stride3):
 * #        # print('allocate tensor')
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_10);
  __Pyx_AddTraceback("PyTorch._LongTensor.newWithStorage4d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":714
 *         return _LongTensor_fromNative(newTensorC, False)
 * 
 *     def clone(_LongTensor self):             # <<<<<<<<<<<<<<
 *         cdef THLongTensor *newTensorC = THLongTensor_newClone(self.native)
 *         return _LongTensor_fromNative(newTensorC, False)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_71clone(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_71clone(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("clone (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_70clone(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_70clone(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self) {
  struct THLongTensor *__pyx_v_newTensorC;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  struct __pyx_opt_args_7PyTorch__LongTensor_fromNative __pyx_t_2;
  __Pyx_RefNannySetupContext("clone", 0);

  /* "PyTorch.pyx":715
 * 
 *     def clone(_LongTensor self):
 *         cdef THLongTensor *newTensorC = THLongTensor_newClone(self.native)             # <<<<<<<<<<<<<<
 *         return _LongTensor_fromNative(newTensorC, False)
 * 
 */
  __pyx_v_newTensorC = THLongTensor_newClone(__pyx_v_self->native);

  /* "PyTorch.pyx":716
 *     def clone(_LongTensor self):
 *         cdef THLongTensor *newTensorC = THLongTensor_newClone(self.native)
 *         return _LongTensor_fromNative(newTensorC, False)             # <<<<<<<<<<<<<<
 * 
 *     def storage(_LongTensor self):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2.__pyx_n = 1;
  __pyx_t_2.retain = Py_False;
  __pyx_t_1 = __pyx_f_7PyTorch__LongTensor_fromNative(__pyx_v_newTensorC, &__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 716, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":714
 *         return _LongTensor_fromNative(newTensorC, False)
 * 
 *     def clone(_LongTensor self):             # <<<<<<<<<<<<<<
 *         cdef THLongTensor *newTensorC = THLongTensor_newClone(self.native)
 *         return _LongTensor_fromNative(newTensorC, False)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._LongTensor.clone", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":718
 *         return _LongTensor_fromNative(newTensorC, False)
 * 
 *     def storage(_LongTensor self):             # <<<<<<<<<<<<<<
 *         cdef Storage.THLongStorage *storageC = THLongTensor_storage(self.native)
 *         if storageC == NULL:
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_73storage(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_73storage(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("storage (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_72storage(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_72storage(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self) {
  struct THLongStorage *__pyx_v_storageC;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("storage", 0);

  /* "PyTorch.pyx":719
 * 
 *     def storage(_LongTensor self):
 *         cdef Storage.THLongStorage *storageC = THLongTensor_storage(self.native)             # <<<<<<<<<<<<<<
 *         if storageC == NULL:
 *             return None
 */
  __pyx_v_storageC = THLongTensor_storage(__pyx_v_self->native);

  /* "PyTorch.pyx":720
 *     def storage(_LongTensor self):
 *         cdef Storage.THLongStorage *storageC = THLongTensor_storage(self.native)
 *         if storageC == NULL:             # <<<<<<<<<<<<<<
 *             return None
 *         return Storage._LongStorage_fromNative(storageC)
 */
  __pyx_t_1 = ((__pyx_v_storageC == NULL) != 0);
  if (__pyx_t_1) {

    /* "PyTorch.pyx":721
 *         cdef Storage.THLongStorage *storageC = THLongTensor_storage(self.native)
 *         if storageC == NULL:
 *             return None             # <<<<<<<<<<<<<<
 *         return Storage._LongStorage_fromNative(storageC)
 * 
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(Py_None);
    __pyx_r = Py_None;
    goto __pyx_L0;

    /* "PyTorch.pyx":720
 *     def storage(_LongTensor self):
 *         cdef Storage.THLongStorage *storageC = THLongTensor_storage(self.native)
 *         if storageC == NULL:             # <<<<<<<<<<<<<<
 *             return None
 *         return Storage._LongStorage_fromNative(storageC)
 */
  }

  /* "PyTorch.pyx":722
 *         if storageC == NULL:
 *             return None
 *         return Storage._LongStorage_fromNative(storageC)             # <<<<<<<<<<<<<<
 * 
 *     def __add__(_LongTensor self, second):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2 = __pyx_f_7Storage__LongStorage_fromNative(__pyx_v_storageC, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 722, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":718
 *         return _LongTensor_fromNative(newTensorC, False)
 * 
 *     def storage(_LongTensor self):             # <<<<<<<<<<<<<<
 *         cdef Storage.THLongStorage *storageC = THLongTensor_storage(self.native)
 *         if storageC == NULL:
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("PyTorch._LongTensor.storage", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":724
 *         return Storage._LongStorage_fromNative(storageC)
 * 
 *     def __add__(_LongTensor self, second):             # <<<<<<<<<<<<<<
 *         # assume 2d matrix for now?
 *         cdef _LongTensor res = _LongTensor.new()
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_75__add__(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_75__add__(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__add__ (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_self), __pyx_ptype_7PyTorch__LongTensor, 1, "self", 0))) __PYX_ERR(0, 724, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_74__add__(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self), ((PyObject *)__pyx_v_second));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_74__add__(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, PyObject *__pyx_v_second) {
  struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_res = 0;
  struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_secondTensor = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  int __pyx_t_5;
  long __pyx_t_6;
  __Pyx_RefNannySetupContext("__add__", 0);

  /* "PyTorch.pyx":726
 *     def __add__(_LongTensor self, second):
 *         # assume 2d matrix for now?
 *         cdef _LongTensor res = _LongTensor.new()             # <<<<<<<<<<<<<<
 *         cdef _LongTensor secondTensor
 *         if isinstance(second, numbers.Number):
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7PyTorch__LongTensor), __pyx_n_s_new); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 726, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 726, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 726, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_7PyTorch__LongTensor))))) __PYX_ERR(0, 726, __pyx_L1_error)
  __pyx_v_res = ((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":728
 *         cdef _LongTensor res = _LongTensor.new()
 *         cdef _LongTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THLongTensor_add(res.native, self.native, second)
 *         else:
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_numbers); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 728, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_Number); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 728, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_4 = PyObject_IsInstance(__pyx_v_second, __pyx_t_2); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 728, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = (__pyx_t_4 != 0);
  if (__pyx_t_5) {

    /* "PyTorch.pyx":729
 *         cdef _LongTensor secondTensor
 *         if isinstance(second, numbers.Number):
 *             THLongTensor_add(res.native, self.native, second)             # <<<<<<<<<<<<<<
 *         else:
 *             secondTensor = second
 */
    __pyx_t_6 = __Pyx_PyInt_As_long(__pyx_v_second); if (unlikely((__pyx_t_6 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 729, __pyx_L1_error)
    THLongTensor_add(__pyx_v_res->native, __pyx_v_self->native, __pyx_t_6);

    /* "PyTorch.pyx":728
 *         cdef _LongTensor res = _LongTensor.new()
 *         cdef _LongTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THLongTensor_add(res.native, self.native, second)
 *         else:
 */
    goto __pyx_L3;
  }

  /* "PyTorch.pyx":731
 *             THLongTensor_add(res.native, self.native, second)
 *         else:
 *             secondTensor = second             # <<<<<<<<<<<<<<
 *             THLongTensor_cadd(res.native, self.native, 1, secondTensor.native)
 *         return res
 */
  /*else*/ {
    if (!(likely(((__pyx_v_second) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_second, __pyx_ptype_7PyTorch__LongTensor))))) __PYX_ERR(0, 731, __pyx_L1_error)
    __pyx_t_2 = __pyx_v_second;
    __Pyx_INCREF(__pyx_t_2);
    __pyx_v_secondTensor = ((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_t_2);
    __pyx_t_2 = 0;

    /* "PyTorch.pyx":732
 *         else:
 *             secondTensor = second
 *             THLongTensor_cadd(res.native, self.native, 1, secondTensor.native)             # <<<<<<<<<<<<<<
 *         return res
 * 
 */
    THLongTensor_cadd(__pyx_v_res->native, __pyx_v_self->native, 1, __pyx_v_secondTensor->native);
  }
  __pyx_L3:;

  /* "PyTorch.pyx":733
 *             secondTensor = second
 *             THLongTensor_cadd(res.native, self.native, 1, secondTensor.native)
 *         return res             # <<<<<<<<<<<<<<
 * 
 *     def cmul(_LongTensor self, second):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = ((PyObject *)__pyx_v_res);
  goto __pyx_L0;

  /* "PyTorch.pyx":724
 *         return Storage._LongStorage_fromNative(storageC)
 * 
 *     def __add__(_LongTensor self, second):             # <<<<<<<<<<<<<<
 *         # assume 2d matrix for now?
 *         cdef _LongTensor res = _LongTensor.new()
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("PyTorch._LongTensor.__add__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XDECREF((PyObject *)__pyx_v_secondTensor);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":735
 *         return res
 * 
 *     def cmul(_LongTensor self, second):             # <<<<<<<<<<<<<<
 * #        cdef _LongTensor res = _LongTensor.new()
 *         cdef _LongTensor secondTensor
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_77cmul(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_77cmul(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cmul (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_76cmul(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self), ((PyObject *)__pyx_v_second));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_76cmul(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, PyObject *__pyx_v_second) {
  struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_secondTensor = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("cmul", 0);

  /* "PyTorch.pyx":738
 * #        cdef _LongTensor res = _LongTensor.new()
 *         cdef _LongTensor secondTensor
 *         secondTensor = second             # <<<<<<<<<<<<<<
 *         THLongTensor_cmul(self.native, self.native, secondTensor.native)
 *         return self
 */
  if (!(likely(((__pyx_v_second) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_second, __pyx_ptype_7PyTorch__LongTensor))))) __PYX_ERR(0, 738, __pyx_L1_error)
  __pyx_t_1 = __pyx_v_second;
  __Pyx_INCREF(__pyx_t_1);
  __pyx_v_secondTensor = ((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":739
 *         cdef _LongTensor secondTensor
 *         secondTensor = second
 *         THLongTensor_cmul(self.native, self.native, secondTensor.native)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THLongTensor_cmul(__pyx_v_self->native, __pyx_v_self->native, __pyx_v_secondTensor->native);

  /* "PyTorch.pyx":740
 *         secondTensor = second
 *         THLongTensor_cmul(self.native, self.native, secondTensor.native)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def __sub__(_LongTensor self, second):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":735
 *         return res
 * 
 *     def cmul(_LongTensor self, second):             # <<<<<<<<<<<<<<
 * #        cdef _LongTensor res = _LongTensor.new()
 *         cdef _LongTensor secondTensor
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._LongTensor.cmul", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_secondTensor);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":742
 *         return self
 * 
 *     def __sub__(_LongTensor self, second):             # <<<<<<<<<<<<<<
 *         # assume 2d matrix for now?
 *         cdef _LongTensor res = _LongTensor.new()
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_79__sub__(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_79__sub__(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__sub__ (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_self), __pyx_ptype_7PyTorch__LongTensor, 1, "self", 0))) __PYX_ERR(0, 742, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_78__sub__(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self), ((PyObject *)__pyx_v_second));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_78__sub__(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, PyObject *__pyx_v_second) {
  struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_res = 0;
  struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_secondTensor = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  int __pyx_t_5;
  long __pyx_t_6;
  __Pyx_RefNannySetupContext("__sub__", 0);

  /* "PyTorch.pyx":744
 *     def __sub__(_LongTensor self, second):
 *         # assume 2d matrix for now?
 *         cdef _LongTensor res = _LongTensor.new()             # <<<<<<<<<<<<<<
 *         cdef _LongTensor secondTensor
 *         if isinstance(second, numbers.Number):
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7PyTorch__LongTensor), __pyx_n_s_new); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 744, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 744, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 744, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_7PyTorch__LongTensor))))) __PYX_ERR(0, 744, __pyx_L1_error)
  __pyx_v_res = ((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":746
 *         cdef _LongTensor res = _LongTensor.new()
 *         cdef _LongTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THLongTensor_add(res.native, self.native, -second)
 *         else:
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_numbers); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 746, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_Number); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 746, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_4 = PyObject_IsInstance(__pyx_v_second, __pyx_t_2); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 746, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = (__pyx_t_4 != 0);
  if (__pyx_t_5) {

    /* "PyTorch.pyx":747
 *         cdef _LongTensor secondTensor
 *         if isinstance(second, numbers.Number):
 *             THLongTensor_add(res.native, self.native, -second)             # <<<<<<<<<<<<<<
 *         else:
 *             secondTensor = second
 */
    __pyx_t_2 = PyNumber_Negative(__pyx_v_second); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 747, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_6 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_6 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 747, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    THLongTensor_add(__pyx_v_res->native, __pyx_v_self->native, __pyx_t_6);

    /* "PyTorch.pyx":746
 *         cdef _LongTensor res = _LongTensor.new()
 *         cdef _LongTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THLongTensor_add(res.native, self.native, -second)
 *         else:
 */
    goto __pyx_L3;
  }

  /* "PyTorch.pyx":749
 *             THLongTensor_add(res.native, self.native, -second)
 *         else:
 *             secondTensor = second             # <<<<<<<<<<<<<<
 *             THLongTensor_cadd(res.native, self.native, -1, secondTensor.native)
 *         return res
 */
  /*else*/ {
    if (!(likely(((__pyx_v_second) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_second, __pyx_ptype_7PyTorch__LongTensor))))) __PYX_ERR(0, 749, __pyx_L1_error)
    __pyx_t_2 = __pyx_v_second;
    __Pyx_INCREF(__pyx_t_2);
    __pyx_v_secondTensor = ((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_t_2);
    __pyx_t_2 = 0;

    /* "PyTorch.pyx":750
 *         else:
 *             secondTensor = second
 *             THLongTensor_cadd(res.native, self.native, -1, secondTensor.native)             # <<<<<<<<<<<<<<
 *         return res
 * 
 */
    THLongTensor_cadd(__pyx_v_res->native, __pyx_v_self->native, -1L, __pyx_v_secondTensor->native);
  }
  __pyx_L3:;

  /* "PyTorch.pyx":751
 *             secondTensor = second
 *             THLongTensor_cadd(res.native, self.native, -1, secondTensor.native)
 *         return res             # <<<<<<<<<<<<<<
 * 
 *     def eq(_LongTensor self, _LongTensor second):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = ((PyObject *)__pyx_v_res);
  goto __pyx_L0;

  /* "PyTorch.pyx":742
 *         return self
 * 
 *     def __sub__(_LongTensor self, second):             # <<<<<<<<<<<<<<
 *         # assume 2d matrix for now?
 *         cdef _LongTensor res = _LongTensor.new()
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("PyTorch._LongTensor.__sub__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XDECREF((PyObject *)__pyx_v_secondTensor);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":753
 *         return res
 * 
 *     def eq(_LongTensor self, _LongTensor second):             # <<<<<<<<<<<<<<
 *         cdef _ByteTensor res = _ByteTensor.new()
 *         THLongTensor_eqTensor(res.native, self.native, second.native);
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_81eq(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_81eq(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("eq (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_second), __pyx_ptype_7PyTorch__LongTensor, 1, "second", 0))) __PYX_ERR(0, 753, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_80eq(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self), ((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_second));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_80eq(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_second) {
  struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_res = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("eq", 0);

  /* "PyTorch.pyx":754
 * 
 *     def eq(_LongTensor self, _LongTensor second):
 *         cdef _ByteTensor res = _ByteTensor.new()             # <<<<<<<<<<<<<<
 *         THLongTensor_eqTensor(res.native, self.native, second.native);
 *         return res
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7PyTorch__ByteTensor), __pyx_n_s_new); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 754, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 754, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 754, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_7PyTorch__ByteTensor))))) __PYX_ERR(0, 754, __pyx_L1_error)
  __pyx_v_res = ((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":755
 *     def eq(_LongTensor self, _LongTensor second):
 *         cdef _ByteTensor res = _ByteTensor.new()
 *         THLongTensor_eqTensor(res.native, self.native, second.native);             # <<<<<<<<<<<<<<
 *         return res
 * 
 */
  THLongTensor_eqTensor(__pyx_v_res->native, __pyx_v_self->native, __pyx_v_second->native);

  /* "PyTorch.pyx":756
 *         cdef _ByteTensor res = _ByteTensor.new()
 *         THLongTensor_eqTensor(res.native, self.native, second.native);
 *         return res             # <<<<<<<<<<<<<<
 * 
 *     def icmin(_LongTensor self, second):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = ((PyObject *)__pyx_v_res);
  goto __pyx_L0;

  /* "PyTorch.pyx":753
 *         return res
 * 
 *     def eq(_LongTensor self, _LongTensor second):             # <<<<<<<<<<<<<<
 *         cdef _ByteTensor res = _ByteTensor.new()
 *         THLongTensor_eqTensor(res.native, self.native, second.native);
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("PyTorch._LongTensor.eq", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":758
 *         return res
 * 
 *     def icmin(_LongTensor self, second):             # <<<<<<<<<<<<<<
 *       THLongTensor_cminValue(self.native, self.native, second)
 *       return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_83icmin(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_83icmin(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("icmin (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_82icmin(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self), ((PyObject *)__pyx_v_second));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_82icmin(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  long __pyx_t_1;
  __Pyx_RefNannySetupContext("icmin", 0);

  /* "PyTorch.pyx":759
 * 
 *     def icmin(_LongTensor self, second):
 *       THLongTensor_cminValue(self.native, self.native, second)             # <<<<<<<<<<<<<<
 *       return self
 * 
 */
  __pyx_t_1 = __Pyx_PyInt_As_long(__pyx_v_second); if (unlikely((__pyx_t_1 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 759, __pyx_L1_error)
  THLongTensor_cminValue(__pyx_v_self->native, __pyx_v_self->native, __pyx_t_1);

  /* "PyTorch.pyx":760
 *     def icmin(_LongTensor self, second):
 *       THLongTensor_cminValue(self.native, self.native, second)
 *       return self             # <<<<<<<<<<<<<<
 * 
 *     def icmax(_LongTensor self, second):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":758
 *         return res
 * 
 *     def icmin(_LongTensor self, second):             # <<<<<<<<<<<<<<
 *       THLongTensor_cminValue(self.native, self.native, second)
 *       return self
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("PyTorch._LongTensor.icmin", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":762
 *       return self
 * 
 *     def icmax(_LongTensor self, second):             # <<<<<<<<<<<<<<
 *       THLongTensor_cmaxValue(self.native, self.native, second)
 *       return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_85icmax(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_85icmax(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("icmax (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_84icmax(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self), ((PyObject *)__pyx_v_second));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_84icmax(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  long __pyx_t_1;
  __Pyx_RefNannySetupContext("icmax", 0);

  /* "PyTorch.pyx":763
 * 
 *     def icmax(_LongTensor self, second):
 *       THLongTensor_cmaxValue(self.native, self.native, second)             # <<<<<<<<<<<<<<
 *       return self
 * 
 */
  __pyx_t_1 = __Pyx_PyInt_As_long(__pyx_v_second); if (unlikely((__pyx_t_1 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 763, __pyx_L1_error)
  THLongTensor_cmaxValue(__pyx_v_self->native, __pyx_v_self->native, __pyx_t_1);

  /* "PyTorch.pyx":764
 *     def icmax(_LongTensor self, second):
 *       THLongTensor_cmaxValue(self.native, self.native, second)
 *       return self             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":762
 *       return self
 * 
 *     def icmax(_LongTensor self, second):             # <<<<<<<<<<<<<<
 *       THLongTensor_cmaxValue(self.native, self.native, second)
 *       return self
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("PyTorch._LongTensor.icmax", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":767
 * 
 * 
 *     def __floordiv__(_LongTensor self, second):             # <<<<<<<<<<<<<<
 *         cdef _LongTensor res = _LongTensor.new()
 *         cdef _LongTensor secondTensor
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_87__floordiv__(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_87__floordiv__(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__floordiv__ (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_self), __pyx_ptype_7PyTorch__LongTensor, 1, "self", 0))) __PYX_ERR(0, 767, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_86__floordiv__(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self), ((PyObject *)__pyx_v_second));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_86__floordiv__(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, PyObject *__pyx_v_second) {
  struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_res = 0;
  struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_secondTensor = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  int __pyx_t_5;
  long __pyx_t_6;
  __Pyx_RefNannySetupContext("__floordiv__", 0);

  /* "PyTorch.pyx":768
 * 
 *     def __floordiv__(_LongTensor self, second):
 *         cdef _LongTensor res = _LongTensor.new()             # <<<<<<<<<<<<<<
 *         cdef _LongTensor secondTensor
 *         if isinstance(second, numbers.Number):
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7PyTorch__LongTensor), __pyx_n_s_new); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 768, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 768, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 768, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_7PyTorch__LongTensor))))) __PYX_ERR(0, 768, __pyx_L1_error)
  __pyx_v_res = ((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":770
 *         cdef _LongTensor res = _LongTensor.new()
 *         cdef _LongTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THLongTensor_div(res.native, self.native, second)
 *         else:
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_numbers); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 770, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_Number); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 770, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_4 = PyObject_IsInstance(__pyx_v_second, __pyx_t_2); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 770, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = (__pyx_t_4 != 0);
  if (__pyx_t_5) {

    /* "PyTorch.pyx":771
 *         cdef _LongTensor secondTensor
 *         if isinstance(second, numbers.Number):
 *             THLongTensor_div(res.native, self.native, second)             # <<<<<<<<<<<<<<
 *         else:
 *             secondTensor = second
 */
    __pyx_t_6 = __Pyx_PyInt_As_long(__pyx_v_second); if (unlikely((__pyx_t_6 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 771, __pyx_L1_error)
    THLongTensor_div(__pyx_v_res->native, __pyx_v_self->native, __pyx_t_6);

    /* "PyTorch.pyx":770
 *         cdef _LongTensor res = _LongTensor.new()
 *         cdef _LongTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THLongTensor_div(res.native, self.native, second)
 *         else:
 */
    goto __pyx_L3;
  }

  /* "PyTorch.pyx":773
 *             THLongTensor_div(res.native, self.native, second)
 *         else:
 *             secondTensor = second             # <<<<<<<<<<<<<<
 *             THLongTensor_cdiv(res.native, self.native, secondTensor.native)
 *         return res
 */
  /*else*/ {
    if (!(likely(((__pyx_v_second) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_second, __pyx_ptype_7PyTorch__LongTensor))))) __PYX_ERR(0, 773, __pyx_L1_error)
    __pyx_t_2 = __pyx_v_second;
    __Pyx_INCREF(__pyx_t_2);
    __pyx_v_secondTensor = ((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_t_2);
    __pyx_t_2 = 0;

    /* "PyTorch.pyx":774
 *         else:
 *             secondTensor = second
 *             THLongTensor_cdiv(res.native, self.native, secondTensor.native)             # <<<<<<<<<<<<<<
 *         return res
 * 
 */
    THLongTensor_cdiv(__pyx_v_res->native, __pyx_v_self->native, __pyx_v_secondTensor->native);
  }
  __pyx_L3:;

  /* "PyTorch.pyx":775
 *             secondTensor = second
 *             THLongTensor_cdiv(res.native, self.native, secondTensor.native)
 *         return res             # <<<<<<<<<<<<<<
 * 
 *     def __ifloordiv__(_LongTensor self, second):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = ((PyObject *)__pyx_v_res);
  goto __pyx_L0;

  /* "PyTorch.pyx":767
 * 
 * 
 *     def __floordiv__(_LongTensor self, second):             # <<<<<<<<<<<<<<
 *         cdef _LongTensor res = _LongTensor.new()
 *         cdef _LongTensor secondTensor
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("PyTorch._LongTensor.__floordiv__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XDECREF((PyObject *)__pyx_v_secondTensor);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":777
 *         return res
 * 
 *     def __ifloordiv__(_LongTensor self, second):             # <<<<<<<<<<<<<<
 *         cdef _LongTensor secondTensor
 *         if isinstance(second, numbers.Number):
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_89__ifloordiv__(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_89__ifloordiv__(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__ifloordiv__ (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_88__ifloordiv__(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self), ((PyObject *)__pyx_v_second));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_88__ifloordiv__(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, PyObject *__pyx_v_second) {
  struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_secondTensor = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  int __pyx_t_4;
  long __pyx_t_5;
  __Pyx_RefNannySetupContext("__ifloordiv__", 0);

  /* "PyTorch.pyx":779
 *     def __ifloordiv__(_LongTensor self, second):
 *         cdef _LongTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THLongTensor_div(self.native, self.native, second)
 *         else:
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_numbers); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 779, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_Number); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 779, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = PyObject_IsInstance(__pyx_v_second, __pyx_t_2); if (unlikely(__pyx_t_3 == -1)) __PYX_ERR(0, 779, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_4 = (__pyx_t_3 != 0);
  if (__pyx_t_4) {

    /* "PyTorch.pyx":780
 *         cdef _LongTensor secondTensor
 *         if isinstance(second, numbers.Number):
 *             THLongTensor_div(self.native, self.native, second)             # <<<<<<<<<<<<<<
 *         else:
 *             secondTensor = second
 */
    __pyx_t_5 = __Pyx_PyInt_As_long(__pyx_v_second); if (unlikely((__pyx_t_5 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 780, __pyx_L1_error)
    THLongTensor_div(__pyx_v_self->native, __pyx_v_self->native, __pyx_t_5);

    /* "PyTorch.pyx":779
 *     def __ifloordiv__(_LongTensor self, second):
 *         cdef _LongTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THLongTensor_div(self.native, self.native, second)
 *         else:
 */
    goto __pyx_L3;
  }

  /* "PyTorch.pyx":782
 *             THLongTensor_div(self.native, self.native, second)
 *         else:
 *             secondTensor = second             # <<<<<<<<<<<<<<
 *             THLongTensor_cdiv(self.native, self.native, secondTensor.native)
 *         return self
 */
  /*else*/ {
    if (!(likely(((__pyx_v_second) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_second, __pyx_ptype_7PyTorch__LongTensor))))) __PYX_ERR(0, 782, __pyx_L1_error)
    __pyx_t_2 = __pyx_v_second;
    __Pyx_INCREF(__pyx_t_2);
    __pyx_v_secondTensor = ((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_t_2);
    __pyx_t_2 = 0;

    /* "PyTorch.pyx":783
 *         else:
 *             secondTensor = second
 *             THLongTensor_cdiv(self.native, self.native, secondTensor.native)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
    THLongTensor_cdiv(__pyx_v_self->native, __pyx_v_self->native, __pyx_v_secondTensor->native);
  }
  __pyx_L3:;

  /* "PyTorch.pyx":784
 *             secondTensor = second
 *             THLongTensor_cdiv(self.native, self.native, secondTensor.native)
 *         return self             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":777
 *         return res
 * 
 *     def __ifloordiv__(_LongTensor self, second):             # <<<<<<<<<<<<<<
 *         cdef _LongTensor secondTensor
 *         if isinstance(second, numbers.Number):
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("PyTorch._LongTensor.__ifloordiv__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_secondTensor);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":787
 * 
 * 
 *     def __iadd__(_LongTensor self, second):             # <<<<<<<<<<<<<<
 *         cdef _LongTensor secondTensor
 *         if isinstance(second, numbers.Number):
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_91__iadd__(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_91__iadd__(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__iadd__ (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_90__iadd__(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self), ((PyObject *)__pyx_v_second));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_90__iadd__(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, PyObject *__pyx_v_second) {
  struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_secondTensor = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  int __pyx_t_4;
  long __pyx_t_5;
  __Pyx_RefNannySetupContext("__iadd__", 0);

  /* "PyTorch.pyx":789
 *     def __iadd__(_LongTensor self, second):
 *         cdef _LongTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THLongTensor_add(self.native, self.native, second)
 *         else:
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_numbers); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 789, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_Number); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 789, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = PyObject_IsInstance(__pyx_v_second, __pyx_t_2); if (unlikely(__pyx_t_3 == -1)) __PYX_ERR(0, 789, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_4 = (__pyx_t_3 != 0);
  if (__pyx_t_4) {

    /* "PyTorch.pyx":790
 *         cdef _LongTensor secondTensor
 *         if isinstance(second, numbers.Number):
 *             THLongTensor_add(self.native, self.native, second)             # <<<<<<<<<<<<<<
 *         else:
 *             secondTensor = second
 */
    __pyx_t_5 = __Pyx_PyInt_As_long(__pyx_v_second); if (unlikely((__pyx_t_5 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 790, __pyx_L1_error)
    THLongTensor_add(__pyx_v_self->native, __pyx_v_self->native, __pyx_t_5);

    /* "PyTorch.pyx":789
 *     def __iadd__(_LongTensor self, second):
 *         cdef _LongTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THLongTensor_add(self.native, self.native, second)
 *         else:
 */
    goto __pyx_L3;
  }

  /* "PyTorch.pyx":792
 *             THLongTensor_add(self.native, self.native, second)
 *         else:
 *             secondTensor = second             # <<<<<<<<<<<<<<
 *             THLongTensor_cadd(self.native, self.native, 1, secondTensor.native)
 *         return self
 */
  /*else*/ {
    if (!(likely(((__pyx_v_second) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_second, __pyx_ptype_7PyTorch__LongTensor))))) __PYX_ERR(0, 792, __pyx_L1_error)
    __pyx_t_2 = __pyx_v_second;
    __Pyx_INCREF(__pyx_t_2);
    __pyx_v_secondTensor = ((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_t_2);
    __pyx_t_2 = 0;

    /* "PyTorch.pyx":793
 *         else:
 *             secondTensor = second
 *             THLongTensor_cadd(self.native, self.native, 1, secondTensor.native)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
    THLongTensor_cadd(__pyx_v_self->native, __pyx_v_self->native, 1, __pyx_v_secondTensor->native);
  }
  __pyx_L3:;

  /* "PyTorch.pyx":794
 *             secondTensor = second
 *             THLongTensor_cadd(self.native, self.native, 1, secondTensor.native)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def __isub__(_LongTensor self, second):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":787
 * 
 * 
 *     def __iadd__(_LongTensor self, second):             # <<<<<<<<<<<<<<
 *         cdef _LongTensor secondTensor
 *         if isinstance(second, numbers.Number):
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("PyTorch._LongTensor.__iadd__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_secondTensor);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":796
 *         return self
 * 
 *     def __isub__(_LongTensor self, second):             # <<<<<<<<<<<<<<
 *         cdef _LongTensor secondTensor
 *         if isinstance(second, numbers.Number):
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_93__isub__(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_93__isub__(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__isub__ (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_92__isub__(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self), ((PyObject *)__pyx_v_second));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_92__isub__(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, PyObject *__pyx_v_second) {
  struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_secondTensor = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  int __pyx_t_4;
  long __pyx_t_5;
  __Pyx_RefNannySetupContext("__isub__", 0);

  /* "PyTorch.pyx":798
 *     def __isub__(_LongTensor self, second):
 *         cdef _LongTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THLongTensor_add(self.native, self.native, -second)
 *         else:
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_numbers); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 798, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_Number); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 798, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = PyObject_IsInstance(__pyx_v_second, __pyx_t_2); if (unlikely(__pyx_t_3 == -1)) __PYX_ERR(0, 798, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_4 = (__pyx_t_3 != 0);
  if (__pyx_t_4) {

    /* "PyTorch.pyx":799
 *         cdef _LongTensor secondTensor
 *         if isinstance(second, numbers.Number):
 *             THLongTensor_add(self.native, self.native, -second)             # <<<<<<<<<<<<<<
 *         else:
 *             secondTensor = second
 */
    __pyx_t_2 = PyNumber_Negative(__pyx_v_second); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 799, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_5 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_5 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 799, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    THLongTensor_add(__pyx_v_self->native, __pyx_v_self->native, __pyx_t_5);

    /* "PyTorch.pyx":798
 *     def __isub__(_LongTensor self, second):
 *         cdef _LongTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THLongTensor_add(self.native, self.native, -second)
 *         else:
 */
    goto __pyx_L3;
  }

  /* "PyTorch.pyx":801
 *             THLongTensor_add(self.native, self.native, -second)
 *         else:
 *             secondTensor = second             # <<<<<<<<<<<<<<
 *             THLongTensor_cadd(self.native, self.native, -1, secondTensor.native)
 *         return self
 */
  /*else*/ {
    if (!(likely(((__pyx_v_second) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_second, __pyx_ptype_7PyTorch__LongTensor))))) __PYX_ERR(0, 801, __pyx_L1_error)
    __pyx_t_2 = __pyx_v_second;
    __Pyx_INCREF(__pyx_t_2);
    __pyx_v_secondTensor = ((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_t_2);
    __pyx_t_2 = 0;

    /* "PyTorch.pyx":802
 *         else:
 *             secondTensor = second
 *             THLongTensor_cadd(self.native, self.native, -1, secondTensor.native)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
    THLongTensor_cadd(__pyx_v_self->native, __pyx_v_self->native, -1L, __pyx_v_secondTensor->native);
  }
  __pyx_L3:;

  /* "PyTorch.pyx":803
 *             secondTensor = second
 *             THLongTensor_cadd(self.native, self.native, -1, secondTensor.native)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def __imul__(_LongTensor self, long value):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":796
 *         return self
 * 
 *     def __isub__(_LongTensor self, second):             # <<<<<<<<<<<<<<
 *         cdef _LongTensor secondTensor
 *         if isinstance(second, numbers.Number):
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("PyTorch._LongTensor.__isub__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_secondTensor);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":805
 *         return self
 * 
 *     def __imul__(_LongTensor self, long value):             # <<<<<<<<<<<<<<
 *         THLongTensor_mul(self.native, self.native, value)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_95__imul__(PyObject *__pyx_v_self, PyObject *__pyx_arg_value); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_95__imul__(PyObject *__pyx_v_self, PyObject *__pyx_arg_value) {
  long __pyx_v_value;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__imul__ (wrapper)", 0);
  assert(__pyx_arg_value); {
    __pyx_v_value = __Pyx_PyInt_As_long(__pyx_arg_value); if (unlikely((__pyx_v_value == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 805, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._LongTensor.__imul__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_94__imul__(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self), ((long)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_94__imul__(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, long __pyx_v_value) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__imul__", 0);

  /* "PyTorch.pyx":806
 * 
 *     def __imul__(_LongTensor self, long value):
 *         THLongTensor_mul(self.native, self.native, value)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THLongTensor_mul(__pyx_v_self->native, __pyx_v_self->native, __pyx_v_value);

  /* "PyTorch.pyx":807
 *     def __imul__(_LongTensor self, long value):
 *         THLongTensor_mul(self.native, self.native, value)
 *         return self             # <<<<<<<<<<<<<<
 * 
 * #    def __mul__(_LongTensor self, _LongTensor M2):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":805
 *         return self
 * 
 *     def __imul__(_LongTensor self, long value):             # <<<<<<<<<<<<<<
 *         THLongTensor_mul(self.native, self.native, value)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":810
 * 
 * #    def __mul__(_LongTensor self, _LongTensor M2):
 *     def __mul__(_LongTensor self, second):             # <<<<<<<<<<<<<<
 *         cdef _LongTensor M2
 *         cdef _LongTensor T
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_97__mul__(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_97__mul__(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__mul__ (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_self), __pyx_ptype_7PyTorch__LongTensor, 1, "self", 0))) __PYX_ERR(0, 810, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_96__mul__(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self), ((PyObject *)__pyx_v_second));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_96__mul__(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, PyObject *__pyx_v_second) {
  struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_res = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  int __pyx_t_5;
  long __pyx_t_6;
  __Pyx_RefNannySetupContext("__mul__", 0);

  /* "PyTorch.pyx":817
 *         cdef int resCols
 * 
 *         res = _LongTensor.new()             # <<<<<<<<<<<<<<
 *         if isinstance(second, numbers.Number):
 *             THLongTensor_mul(res.native, self.native, second)
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7PyTorch__LongTensor), __pyx_n_s_new); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 817, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 817, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 817, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_7PyTorch__LongTensor))))) __PYX_ERR(0, 817, __pyx_L1_error)
  __pyx_v_res = ((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":818
 * 
 *         res = _LongTensor.new()
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THLongTensor_mul(res.native, self.native, second)
 *             return res
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_numbers); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 818, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_Number); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 818, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_4 = PyObject_IsInstance(__pyx_v_second, __pyx_t_2); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 818, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = (__pyx_t_4 != 0);
  if (__pyx_t_5) {

    /* "PyTorch.pyx":819
 *         res = _LongTensor.new()
 *         if isinstance(second, numbers.Number):
 *             THLongTensor_mul(res.native, self.native, second)             # <<<<<<<<<<<<<<
 *             return res
 *         else:
 */
    __pyx_t_6 = __Pyx_PyInt_As_long(__pyx_v_second); if (unlikely((__pyx_t_6 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 819, __pyx_L1_error)
    THLongTensor_mul(__pyx_v_res->native, __pyx_v_self->native, __pyx_t_6);

    /* "PyTorch.pyx":820
 *         if isinstance(second, numbers.Number):
 *             THLongTensor_mul(res.native, self.native, second)
 *             return res             # <<<<<<<<<<<<<<
 *         else:
 * 
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(((PyObject *)__pyx_v_res));
    __pyx_r = ((PyObject *)__pyx_v_res);
    goto __pyx_L0;

    /* "PyTorch.pyx":818
 * 
 *         res = _LongTensor.new()
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THLongTensor_mul(res.native, self.native, second)
 *             return res
 */
  }

  /* "PyTorch.pyx":823
 *         else:
 * 
 *             raise Exception('Invalid arg type for second: ' + str(type(second)))             # <<<<<<<<<<<<<<
 * 
 * 
 */
  /*else*/ {
    __pyx_t_2 = PyTuple_New(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 823, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_INCREF(((PyObject *)Py_TYPE(__pyx_v_second)));
    __Pyx_GIVEREF(((PyObject *)Py_TYPE(__pyx_v_second)));
    PyTuple_SET_ITEM(__pyx_t_2, 0, ((PyObject *)Py_TYPE(__pyx_v_second)));
    __pyx_t_1 = __Pyx_PyObject_Call(((PyObject *)(&PyString_Type)), __pyx_t_2, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 823, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = PyNumber_Add(__pyx_kp_s_Invalid_arg_type_for_second, __pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 823, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 823, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_GIVEREF(__pyx_t_2);
    PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_2);
    __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_t_1, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 823, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(0, 823, __pyx_L1_error)
  }

  /* "PyTorch.pyx":810
 * 
 * #    def __mul__(_LongTensor self, _LongTensor M2):
 *     def __mul__(_LongTensor self, second):             # <<<<<<<<<<<<<<
 *         cdef _LongTensor M2
 *         cdef _LongTensor T
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("PyTorch._LongTensor.__mul__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":828
 *     # ========== random ===============================
 * 
 *     def bernoulli(_LongTensor self, float p=0.5):             # <<<<<<<<<<<<<<
 *         THLongTensor_bernoulli(self.native, globalState.generator, p)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_99bernoulli(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_99bernoulli(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  float __pyx_v_p;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("bernoulli (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_p,0};
    PyObject* values[1] = {0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_p);
          if (value) { values[0] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "bernoulli") < 0)) __PYX_ERR(0, 828, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    if (values[0]) {
      __pyx_v_p = __pyx_PyFloat_AsFloat(values[0]); if (unlikely((__pyx_v_p == (float)-1) && PyErr_Occurred())) __PYX_ERR(0, 828, __pyx_L3_error)
    } else {
      __pyx_v_p = ((float)0.5);
    }
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("bernoulli", 0, 0, 1, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 828, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._LongTensor.bernoulli", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_98bernoulli(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self), __pyx_v_p);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_98bernoulli(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, float __pyx_v_p) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("bernoulli", 0);

  /* "PyTorch.pyx":829
 * 
 *     def bernoulli(_LongTensor self, float p=0.5):
 *         THLongTensor_bernoulli(self.native, globalState.generator, p)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THLongTensor_bernoulli(__pyx_v_self->native, __pyx_v_7PyTorch_globalState->generator, __pyx_v_p);

  /* "PyTorch.pyx":830
 *     def bernoulli(_LongTensor self, float p=0.5):
 *         THLongTensor_bernoulli(self.native, globalState.generator, p)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def geometric(_LongTensor self, float p=0.5):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":828
 *     # ========== random ===============================
 * 
 *     def bernoulli(_LongTensor self, float p=0.5):             # <<<<<<<<<<<<<<
 *         THLongTensor_bernoulli(self.native, globalState.generator, p)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":832
 *         return self
 * 
 *     def geometric(_LongTensor self, float p=0.5):             # <<<<<<<<<<<<<<
 *         THLongTensor_geometric(self.native, globalState.generator, p)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_101geometric(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_LongTensor_101geometric(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  float __pyx_v_p;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("geometric (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_p,0};
    PyObject* values[1] = {0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_p);
          if (value) { values[0] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "geometric") < 0)) __PYX_ERR(0, 832, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    if (values[0]) {
      __pyx_v_p = __pyx_PyFloat_AsFloat(values[0]); if (unlikely((__pyx_v_p == (float)-1) && PyErr_Occurred())) __PYX_ERR(0, 832, __pyx_L3_error)
    } else {
      __pyx_v_p = ((float)0.5);
    }
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("geometric", 0, 0, 1, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 832, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._LongTensor.geometric", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_11_LongTensor_100geometric(((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_v_self), __pyx_v_p);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_LongTensor_100geometric(struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_self, float __pyx_v_p) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("geometric", 0);

  /* "PyTorch.pyx":833
 * 
 *     def geometric(_LongTensor self, float p=0.5):
 *         THLongTensor_geometric(self.native, globalState.generator, p)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THLongTensor_geometric(__pyx_v_self->native, __pyx_v_7PyTorch_globalState->generator, __pyx_v_p);

  /* "PyTorch.pyx":834
 *     def geometric(_LongTensor self, float p=0.5):
 *         THLongTensor_geometric(self.native, globalState.generator, p)
 *         return self             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":832
 *         return self
 * 
 *     def geometric(_LongTensor self, float p=0.5):             # <<<<<<<<<<<<<<
 *         THLongTensor_geometric(self.native, globalState.generator, p)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":839
 * 
 * #    @staticmethod
 * cdef _LongTensor_fromNative(THLongTensor *tensorC, retain=True):             # <<<<<<<<<<<<<<
 *     if retain:
 *         THLongTensor_retain(tensorC)
 */

static PyObject *__pyx_f_7PyTorch__LongTensor_fromNative(struct THLongTensor *__pyx_v_tensorC, struct __pyx_opt_args_7PyTorch__LongTensor_fromNative *__pyx_optional_args) {
  PyObject *__pyx_v_retain = ((PyObject *)Py_True);
  struct __pyx_obj_7PyTorch__LongTensor *__pyx_v_tensor = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("_LongTensor_fromNative", 0);
  if (__pyx_optional_args) {
    if (__pyx_optional_args->__pyx_n > 0) {
      __pyx_v_retain = __pyx_optional_args->retain;
    }
  }

  /* "PyTorch.pyx":840
 * #    @staticmethod
 * cdef _LongTensor_fromNative(THLongTensor *tensorC, retain=True):
 *     if retain:             # <<<<<<<<<<<<<<
 *         THLongTensor_retain(tensorC)
 *     tensor = _LongTensor(_allocate=False)
 */
  __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_v_retain); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(0, 840, __pyx_L1_error)
  if (__pyx_t_1) {

    /* "PyTorch.pyx":841
 * cdef _LongTensor_fromNative(THLongTensor *tensorC, retain=True):
 *     if retain:
 *         THLongTensor_retain(tensorC)             # <<<<<<<<<<<<<<
 *     tensor = _LongTensor(_allocate=False)
 *     tensor.native = tensorC
 */
    THLongTensor_retain(__pyx_v_tensorC);

    /* "PyTorch.pyx":840
 * #    @staticmethod
 * cdef _LongTensor_fromNative(THLongTensor *tensorC, retain=True):
 *     if retain:             # <<<<<<<<<<<<<<
 *         THLongTensor_retain(tensorC)
 *     tensor = _LongTensor(_allocate=False)
 */
  }

  /* "PyTorch.pyx":842
 *     if retain:
 *         THLongTensor_retain(tensorC)
 *     tensor = _LongTensor(_allocate=False)             # <<<<<<<<<<<<<<
 *     tensor.native = tensorC
 *     return tensor
 */
  __pyx_t_2 = PyDict_New(); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 842, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_t_2, __pyx_n_s_allocate, Py_False) < 0) __PYX_ERR(0, 842, __pyx_L1_error)
  __pyx_t_3 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_7PyTorch__LongTensor), __pyx_empty_tuple, __pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 842, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_tensor = ((struct __pyx_obj_7PyTorch__LongTensor *)__pyx_t_3);
  __pyx_t_3 = 0;

  /* "PyTorch.pyx":843
 *         THLongTensor_retain(tensorC)
 *     tensor = _LongTensor(_allocate=False)
 *     tensor.native = tensorC             # <<<<<<<<<<<<<<
 *     return tensor
 * 
 */
  __pyx_v_tensor->native = __pyx_v_tensorC;

  /* "PyTorch.pyx":844
 *     tensor = _LongTensor(_allocate=False)
 *     tensor.native = tensorC
 *     return tensor             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_tensor));
  __pyx_r = ((PyObject *)__pyx_v_tensor);
  goto __pyx_L0;

  /* "PyTorch.pyx":839
 * 
 * #    @staticmethod
 * cdef _LongTensor_fromNative(THLongTensor *tensorC, retain=True):             # <<<<<<<<<<<<<<
 *     if retain:
 *         THLongTensor_retain(tensorC)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("PyTorch._LongTensor_fromNative", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_tensor);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":857
 * #        self.thFloatTensor = tensorC
 * 
 *     def __cinit__(self, *args, _allocate=True):             # <<<<<<<<<<<<<<
 * #        cdef _FloatTensor childobject
 *         cdef THFloatTensor *newTensorC
 */

/* Python wrapper */
static int __pyx_pw_7PyTorch_12_FloatTensor_1__cinit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static int __pyx_pw_7PyTorch_12_FloatTensor_1__cinit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v__allocate = 0;
  PyObject *__pyx_v_args = 0;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__cinit__ (wrapper)", 0);
  if (PyTuple_GET_SIZE(__pyx_args) > 0) {
    __pyx_v_args = PyTuple_GetSlice(__pyx_args, 0, PyTuple_GET_SIZE(__pyx_args));
    if (unlikely(!__pyx_v_args)) {
      __Pyx_RefNannyFinishContext();
      return -1;
    }
    __Pyx_GOTREF(__pyx_v_args);
  } else {
    __pyx_v_args = __pyx_empty_tuple; __Pyx_INCREF(__pyx_empty_tuple);
  }
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_allocate,0};
    PyObject* values[1] = {0};
    values[0] = ((PyObject *)Py_True);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        default:
        case  0: break;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      if (kw_args == 1) {
        const Py_ssize_t index = 0;
        PyObject* value = PyDict_GetItem(__pyx_kwds, *__pyx_pyargnames[index]);
        if (value) { values[index] = value; kw_args--; }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, 0, "__cinit__") < 0)) __PYX_ERR(0, 857, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) < 0) {
      goto __pyx_L5_argtuple_error;
    } else {
    }
    __pyx_v__allocate = values[0];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__cinit__", 0, 0, 0, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 857, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_DECREF(__pyx_v_args); __pyx_v_args = 0;
  __Pyx_AddTraceback("PyTorch._FloatTensor.__cinit__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return -1;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor___cinit__(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self), __pyx_v__allocate, __pyx_v_args);

  /* function exit code */
  __Pyx_XDECREF(__pyx_v_args);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_7PyTorch_12_FloatTensor___cinit__(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, PyObject *__pyx_v__allocate, PyObject *__pyx_v_args) {
  struct THFloatTensor *__pyx_v_newTensorC;
  struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_templateObject = 0;
  PyObject *__pyx_v_arg = NULL;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  Py_ssize_t __pyx_t_4;
  int __pyx_t_5;
  int __pyx_t_6;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  long __pyx_t_10;
  long __pyx_t_11;
  long __pyx_t_12;
  long __pyx_t_13;
  __Pyx_RefNannySetupContext("__cinit__", 0);

  /* "PyTorch.pyx":861
 *         cdef THFloatTensor *newTensorC
 *         cdef _FloatTensor templateObject
 *         logger.debug('FloatTensor.__cinit__')             # <<<<<<<<<<<<<<
 * #        cdef THFloatStorage *storageC
 * #        cdef long addr
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_logger); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 861, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_debug); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 861, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_tuple__16, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 861, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "PyTorch.pyx":866
 * #        if len(kwargs) > 0:
 * #            raise Exception('cannot provide arguments to initializer')
 *         if _allocate:             # <<<<<<<<<<<<<<
 *             if len(args) == 1 and isinstance(args[0], _LongStorage):  # it's a size tensor
 *                self.native = THFloatTensor_new()
 */
  __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_v__allocate); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 866, __pyx_L1_error)
  if (__pyx_t_3) {

    /* "PyTorch.pyx":867
 * #            raise Exception('cannot provide arguments to initializer')
 *         if _allocate:
 *             if len(args) == 1 and isinstance(args[0], _LongStorage):  # it's a size tensor             # <<<<<<<<<<<<<<
 *                self.native = THFloatTensor_new()
 *                self.resize(args[0])
 */
    __pyx_t_4 = PyTuple_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 867, __pyx_L1_error)
    __pyx_t_5 = ((__pyx_t_4 == 1) != 0);
    if (__pyx_t_5) {
    } else {
      __pyx_t_3 = __pyx_t_5;
      goto __pyx_L5_bool_binop_done;
    }
    __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 867, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_LongStorage); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 867, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_5 = PyObject_IsInstance(__pyx_t_1, __pyx_t_2); if (unlikely(__pyx_t_5 == -1)) __PYX_ERR(0, 867, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_6 = (__pyx_t_5 != 0);
    __pyx_t_3 = __pyx_t_6;
    __pyx_L5_bool_binop_done:;
    if (__pyx_t_3) {

      /* "PyTorch.pyx":868
 *         if _allocate:
 *             if len(args) == 1 and isinstance(args[0], _LongStorage):  # it's a size tensor
 *                self.native = THFloatTensor_new()             # <<<<<<<<<<<<<<
 *                self.resize(args[0])
 *                return
 */
      __pyx_v_self->native = THFloatTensor_new();

      /* "PyTorch.pyx":869
 *             if len(args) == 1 and isinstance(args[0], _LongStorage):  # it's a size tensor
 *                self.native = THFloatTensor_new()
 *                self.resize(args[0])             # <<<<<<<<<<<<<<
 *                return
 *             if len(args) == 1 and isinstance(args[0], _FloatTensor):
 */
      __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_resize); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 869, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_7 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 869, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __pyx_t_8 = NULL;
      if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_1))) {
        __pyx_t_8 = PyMethod_GET_SELF(__pyx_t_1);
        if (likely(__pyx_t_8)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
          __Pyx_INCREF(__pyx_t_8);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_1, function);
        }
      }
      if (!__pyx_t_8) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_t_7); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 869, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        __Pyx_GOTREF(__pyx_t_2);
      } else {
        #if CYTHON_FAST_PYCALL
        if (PyFunction_Check(__pyx_t_1)) {
          PyObject *__pyx_temp[2] = {__pyx_t_8, __pyx_t_7};
          __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_1, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 869, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        } else
        #endif
        #if CYTHON_FAST_PYCCALL
        if (__Pyx_PyFastCFunction_Check(__pyx_t_1)) {
          PyObject *__pyx_temp[2] = {__pyx_t_8, __pyx_t_7};
          __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_1, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 869, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        } else
        #endif
        {
          __pyx_t_9 = PyTuple_New(1+1); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 869, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_9);
          __Pyx_GIVEREF(__pyx_t_8); PyTuple_SET_ITEM(__pyx_t_9, 0, __pyx_t_8); __pyx_t_8 = NULL;
          __Pyx_GIVEREF(__pyx_t_7);
          PyTuple_SET_ITEM(__pyx_t_9, 0+1, __pyx_t_7);
          __pyx_t_7 = 0;
          __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_9, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 869, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
        }
      }
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

      /* "PyTorch.pyx":870
 *                self.native = THFloatTensor_new()
 *                self.resize(args[0])
 *                return             # <<<<<<<<<<<<<<
 *             if len(args) == 1 and isinstance(args[0], _FloatTensor):
 *                templateObject = args[0]
 */
      __pyx_r = 0;
      goto __pyx_L0;

      /* "PyTorch.pyx":867
 * #            raise Exception('cannot provide arguments to initializer')
 *         if _allocate:
 *             if len(args) == 1 and isinstance(args[0], _LongStorage):  # it's a size tensor             # <<<<<<<<<<<<<<
 *                self.native = THFloatTensor_new()
 *                self.resize(args[0])
 */
    }

    /* "PyTorch.pyx":871
 *                self.resize(args[0])
 *                return
 *             if len(args) == 1 and isinstance(args[0], _FloatTensor):             # <<<<<<<<<<<<<<
 *                templateObject = args[0]
 *                newTensorC = THFloatTensor_newClone(templateObject.native)
 */
    __pyx_t_4 = PyTuple_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 871, __pyx_L1_error)
    __pyx_t_6 = ((__pyx_t_4 == 1) != 0);
    if (__pyx_t_6) {
    } else {
      __pyx_t_3 = __pyx_t_6;
      goto __pyx_L8_bool_binop_done;
    }
    __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 871, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_6 = __Pyx_TypeCheck(__pyx_t_2, __pyx_ptype_7PyTorch__FloatTensor); 
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_5 = (__pyx_t_6 != 0);
    __pyx_t_3 = __pyx_t_5;
    __pyx_L8_bool_binop_done:;
    if (__pyx_t_3) {

      /* "PyTorch.pyx":872
 *                return
 *             if len(args) == 1 and isinstance(args[0], _FloatTensor):
 *                templateObject = args[0]             # <<<<<<<<<<<<<<
 *                newTensorC = THFloatTensor_newClone(templateObject.native)
 *                self.native = newTensorC
 */
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 872, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      if (!(likely(((__pyx_t_2) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_2, __pyx_ptype_7PyTorch__FloatTensor))))) __PYX_ERR(0, 872, __pyx_L1_error)
      __pyx_v_templateObject = ((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_t_2);
      __pyx_t_2 = 0;

      /* "PyTorch.pyx":873
 *             if len(args) == 1 and isinstance(args[0], _FloatTensor):
 *                templateObject = args[0]
 *                newTensorC = THFloatTensor_newClone(templateObject.native)             # <<<<<<<<<<<<<<
 *                self.native = newTensorC
 *                return
 */
      __pyx_v_newTensorC = THFloatTensor_newClone(__pyx_v_templateObject->native);

      /* "PyTorch.pyx":874
 *                templateObject = args[0]
 *                newTensorC = THFloatTensor_newClone(templateObject.native)
 *                self.native = newTensorC             # <<<<<<<<<<<<<<
 *                return
 *             for arg in args:
 */
      __pyx_v_self->native = __pyx_v_newTensorC;

      /* "PyTorch.pyx":875
 *                newTensorC = THFloatTensor_newClone(templateObject.native)
 *                self.native = newTensorC
 *                return             # <<<<<<<<<<<<<<
 *             for arg in args:
 *                 if not isinstance(arg, int):
 */
      __pyx_r = 0;
      goto __pyx_L0;

      /* "PyTorch.pyx":871
 *                self.resize(args[0])
 *                return
 *             if len(args) == 1 and isinstance(args[0], _FloatTensor):             # <<<<<<<<<<<<<<
 *                templateObject = args[0]
 *                newTensorC = THFloatTensor_newClone(templateObject.native)
 */
    }

    /* "PyTorch.pyx":876
 *                self.native = newTensorC
 *                return
 *             for arg in args:             # <<<<<<<<<<<<<<
 *                 if not isinstance(arg, int):
 *                     raise Exception('cannot provide arguments to initializer')
 */
    __pyx_t_2 = __pyx_v_args; __Pyx_INCREF(__pyx_t_2); __pyx_t_4 = 0;
    for (;;) {
      if (__pyx_t_4 >= PyTuple_GET_SIZE(__pyx_t_2)) break;
      #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
      __pyx_t_1 = PyTuple_GET_ITEM(__pyx_t_2, __pyx_t_4); __Pyx_INCREF(__pyx_t_1); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 876, __pyx_L1_error)
      #else
      __pyx_t_1 = PySequence_ITEM(__pyx_t_2, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 876, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      #endif
      __Pyx_XDECREF_SET(__pyx_v_arg, __pyx_t_1);
      __pyx_t_1 = 0;

      /* "PyTorch.pyx":877
 *                return
 *             for arg in args:
 *                 if not isinstance(arg, int):             # <<<<<<<<<<<<<<
 *                     raise Exception('cannot provide arguments to initializer')
 *             if len(args) == 0:
 */
      __pyx_t_3 = PyInt_Check(__pyx_v_arg); 
      __pyx_t_5 = ((!(__pyx_t_3 != 0)) != 0);
      if (__pyx_t_5) {

        /* "PyTorch.pyx":878
 *             for arg in args:
 *                 if not isinstance(arg, int):
 *                     raise Exception('cannot provide arguments to initializer')             # <<<<<<<<<<<<<<
 *             if len(args) == 0:
 *                 # print('no args, calling THFloatTensor_new()')
 */
        __pyx_t_1 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_tuple__17, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 878, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_Raise(__pyx_t_1, 0, 0, 0);
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        __PYX_ERR(0, 878, __pyx_L1_error)

        /* "PyTorch.pyx":877
 *                return
 *             for arg in args:
 *                 if not isinstance(arg, int):             # <<<<<<<<<<<<<<
 *                     raise Exception('cannot provide arguments to initializer')
 *             if len(args) == 0:
 */
      }

      /* "PyTorch.pyx":876
 *                self.native = newTensorC
 *                return
 *             for arg in args:             # <<<<<<<<<<<<<<
 *                 if not isinstance(arg, int):
 *                     raise Exception('cannot provide arguments to initializer')
 */
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

    /* "PyTorch.pyx":879
 *                 if not isinstance(arg, int):
 *                     raise Exception('cannot provide arguments to initializer')
 *             if len(args) == 0:             # <<<<<<<<<<<<<<
 *                 # print('no args, calling THFloatTensor_new()')
 *                 self.native = THFloatTensor_new()
 */
    __pyx_t_4 = PyTuple_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 879, __pyx_L1_error)
    __pyx_t_5 = ((__pyx_t_4 == 0) != 0);
    if (__pyx_t_5) {

      /* "PyTorch.pyx":881
 *             if len(args) == 0:
 *                 # print('no args, calling THFloatTensor_new()')
 *                 self.native = THFloatTensor_new()             # <<<<<<<<<<<<<<
 *             elif len(args) == 1:
 *                 # print('new tensor 1d length', args[0])
 */
      __pyx_v_self->native = THFloatTensor_new();

      /* "PyTorch.pyx":879
 *                 if not isinstance(arg, int):
 *                     raise Exception('cannot provide arguments to initializer')
 *             if len(args) == 0:             # <<<<<<<<<<<<<<
 *                 # print('no args, calling THFloatTensor_new()')
 *                 self.native = THFloatTensor_new()
 */
      goto __pyx_L13;
    }

    /* "PyTorch.pyx":882
 *                 # print('no args, calling THFloatTensor_new()')
 *                 self.native = THFloatTensor_new()
 *             elif len(args) == 1:             # <<<<<<<<<<<<<<
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THFloatTensor_newWithSize1d(args[0])
 */
    __pyx_t_4 = PyTuple_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 882, __pyx_L1_error)
    __pyx_t_5 = ((__pyx_t_4 == 1) != 0);
    if (__pyx_t_5) {

      /* "PyTorch.pyx":884
 *             elif len(args) == 1:
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THFloatTensor_newWithSize1d(args[0])             # <<<<<<<<<<<<<<
 *             elif len(args) == 2:
 *                 # print('args=2')
 */
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 884, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_10 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_10 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 884, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_v_self->native = THFloatTensor_newWithSize1d(__pyx_t_10);

      /* "PyTorch.pyx":882
 *                 # print('no args, calling THFloatTensor_new()')
 *                 self.native = THFloatTensor_new()
 *             elif len(args) == 1:             # <<<<<<<<<<<<<<
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THFloatTensor_newWithSize1d(args[0])
 */
      goto __pyx_L13;
    }

    /* "PyTorch.pyx":885
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THFloatTensor_newWithSize1d(args[0])
 *             elif len(args) == 2:             # <<<<<<<<<<<<<<
 *                 # print('args=2')
 *                 self.native = THFloatTensor_newWithSize2d(args[0], args[1])
 */
    __pyx_t_4 = PyTuple_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 885, __pyx_L1_error)
    __pyx_t_5 = ((__pyx_t_4 == 2) != 0);
    if (__pyx_t_5) {

      /* "PyTorch.pyx":887
 *             elif len(args) == 2:
 *                 # print('args=2')
 *                 self.native = THFloatTensor_newWithSize2d(args[0], args[1])             # <<<<<<<<<<<<<<
 *             elif len(args) == 3:
 *                 # print('new tensor 1d length', args[0])
 */
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 887, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_10 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_10 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 887, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 887, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_11 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_11 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 887, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_v_self->native = THFloatTensor_newWithSize2d(__pyx_t_10, __pyx_t_11);

      /* "PyTorch.pyx":885
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THFloatTensor_newWithSize1d(args[0])
 *             elif len(args) == 2:             # <<<<<<<<<<<<<<
 *                 # print('args=2')
 *                 self.native = THFloatTensor_newWithSize2d(args[0], args[1])
 */
      goto __pyx_L13;
    }

    /* "PyTorch.pyx":888
 *                 # print('args=2')
 *                 self.native = THFloatTensor_newWithSize2d(args[0], args[1])
 *             elif len(args) == 3:             # <<<<<<<<<<<<<<
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THFloatTensor_newWithSize3d(args[0], args[1], args[2])
 */
    __pyx_t_4 = PyTuple_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 888, __pyx_L1_error)
    __pyx_t_5 = ((__pyx_t_4 == 3) != 0);
    if (__pyx_t_5) {

      /* "PyTorch.pyx":890
 *             elif len(args) == 3:
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THFloatTensor_newWithSize3d(args[0], args[1], args[2])             # <<<<<<<<<<<<<<
 *             elif len(args) == 4:
 *                 # print('new tensor 1d length', args[0])
 */
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 890, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_11 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_11 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 890, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 890, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_10 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_10 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 890, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 890, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_12 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_12 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 890, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_v_self->native = THFloatTensor_newWithSize3d(__pyx_t_11, __pyx_t_10, __pyx_t_12);

      /* "PyTorch.pyx":888
 *                 # print('args=2')
 *                 self.native = THFloatTensor_newWithSize2d(args[0], args[1])
 *             elif len(args) == 3:             # <<<<<<<<<<<<<<
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THFloatTensor_newWithSize3d(args[0], args[1], args[2])
 */
      goto __pyx_L13;
    }

    /* "PyTorch.pyx":891
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THFloatTensor_newWithSize3d(args[0], args[1], args[2])
 *             elif len(args) == 4:             # <<<<<<<<<<<<<<
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THFloatTensor_newWithSize4d(args[0], args[1], args[2], args[3])
 */
    __pyx_t_4 = PyTuple_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 891, __pyx_L1_error)
    __pyx_t_5 = ((__pyx_t_4 == 4) != 0);
    if (__pyx_t_5) {

      /* "PyTorch.pyx":893
 *             elif len(args) == 4:
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THFloatTensor_newWithSize4d(args[0], args[1], args[2], args[3])             # <<<<<<<<<<<<<<
 *             else:
 *                 logger.error('Raising exception...')
 */
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 893, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_12 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_12 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 893, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 893, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_10 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_10 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 893, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 893, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_11 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_11 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 893, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 3, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 893, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_13 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_13 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 893, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_v_self->native = THFloatTensor_newWithSize4d(__pyx_t_12, __pyx_t_10, __pyx_t_11, __pyx_t_13);

      /* "PyTorch.pyx":891
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THFloatTensor_newWithSize3d(args[0], args[1], args[2])
 *             elif len(args) == 4:             # <<<<<<<<<<<<<<
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THFloatTensor_newWithSize4d(args[0], args[1], args[2], args[3])
 */
      goto __pyx_L13;
    }

    /* "PyTorch.pyx":895
 *                 self.native = THFloatTensor_newWithSize4d(args[0], args[1], args[2], args[3])
 *             else:
 *                 logger.error('Raising exception...')             # <<<<<<<<<<<<<<
 *                 raise Exception('Not implemented, len(args)=' + str(len(args)))
 * #        else:
 */
    /*else*/ {
      __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_logger); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 895, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_error); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 895, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_tuple__18, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 895, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

      /* "PyTorch.pyx":896
 *             else:
 *                 logger.error('Raising exception...')
 *                 raise Exception('Not implemented, len(args)=' + str(len(args)))             # <<<<<<<<<<<<<<
 * #        else:
 * #            if len(args) > 0:
 */
      __pyx_t_4 = PyTuple_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 896, __pyx_L1_error)
      __pyx_t_2 = PyInt_FromSsize_t(__pyx_t_4); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 896, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 896, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_GIVEREF(__pyx_t_2);
      PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_2);
      __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)(&PyString_Type)), __pyx_t_1, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 896, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_t_1 = PyNumber_Add(__pyx_kp_s_Not_implemented_len_args, __pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 896, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = PyTuple_New(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 896, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_GIVEREF(__pyx_t_1);
      PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_1);
      __pyx_t_1 = 0;
      __pyx_t_1 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_t_2, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 896, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_Raise(__pyx_t_1, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __PYX_ERR(0, 896, __pyx_L1_error)
    }
    __pyx_L13:;

    /* "PyTorch.pyx":866
 * #        if len(kwargs) > 0:
 * #            raise Exception('cannot provide arguments to initializer')
 *         if _allocate:             # <<<<<<<<<<<<<<
 *             if len(args) == 1 and isinstance(args[0], _LongStorage):  # it's a size tensor
 *                self.native = THFloatTensor_new()
 */
  }

  /* "PyTorch.pyx":857
 * #        self.thFloatTensor = tensorC
 * 
 *     def __cinit__(self, *args, _allocate=True):             # <<<<<<<<<<<<<<
 * #        cdef _FloatTensor childobject
 *         cdef THFloatTensor *newTensorC
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_AddTraceback("PyTorch._FloatTensor.__cinit__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_templateObject);
  __Pyx_XDECREF(__pyx_v_arg);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":915
 * #        self.storage = storage
 * 
 *     def __dealloc__(self):             # <<<<<<<<<<<<<<
 *         cdef int refCount
 * #        cdef int dims
 */

/* Python wrapper */
static void __pyx_pw_7PyTorch_12_FloatTensor_3__dealloc__(PyObject *__pyx_v_self); /*proto*/
static void __pyx_pw_7PyTorch_12_FloatTensor_3__dealloc__(PyObject *__pyx_v_self) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__dealloc__ (wrapper)", 0);
  __pyx_pf_7PyTorch_12_FloatTensor_2__dealloc__(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

static void __pyx_pf_7PyTorch_12_FloatTensor_2__dealloc__(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self) {
  int __pyx_v_refCount;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("__dealloc__", 0);

  /* "PyTorch.pyx":922
 * #        cdef THFloatStorage *storage
 * #        logger.debug('__dealloc__ native %s', <long>(self.native) != 0)
 *         if <long>(self.native) != 0:             # <<<<<<<<<<<<<<
 *             refCount = THFloatTensor_getRefCount(self.native)
 *    #         print('FloatTensor.dealloc old refcount', refCount)
 */
  __pyx_t_1 = ((((long)__pyx_v_self->native) != 0) != 0);
  if (__pyx_t_1) {

    /* "PyTorch.pyx":923
 * #        logger.debug('__dealloc__ native %s', <long>(self.native) != 0)
 *         if <long>(self.native) != 0:
 *             refCount = THFloatTensor_getRefCount(self.native)             # <<<<<<<<<<<<<<
 *    #         print('FloatTensor.dealloc old refcount', refCount)
 *    #        storage = THFloatTensor_storage(self.thFloatTensor)
 */
    __pyx_v_refCount = THFloatTensor_getRefCount(__pyx_v_self->native);

    /* "PyTorch.pyx":934
 *    #        for i in range(dims):
 *    #            # print('   size[', i, ']', THFloatTensor_size(self.thFloatTensor, i))
 *             if refCount < 1:             # <<<<<<<<<<<<<<
 *                 raise Exception('Unallocated an already deallocated tensor... :-O')  # Hmmm, seems this exceptoin wont go anywhere useful... :-P
 *             THFloatTensor_free(self.native)
 */
    __pyx_t_1 = ((__pyx_v_refCount < 1) != 0);
    if (__pyx_t_1) {

      /* "PyTorch.pyx":935
 *    #            # print('   size[', i, ']', THFloatTensor_size(self.thFloatTensor, i))
 *             if refCount < 1:
 *                 raise Exception('Unallocated an already deallocated tensor... :-O')  # Hmmm, seems this exceptoin wont go anywhere useful... :-P             # <<<<<<<<<<<<<<
 *             THFloatTensor_free(self.native)
 *         else:
 */
      __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_tuple__19, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 935, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_Raise(__pyx_t_2, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __PYX_ERR(0, 935, __pyx_L1_error)

      /* "PyTorch.pyx":934
 *    #        for i in range(dims):
 *    #            # print('   size[', i, ']', THFloatTensor_size(self.thFloatTensor, i))
 *             if refCount < 1:             # <<<<<<<<<<<<<<
 *                 raise Exception('Unallocated an already deallocated tensor... :-O')  # Hmmm, seems this exceptoin wont go anywhere useful... :-P
 *             THFloatTensor_free(self.native)
 */
    }

    /* "PyTorch.pyx":936
 *             if refCount < 1:
 *                 raise Exception('Unallocated an already deallocated tensor... :-O')  # Hmmm, seems this exceptoin wont go anywhere useful... :-P
 *             THFloatTensor_free(self.native)             # <<<<<<<<<<<<<<
 *         else:
 *             logger.debug('__dealloc__ tensor never allocated')
 */
    THFloatTensor_free(__pyx_v_self->native);

    /* "PyTorch.pyx":922
 * #        cdef THFloatStorage *storage
 * #        logger.debug('__dealloc__ native %s', <long>(self.native) != 0)
 *         if <long>(self.native) != 0:             # <<<<<<<<<<<<<<
 *             refCount = THFloatTensor_getRefCount(self.native)
 *    #         print('FloatTensor.dealloc old refcount', refCount)
 */
    goto __pyx_L3;
  }

  /* "PyTorch.pyx":938
 *             THFloatTensor_free(self.native)
 *         else:
 *             logger.debug('__dealloc__ tensor never allocated')             # <<<<<<<<<<<<<<
 * 
 *     def nElement(_FloatTensor self):
 */
  /*else*/ {
    __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_logger); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 938, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_debug); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 938, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_tuple__20, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 938, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  }
  __pyx_L3:;

  /* "PyTorch.pyx":915
 * #        self.storage = storage
 * 
 *     def __dealloc__(self):             # <<<<<<<<<<<<<<
 *         cdef int refCount
 * #        cdef int dims
 */

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_WriteUnraisable("PyTorch._FloatTensor.__dealloc__", __pyx_clineno, __pyx_lineno, __pyx_filename, 0, 0);
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
}

/* "PyTorch.pyx":940
 *             logger.debug('__dealloc__ tensor never allocated')
 * 
 *     def nElement(_FloatTensor self):             # <<<<<<<<<<<<<<
 *         return THFloatTensor_nElement(self.native)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_5nElement(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_5nElement(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("nElement (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_4nElement(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_4nElement(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("nElement", 0);

  /* "PyTorch.pyx":941
 * 
 *     def nElement(_FloatTensor self):
 *         return THFloatTensor_nElement(self.native)             # <<<<<<<<<<<<<<
 * 
 *     def asNumpyTensor(_FloatTensor self):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_long(THFloatTensor_nElement(__pyx_v_self->native)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 941, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":940
 *             logger.debug('__dealloc__ tensor never allocated')
 * 
 *     def nElement(_FloatTensor self):             # <<<<<<<<<<<<<<
 *         return THFloatTensor_nElement(self.native)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._FloatTensor.nElement", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":943
 *         return THFloatTensor_nElement(self.native)
 * 
 *     def asNumpyTensor(_FloatTensor self):             # <<<<<<<<<<<<<<
 *         cdef Storage._FloatStorage storage
 *         cdef float *data
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_7asNumpyTensor(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_7asNumpyTensor(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("asNumpyTensor (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_6asNumpyTensor(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_6asNumpyTensor(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self) {
  float *__pyx_v_data;
  struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_contig = 0;
  PyObject *__pyx_v_size = NULL;
  PyObject *__pyx_v_dims = NULL;
  PyObject *__pyx_v_dtype = NULL;
  PyObject *__pyx_v_totalSize = NULL;
  PyObject *__pyx_v_d = NULL;
  PyObject *__pyx_v_myarray = NULL;
  PyObject *__pyx_v_i = NULL;
  PyObject *__pyx_v_shape = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  Py_ssize_t __pyx_t_4;
  int __pyx_t_5;
  int __pyx_t_6;
  PyObject *(*__pyx_t_7)(PyObject *);
  PyObject *__pyx_t_8 = NULL;
  Py_ssize_t __pyx_t_9;
  int __pyx_t_10;
  __Pyx_RefNannySetupContext("asNumpyTensor", 0);

  /* "PyTorch.pyx":947
 *         cdef float *data
 *         cdef _FloatTensor contig
 *         size = self.size()             # <<<<<<<<<<<<<<
 *         dims = len(size)
 *         dtype = None
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_size); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 947, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 947, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 947, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_size = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":948
 *         cdef _FloatTensor contig
 *         size = self.size()
 *         dims = len(size)             # <<<<<<<<<<<<<<
 *         dtype = None
 * 
 */
  __pyx_t_4 = PyObject_Length(__pyx_v_size); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 948, __pyx_L1_error)
  __pyx_t_1 = PyInt_FromSsize_t(__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 948, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_dims = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":949
 *         size = self.size()
 *         dims = len(size)
 *         dtype = None             # <<<<<<<<<<<<<<
 * 
 *         dtype=np.float32
 */
  __Pyx_INCREF(Py_None);
  __pyx_v_dtype = Py_None;

  /* "PyTorch.pyx":951
 *         dtype = None
 * 
 *         dtype=np.float32             # <<<<<<<<<<<<<<
 * 
 *         if dtype is None:
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_np); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 951, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_float32); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 951, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF_SET(__pyx_v_dtype, __pyx_t_2);
  __pyx_t_2 = 0;

  /* "PyTorch.pyx":953
 *         dtype=np.float32
 * 
 *         if dtype is None:             # <<<<<<<<<<<<<<
 *           raise Exception("not implemented for Float")
 * #        print('dtype', dtype)
 */
  __pyx_t_5 = (__pyx_v_dtype == Py_None);
  __pyx_t_6 = (__pyx_t_5 != 0);
  if (__pyx_t_6) {

    /* "PyTorch.pyx":954
 * 
 *         if dtype is None:
 *           raise Exception("not implemented for Float")             # <<<<<<<<<<<<<<
 * #        print('dtype', dtype)
 *         if dims >= 1:
 */
    __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_tuple__21, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 954, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(0, 954, __pyx_L1_error)

    /* "PyTorch.pyx":953
 *         dtype=np.float32
 * 
 *         if dtype is None:             # <<<<<<<<<<<<<<
 *           raise Exception("not implemented for Float")
 * #        print('dtype', dtype)
 */
  }

  /* "PyTorch.pyx":956
 *           raise Exception("not implemented for Float")
 * #        print('dtype', dtype)
 *         if dims >= 1:             # <<<<<<<<<<<<<<
 *             totalSize = 1
 *             for d in range(dims - 1, -1, -1):
 */
  __pyx_t_2 = PyObject_RichCompare(__pyx_v_dims, __pyx_int_1, Py_GE); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 956, __pyx_L1_error)
  __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely(__pyx_t_6 < 0)) __PYX_ERR(0, 956, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (__pyx_t_6) {

    /* "PyTorch.pyx":957
 * #        print('dtype', dtype)
 *         if dims >= 1:
 *             totalSize = 1             # <<<<<<<<<<<<<<
 *             for d in range(dims - 1, -1, -1):
 *                 totalSize *= size[d]
 */
    __Pyx_INCREF(__pyx_int_1);
    __pyx_v_totalSize = __pyx_int_1;

    /* "PyTorch.pyx":958
 *         if dims >= 1:
 *             totalSize = 1
 *             for d in range(dims - 1, -1, -1):             # <<<<<<<<<<<<<<
 *                 totalSize *= size[d]
 *             myarray = np.zeros(totalSize, dtype=dtype)
 */
    __pyx_t_2 = __Pyx_PyInt_SubtractObjC(__pyx_v_dims, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 958, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_1 = PyTuple_New(3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 958, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_GIVEREF(__pyx_t_2);
    PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_2);
    __Pyx_INCREF(__pyx_int_neg_1);
    __Pyx_GIVEREF(__pyx_int_neg_1);
    PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_int_neg_1);
    __Pyx_INCREF(__pyx_int_neg_1);
    __Pyx_GIVEREF(__pyx_int_neg_1);
    PyTuple_SET_ITEM(__pyx_t_1, 2, __pyx_int_neg_1);
    __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_range, __pyx_t_1, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 958, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    if (likely(PyList_CheckExact(__pyx_t_2)) || PyTuple_CheckExact(__pyx_t_2)) {
      __pyx_t_1 = __pyx_t_2; __Pyx_INCREF(__pyx_t_1); __pyx_t_4 = 0;
      __pyx_t_7 = NULL;
    } else {
      __pyx_t_4 = -1; __pyx_t_1 = PyObject_GetIter(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 958, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_7 = Py_TYPE(__pyx_t_1)->tp_iternext; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 958, __pyx_L1_error)
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    for (;;) {
      if (likely(!__pyx_t_7)) {
        if (likely(PyList_CheckExact(__pyx_t_1))) {
          if (__pyx_t_4 >= PyList_GET_SIZE(__pyx_t_1)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_2 = PyList_GET_ITEM(__pyx_t_1, __pyx_t_4); __Pyx_INCREF(__pyx_t_2); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 958, __pyx_L1_error)
          #else
          __pyx_t_2 = PySequence_ITEM(__pyx_t_1, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 958, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          #endif
        } else {
          if (__pyx_t_4 >= PyTuple_GET_SIZE(__pyx_t_1)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_2 = PyTuple_GET_ITEM(__pyx_t_1, __pyx_t_4); __Pyx_INCREF(__pyx_t_2); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 958, __pyx_L1_error)
          #else
          __pyx_t_2 = PySequence_ITEM(__pyx_t_1, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 958, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          #endif
        }
      } else {
        __pyx_t_2 = __pyx_t_7(__pyx_t_1);
        if (unlikely(!__pyx_t_2)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(exc_type == PyExc_StopIteration || PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 958, __pyx_L1_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_2);
      }
      __Pyx_XDECREF_SET(__pyx_v_d, __pyx_t_2);
      __pyx_t_2 = 0;

      /* "PyTorch.pyx":959
 *             totalSize = 1
 *             for d in range(dims - 1, -1, -1):
 *                 totalSize *= size[d]             # <<<<<<<<<<<<<<
 *             myarray = np.zeros(totalSize, dtype=dtype)
 *             contig = self.contiguous()
 */
      __pyx_t_2 = PyObject_GetItem(__pyx_v_size, __pyx_v_d); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 959, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_3 = PyNumber_InPlaceMultiply(__pyx_v_totalSize, __pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 959, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_DECREF_SET(__pyx_v_totalSize, __pyx_t_3);
      __pyx_t_3 = 0;

      /* "PyTorch.pyx":958
 *         if dims >= 1:
 *             totalSize = 1
 *             for d in range(dims - 1, -1, -1):             # <<<<<<<<<<<<<<
 *                 totalSize *= size[d]
 *             myarray = np.zeros(totalSize, dtype=dtype)
 */
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "PyTorch.pyx":960
 *             for d in range(dims - 1, -1, -1):
 *                 totalSize *= size[d]
 *             myarray = np.zeros(totalSize, dtype=dtype)             # <<<<<<<<<<<<<<
 *             contig = self.contiguous()
 *             data = contig.data()
 */
    __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_np); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 960, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_zeros); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 960, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 960, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_INCREF(__pyx_v_totalSize);
    __Pyx_GIVEREF(__pyx_v_totalSize);
    PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_v_totalSize);
    __pyx_t_2 = PyDict_New(); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 960, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    if (PyDict_SetItem(__pyx_t_2, __pyx_n_s_dtype, __pyx_v_dtype) < 0) __PYX_ERR(0, 960, __pyx_L1_error)
    __pyx_t_8 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_1, __pyx_t_2); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 960, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_v_myarray = __pyx_t_8;
    __pyx_t_8 = 0;

    /* "PyTorch.pyx":961
 *                 totalSize *= size[d]
 *             myarray = np.zeros(totalSize, dtype=dtype)
 *             contig = self.contiguous()             # <<<<<<<<<<<<<<
 *             data = contig.data()
 *             for i in range(totalSize):
 */
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_contiguous); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 961, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_1 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
      __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_2);
      if (likely(__pyx_t_1)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
        __Pyx_INCREF(__pyx_t_1);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_2, function);
      }
    }
    if (__pyx_t_1) {
      __pyx_t_8 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 961, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    } else {
      __pyx_t_8 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 961, __pyx_L1_error)
    }
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    if (!(likely(((__pyx_t_8) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_8, __pyx_ptype_7PyTorch__FloatTensor))))) __PYX_ERR(0, 961, __pyx_L1_error)
    __pyx_v_contig = ((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_t_8);
    __pyx_t_8 = 0;

    /* "PyTorch.pyx":962
 *             myarray = np.zeros(totalSize, dtype=dtype)
 *             contig = self.contiguous()
 *             data = contig.data()             # <<<<<<<<<<<<<<
 *             for i in range(totalSize):
 *                 myarray[i] = data[i]
 */
    __pyx_v_data = ((struct __pyx_vtabstruct_7PyTorch__FloatTensor *)__pyx_v_contig->__pyx_vtab)->data(__pyx_v_contig);

    /* "PyTorch.pyx":963
 *             contig = self.contiguous()
 *             data = contig.data()
 *             for i in range(totalSize):             # <<<<<<<<<<<<<<
 *                 myarray[i] = data[i]
 *             shape = []
 */
    __pyx_t_8 = PyTuple_New(1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 963, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_INCREF(__pyx_v_totalSize);
    __Pyx_GIVEREF(__pyx_v_totalSize);
    PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_v_totalSize);
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_range, __pyx_t_8, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 963, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    if (likely(PyList_CheckExact(__pyx_t_2)) || PyTuple_CheckExact(__pyx_t_2)) {
      __pyx_t_8 = __pyx_t_2; __Pyx_INCREF(__pyx_t_8); __pyx_t_4 = 0;
      __pyx_t_7 = NULL;
    } else {
      __pyx_t_4 = -1; __pyx_t_8 = PyObject_GetIter(__pyx_t_2); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 963, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_7 = Py_TYPE(__pyx_t_8)->tp_iternext; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 963, __pyx_L1_error)
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    for (;;) {
      if (likely(!__pyx_t_7)) {
        if (likely(PyList_CheckExact(__pyx_t_8))) {
          if (__pyx_t_4 >= PyList_GET_SIZE(__pyx_t_8)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_2 = PyList_GET_ITEM(__pyx_t_8, __pyx_t_4); __Pyx_INCREF(__pyx_t_2); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 963, __pyx_L1_error)
          #else
          __pyx_t_2 = PySequence_ITEM(__pyx_t_8, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 963, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          #endif
        } else {
          if (__pyx_t_4 >= PyTuple_GET_SIZE(__pyx_t_8)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_2 = PyTuple_GET_ITEM(__pyx_t_8, __pyx_t_4); __Pyx_INCREF(__pyx_t_2); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 963, __pyx_L1_error)
          #else
          __pyx_t_2 = PySequence_ITEM(__pyx_t_8, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 963, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          #endif
        }
      } else {
        __pyx_t_2 = __pyx_t_7(__pyx_t_8);
        if (unlikely(!__pyx_t_2)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(exc_type == PyExc_StopIteration || PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 963, __pyx_L1_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_2);
      }
      __Pyx_XDECREF_SET(__pyx_v_i, __pyx_t_2);
      __pyx_t_2 = 0;

      /* "PyTorch.pyx":964
 *             data = contig.data()
 *             for i in range(totalSize):
 *                 myarray[i] = data[i]             # <<<<<<<<<<<<<<
 *             shape = []
 *             for d in range(dims):
 */
      __pyx_t_9 = __Pyx_PyIndex_AsSsize_t(__pyx_v_i); if (unlikely((__pyx_t_9 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 964, __pyx_L1_error)
      __pyx_t_2 = PyFloat_FromDouble((__pyx_v_data[__pyx_t_9])); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 964, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      if (unlikely(PyObject_SetItem(__pyx_v_myarray, __pyx_v_i, __pyx_t_2) < 0)) __PYX_ERR(0, 964, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

      /* "PyTorch.pyx":963
 *             contig = self.contiguous()
 *             data = contig.data()
 *             for i in range(totalSize):             # <<<<<<<<<<<<<<
 *                 myarray[i] = data[i]
 *             shape = []
 */
    }
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;

    /* "PyTorch.pyx":965
 *             for i in range(totalSize):
 *                 myarray[i] = data[i]
 *             shape = []             # <<<<<<<<<<<<<<
 *             for d in range(dims):
 *                 shape.append(size[d])
 */
    __pyx_t_8 = PyList_New(0); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 965, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_v_shape = ((PyObject*)__pyx_t_8);
    __pyx_t_8 = 0;

    /* "PyTorch.pyx":966
 *                 myarray[i] = data[i]
 *             shape = []
 *             for d in range(dims):             # <<<<<<<<<<<<<<
 *                 shape.append(size[d])
 *             return myarray.reshape(shape)
 */
    __pyx_t_8 = PyTuple_New(1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 966, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_INCREF(__pyx_v_dims);
    __Pyx_GIVEREF(__pyx_v_dims);
    PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_v_dims);
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_range, __pyx_t_8, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 966, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    if (likely(PyList_CheckExact(__pyx_t_2)) || PyTuple_CheckExact(__pyx_t_2)) {
      __pyx_t_8 = __pyx_t_2; __Pyx_INCREF(__pyx_t_8); __pyx_t_4 = 0;
      __pyx_t_7 = NULL;
    } else {
      __pyx_t_4 = -1; __pyx_t_8 = PyObject_GetIter(__pyx_t_2); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 966, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_7 = Py_TYPE(__pyx_t_8)->tp_iternext; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 966, __pyx_L1_error)
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    for (;;) {
      if (likely(!__pyx_t_7)) {
        if (likely(PyList_CheckExact(__pyx_t_8))) {
          if (__pyx_t_4 >= PyList_GET_SIZE(__pyx_t_8)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_2 = PyList_GET_ITEM(__pyx_t_8, __pyx_t_4); __Pyx_INCREF(__pyx_t_2); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 966, __pyx_L1_error)
          #else
          __pyx_t_2 = PySequence_ITEM(__pyx_t_8, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 966, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          #endif
        } else {
          if (__pyx_t_4 >= PyTuple_GET_SIZE(__pyx_t_8)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_2 = PyTuple_GET_ITEM(__pyx_t_8, __pyx_t_4); __Pyx_INCREF(__pyx_t_2); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 966, __pyx_L1_error)
          #else
          __pyx_t_2 = PySequence_ITEM(__pyx_t_8, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 966, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          #endif
        }
      } else {
        __pyx_t_2 = __pyx_t_7(__pyx_t_8);
        if (unlikely(!__pyx_t_2)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(exc_type == PyExc_StopIteration || PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 966, __pyx_L1_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_2);
      }
      __Pyx_XDECREF_SET(__pyx_v_d, __pyx_t_2);
      __pyx_t_2 = 0;

      /* "PyTorch.pyx":967
 *             shape = []
 *             for d in range(dims):
 *                 shape.append(size[d])             # <<<<<<<<<<<<<<
 *             return myarray.reshape(shape)
 *         else:
 */
      __pyx_t_2 = PyObject_GetItem(__pyx_v_size, __pyx_v_d); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 967, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_10 = __Pyx_PyList_Append(__pyx_v_shape, __pyx_t_2); if (unlikely(__pyx_t_10 == -1)) __PYX_ERR(0, 967, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

      /* "PyTorch.pyx":966
 *                 myarray[i] = data[i]
 *             shape = []
 *             for d in range(dims):             # <<<<<<<<<<<<<<
 *                 shape.append(size[d])
 *             return myarray.reshape(shape)
 */
    }
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;

    /* "PyTorch.pyx":968
 *             for d in range(dims):
 *                 shape.append(size[d])
 *             return myarray.reshape(shape)             # <<<<<<<<<<<<<<
 *         else:
 *             raise Exception('Not implemented for dims = {dims}'.format(dims=dims))
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_myarray, __pyx_n_s_reshape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 968, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_1 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
      __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_2);
      if (likely(__pyx_t_1)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
        __Pyx_INCREF(__pyx_t_1);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_2, function);
      }
    }
    if (!__pyx_t_1) {
      __pyx_t_8 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_v_shape); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 968, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[2] = {__pyx_t_1, __pyx_v_shape};
        __pyx_t_8 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 968, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
        __Pyx_GOTREF(__pyx_t_8);
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[2] = {__pyx_t_1, __pyx_v_shape};
        __pyx_t_8 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 968, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
        __Pyx_GOTREF(__pyx_t_8);
      } else
      #endif
      {
        __pyx_t_3 = PyTuple_New(1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 968, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_GIVEREF(__pyx_t_1); PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_1); __pyx_t_1 = NULL;
        __Pyx_INCREF(__pyx_v_shape);
        __Pyx_GIVEREF(__pyx_v_shape);
        PyTuple_SET_ITEM(__pyx_t_3, 0+1, __pyx_v_shape);
        __pyx_t_8 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_3, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 968, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_r = __pyx_t_8;
    __pyx_t_8 = 0;
    goto __pyx_L0;

    /* "PyTorch.pyx":956
 *           raise Exception("not implemented for Float")
 * #        print('dtype', dtype)
 *         if dims >= 1:             # <<<<<<<<<<<<<<
 *             totalSize = 1
 *             for d in range(dims - 1, -1, -1):
 */
  }

  /* "PyTorch.pyx":970
 *             return myarray.reshape(shape)
 *         else:
 *             raise Exception('Not implemented for dims = {dims}'.format(dims=dims))             # <<<<<<<<<<<<<<
 * 
 *     @property
 */
  /*else*/ {
    __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_kp_s_Not_implemented_for_dims_dims, __pyx_n_s_format); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 970, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_2 = PyDict_New(); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 970, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    if (PyDict_SetItem(__pyx_t_2, __pyx_n_s_dims, __pyx_v_dims) < 0) __PYX_ERR(0, 970, __pyx_L1_error)
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_8, __pyx_empty_tuple, __pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 970, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = PyTuple_New(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 970, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_GIVEREF(__pyx_t_3);
    PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_3);
    __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_t_2, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 970, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(0, 970, __pyx_L1_error)
  }

  /* "PyTorch.pyx":943
 *         return THFloatTensor_nElement(self.native)
 * 
 *     def asNumpyTensor(_FloatTensor self):             # <<<<<<<<<<<<<<
 *         cdef Storage._FloatStorage storage
 *         cdef float *data
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("PyTorch._FloatTensor.asNumpyTensor", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_contig);
  __Pyx_XDECREF(__pyx_v_size);
  __Pyx_XDECREF(__pyx_v_dims);
  __Pyx_XDECREF(__pyx_v_dtype);
  __Pyx_XDECREF(__pyx_v_totalSize);
  __Pyx_XDECREF(__pyx_v_d);
  __Pyx_XDECREF(__pyx_v_myarray);
  __Pyx_XDECREF(__pyx_v_i);
  __Pyx_XDECREF(__pyx_v_shape);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":973
 * 
 *     @property
 *     def refCount(_FloatTensor self):             # <<<<<<<<<<<<<<
 *         return THFloatTensor_getRefCount(self.native)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_8refCount_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_8refCount_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_8refCount___get__(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_8refCount___get__(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "PyTorch.pyx":974
 *     @property
 *     def refCount(_FloatTensor self):
 *         return THFloatTensor_getRefCount(self.native)             # <<<<<<<<<<<<<<
 * 
 *     cdef float *data(_FloatTensor self):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_int(THFloatTensor_getRefCount(__pyx_v_self->native)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 974, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":973
 * 
 *     @property
 *     def refCount(_FloatTensor self):             # <<<<<<<<<<<<<<
 *         return THFloatTensor_getRefCount(self.native)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._FloatTensor.refCount.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":976
 *         return THFloatTensor_getRefCount(self.native)
 * 
 *     cdef float *data(_FloatTensor self):             # <<<<<<<<<<<<<<
 *         return THFloatTensor_data(self.native)
 * 
 */

static float *__pyx_f_7PyTorch_12_FloatTensor_data(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self) {
  float *__pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("data", 0);

  /* "PyTorch.pyx":977
 * 
 *     cdef float *data(_FloatTensor self):
 *         return THFloatTensor_data(self.native)             # <<<<<<<<<<<<<<
 * 
 *     cpdef int dims(self):
 */
  __pyx_r = THFloatTensor_data(__pyx_v_self->native);
  goto __pyx_L0;

  /* "PyTorch.pyx":976
 *         return THFloatTensor_getRefCount(self.native)
 * 
 *     cdef float *data(_FloatTensor self):             # <<<<<<<<<<<<<<
 *         return THFloatTensor_data(self.native)
 * 
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":979
 *         return THFloatTensor_data(self.native)
 * 
 *     cpdef int dims(self):             # <<<<<<<<<<<<<<
 *         return THFloatTensor_nDimension(self.native)
 * 
 */

static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_9dims(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static int __pyx_f_7PyTorch_12_FloatTensor_dims(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, int __pyx_skip_dispatch) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  int __pyx_t_5;
  __Pyx_RefNannySetupContext("dims", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_dims); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 979, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_9dims)) {
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_3 = __pyx_t_1; __pyx_t_4 = NULL;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
        __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
        if (likely(__pyx_t_4)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
          __Pyx_INCREF(__pyx_t_4);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_3, function);
        }
      }
      if (__pyx_t_4) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_4); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 979, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else {
        __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 979, __pyx_L1_error)
      }
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_5 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_5 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 979, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_r = __pyx_t_5;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "PyTorch.pyx":980
 * 
 *     cpdef int dims(self):
 *         return THFloatTensor_nDimension(self.native)             # <<<<<<<<<<<<<<
 * 
 *     cpdef set1d(self, int x0, float value):
 */
  __pyx_r = THFloatTensor_nDimension(__pyx_v_self->native);
  goto __pyx_L0;

  /* "PyTorch.pyx":979
 *         return THFloatTensor_data(self.native)
 * 
 *     cpdef int dims(self):             # <<<<<<<<<<<<<<
 *         return THFloatTensor_nDimension(self.native)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_WriteUnraisable("PyTorch._FloatTensor.dims", __pyx_clineno, __pyx_lineno, __pyx_filename, 0, 0);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_9dims(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_9dims(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("dims (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_8dims(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_8dims(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("dims", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_f_7PyTorch_12_FloatTensor_dims(__pyx_v_self, 1)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 979, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._FloatTensor.dims", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":982
 *         return THFloatTensor_nDimension(self.native)
 * 
 *     cpdef set1d(self, int x0, float value):             # <<<<<<<<<<<<<<
 *         THFloatTensor_set1d(self.native, x0, value)
 * 
 */

static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_11set1d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_f_7PyTorch_12_FloatTensor_set1d(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, int __pyx_v_x0, float __pyx_v_value, int __pyx_skip_dispatch) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  int __pyx_t_7;
  PyObject *__pyx_t_8 = NULL;
  __Pyx_RefNannySetupContext("set1d", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_set1d); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 982, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_11set1d)) {
      __Pyx_XDECREF(__pyx_r);
      __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_x0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 982, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_4 = PyFloat_FromDouble(__pyx_v_value); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 982, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_5 = __pyx_t_1; __pyx_t_6 = NULL;
      __pyx_t_7 = 0;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
        __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_5);
        if (likely(__pyx_t_6)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
          __Pyx_INCREF(__pyx_t_6);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_5, function);
          __pyx_t_7 = 1;
        }
      }
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_5)) {
        PyObject *__pyx_temp[3] = {__pyx_t_6, __pyx_t_3, __pyx_t_4};
        __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_7, 2+__pyx_t_7); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 982, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
        PyObject *__pyx_temp[3] = {__pyx_t_6, __pyx_t_3, __pyx_t_4};
        __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_7, 2+__pyx_t_7); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 982, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else
      #endif
      {
        __pyx_t_8 = PyTuple_New(2+__pyx_t_7); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 982, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        if (__pyx_t_6) {
          __Pyx_GIVEREF(__pyx_t_6); PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_t_6); __pyx_t_6 = NULL;
        }
        __Pyx_GIVEREF(__pyx_t_3);
        PyTuple_SET_ITEM(__pyx_t_8, 0+__pyx_t_7, __pyx_t_3);
        __Pyx_GIVEREF(__pyx_t_4);
        PyTuple_SET_ITEM(__pyx_t_8, 1+__pyx_t_7, __pyx_t_4);
        __pyx_t_3 = 0;
        __pyx_t_4 = 0;
        __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_8, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 982, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      }
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __pyx_r = __pyx_t_2;
      __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "PyTorch.pyx":983
 * 
 *     cpdef set1d(self, int x0, float value):
 *         THFloatTensor_set1d(self.native, x0, value)             # <<<<<<<<<<<<<<
 * 
 *     cpdef set2d(self, int x0, int x1, float value):
 */
  THFloatTensor_set1d(__pyx_v_self->native, __pyx_v_x0, __pyx_v_value);

  /* "PyTorch.pyx":982
 *         return THFloatTensor_nDimension(self.native)
 * 
 *     cpdef set1d(self, int x0, float value):             # <<<<<<<<<<<<<<
 *         THFloatTensor_set1d(self.native, x0, value)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("PyTorch._FloatTensor.set1d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_11set1d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_11set1d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  int __pyx_v_x0;
  float __pyx_v_value;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("set1d (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_x0,&__pyx_n_s_value,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_x0)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_value)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("set1d", 1, 2, 2, 1); __PYX_ERR(0, 982, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "set1d") < 0)) __PYX_ERR(0, 982, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_x0 = __Pyx_PyInt_As_int(values[0]); if (unlikely((__pyx_v_x0 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 982, __pyx_L3_error)
    __pyx_v_value = __pyx_PyFloat_AsFloat(values[1]); if (unlikely((__pyx_v_value == (float)-1) && PyErr_Occurred())) __PYX_ERR(0, 982, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("set1d", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 982, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._FloatTensor.set1d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_10set1d(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self), __pyx_v_x0, __pyx_v_value);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_10set1d(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, int __pyx_v_x0, float __pyx_v_value) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("set1d", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_7PyTorch_12_FloatTensor_set1d(__pyx_v_self, __pyx_v_x0, __pyx_v_value, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 982, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._FloatTensor.set1d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":985
 *         THFloatTensor_set1d(self.native, x0, value)
 * 
 *     cpdef set2d(self, int x0, int x1, float value):             # <<<<<<<<<<<<<<
 *         THFloatTensor_set2d(self.native, x0, x1, value)
 * 
 */

static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_13set2d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_f_7PyTorch_12_FloatTensor_set2d(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_v_x1, float __pyx_v_value, int __pyx_skip_dispatch) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  int __pyx_t_8;
  PyObject *__pyx_t_9 = NULL;
  __Pyx_RefNannySetupContext("set2d", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_set2d); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 985, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_13set2d)) {
      __Pyx_XDECREF(__pyx_r);
      __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_x0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 985, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_4 = __Pyx_PyInt_From_int(__pyx_v_x1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 985, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_t_5 = PyFloat_FromDouble(__pyx_v_value); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 985, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_6 = __pyx_t_1; __pyx_t_7 = NULL;
      __pyx_t_8 = 0;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_6))) {
        __pyx_t_7 = PyMethod_GET_SELF(__pyx_t_6);
        if (likely(__pyx_t_7)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
          __Pyx_INCREF(__pyx_t_7);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_6, function);
          __pyx_t_8 = 1;
        }
      }
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_6)) {
        PyObject *__pyx_temp[4] = {__pyx_t_7, __pyx_t_3, __pyx_t_4, __pyx_t_5};
        __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_8, 3+__pyx_t_8); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 985, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_6)) {
        PyObject *__pyx_temp[4] = {__pyx_t_7, __pyx_t_3, __pyx_t_4, __pyx_t_5};
        __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_8, 3+__pyx_t_8); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 985, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      } else
      #endif
      {
        __pyx_t_9 = PyTuple_New(3+__pyx_t_8); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 985, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_9);
        if (__pyx_t_7) {
          __Pyx_GIVEREF(__pyx_t_7); PyTuple_SET_ITEM(__pyx_t_9, 0, __pyx_t_7); __pyx_t_7 = NULL;
        }
        __Pyx_GIVEREF(__pyx_t_3);
        PyTuple_SET_ITEM(__pyx_t_9, 0+__pyx_t_8, __pyx_t_3);
        __Pyx_GIVEREF(__pyx_t_4);
        PyTuple_SET_ITEM(__pyx_t_9, 1+__pyx_t_8, __pyx_t_4);
        __Pyx_GIVEREF(__pyx_t_5);
        PyTuple_SET_ITEM(__pyx_t_9, 2+__pyx_t_8, __pyx_t_5);
        __pyx_t_3 = 0;
        __pyx_t_4 = 0;
        __pyx_t_5 = 0;
        __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_9, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 985, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      }
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_r = __pyx_t_2;
      __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "PyTorch.pyx":986
 * 
 *     cpdef set2d(self, int x0, int x1, float value):
 *         THFloatTensor_set2d(self.native, x0, x1, value)             # <<<<<<<<<<<<<<
 * 
 *     cpdef float get1d(self, int x0):
 */
  THFloatTensor_set2d(__pyx_v_self->native, __pyx_v_x0, __pyx_v_x1, __pyx_v_value);

  /* "PyTorch.pyx":985
 *         THFloatTensor_set1d(self.native, x0, value)
 * 
 *     cpdef set2d(self, int x0, int x1, float value):             # <<<<<<<<<<<<<<
 *         THFloatTensor_set2d(self.native, x0, x1, value)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_AddTraceback("PyTorch._FloatTensor.set2d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_13set2d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_13set2d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  int __pyx_v_x0;
  int __pyx_v_x1;
  float __pyx_v_value;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("set2d (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_x0,&__pyx_n_s_x1,&__pyx_n_s_value,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_x0)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_x1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("set2d", 1, 3, 3, 1); __PYX_ERR(0, 985, __pyx_L3_error)
        }
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_value)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("set2d", 1, 3, 3, 2); __PYX_ERR(0, 985, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "set2d") < 0)) __PYX_ERR(0, 985, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_x0 = __Pyx_PyInt_As_int(values[0]); if (unlikely((__pyx_v_x0 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 985, __pyx_L3_error)
    __pyx_v_x1 = __Pyx_PyInt_As_int(values[1]); if (unlikely((__pyx_v_x1 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 985, __pyx_L3_error)
    __pyx_v_value = __pyx_PyFloat_AsFloat(values[2]); if (unlikely((__pyx_v_value == (float)-1) && PyErr_Occurred())) __PYX_ERR(0, 985, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("set2d", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 985, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._FloatTensor.set2d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_12set2d(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self), __pyx_v_x0, __pyx_v_x1, __pyx_v_value);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_12set2d(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_v_x1, float __pyx_v_value) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("set2d", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_7PyTorch_12_FloatTensor_set2d(__pyx_v_self, __pyx_v_x0, __pyx_v_x1, __pyx_v_value, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 985, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._FloatTensor.set2d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":988
 *         THFloatTensor_set2d(self.native, x0, x1, value)
 * 
 *     cpdef float get1d(self, int x0):             # <<<<<<<<<<<<<<
 *         return THFloatTensor_get1d(self.native, x0)
 * 
 */

static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_15get1d(PyObject *__pyx_v_self, PyObject *__pyx_arg_x0); /*proto*/
static float __pyx_f_7PyTorch_12_FloatTensor_get1d(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_skip_dispatch) {
  float __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  float __pyx_t_7;
  __Pyx_RefNannySetupContext("get1d", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_get1d); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 988, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_15get1d)) {
      __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_x0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 988, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_4 = __pyx_t_1; __pyx_t_5 = NULL;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_4))) {
        __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_4);
        if (likely(__pyx_t_5)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
          __Pyx_INCREF(__pyx_t_5);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_4, function);
        }
      }
      if (!__pyx_t_5) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 988, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_GOTREF(__pyx_t_2);
      } else {
        #if CYTHON_FAST_PYCALL
        if (PyFunction_Check(__pyx_t_4)) {
          PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_t_3};
          __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_4, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 988, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        } else
        #endif
        #if CYTHON_FAST_PYCCALL
        if (__Pyx_PyFastCFunction_Check(__pyx_t_4)) {
          PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_t_3};
          __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_4, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 988, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        } else
        #endif
        {
          __pyx_t_6 = PyTuple_New(1+1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 988, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_6);
          __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_5); __pyx_t_5 = NULL;
          __Pyx_GIVEREF(__pyx_t_3);
          PyTuple_SET_ITEM(__pyx_t_6, 0+1, __pyx_t_3);
          __pyx_t_3 = 0;
          __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_4, __pyx_t_6, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 988, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
        }
      }
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_7 = __pyx_PyFloat_AsFloat(__pyx_t_2); if (unlikely((__pyx_t_7 == (float)-1) && PyErr_Occurred())) __PYX_ERR(0, 988, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_r = __pyx_t_7;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "PyTorch.pyx":989
 * 
 *     cpdef float get1d(self, int x0):
 *         return THFloatTensor_get1d(self.native, x0)             # <<<<<<<<<<<<<<
 * 
 *     cpdef float get2d(self, int x0, int x1):
 */
  __pyx_r = THFloatTensor_get1d(__pyx_v_self->native, __pyx_v_x0);
  goto __pyx_L0;

  /* "PyTorch.pyx":988
 *         THFloatTensor_set2d(self.native, x0, x1, value)
 * 
 *     cpdef float get1d(self, int x0):             # <<<<<<<<<<<<<<
 *         return THFloatTensor_get1d(self.native, x0)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_WriteUnraisable("PyTorch._FloatTensor.get1d", __pyx_clineno, __pyx_lineno, __pyx_filename, 0, 0);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_15get1d(PyObject *__pyx_v_self, PyObject *__pyx_arg_x0); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_15get1d(PyObject *__pyx_v_self, PyObject *__pyx_arg_x0) {
  int __pyx_v_x0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("get1d (wrapper)", 0);
  assert(__pyx_arg_x0); {
    __pyx_v_x0 = __Pyx_PyInt_As_int(__pyx_arg_x0); if (unlikely((__pyx_v_x0 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 988, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._FloatTensor.get1d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_14get1d(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self), ((int)__pyx_v_x0));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_14get1d(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, int __pyx_v_x0) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("get1d", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyFloat_FromDouble(__pyx_f_7PyTorch_12_FloatTensor_get1d(__pyx_v_self, __pyx_v_x0, 1)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 988, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._FloatTensor.get1d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":991
 *         return THFloatTensor_get1d(self.native, x0)
 * 
 *     cpdef float get2d(self, int x0, int x1):             # <<<<<<<<<<<<<<
 *         return THFloatTensor_get2d(self.native, x0, x1)
 * 
 */

static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_17get2d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static float __pyx_f_7PyTorch_12_FloatTensor_get2d(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_v_x1, int __pyx_skip_dispatch) {
  float __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  int __pyx_t_7;
  PyObject *__pyx_t_8 = NULL;
  float __pyx_t_9;
  __Pyx_RefNannySetupContext("get2d", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_get2d); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 991, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_17get2d)) {
      __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_x0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 991, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_4 = __Pyx_PyInt_From_int(__pyx_v_x1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 991, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_5 = __pyx_t_1; __pyx_t_6 = NULL;
      __pyx_t_7 = 0;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
        __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_5);
        if (likely(__pyx_t_6)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
          __Pyx_INCREF(__pyx_t_6);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_5, function);
          __pyx_t_7 = 1;
        }
      }
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_5)) {
        PyObject *__pyx_temp[3] = {__pyx_t_6, __pyx_t_3, __pyx_t_4};
        __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_7, 2+__pyx_t_7); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 991, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
        PyObject *__pyx_temp[3] = {__pyx_t_6, __pyx_t_3, __pyx_t_4};
        __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_7, 2+__pyx_t_7); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 991, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else
      #endif
      {
        __pyx_t_8 = PyTuple_New(2+__pyx_t_7); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 991, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        if (__pyx_t_6) {
          __Pyx_GIVEREF(__pyx_t_6); PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_t_6); __pyx_t_6 = NULL;
        }
        __Pyx_GIVEREF(__pyx_t_3);
        PyTuple_SET_ITEM(__pyx_t_8, 0+__pyx_t_7, __pyx_t_3);
        __Pyx_GIVEREF(__pyx_t_4);
        PyTuple_SET_ITEM(__pyx_t_8, 1+__pyx_t_7, __pyx_t_4);
        __pyx_t_3 = 0;
        __pyx_t_4 = 0;
        __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_8, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 991, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      }
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __pyx_t_9 = __pyx_PyFloat_AsFloat(__pyx_t_2); if (unlikely((__pyx_t_9 == (float)-1) && PyErr_Occurred())) __PYX_ERR(0, 991, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_r = __pyx_t_9;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "PyTorch.pyx":992
 * 
 *     cpdef float get2d(self, int x0, int x1):
 *         return THFloatTensor_get2d(self.native, x0, x1)             # <<<<<<<<<<<<<<
 * 
 *     cpdef int isContiguous(_FloatTensor self):
 */
  __pyx_r = THFloatTensor_get2d(__pyx_v_self->native, __pyx_v_x0, __pyx_v_x1);
  goto __pyx_L0;

  /* "PyTorch.pyx":991
 *         return THFloatTensor_get1d(self.native, x0)
 * 
 *     cpdef float get2d(self, int x0, int x1):             # <<<<<<<<<<<<<<
 *         return THFloatTensor_get2d(self.native, x0, x1)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_WriteUnraisable("PyTorch._FloatTensor.get2d", __pyx_clineno, __pyx_lineno, __pyx_filename, 0, 0);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_17get2d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_17get2d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  int __pyx_v_x0;
  int __pyx_v_x1;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("get2d (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_x0,&__pyx_n_s_x1,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_x0)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_x1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("get2d", 1, 2, 2, 1); __PYX_ERR(0, 991, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "get2d") < 0)) __PYX_ERR(0, 991, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_x0 = __Pyx_PyInt_As_int(values[0]); if (unlikely((__pyx_v_x0 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 991, __pyx_L3_error)
    __pyx_v_x1 = __Pyx_PyInt_As_int(values[1]); if (unlikely((__pyx_v_x1 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 991, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("get2d", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 991, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._FloatTensor.get2d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_16get2d(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self), __pyx_v_x0, __pyx_v_x1);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_16get2d(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_v_x1) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("get2d", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyFloat_FromDouble(__pyx_f_7PyTorch_12_FloatTensor_get2d(__pyx_v_self, __pyx_v_x0, __pyx_v_x1, 1)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 991, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._FloatTensor.get2d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":994
 *         return THFloatTensor_get2d(self.native, x0, x1)
 * 
 *     cpdef int isContiguous(_FloatTensor self):             # <<<<<<<<<<<<<<
 *         return THFloatTensor_isContiguous(self.native)
 * 
 */

static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_19isContiguous(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static int __pyx_f_7PyTorch_12_FloatTensor_isContiguous(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, int __pyx_skip_dispatch) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  int __pyx_t_5;
  __Pyx_RefNannySetupContext("isContiguous", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_isContiguous); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 994, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_19isContiguous)) {
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_3 = __pyx_t_1; __pyx_t_4 = NULL;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
        __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
        if (likely(__pyx_t_4)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
          __Pyx_INCREF(__pyx_t_4);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_3, function);
        }
      }
      if (__pyx_t_4) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_4); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 994, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else {
        __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 994, __pyx_L1_error)
      }
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_5 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_5 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 994, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_r = __pyx_t_5;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "PyTorch.pyx":995
 * 
 *     cpdef int isContiguous(_FloatTensor self):
 *         return THFloatTensor_isContiguous(self.native)             # <<<<<<<<<<<<<<
 * 
 *     cpdef float max(self):
 */
  __pyx_r = THFloatTensor_isContiguous(__pyx_v_self->native);
  goto __pyx_L0;

  /* "PyTorch.pyx":994
 *         return THFloatTensor_get2d(self.native, x0, x1)
 * 
 *     cpdef int isContiguous(_FloatTensor self):             # <<<<<<<<<<<<<<
 *         return THFloatTensor_isContiguous(self.native)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_WriteUnraisable("PyTorch._FloatTensor.isContiguous", __pyx_clineno, __pyx_lineno, __pyx_filename, 0, 0);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_19isContiguous(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_19isContiguous(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("isContiguous (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_18isContiguous(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_18isContiguous(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("isContiguous", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_f_7PyTorch_12_FloatTensor_isContiguous(__pyx_v_self, 1)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 994, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._FloatTensor.isContiguous", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":997
 *         return THFloatTensor_isContiguous(self.native)
 * 
 *     cpdef float max(self):             # <<<<<<<<<<<<<<
 *         return THFloatTensor_maxall(self.native)
 * 
 */

static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_21max(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static float __pyx_f_7PyTorch_12_FloatTensor_max(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, int __pyx_skip_dispatch) {
  float __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  float __pyx_t_5;
  __Pyx_RefNannySetupContext("max", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_max); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 997, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_21max)) {
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_3 = __pyx_t_1; __pyx_t_4 = NULL;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
        __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
        if (likely(__pyx_t_4)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
          __Pyx_INCREF(__pyx_t_4);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_3, function);
        }
      }
      if (__pyx_t_4) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_4); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 997, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else {
        __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 997, __pyx_L1_error)
      }
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_5 = __pyx_PyFloat_AsFloat(__pyx_t_2); if (unlikely((__pyx_t_5 == (float)-1) && PyErr_Occurred())) __PYX_ERR(0, 997, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_r = __pyx_t_5;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "PyTorch.pyx":998
 * 
 *     cpdef float max(self):
 *         return THFloatTensor_maxall(self.native)             # <<<<<<<<<<<<<<
 * 
 *     cpdef float min(self):
 */
  __pyx_r = THFloatTensor_maxall(__pyx_v_self->native);
  goto __pyx_L0;

  /* "PyTorch.pyx":997
 *         return THFloatTensor_isContiguous(self.native)
 * 
 *     cpdef float max(self):             # <<<<<<<<<<<<<<
 *         return THFloatTensor_maxall(self.native)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_WriteUnraisable("PyTorch._FloatTensor.max", __pyx_clineno, __pyx_lineno, __pyx_filename, 0, 0);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_21max(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_21max(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("max (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_20max(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_20max(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("max", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyFloat_FromDouble(__pyx_f_7PyTorch_12_FloatTensor_max(__pyx_v_self, 1)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 997, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._FloatTensor.max", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1000
 *         return THFloatTensor_maxall(self.native)
 * 
 *     cpdef float min(self):             # <<<<<<<<<<<<<<
 *         return THFloatTensor_minall(self.native)
 * 
 */

static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_23min(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static float __pyx_f_7PyTorch_12_FloatTensor_min(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, int __pyx_skip_dispatch) {
  float __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  float __pyx_t_5;
  __Pyx_RefNannySetupContext("min", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_min); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1000, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_23min)) {
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_3 = __pyx_t_1; __pyx_t_4 = NULL;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
        __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
        if (likely(__pyx_t_4)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
          __Pyx_INCREF(__pyx_t_4);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_3, function);
        }
      }
      if (__pyx_t_4) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_4); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1000, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else {
        __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1000, __pyx_L1_error)
      }
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_5 = __pyx_PyFloat_AsFloat(__pyx_t_2); if (unlikely((__pyx_t_5 == (float)-1) && PyErr_Occurred())) __PYX_ERR(0, 1000, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_r = __pyx_t_5;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "PyTorch.pyx":1001
 * 
 *     cpdef float min(self):
 *         return THFloatTensor_minall(self.native)             # <<<<<<<<<<<<<<
 * 
 *     def __repr__(_FloatTensor self):
 */
  __pyx_r = THFloatTensor_minall(__pyx_v_self->native);
  goto __pyx_L0;

  /* "PyTorch.pyx":1000
 *         return THFloatTensor_maxall(self.native)
 * 
 *     cpdef float min(self):             # <<<<<<<<<<<<<<
 *         return THFloatTensor_minall(self.native)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_WriteUnraisable("PyTorch._FloatTensor.min", __pyx_clineno, __pyx_lineno, __pyx_filename, 0, 0);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_23min(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_23min(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("min (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_22min(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_22min(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("min", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyFloat_FromDouble(__pyx_f_7PyTorch_12_FloatTensor_min(__pyx_v_self, 1)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1000, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._FloatTensor.min", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1003
 *         return THFloatTensor_minall(self.native)
 * 
 *     def __repr__(_FloatTensor self):             # <<<<<<<<<<<<<<
 *         return self.as_string(self)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_25__repr__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_25__repr__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__repr__ (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_24__repr__(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_24__repr__(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  __Pyx_RefNannySetupContext("__repr__", 0);

  /* "PyTorch.pyx":1004
 * 
 *     def __repr__(_FloatTensor self):
 *         return self.as_string(self)             # <<<<<<<<<<<<<<
 * 
 *     def as_string(_FloatTensor self, show_size=True):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_as_string); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1004, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (!__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, ((PyObject *)__pyx_v_self)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1004, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
  } else {
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_2)) {
      PyObject *__pyx_temp[2] = {__pyx_t_3, ((PyObject *)__pyx_v_self)};
      __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1004, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_GOTREF(__pyx_t_1);
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
      PyObject *__pyx_temp[2] = {__pyx_t_3, ((PyObject *)__pyx_v_self)};
      __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1004, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_GOTREF(__pyx_t_1);
    } else
    #endif
    {
      __pyx_t_4 = PyTuple_New(1+1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1004, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_GIVEREF(__pyx_t_3); PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_3); __pyx_t_3 = NULL;
      __Pyx_INCREF(((PyObject *)__pyx_v_self));
      __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
      PyTuple_SET_ITEM(__pyx_t_4, 0+1, ((PyObject *)__pyx_v_self));
      __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_4, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1004, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    }
  }
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":1003
 *         return THFloatTensor_minall(self.native)
 * 
 *     def __repr__(_FloatTensor self):             # <<<<<<<<<<<<<<
 *         return self.as_string(self)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("PyTorch._FloatTensor.__repr__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1006
 *         return self.as_string(self)
 * 
 *     def as_string(_FloatTensor self, show_size=True):             # <<<<<<<<<<<<<<
 *         # assume 2d matrix for now
 *         cdef int size0
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_27as_string(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_27as_string(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_show_size = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("as_string (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_show_size,0};
    PyObject* values[1] = {0};
    values[0] = ((PyObject *)Py_True);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_show_size);
          if (value) { values[0] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "as_string") < 0)) __PYX_ERR(0, 1006, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_show_size = values[0];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("as_string", 0, 0, 1, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1006, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._FloatTensor.as_string", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_26as_string(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self), __pyx_v_show_size);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_26as_string(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, PyObject *__pyx_v_show_size) {
  int __pyx_v_size0;
  int __pyx_v_size1;
  int __pyx_v_dims;
  PyObject *__pyx_v_res = NULL;
  int __pyx_v_r;
  PyObject *__pyx_v_thisline = NULL;
  int __pyx_v_c;
  PyObject *__pyx_v_d = NULL;
  int __pyx_v_first;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  int __pyx_t_3;
  int __pyx_t_4;
  int __pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  Py_ssize_t __pyx_t_9;
  PyObject *(*__pyx_t_10)(PyObject *);
  PyObject *__pyx_t_11 = NULL;
  __Pyx_RefNannySetupContext("as_string", 0);

  /* "PyTorch.pyx":1010
 *         cdef int size0
 *         cdef int size1
 *         dims = self.dims()             # <<<<<<<<<<<<<<
 *         if dims == 0:
 *             return '[torch.FloatTensor with no dimension]\n'
 */
  __pyx_v_dims = ((struct __pyx_vtabstruct_7PyTorch__FloatTensor *)__pyx_v_self->__pyx_vtab)->dims(__pyx_v_self, 0);

  /* "PyTorch.pyx":1011
 *         cdef int size1
 *         dims = self.dims()
 *         if dims == 0:             # <<<<<<<<<<<<<<
 *             return '[torch.FloatTensor with no dimension]\n'
 *         elif dims == 2:
 */
  switch (__pyx_v_dims) {
    case 0:

    /* "PyTorch.pyx":1012
 *         dims = self.dims()
 *         if dims == 0:
 *             return '[torch.FloatTensor with no dimension]\n'             # <<<<<<<<<<<<<<
 *         elif dims == 2:
 *             size0 = THFloatTensor_size(self.native, 0)
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(__pyx_kp_s_torch_FloatTensor_with_no_dimen);
    __pyx_r = __pyx_kp_s_torch_FloatTensor_with_no_dimen;
    goto __pyx_L0;

    /* "PyTorch.pyx":1011
 *         cdef int size1
 *         dims = self.dims()
 *         if dims == 0:             # <<<<<<<<<<<<<<
 *             return '[torch.FloatTensor with no dimension]\n'
 *         elif dims == 2:
 */
    break;

    /* "PyTorch.pyx":1013
 *         if dims == 0:
 *             return '[torch.FloatTensor with no dimension]\n'
 *         elif dims == 2:             # <<<<<<<<<<<<<<
 *             size0 = THFloatTensor_size(self.native, 0)
 *             size1 = THFloatTensor_size(self.native, 1)
 */
    case 2:

    /* "PyTorch.pyx":1014
 *             return '[torch.FloatTensor with no dimension]\n'
 *         elif dims == 2:
 *             size0 = THFloatTensor_size(self.native, 0)             # <<<<<<<<<<<<<<
 *             size1 = THFloatTensor_size(self.native, 1)
 *             res = ''
 */
    __pyx_v_size0 = THFloatTensor_size(__pyx_v_self->native, 0);

    /* "PyTorch.pyx":1015
 *         elif dims == 2:
 *             size0 = THFloatTensor_size(self.native, 0)
 *             size1 = THFloatTensor_size(self.native, 1)             # <<<<<<<<<<<<<<
 *             res = ''
 *             for r in range(size0):
 */
    __pyx_v_size1 = THFloatTensor_size(__pyx_v_self->native, 1);

    /* "PyTorch.pyx":1016
 *             size0 = THFloatTensor_size(self.native, 0)
 *             size1 = THFloatTensor_size(self.native, 1)
 *             res = ''             # <<<<<<<<<<<<<<
 *             for r in range(size0):
 *                 thisline = ''
 */
    __Pyx_INCREF(__pyx_kp_s__7);
    __pyx_v_res = __pyx_kp_s__7;

    /* "PyTorch.pyx":1017
 *             size1 = THFloatTensor_size(self.native, 1)
 *             res = ''
 *             for r in range(size0):             # <<<<<<<<<<<<<<
 *                 thisline = ''
 *                 for c in range(size1):
 */
    __pyx_t_1 = __pyx_v_size0;
    for (__pyx_t_2 = 0; __pyx_t_2 < __pyx_t_1; __pyx_t_2+=1) {
      __pyx_v_r = __pyx_t_2;

      /* "PyTorch.pyx":1018
 *             res = ''
 *             for r in range(size0):
 *                 thisline = ''             # <<<<<<<<<<<<<<
 *                 for c in range(size1):
 *                     if c > 0:
 */
      __Pyx_INCREF(__pyx_kp_s__7);
      __Pyx_XDECREF_SET(__pyx_v_thisline, __pyx_kp_s__7);

      /* "PyTorch.pyx":1019
 *             for r in range(size0):
 *                 thisline = ''
 *                 for c in range(size1):             # <<<<<<<<<<<<<<
 *                     if c > 0:
 *                         thisline += ' '
 */
      __pyx_t_3 = __pyx_v_size1;
      for (__pyx_t_4 = 0; __pyx_t_4 < __pyx_t_3; __pyx_t_4+=1) {
        __pyx_v_c = __pyx_t_4;

        /* "PyTorch.pyx":1020
 *                 thisline = ''
 *                 for c in range(size1):
 *                     if c > 0:             # <<<<<<<<<<<<<<
 *                         thisline += ' '
 * 
 */
        __pyx_t_5 = ((__pyx_v_c > 0) != 0);
        if (__pyx_t_5) {

          /* "PyTorch.pyx":1021
 *                 for c in range(size1):
 *                     if c > 0:
 *                         thisline += ' '             # <<<<<<<<<<<<<<
 * 
 *                     thisline += floatToString(self.get2d(r,c),)
 */
          __pyx_t_6 = PyNumber_InPlaceAdd(__pyx_v_thisline, __pyx_kp_s__8); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1021, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_6);
          __Pyx_DECREF_SET(__pyx_v_thisline, __pyx_t_6);
          __pyx_t_6 = 0;

          /* "PyTorch.pyx":1020
 *                 thisline = ''
 *                 for c in range(size1):
 *                     if c > 0:             # <<<<<<<<<<<<<<
 *                         thisline += ' '
 * 
 */
        }

        /* "PyTorch.pyx":1023
 *                         thisline += ' '
 * 
 *                     thisline += floatToString(self.get2d(r,c),)             # <<<<<<<<<<<<<<
 * 
 *                 res += thisline + '\n'
 */
        __pyx_t_6 = __pyx_f_7PyTorch_floatToString(((struct __pyx_vtabstruct_7PyTorch__FloatTensor *)__pyx_v_self->__pyx_vtab)->get2d(__pyx_v_self, __pyx_v_r, __pyx_v_c, 0)); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1023, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __pyx_t_7 = PyNumber_InPlaceAdd(__pyx_v_thisline, __pyx_t_6); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1023, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_DECREF_SET(__pyx_v_thisline, __pyx_t_7);
        __pyx_t_7 = 0;
      }

      /* "PyTorch.pyx":1025
 *                     thisline += floatToString(self.get2d(r,c),)
 * 
 *                 res += thisline + '\n'             # <<<<<<<<<<<<<<
 *             if show_size:
 *                 res += '[torch.FloatTensor of size ' + ('%.0f' % size0) + 'x' + str(size1) + ']\n'
 */
      __pyx_t_7 = PyNumber_Add(__pyx_v_thisline, __pyx_kp_s__9); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1025, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __pyx_t_6 = PyNumber_InPlaceAdd(__pyx_v_res, __pyx_t_7); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1025, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_DECREF_SET(__pyx_v_res, __pyx_t_6);
      __pyx_t_6 = 0;
    }

    /* "PyTorch.pyx":1026
 * 
 *                 res += thisline + '\n'
 *             if show_size:             # <<<<<<<<<<<<<<
 *                 res += '[torch.FloatTensor of size ' + ('%.0f' % size0) + 'x' + str(size1) + ']\n'
 *             return res
 */
    __pyx_t_5 = __Pyx_PyObject_IsTrue(__pyx_v_show_size); if (unlikely(__pyx_t_5 < 0)) __PYX_ERR(0, 1026, __pyx_L1_error)
    if (__pyx_t_5) {

      /* "PyTorch.pyx":1027
 *                 res += thisline + '\n'
 *             if show_size:
 *                 res += '[torch.FloatTensor of size ' + ('%.0f' % size0) + 'x' + str(size1) + ']\n'             # <<<<<<<<<<<<<<
 *             return res
 *         elif dims == 1:
 */
      __pyx_t_6 = __Pyx_PyInt_From_int(__pyx_v_size0); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1027, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __pyx_t_7 = __Pyx_PyString_Format(__pyx_kp_s_0f, __pyx_t_6); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1027, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_6 = PyNumber_Add(__pyx_kp_s_torch_FloatTensor_of_size, __pyx_t_7); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1027, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __pyx_t_7 = PyNumber_Add(__pyx_t_6, __pyx_n_s_x); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1027, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_6 = __Pyx_PyInt_From_int(__pyx_v_size1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1027, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __pyx_t_8 = PyTuple_New(1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1027, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_GIVEREF(__pyx_t_6);
      PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_t_6);
      __pyx_t_6 = 0;
      __pyx_t_6 = __Pyx_PyObject_Call(((PyObject *)(&PyString_Type)), __pyx_t_8, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1027, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_8 = PyNumber_Add(__pyx_t_7, __pyx_t_6); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1027, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_6 = PyNumber_Add(__pyx_t_8, __pyx_kp_s__10); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1027, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_8 = PyNumber_InPlaceAdd(__pyx_v_res, __pyx_t_6); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1027, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_DECREF_SET(__pyx_v_res, __pyx_t_8);
      __pyx_t_8 = 0;

      /* "PyTorch.pyx":1026
 * 
 *                 res += thisline + '\n'
 *             if show_size:             # <<<<<<<<<<<<<<
 *                 res += '[torch.FloatTensor of size ' + ('%.0f' % size0) + 'x' + str(size1) + ']\n'
 *             return res
 */
    }

    /* "PyTorch.pyx":1028
 *             if show_size:
 *                 res += '[torch.FloatTensor of size ' + ('%.0f' % size0) + 'x' + str(size1) + ']\n'
 *             return res             # <<<<<<<<<<<<<<
 *         elif dims == 1:
 *             size0 = THFloatTensor_size(self.native, 0)
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(__pyx_v_res);
    __pyx_r = __pyx_v_res;
    goto __pyx_L0;

    /* "PyTorch.pyx":1013
 *         if dims == 0:
 *             return '[torch.FloatTensor with no dimension]\n'
 *         elif dims == 2:             # <<<<<<<<<<<<<<
 *             size0 = THFloatTensor_size(self.native, 0)
 *             size1 = THFloatTensor_size(self.native, 1)
 */
    break;

    /* "PyTorch.pyx":1029
 *                 res += '[torch.FloatTensor of size ' + ('%.0f' % size0) + 'x' + str(size1) + ']\n'
 *             return res
 *         elif dims == 1:             # <<<<<<<<<<<<<<
 *             size0 = THFloatTensor_size(self.native, 0)
 *             res = ''
 */
    case 1:

    /* "PyTorch.pyx":1030
 *             return res
 *         elif dims == 1:
 *             size0 = THFloatTensor_size(self.native, 0)             # <<<<<<<<<<<<<<
 *             res = ''
 *             thisline = ''
 */
    __pyx_v_size0 = THFloatTensor_size(__pyx_v_self->native, 0);

    /* "PyTorch.pyx":1031
 *         elif dims == 1:
 *             size0 = THFloatTensor_size(self.native, 0)
 *             res = ''             # <<<<<<<<<<<<<<
 *             thisline = ''
 *             for c in range(size0):
 */
    __Pyx_INCREF(__pyx_kp_s__7);
    __pyx_v_res = __pyx_kp_s__7;

    /* "PyTorch.pyx":1032
 *             size0 = THFloatTensor_size(self.native, 0)
 *             res = ''
 *             thisline = ''             # <<<<<<<<<<<<<<
 *             for c in range(size0):
 *                 if c > 0:
 */
    __Pyx_INCREF(__pyx_kp_s__7);
    __pyx_v_thisline = __pyx_kp_s__7;

    /* "PyTorch.pyx":1033
 *             res = ''
 *             thisline = ''
 *             for c in range(size0):             # <<<<<<<<<<<<<<
 *                 if c > 0:
 *                     thisline += ' '
 */
    __pyx_t_1 = __pyx_v_size0;
    for (__pyx_t_2 = 0; __pyx_t_2 < __pyx_t_1; __pyx_t_2+=1) {
      __pyx_v_c = __pyx_t_2;

      /* "PyTorch.pyx":1034
 *             thisline = ''
 *             for c in range(size0):
 *                 if c > 0:             # <<<<<<<<<<<<<<
 *                     thisline += ' '
 * 
 */
      __pyx_t_5 = ((__pyx_v_c > 0) != 0);
      if (__pyx_t_5) {

        /* "PyTorch.pyx":1035
 *             for c in range(size0):
 *                 if c > 0:
 *                     thisline += ' '             # <<<<<<<<<<<<<<
 * 
 *                 thisline += floatToString(self.get1d(c))
 */
        __pyx_t_8 = PyNumber_InPlaceAdd(__pyx_v_thisline, __pyx_kp_s__8); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1035, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        __Pyx_DECREF_SET(__pyx_v_thisline, __pyx_t_8);
        __pyx_t_8 = 0;

        /* "PyTorch.pyx":1034
 *             thisline = ''
 *             for c in range(size0):
 *                 if c > 0:             # <<<<<<<<<<<<<<
 *                     thisline += ' '
 * 
 */
      }

      /* "PyTorch.pyx":1037
 *                     thisline += ' '
 * 
 *                 thisline += floatToString(self.get1d(c))             # <<<<<<<<<<<<<<
 * 
 *             res += thisline + '\n'
 */
      __pyx_t_8 = __pyx_f_7PyTorch_floatToString(((struct __pyx_vtabstruct_7PyTorch__FloatTensor *)__pyx_v_self->__pyx_vtab)->get1d(__pyx_v_self, __pyx_v_c, 0)); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1037, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_6 = PyNumber_InPlaceAdd(__pyx_v_thisline, __pyx_t_8); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1037, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_DECREF_SET(__pyx_v_thisline, __pyx_t_6);
      __pyx_t_6 = 0;
    }

    /* "PyTorch.pyx":1039
 *                 thisline += floatToString(self.get1d(c))
 * 
 *             res += thisline + '\n'             # <<<<<<<<<<<<<<
 *             if show_size:
 *                 res += '[torch.FloatTensor of size ' + str(size0) + ']\n'
 */
    __pyx_t_6 = PyNumber_Add(__pyx_v_thisline, __pyx_kp_s__9); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1039, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_8 = PyNumber_InPlaceAdd(__pyx_v_res, __pyx_t_6); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1039, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_DECREF_SET(__pyx_v_res, __pyx_t_8);
    __pyx_t_8 = 0;

    /* "PyTorch.pyx":1040
 * 
 *             res += thisline + '\n'
 *             if show_size:             # <<<<<<<<<<<<<<
 *                 res += '[torch.FloatTensor of size ' + str(size0) + ']\n'
 *             return res
 */
    __pyx_t_5 = __Pyx_PyObject_IsTrue(__pyx_v_show_size); if (unlikely(__pyx_t_5 < 0)) __PYX_ERR(0, 1040, __pyx_L1_error)
    if (__pyx_t_5) {

      /* "PyTorch.pyx":1041
 *             res += thisline + '\n'
 *             if show_size:
 *                 res += '[torch.FloatTensor of size ' + str(size0) + ']\n'             # <<<<<<<<<<<<<<
 *             return res
 *         elif dims == 3:
 */
      __pyx_t_8 = __Pyx_PyInt_From_int(__pyx_v_size0); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1041, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_6 = PyTuple_New(1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1041, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_GIVEREF(__pyx_t_8);
      PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_8);
      __pyx_t_8 = 0;
      __pyx_t_8 = __Pyx_PyObject_Call(((PyObject *)(&PyString_Type)), __pyx_t_6, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1041, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_6 = PyNumber_Add(__pyx_kp_s_torch_FloatTensor_of_size, __pyx_t_8); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1041, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_8 = PyNumber_Add(__pyx_t_6, __pyx_kp_s__10); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1041, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_6 = PyNumber_InPlaceAdd(__pyx_v_res, __pyx_t_8); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1041, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_DECREF_SET(__pyx_v_res, __pyx_t_6);
      __pyx_t_6 = 0;

      /* "PyTorch.pyx":1040
 * 
 *             res += thisline + '\n'
 *             if show_size:             # <<<<<<<<<<<<<<
 *                 res += '[torch.FloatTensor of size ' + str(size0) + ']\n'
 *             return res
 */
    }

    /* "PyTorch.pyx":1042
 *             if show_size:
 *                 res += '[torch.FloatTensor of size ' + str(size0) + ']\n'
 *             return res             # <<<<<<<<<<<<<<
 *         elif dims == 3:
 *             res = ''
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(__pyx_v_res);
    __pyx_r = __pyx_v_res;
    goto __pyx_L0;

    /* "PyTorch.pyx":1029
 *                 res += '[torch.FloatTensor of size ' + ('%.0f' % size0) + 'x' + str(size1) + ']\n'
 *             return res
 *         elif dims == 1:             # <<<<<<<<<<<<<<
 *             size0 = THFloatTensor_size(self.native, 0)
 *             res = ''
 */
    break;

    /* "PyTorch.pyx":1043
 *                 res += '[torch.FloatTensor of size ' + str(size0) + ']\n'
 *             return res
 *         elif dims == 3:             # <<<<<<<<<<<<<<
 *             res = ''
 *             for d in range(self.size()[0]):
 */
    case 3:

    /* "PyTorch.pyx":1044
 *             return res
 *         elif dims == 3:
 *             res = ''             # <<<<<<<<<<<<<<
 *             for d in range(self.size()[0]):
 *                 res += '(' + str(d) + ',.,.) =\n'
 */
    __Pyx_INCREF(__pyx_kp_s__7);
    __pyx_v_res = __pyx_kp_s__7;

    /* "PyTorch.pyx":1045
 *         elif dims == 3:
 *             res = ''
 *             for d in range(self.size()[0]):             # <<<<<<<<<<<<<<
 *                 res += '(' + str(d) + ',.,.) =\n'
 *                 res += self[d].as_string(show_size=False)
 */
    __pyx_t_8 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_size); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1045, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_7 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_8))) {
      __pyx_t_7 = PyMethod_GET_SELF(__pyx_t_8);
      if (likely(__pyx_t_7)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_8);
        __Pyx_INCREF(__pyx_t_7);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_8, function);
      }
    }
    if (__pyx_t_7) {
      __pyx_t_6 = __Pyx_PyObject_CallOneArg(__pyx_t_8, __pyx_t_7); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1045, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    } else {
      __pyx_t_6 = __Pyx_PyObject_CallNoArg(__pyx_t_8); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1045, __pyx_L1_error)
    }
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_6, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1045, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_6 = PyTuple_New(1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1045, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_GIVEREF(__pyx_t_8);
    PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_8);
    __pyx_t_8 = 0;
    __pyx_t_8 = __Pyx_PyObject_Call(__pyx_builtin_range, __pyx_t_6, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1045, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    if (likely(PyList_CheckExact(__pyx_t_8)) || PyTuple_CheckExact(__pyx_t_8)) {
      __pyx_t_6 = __pyx_t_8; __Pyx_INCREF(__pyx_t_6); __pyx_t_9 = 0;
      __pyx_t_10 = NULL;
    } else {
      __pyx_t_9 = -1; __pyx_t_6 = PyObject_GetIter(__pyx_t_8); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1045, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __pyx_t_10 = Py_TYPE(__pyx_t_6)->tp_iternext; if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 1045, __pyx_L1_error)
    }
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    for (;;) {
      if (likely(!__pyx_t_10)) {
        if (likely(PyList_CheckExact(__pyx_t_6))) {
          if (__pyx_t_9 >= PyList_GET_SIZE(__pyx_t_6)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_8 = PyList_GET_ITEM(__pyx_t_6, __pyx_t_9); __Pyx_INCREF(__pyx_t_8); __pyx_t_9++; if (unlikely(0 < 0)) __PYX_ERR(0, 1045, __pyx_L1_error)
          #else
          __pyx_t_8 = PySequence_ITEM(__pyx_t_6, __pyx_t_9); __pyx_t_9++; if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1045, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_8);
          #endif
        } else {
          if (__pyx_t_9 >= PyTuple_GET_SIZE(__pyx_t_6)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_8 = PyTuple_GET_ITEM(__pyx_t_6, __pyx_t_9); __Pyx_INCREF(__pyx_t_8); __pyx_t_9++; if (unlikely(0 < 0)) __PYX_ERR(0, 1045, __pyx_L1_error)
          #else
          __pyx_t_8 = PySequence_ITEM(__pyx_t_6, __pyx_t_9); __pyx_t_9++; if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1045, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_8);
          #endif
        }
      } else {
        __pyx_t_8 = __pyx_t_10(__pyx_t_6);
        if (unlikely(!__pyx_t_8)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(exc_type == PyExc_StopIteration || PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 1045, __pyx_L1_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_8);
      }
      __Pyx_XDECREF_SET(__pyx_v_d, __pyx_t_8);
      __pyx_t_8 = 0;

      /* "PyTorch.pyx":1046
 *             res = ''
 *             for d in range(self.size()[0]):
 *                 res += '(' + str(d) + ',.,.) =\n'             # <<<<<<<<<<<<<<
 *                 res += self[d].as_string(show_size=False)
 *             res += '\ntorch.FloatTensor of size '
 */
      __pyx_t_8 = PyTuple_New(1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1046, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_INCREF(__pyx_v_d);
      __Pyx_GIVEREF(__pyx_v_d);
      PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_v_d);
      __pyx_t_7 = __Pyx_PyObject_Call(((PyObject *)(&PyString_Type)), __pyx_t_8, NULL); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1046, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_8 = PyNumber_Add(__pyx_kp_s__11, __pyx_t_7); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1046, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __pyx_t_7 = PyNumber_Add(__pyx_t_8, __pyx_kp_s__12); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1046, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_8 = PyNumber_InPlaceAdd(__pyx_v_res, __pyx_t_7); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1046, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_DECREF_SET(__pyx_v_res, __pyx_t_8);
      __pyx_t_8 = 0;

      /* "PyTorch.pyx":1047
 *             for d in range(self.size()[0]):
 *                 res += '(' + str(d) + ',.,.) =\n'
 *                 res += self[d].as_string(show_size=False)             # <<<<<<<<<<<<<<
 *             res += '\ntorch.FloatTensor of size '
 *             first = True
 */
      __pyx_t_8 = PyObject_GetItem(((PyObject *)__pyx_v_self), __pyx_v_d); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1047, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_t_8, __pyx_n_s_as_string); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1047, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_8 = PyDict_New(); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1047, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      if (PyDict_SetItem(__pyx_t_8, __pyx_n_s_show_size, Py_False) < 0) __PYX_ERR(0, 1047, __pyx_L1_error)
      __pyx_t_11 = __Pyx_PyObject_Call(__pyx_t_7, __pyx_empty_tuple, __pyx_t_8); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 1047, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_11);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_8 = PyNumber_InPlaceAdd(__pyx_v_res, __pyx_t_11); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1047, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
      __Pyx_DECREF_SET(__pyx_v_res, __pyx_t_8);
      __pyx_t_8 = 0;

      /* "PyTorch.pyx":1045
 *         elif dims == 3:
 *             res = ''
 *             for d in range(self.size()[0]):             # <<<<<<<<<<<<<<
 *                 res += '(' + str(d) + ',.,.) =\n'
 *                 res += self[d].as_string(show_size=False)
 */
    }
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;

    /* "PyTorch.pyx":1048
 *                 res += '(' + str(d) + ',.,.) =\n'
 *                 res += self[d].as_string(show_size=False)
 *             res += '\ntorch.FloatTensor of size '             # <<<<<<<<<<<<<<
 *             first = True
 *             for d in self.size():
 */
    __pyx_t_6 = PyNumber_InPlaceAdd(__pyx_v_res, __pyx_kp_s_torch_FloatTensor_of_size_2); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1048, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF_SET(__pyx_v_res, __pyx_t_6);
    __pyx_t_6 = 0;

    /* "PyTorch.pyx":1049
 *                 res += self[d].as_string(show_size=False)
 *             res += '\ntorch.FloatTensor of size '
 *             first = True             # <<<<<<<<<<<<<<
 *             for d in self.size():
 *                if not first:
 */
    __pyx_v_first = 1;

    /* "PyTorch.pyx":1050
 *             res += '\ntorch.FloatTensor of size '
 *             first = True
 *             for d in self.size():             # <<<<<<<<<<<<<<
 *                if not first:
 *                   res += 'x'
 */
    __pyx_t_8 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_size); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1050, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_11 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_8))) {
      __pyx_t_11 = PyMethod_GET_SELF(__pyx_t_8);
      if (likely(__pyx_t_11)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_8);
        __Pyx_INCREF(__pyx_t_11);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_8, function);
      }
    }
    if (__pyx_t_11) {
      __pyx_t_6 = __Pyx_PyObject_CallOneArg(__pyx_t_8, __pyx_t_11); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1050, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
    } else {
      __pyx_t_6 = __Pyx_PyObject_CallNoArg(__pyx_t_8); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1050, __pyx_L1_error)
    }
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    if (likely(PyList_CheckExact(__pyx_t_6)) || PyTuple_CheckExact(__pyx_t_6)) {
      __pyx_t_8 = __pyx_t_6; __Pyx_INCREF(__pyx_t_8); __pyx_t_9 = 0;
      __pyx_t_10 = NULL;
    } else {
      __pyx_t_9 = -1; __pyx_t_8 = PyObject_GetIter(__pyx_t_6); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1050, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_10 = Py_TYPE(__pyx_t_8)->tp_iternext; if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 1050, __pyx_L1_error)
    }
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    for (;;) {
      if (likely(!__pyx_t_10)) {
        if (likely(PyList_CheckExact(__pyx_t_8))) {
          if (__pyx_t_9 >= PyList_GET_SIZE(__pyx_t_8)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_6 = PyList_GET_ITEM(__pyx_t_8, __pyx_t_9); __Pyx_INCREF(__pyx_t_6); __pyx_t_9++; if (unlikely(0 < 0)) __PYX_ERR(0, 1050, __pyx_L1_error)
          #else
          __pyx_t_6 = PySequence_ITEM(__pyx_t_8, __pyx_t_9); __pyx_t_9++; if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1050, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_6);
          #endif
        } else {
          if (__pyx_t_9 >= PyTuple_GET_SIZE(__pyx_t_8)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_6 = PyTuple_GET_ITEM(__pyx_t_8, __pyx_t_9); __Pyx_INCREF(__pyx_t_6); __pyx_t_9++; if (unlikely(0 < 0)) __PYX_ERR(0, 1050, __pyx_L1_error)
          #else
          __pyx_t_6 = PySequence_ITEM(__pyx_t_8, __pyx_t_9); __pyx_t_9++; if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1050, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_6);
          #endif
        }
      } else {
        __pyx_t_6 = __pyx_t_10(__pyx_t_8);
        if (unlikely(!__pyx_t_6)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(exc_type == PyExc_StopIteration || PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 1050, __pyx_L1_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_6);
      }
      __Pyx_XDECREF_SET(__pyx_v_d, __pyx_t_6);
      __pyx_t_6 = 0;

      /* "PyTorch.pyx":1051
 *             first = True
 *             for d in self.size():
 *                if not first:             # <<<<<<<<<<<<<<
 *                   res += 'x'
 *                res += str(d)
 */
      __pyx_t_5 = ((!(__pyx_v_first != 0)) != 0);
      if (__pyx_t_5) {

        /* "PyTorch.pyx":1052
 *             for d in self.size():
 *                if not first:
 *                   res += 'x'             # <<<<<<<<<<<<<<
 *                res += str(d)
 *                first = False
 */
        __pyx_t_6 = PyNumber_InPlaceAdd(__pyx_v_res, __pyx_n_s_x); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1052, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __Pyx_DECREF_SET(__pyx_v_res, __pyx_t_6);
        __pyx_t_6 = 0;

        /* "PyTorch.pyx":1051
 *             first = True
 *             for d in self.size():
 *                if not first:             # <<<<<<<<<<<<<<
 *                   res += 'x'
 *                res += str(d)
 */
      }

      /* "PyTorch.pyx":1053
 *                if not first:
 *                   res += 'x'
 *                res += str(d)             # <<<<<<<<<<<<<<
 *                first = False
 *             res += ']'
 */
      __pyx_t_6 = PyTuple_New(1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1053, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_INCREF(__pyx_v_d);
      __Pyx_GIVEREF(__pyx_v_d);
      PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_v_d);
      __pyx_t_11 = __Pyx_PyObject_Call(((PyObject *)(&PyString_Type)), __pyx_t_6, NULL); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 1053, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_11);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_6 = PyNumber_InPlaceAdd(__pyx_v_res, __pyx_t_11); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1053, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
      __Pyx_DECREF_SET(__pyx_v_res, __pyx_t_6);
      __pyx_t_6 = 0;

      /* "PyTorch.pyx":1054
 *                   res += 'x'
 *                res += str(d)
 *                first = False             # <<<<<<<<<<<<<<
 *             res += ']'
 *             return res
 */
      __pyx_v_first = 0;

      /* "PyTorch.pyx":1050
 *             res += '\ntorch.FloatTensor of size '
 *             first = True
 *             for d in self.size():             # <<<<<<<<<<<<<<
 *                if not first:
 *                   res += 'x'
 */
    }
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;

    /* "PyTorch.pyx":1055
 *                res += str(d)
 *                first = False
 *             res += ']'             # <<<<<<<<<<<<<<
 *             return res
 *         else:
 */
    __pyx_t_8 = PyNumber_InPlaceAdd(__pyx_v_res, __pyx_kp_s__13); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1055, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF_SET(__pyx_v_res, __pyx_t_8);
    __pyx_t_8 = 0;

    /* "PyTorch.pyx":1056
 *                first = False
 *             res += ']'
 *             return res             # <<<<<<<<<<<<<<
 *         else:
 *             raise Exception("Not implemented: dims > 2")
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(__pyx_v_res);
    __pyx_r = __pyx_v_res;
    goto __pyx_L0;

    /* "PyTorch.pyx":1043
 *                 res += '[torch.FloatTensor of size ' + str(size0) + ']\n'
 *             return res
 *         elif dims == 3:             # <<<<<<<<<<<<<<
 *             res = ''
 *             for d in range(self.size()[0]):
 */
    break;
    default:

    /* "PyTorch.pyx":1058
 *             return res
 *         else:
 *             raise Exception("Not implemented: dims > 2")             # <<<<<<<<<<<<<<
 * 
 *     def __getitem__(_FloatTensor self, int index):
 */
    __pyx_t_8 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_tuple__22, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1058, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_Raise(__pyx_t_8, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __PYX_ERR(0, 1058, __pyx_L1_error)
    break;
  }

  /* "PyTorch.pyx":1006
 *         return self.as_string(self)
 * 
 *     def as_string(_FloatTensor self, show_size=True):             # <<<<<<<<<<<<<<
 *         # assume 2d matrix for now
 *         cdef int size0
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_11);
  __Pyx_AddTraceback("PyTorch._FloatTensor.as_string", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_res);
  __Pyx_XDECREF(__pyx_v_thisline);
  __Pyx_XDECREF(__pyx_v_d);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1060
 *             raise Exception("Not implemented: dims > 2")
 * 
 *     def __getitem__(_FloatTensor self, int index):             # <<<<<<<<<<<<<<
 *         if self.dims() == 1:
 *             return self.get1d(index)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_29__getitem__(PyObject *__pyx_v_self, PyObject *__pyx_arg_index); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_29__getitem__(PyObject *__pyx_v_self, PyObject *__pyx_arg_index) {
  int __pyx_v_index;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__getitem__ (wrapper)", 0);
  assert(__pyx_arg_index); {
    __pyx_v_index = __Pyx_PyInt_As_int(__pyx_arg_index); if (unlikely((__pyx_v_index == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1060, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._FloatTensor.__getitem__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_28__getitem__(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self), ((int)__pyx_v_index));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_28__getitem__(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, int __pyx_v_index) {
  struct THFloatTensor *__pyx_v_res;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  struct __pyx_opt_args_7PyTorch__FloatTensor_fromNative __pyx_t_3;
  __Pyx_RefNannySetupContext("__getitem__", 0);

  /* "PyTorch.pyx":1061
 * 
 *     def __getitem__(_FloatTensor self, int index):
 *         if self.dims() == 1:             # <<<<<<<<<<<<<<
 *             return self.get1d(index)
 *         cdef THFloatTensor *res = THFloatTensor_newSelect(self.native, 0, index)
 */
  __pyx_t_1 = ((((struct __pyx_vtabstruct_7PyTorch__FloatTensor *)__pyx_v_self->__pyx_vtab)->dims(__pyx_v_self, 0) == 1) != 0);
  if (__pyx_t_1) {

    /* "PyTorch.pyx":1062
 *     def __getitem__(_FloatTensor self, int index):
 *         if self.dims() == 1:
 *             return self.get1d(index)             # <<<<<<<<<<<<<<
 *         cdef THFloatTensor *res = THFloatTensor_newSelect(self.native, 0, index)
 *         return _FloatTensor_fromNative(res, False)
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_2 = PyFloat_FromDouble(((struct __pyx_vtabstruct_7PyTorch__FloatTensor *)__pyx_v_self->__pyx_vtab)->get1d(__pyx_v_self, __pyx_v_index, 0)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1062, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_r = __pyx_t_2;
    __pyx_t_2 = 0;
    goto __pyx_L0;

    /* "PyTorch.pyx":1061
 * 
 *     def __getitem__(_FloatTensor self, int index):
 *         if self.dims() == 1:             # <<<<<<<<<<<<<<
 *             return self.get1d(index)
 *         cdef THFloatTensor *res = THFloatTensor_newSelect(self.native, 0, index)
 */
  }

  /* "PyTorch.pyx":1063
 *         if self.dims() == 1:
 *             return self.get1d(index)
 *         cdef THFloatTensor *res = THFloatTensor_newSelect(self.native, 0, index)             # <<<<<<<<<<<<<<
 *         return _FloatTensor_fromNative(res, False)
 * 
 */
  __pyx_v_res = THFloatTensor_newSelect(__pyx_v_self->native, 0, __pyx_v_index);

  /* "PyTorch.pyx":1064
 *             return self.get1d(index)
 *         cdef THFloatTensor *res = THFloatTensor_newSelect(self.native, 0, index)
 *         return _FloatTensor_fromNative(res, False)             # <<<<<<<<<<<<<<
 * 
 *     def __setitem__(_FloatTensor self, int index, float value):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_3.__pyx_n = 1;
  __pyx_t_3.retain = Py_False;
  __pyx_t_2 = __pyx_f_7PyTorch__FloatTensor_fromNative(__pyx_v_res, &__pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1064, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":1060
 *             raise Exception("Not implemented: dims > 2")
 * 
 *     def __getitem__(_FloatTensor self, int index):             # <<<<<<<<<<<<<<
 *         if self.dims() == 1:
 *             return self.get1d(index)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("PyTorch._FloatTensor.__getitem__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1066
 *         return _FloatTensor_fromNative(res, False)
 * 
 *     def __setitem__(_FloatTensor self, int index, float value):             # <<<<<<<<<<<<<<
 *         if self.dims() == 1:
 *             self.set1d(index, value)
 */

/* Python wrapper */
static int __pyx_pw_7PyTorch_12_FloatTensor_31__setitem__(PyObject *__pyx_v_self, PyObject *__pyx_arg_index, PyObject *__pyx_arg_value); /*proto*/
static int __pyx_pw_7PyTorch_12_FloatTensor_31__setitem__(PyObject *__pyx_v_self, PyObject *__pyx_arg_index, PyObject *__pyx_arg_value) {
  int __pyx_v_index;
  float __pyx_v_value;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__setitem__ (wrapper)", 0);
  assert(__pyx_arg_index); {
    __pyx_v_index = __Pyx_PyInt_As_int(__pyx_arg_index); if (unlikely((__pyx_v_index == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1066, __pyx_L3_error)
  }
  assert(__pyx_arg_value); {
    __pyx_v_value = __pyx_PyFloat_AsFloat(__pyx_arg_value); if (unlikely((__pyx_v_value == (float)-1) && PyErr_Occurred())) __PYX_ERR(0, 1066, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._FloatTensor.__setitem__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return -1;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_30__setitem__(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self), ((int)__pyx_v_index), ((float)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_7PyTorch_12_FloatTensor_30__setitem__(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, int __pyx_v_index, float __pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("__setitem__", 0);

  /* "PyTorch.pyx":1067
 * 
 *     def __setitem__(_FloatTensor self, int index, float value):
 *         if self.dims() == 1:             # <<<<<<<<<<<<<<
 *             self.set1d(index, value)
 *         else:
 */
  __pyx_t_1 = ((((struct __pyx_vtabstruct_7PyTorch__FloatTensor *)__pyx_v_self->__pyx_vtab)->dims(__pyx_v_self, 0) == 1) != 0);
  if (__pyx_t_1) {

    /* "PyTorch.pyx":1068
 *     def __setitem__(_FloatTensor self, int index, float value):
 *         if self.dims() == 1:
 *             self.set1d(index, value)             # <<<<<<<<<<<<<<
 *         else:
 *             raise Exception("not implemented")
 */
    __pyx_t_2 = ((struct __pyx_vtabstruct_7PyTorch__FloatTensor *)__pyx_v_self->__pyx_vtab)->set1d(__pyx_v_self, __pyx_v_index, __pyx_v_value, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1068, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

    /* "PyTorch.pyx":1067
 * 
 *     def __setitem__(_FloatTensor self, int index, float value):
 *         if self.dims() == 1:             # <<<<<<<<<<<<<<
 *             self.set1d(index, value)
 *         else:
 */
    goto __pyx_L3;
  }

  /* "PyTorch.pyx":1070
 *             self.set1d(index, value)
 *         else:
 *             raise Exception("not implemented")             # <<<<<<<<<<<<<<
 * 
 *     def fill(_FloatTensor self, float value):
 */
  /*else*/ {
    __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_tuple__23, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1070, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(0, 1070, __pyx_L1_error)
  }
  __pyx_L3:;

  /* "PyTorch.pyx":1066
 *         return _FloatTensor_fromNative(res, False)
 * 
 *     def __setitem__(_FloatTensor self, int index, float value):             # <<<<<<<<<<<<<<
 *         if self.dims() == 1:
 *             self.set1d(index, value)
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("PyTorch._FloatTensor.__setitem__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1072
 *             raise Exception("not implemented")
 * 
 *     def fill(_FloatTensor self, float value):             # <<<<<<<<<<<<<<
 *         THFloatTensor_fill(self.native, value)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_33fill(PyObject *__pyx_v_self, PyObject *__pyx_arg_value); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_33fill(PyObject *__pyx_v_self, PyObject *__pyx_arg_value) {
  float __pyx_v_value;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("fill (wrapper)", 0);
  assert(__pyx_arg_value); {
    __pyx_v_value = __pyx_PyFloat_AsFloat(__pyx_arg_value); if (unlikely((__pyx_v_value == (float)-1) && PyErr_Occurred())) __PYX_ERR(0, 1072, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._FloatTensor.fill", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_32fill(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self), ((float)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_32fill(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, float __pyx_v_value) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("fill", 0);

  /* "PyTorch.pyx":1073
 * 
 *     def fill(_FloatTensor self, float value):
 *         THFloatTensor_fill(self.native, value)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THFloatTensor_fill(__pyx_v_self->native, __pyx_v_value);

  /* "PyTorch.pyx":1074
 *     def fill(_FloatTensor self, float value):
 *         THFloatTensor_fill(self.native, value)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def sum(_FloatTensor self):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1072
 *             raise Exception("not implemented")
 * 
 *     def fill(_FloatTensor self, float value):             # <<<<<<<<<<<<<<
 *         THFloatTensor_fill(self.native, value)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1076
 *         return self
 * 
 *     def sum(_FloatTensor self):             # <<<<<<<<<<<<<<
 *         cdef float result = THFloatTensor_sumall(self.native)
 *         return result
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_35sum(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_35sum(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("sum (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_34sum(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_34sum(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self) {
  float __pyx_v_result;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("sum", 0);

  /* "PyTorch.pyx":1077
 * 
 *     def sum(_FloatTensor self):
 *         cdef float result = THFloatTensor_sumall(self.native)             # <<<<<<<<<<<<<<
 *         return result
 * 
 */
  __pyx_v_result = THFloatTensor_sumall(__pyx_v_self->native);

  /* "PyTorch.pyx":1078
 *     def sum(_FloatTensor self):
 *         cdef float result = THFloatTensor_sumall(self.native)
 *         return result             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyFloat_FromDouble(__pyx_v_result); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1078, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":1076
 *         return self
 * 
 *     def sum(_FloatTensor self):             # <<<<<<<<<<<<<<
 *         cdef float result = THFloatTensor_sumall(self.native)
 *         return result
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._FloatTensor.sum", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1082
 * 
 * 
 *     def itanh(_FloatTensor self):             # <<<<<<<<<<<<<<
 *         THFloatTensor_tanh(self.native, self.native)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_37itanh(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_37itanh(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("itanh (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_36itanh(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_36itanh(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("itanh", 0);

  /* "PyTorch.pyx":1083
 * 
 *     def itanh(_FloatTensor self):
 *         THFloatTensor_tanh(self.native, self.native)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THFloatTensor_tanh(__pyx_v_self->native, __pyx_v_self->native);

  /* "PyTorch.pyx":1084
 *     def itanh(_FloatTensor self):
 *         THFloatTensor_tanh(self.native, self.native)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def isigmoid(_FloatTensor self):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1082
 * 
 * 
 *     def itanh(_FloatTensor self):             # <<<<<<<<<<<<<<
 *         THFloatTensor_tanh(self.native, self.native)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1086
 *         return self
 * 
 *     def isigmoid(_FloatTensor self):             # <<<<<<<<<<<<<<
 *         THFloatTensor_sigmoid(self.native, self.native)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_39isigmoid(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_39isigmoid(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("isigmoid (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_38isigmoid(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_38isigmoid(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("isigmoid", 0);

  /* "PyTorch.pyx":1087
 * 
 *     def isigmoid(_FloatTensor self):
 *         THFloatTensor_sigmoid(self.native, self.native)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THFloatTensor_sigmoid(__pyx_v_self->native, __pyx_v_self->native);

  /* "PyTorch.pyx":1088
 *     def isigmoid(_FloatTensor self):
 *         THFloatTensor_sigmoid(self.native, self.native)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def icinv(_FloatTensor self):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1086
 *         return self
 * 
 *     def isigmoid(_FloatTensor self):             # <<<<<<<<<<<<<<
 *         THFloatTensor_sigmoid(self.native, self.native)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1090
 *         return self
 * 
 *     def icinv(_FloatTensor self):             # <<<<<<<<<<<<<<
 *         THFloatTensor_cinv(self.native, self.native)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_41icinv(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_41icinv(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("icinv (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_40icinv(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_40icinv(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("icinv", 0);

  /* "PyTorch.pyx":1091
 * 
 *     def icinv(_FloatTensor self):
 *         THFloatTensor_cinv(self.native, self.native)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THFloatTensor_cinv(__pyx_v_self->native, __pyx_v_self->native);

  /* "PyTorch.pyx":1092
 *     def icinv(_FloatTensor self):
 *         THFloatTensor_cinv(self.native, self.native)
 *         return self             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1090
 *         return self
 * 
 *     def icinv(_FloatTensor self):             # <<<<<<<<<<<<<<
 *         THFloatTensor_cinv(self.native, self.native)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1095
 * 
 * 
 *     def tanh(_FloatTensor self):             # <<<<<<<<<<<<<<
 *         cdef _FloatTensor res = _FloatTensor.new()
 *         THFloatTensor_tanh(res.native, self.native)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_43tanh(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_43tanh(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("tanh (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_42tanh(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_42tanh(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self) {
  struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_res = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("tanh", 0);

  /* "PyTorch.pyx":1096
 * 
 *     def tanh(_FloatTensor self):
 *         cdef _FloatTensor res = _FloatTensor.new()             # <<<<<<<<<<<<<<
 *         THFloatTensor_tanh(res.native, self.native)
 *         return res
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7PyTorch__FloatTensor), __pyx_n_s_new); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1096, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1096, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1096, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_7PyTorch__FloatTensor))))) __PYX_ERR(0, 1096, __pyx_L1_error)
  __pyx_v_res = ((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":1097
 *     def tanh(_FloatTensor self):
 *         cdef _FloatTensor res = _FloatTensor.new()
 *         THFloatTensor_tanh(res.native, self.native)             # <<<<<<<<<<<<<<
 *         return res
 * 
 */
  THFloatTensor_tanh(__pyx_v_res->native, __pyx_v_self->native);

  /* "PyTorch.pyx":1098
 *         cdef _FloatTensor res = _FloatTensor.new()
 *         THFloatTensor_tanh(res.native, self.native)
 *         return res             # <<<<<<<<<<<<<<
 * 
 *     def sigmoid(_FloatTensor self):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = ((PyObject *)__pyx_v_res);
  goto __pyx_L0;

  /* "PyTorch.pyx":1095
 * 
 * 
 *     def tanh(_FloatTensor self):             # <<<<<<<<<<<<<<
 *         cdef _FloatTensor res = _FloatTensor.new()
 *         THFloatTensor_tanh(res.native, self.native)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("PyTorch._FloatTensor.tanh", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1100
 *         return res
 * 
 *     def sigmoid(_FloatTensor self):             # <<<<<<<<<<<<<<
 *         cdef _FloatTensor res = _FloatTensor.new()
 *         THFloatTensor_sigmoid(res.native, self.native)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_45sigmoid(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_45sigmoid(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("sigmoid (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_44sigmoid(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_44sigmoid(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self) {
  struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_res = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("sigmoid", 0);

  /* "PyTorch.pyx":1101
 * 
 *     def sigmoid(_FloatTensor self):
 *         cdef _FloatTensor res = _FloatTensor.new()             # <<<<<<<<<<<<<<
 *         THFloatTensor_sigmoid(res.native, self.native)
 *         return res
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7PyTorch__FloatTensor), __pyx_n_s_new); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1101, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1101, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1101, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_7PyTorch__FloatTensor))))) __PYX_ERR(0, 1101, __pyx_L1_error)
  __pyx_v_res = ((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":1102
 *     def sigmoid(_FloatTensor self):
 *         cdef _FloatTensor res = _FloatTensor.new()
 *         THFloatTensor_sigmoid(res.native, self.native)             # <<<<<<<<<<<<<<
 *         return res
 * 
 */
  THFloatTensor_sigmoid(__pyx_v_res->native, __pyx_v_self->native);

  /* "PyTorch.pyx":1103
 *         cdef _FloatTensor res = _FloatTensor.new()
 *         THFloatTensor_sigmoid(res.native, self.native)
 *         return res             # <<<<<<<<<<<<<<
 * 
 *     def cinv(_FloatTensor self):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = ((PyObject *)__pyx_v_res);
  goto __pyx_L0;

  /* "PyTorch.pyx":1100
 *         return res
 * 
 *     def sigmoid(_FloatTensor self):             # <<<<<<<<<<<<<<
 *         cdef _FloatTensor res = _FloatTensor.new()
 *         THFloatTensor_sigmoid(res.native, self.native)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("PyTorch._FloatTensor.sigmoid", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1105
 *         return res
 * 
 *     def cinv(_FloatTensor self):             # <<<<<<<<<<<<<<
 *         cdef _FloatTensor res = _FloatTensor.new()
 *         THFloatTensor_cinv(res.native, self.native)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_47cinv(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_47cinv(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cinv (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_46cinv(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_46cinv(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self) {
  struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_res = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("cinv", 0);

  /* "PyTorch.pyx":1106
 * 
 *     def cinv(_FloatTensor self):
 *         cdef _FloatTensor res = _FloatTensor.new()             # <<<<<<<<<<<<<<
 *         THFloatTensor_cinv(res.native, self.native)
 *         return res
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7PyTorch__FloatTensor), __pyx_n_s_new); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1106, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1106, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1106, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_7PyTorch__FloatTensor))))) __PYX_ERR(0, 1106, __pyx_L1_error)
  __pyx_v_res = ((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":1107
 *     def cinv(_FloatTensor self):
 *         cdef _FloatTensor res = _FloatTensor.new()
 *         THFloatTensor_cinv(res.native, self.native)             # <<<<<<<<<<<<<<
 *         return res
 * 
 */
  THFloatTensor_cinv(__pyx_v_res->native, __pyx_v_self->native);

  /* "PyTorch.pyx":1108
 *         cdef _FloatTensor res = _FloatTensor.new()
 *         THFloatTensor_cinv(res.native, self.native)
 *         return res             # <<<<<<<<<<<<<<
 * 
 *     def neg(_FloatTensor self):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = ((PyObject *)__pyx_v_res);
  goto __pyx_L0;

  /* "PyTorch.pyx":1105
 *         return res
 * 
 *     def cinv(_FloatTensor self):             # <<<<<<<<<<<<<<
 *         cdef _FloatTensor res = _FloatTensor.new()
 *         THFloatTensor_cinv(res.native, self.native)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("PyTorch._FloatTensor.cinv", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1110
 *         return res
 * 
 *     def neg(_FloatTensor self):             # <<<<<<<<<<<<<<
 *         cdef _FloatTensor res = _FloatTensor.new()
 *         THFloatTensor_neg(res.native, self.native)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_49neg(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_49neg(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("neg (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_48neg(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_48neg(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self) {
  struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_res = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("neg", 0);

  /* "PyTorch.pyx":1111
 * 
 *     def neg(_FloatTensor self):
 *         cdef _FloatTensor res = _FloatTensor.new()             # <<<<<<<<<<<<<<
 *         THFloatTensor_neg(res.native, self.native)
 *         return res
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7PyTorch__FloatTensor), __pyx_n_s_new); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1111, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1111, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1111, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_7PyTorch__FloatTensor))))) __PYX_ERR(0, 1111, __pyx_L1_error)
  __pyx_v_res = ((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":1112
 *     def neg(_FloatTensor self):
 *         cdef _FloatTensor res = _FloatTensor.new()
 *         THFloatTensor_neg(res.native, self.native)             # <<<<<<<<<<<<<<
 *         return res
 * 
 */
  THFloatTensor_neg(__pyx_v_res->native, __pyx_v_self->native);

  /* "PyTorch.pyx":1113
 *         cdef _FloatTensor res = _FloatTensor.new()
 *         THFloatTensor_neg(res.native, self.native)
 *         return res             # <<<<<<<<<<<<<<
 * 
 *     def ineg(_FloatTensor self):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = ((PyObject *)__pyx_v_res);
  goto __pyx_L0;

  /* "PyTorch.pyx":1110
 *         return res
 * 
 *     def neg(_FloatTensor self):             # <<<<<<<<<<<<<<
 *         cdef _FloatTensor res = _FloatTensor.new()
 *         THFloatTensor_neg(res.native, self.native)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("PyTorch._FloatTensor.neg", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1115
 *         return res
 * 
 *     def ineg(_FloatTensor self):             # <<<<<<<<<<<<<<
 *         THFloatTensor_neg(self.native, self.native)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_51ineg(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_51ineg(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("ineg (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_50ineg(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_50ineg(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("ineg", 0);

  /* "PyTorch.pyx":1116
 * 
 *     def ineg(_FloatTensor self):
 *         THFloatTensor_neg(self.native, self.native)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THFloatTensor_neg(__pyx_v_self->native, __pyx_v_self->native);

  /* "PyTorch.pyx":1117
 *     def ineg(_FloatTensor self):
 *         THFloatTensor_neg(self.native, self.native)
 *         return self             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1115
 *         return res
 * 
 *     def ineg(_FloatTensor self):             # <<<<<<<<<<<<<<
 *         THFloatTensor_neg(self.native, self.native)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1122
 * 
 * 
 *     def abs(_FloatTensor self):             # <<<<<<<<<<<<<<
 *         cdef _FloatTensor res = _FloatTensor.new()
 *         THFloatTensor_abs(res.native, self.native)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_53abs(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_53abs(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("abs (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_52abs(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_52abs(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self) {
  struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_res = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("abs", 0);

  /* "PyTorch.pyx":1123
 * 
 *     def abs(_FloatTensor self):
 *         cdef _FloatTensor res = _FloatTensor.new()             # <<<<<<<<<<<<<<
 *         THFloatTensor_abs(res.native, self.native)
 *         return res
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7PyTorch__FloatTensor), __pyx_n_s_new); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1123, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1123, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1123, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_7PyTorch__FloatTensor))))) __PYX_ERR(0, 1123, __pyx_L1_error)
  __pyx_v_res = ((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":1124
 *     def abs(_FloatTensor self):
 *         cdef _FloatTensor res = _FloatTensor.new()
 *         THFloatTensor_abs(res.native, self.native)             # <<<<<<<<<<<<<<
 *         return res
 * 
 */
  THFloatTensor_abs(__pyx_v_res->native, __pyx_v_self->native);

  /* "PyTorch.pyx":1125
 *         cdef _FloatTensor res = _FloatTensor.new()
 *         THFloatTensor_abs(res.native, self.native)
 *         return res             # <<<<<<<<<<<<<<
 * 
 *     def iabs(_FloatTensor self):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = ((PyObject *)__pyx_v_res);
  goto __pyx_L0;

  /* "PyTorch.pyx":1122
 * 
 * 
 *     def abs(_FloatTensor self):             # <<<<<<<<<<<<<<
 *         cdef _FloatTensor res = _FloatTensor.new()
 *         THFloatTensor_abs(res.native, self.native)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("PyTorch._FloatTensor.abs", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1127
 *         return res
 * 
 *     def iabs(_FloatTensor self):             # <<<<<<<<<<<<<<
 *         THFloatTensor_abs(self.native, self.native)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_55iabs(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_55iabs(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("iabs (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_54iabs(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_54iabs(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("iabs", 0);

  /* "PyTorch.pyx":1128
 * 
 *     def iabs(_FloatTensor self):
 *         THFloatTensor_abs(self.native, self.native)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THFloatTensor_abs(__pyx_v_self->native, __pyx_v_self->native);

  /* "PyTorch.pyx":1129
 *     def iabs(_FloatTensor self):
 *         THFloatTensor_abs(self.native, self.native)
 *         return self             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1127
 *         return res
 * 
 *     def iabs(_FloatTensor self):             # <<<<<<<<<<<<<<
 *         THFloatTensor_abs(self.native, self.native)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1133
 * 
 * 
 *     def size(_FloatTensor self):             # <<<<<<<<<<<<<<
 *         cdef int dims = self.dims()
 * #        cdef LongStorage size
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_57size(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_57size(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("size (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_56size(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_56size(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self) {
  int __pyx_v_dims;
  PyObject *__pyx_v_size = NULL;
  int __pyx_v_d;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  int __pyx_t_7;
  int __pyx_t_8;
  __Pyx_RefNannySetupContext("size", 0);

  /* "PyTorch.pyx":1134
 * 
 *     def size(_FloatTensor self):
 *         cdef int dims = self.dims()             # <<<<<<<<<<<<<<
 * #        cdef LongStorage size
 *         if dims > 0:
 */
  __pyx_v_dims = ((struct __pyx_vtabstruct_7PyTorch__FloatTensor *)__pyx_v_self->__pyx_vtab)->dims(__pyx_v_self, 0);

  /* "PyTorch.pyx":1136
 *         cdef int dims = self.dims()
 * #        cdef LongStorage size
 *         if dims > 0:             # <<<<<<<<<<<<<<
 *             size = _LongStorage(dims)
 *             for d in range(dims):
 */
  __pyx_t_1 = ((__pyx_v_dims > 0) != 0);
  if (__pyx_t_1) {

    /* "PyTorch.pyx":1137
 * #        cdef LongStorage size
 *         if dims > 0:
 *             size = _LongStorage(dims)             # <<<<<<<<<<<<<<
 *             for d in range(dims):
 *                 size[d] = THFloatTensor_size(self.native, d)
 */
    __pyx_t_3 = __Pyx_GetModuleGlobalName(__pyx_n_s_LongStorage); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1137, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = __Pyx_PyInt_From_int(__pyx_v_dims); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1137, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_5 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
      __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_3);
      if (likely(__pyx_t_5)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
        __Pyx_INCREF(__pyx_t_5);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_3, function);
      }
    }
    if (!__pyx_t_5) {
      __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_4); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1137, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_GOTREF(__pyx_t_2);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_3)) {
        PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_t_4};
        __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1137, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
        PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_t_4};
        __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1137, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else
      #endif
      {
        __pyx_t_6 = PyTuple_New(1+1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1137, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_5); __pyx_t_5 = NULL;
        __Pyx_GIVEREF(__pyx_t_4);
        PyTuple_SET_ITEM(__pyx_t_6, 0+1, __pyx_t_4);
        __pyx_t_4 = 0;
        __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_6, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1137, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_v_size = __pyx_t_2;
    __pyx_t_2 = 0;

    /* "PyTorch.pyx":1138
 *         if dims > 0:
 *             size = _LongStorage(dims)
 *             for d in range(dims):             # <<<<<<<<<<<<<<
 *                 size[d] = THFloatTensor_size(self.native, d)
 *             return size
 */
    __pyx_t_7 = __pyx_v_dims;
    for (__pyx_t_8 = 0; __pyx_t_8 < __pyx_t_7; __pyx_t_8+=1) {
      __pyx_v_d = __pyx_t_8;

      /* "PyTorch.pyx":1139
 *             size = _LongStorage(dims)
 *             for d in range(dims):
 *                 size[d] = THFloatTensor_size(self.native, d)             # <<<<<<<<<<<<<<
 *             return size
 *         else:
 */
      __pyx_t_2 = __Pyx_PyInt_From_long(THFloatTensor_size(__pyx_v_self->native, __pyx_v_d)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1139, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      if (unlikely(__Pyx_SetItemInt(__pyx_v_size, __pyx_v_d, __pyx_t_2, int, 1, __Pyx_PyInt_From_int, 0, 1, 1) < 0)) __PYX_ERR(0, 1139, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    }

    /* "PyTorch.pyx":1140
 *             for d in range(dims):
 *                 size[d] = THFloatTensor_size(self.native, d)
 *             return size             # <<<<<<<<<<<<<<
 *         else:
 *             return None  # not sure how to handle this yet
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(__pyx_v_size);
    __pyx_r = __pyx_v_size;
    goto __pyx_L0;

    /* "PyTorch.pyx":1136
 *         cdef int dims = self.dims()
 * #        cdef LongStorage size
 *         if dims > 0:             # <<<<<<<<<<<<<<
 *             size = _LongStorage(dims)
 *             for d in range(dims):
 */
  }

  /* "PyTorch.pyx":1142
 *             return size
 *         else:
 *             return None  # not sure how to handle this yet             # <<<<<<<<<<<<<<
 * 
 *     @staticmethod
 */
  /*else*/ {
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(Py_None);
    __pyx_r = Py_None;
    goto __pyx_L0;
  }

  /* "PyTorch.pyx":1133
 * 
 * 
 *     def size(_FloatTensor self):             # <<<<<<<<<<<<<<
 *         cdef int dims = self.dims()
 * #        cdef LongStorage size
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("PyTorch._FloatTensor.size", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_size);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1145
 * 
 *     @staticmethod
 *     def new():             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         return _FloatTensor()
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_59new(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_7PyTorch_12_FloatTensor_59new = {"new", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_59new, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_59new(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("new (wrapper)", 0);
  if (unlikely(PyTuple_GET_SIZE(__pyx_args) > 0)) {
    __Pyx_RaiseArgtupleInvalid("new", 1, 0, 0, PyTuple_GET_SIZE(__pyx_args)); return NULL;}
  if (unlikely(__pyx_kwds) && unlikely(PyDict_Size(__pyx_kwds) > 0) && unlikely(!__Pyx_CheckKeywordStrings(__pyx_kwds, "new", 0))) return NULL;
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_58new();

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_58new() {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("new", 0);

  /* "PyTorch.pyx":1147
 *     def new():
 * #        # print('allocate tensor')
 *         return _FloatTensor()             # <<<<<<<<<<<<<<
 * #        return _FloatTensor_fromNative(newTensorC, False)
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_7PyTorch__FloatTensor), __pyx_empty_tuple, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1147, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":1145
 * 
 *     @staticmethod
 *     def new():             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         return _FloatTensor()
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._FloatTensor.new", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1150
 * #        return _FloatTensor_fromNative(newTensorC, False)
 * 
 *     def narrow(_FloatTensor self, int dimension, long firstIndex, long size):             # <<<<<<<<<<<<<<
 *         cdef THFloatTensor *narrowedC = THFloatTensor_newNarrow(self.native, dimension, firstIndex, size)
 *         return _FloatTensor_fromNative(narrowedC, retain=False)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_61narrow(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_61narrow(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  int __pyx_v_dimension;
  long __pyx_v_firstIndex;
  long __pyx_v_size;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("narrow (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_dimension,&__pyx_n_s_firstIndex,&__pyx_n_s_size,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_dimension)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_firstIndex)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("narrow", 1, 3, 3, 1); __PYX_ERR(0, 1150, __pyx_L3_error)
        }
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("narrow", 1, 3, 3, 2); __PYX_ERR(0, 1150, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "narrow") < 0)) __PYX_ERR(0, 1150, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_dimension = __Pyx_PyInt_As_int(values[0]); if (unlikely((__pyx_v_dimension == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1150, __pyx_L3_error)
    __pyx_v_firstIndex = __Pyx_PyInt_As_long(values[1]); if (unlikely((__pyx_v_firstIndex == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1150, __pyx_L3_error)
    __pyx_v_size = __Pyx_PyInt_As_long(values[2]); if (unlikely((__pyx_v_size == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1150, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("narrow", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1150, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._FloatTensor.narrow", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_60narrow(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self), __pyx_v_dimension, __pyx_v_firstIndex, __pyx_v_size);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_60narrow(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, int __pyx_v_dimension, long __pyx_v_firstIndex, long __pyx_v_size) {
  struct THFloatTensor *__pyx_v_narrowedC;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  struct __pyx_opt_args_7PyTorch__FloatTensor_fromNative __pyx_t_2;
  __Pyx_RefNannySetupContext("narrow", 0);

  /* "PyTorch.pyx":1151
 * 
 *     def narrow(_FloatTensor self, int dimension, long firstIndex, long size):
 *         cdef THFloatTensor *narrowedC = THFloatTensor_newNarrow(self.native, dimension, firstIndex, size)             # <<<<<<<<<<<<<<
 *         return _FloatTensor_fromNative(narrowedC, retain=False)
 * 
 */
  __pyx_v_narrowedC = THFloatTensor_newNarrow(__pyx_v_self->native, __pyx_v_dimension, __pyx_v_firstIndex, __pyx_v_size);

  /* "PyTorch.pyx":1152
 *     def narrow(_FloatTensor self, int dimension, long firstIndex, long size):
 *         cdef THFloatTensor *narrowedC = THFloatTensor_newNarrow(self.native, dimension, firstIndex, size)
 *         return _FloatTensor_fromNative(narrowedC, retain=False)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2.__pyx_n = 1;
  __pyx_t_2.retain = Py_False;
  __pyx_t_1 = __pyx_f_7PyTorch__FloatTensor_fromNative(__pyx_v_narrowedC, &__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1152, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":1150
 * #        return _FloatTensor_fromNative(newTensorC, False)
 * 
 *     def narrow(_FloatTensor self, int dimension, long firstIndex, long size):             # <<<<<<<<<<<<<<
 *         cdef THFloatTensor *narrowedC = THFloatTensor_newNarrow(self.native, dimension, firstIndex, size)
 *         return _FloatTensor_fromNative(narrowedC, retain=False)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._FloatTensor.narrow", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1155
 * 
 * 
 *     def contiguous(_FloatTensor self):             # <<<<<<<<<<<<<<
 *         cdef THFloatTensor *newTensorC = THFloatTensor_newContiguous(self.native)
 *         return _FloatTensor_fromNative(newTensorC, retain=False)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_63contiguous(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_63contiguous(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("contiguous (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_62contiguous(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_62contiguous(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self) {
  struct THFloatTensor *__pyx_v_newTensorC;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  struct __pyx_opt_args_7PyTorch__FloatTensor_fromNative __pyx_t_2;
  __Pyx_RefNannySetupContext("contiguous", 0);

  /* "PyTorch.pyx":1156
 * 
 *     def contiguous(_FloatTensor self):
 *         cdef THFloatTensor *newTensorC = THFloatTensor_newContiguous(self.native)             # <<<<<<<<<<<<<<
 *         return _FloatTensor_fromNative(newTensorC, retain=False)
 * 
 */
  __pyx_v_newTensorC = THFloatTensor_newContiguous(__pyx_v_self->native);

  /* "PyTorch.pyx":1157
 *     def contiguous(_FloatTensor self):
 *         cdef THFloatTensor *newTensorC = THFloatTensor_newContiguous(self.native)
 *         return _FloatTensor_fromNative(newTensorC, retain=False)             # <<<<<<<<<<<<<<
 * 
 *     def resize1d(_FloatTensor self, int size0):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2.__pyx_n = 1;
  __pyx_t_2.retain = Py_False;
  __pyx_t_1 = __pyx_f_7PyTorch__FloatTensor_fromNative(__pyx_v_newTensorC, &__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1157, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":1155
 * 
 * 
 *     def contiguous(_FloatTensor self):             # <<<<<<<<<<<<<<
 *         cdef THFloatTensor *newTensorC = THFloatTensor_newContiguous(self.native)
 *         return _FloatTensor_fromNative(newTensorC, retain=False)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._FloatTensor.contiguous", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1159
 *         return _FloatTensor_fromNative(newTensorC, retain=False)
 * 
 *     def resize1d(_FloatTensor self, int size0):             # <<<<<<<<<<<<<<
 *         THFloatTensor_resize1d(self.native, size0)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_65resize1d(PyObject *__pyx_v_self, PyObject *__pyx_arg_size0); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_65resize1d(PyObject *__pyx_v_self, PyObject *__pyx_arg_size0) {
  int __pyx_v_size0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resize1d (wrapper)", 0);
  assert(__pyx_arg_size0); {
    __pyx_v_size0 = __Pyx_PyInt_As_int(__pyx_arg_size0); if (unlikely((__pyx_v_size0 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1159, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._FloatTensor.resize1d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_64resize1d(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self), ((int)__pyx_v_size0));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_64resize1d(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, int __pyx_v_size0) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resize1d", 0);

  /* "PyTorch.pyx":1160
 * 
 *     def resize1d(_FloatTensor self, int size0):
 *         THFloatTensor_resize1d(self.native, size0)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THFloatTensor_resize1d(__pyx_v_self->native, __pyx_v_size0);

  /* "PyTorch.pyx":1161
 *     def resize1d(_FloatTensor self, int size0):
 *         THFloatTensor_resize1d(self.native, size0)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def resize2d(_FloatTensor self, int size0, int size1):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1159
 *         return _FloatTensor_fromNative(newTensorC, retain=False)
 * 
 *     def resize1d(_FloatTensor self, int size0):             # <<<<<<<<<<<<<<
 *         THFloatTensor_resize1d(self.native, size0)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1163
 *         return self
 * 
 *     def resize2d(_FloatTensor self, int size0, int size1):             # <<<<<<<<<<<<<<
 *         THFloatTensor_resize2d(self.native, size0, size1)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_67resize2d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_67resize2d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  int __pyx_v_size0;
  int __pyx_v_size1;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resize2d (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_size0,&__pyx_n_s_size1,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size0)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("resize2d", 1, 2, 2, 1); __PYX_ERR(0, 1163, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "resize2d") < 0)) __PYX_ERR(0, 1163, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_size0 = __Pyx_PyInt_As_int(values[0]); if (unlikely((__pyx_v_size0 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1163, __pyx_L3_error)
    __pyx_v_size1 = __Pyx_PyInt_As_int(values[1]); if (unlikely((__pyx_v_size1 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1163, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("resize2d", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1163, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._FloatTensor.resize2d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_66resize2d(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self), __pyx_v_size0, __pyx_v_size1);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_66resize2d(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, int __pyx_v_size0, int __pyx_v_size1) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resize2d", 0);

  /* "PyTorch.pyx":1164
 * 
 *     def resize2d(_FloatTensor self, int size0, int size1):
 *         THFloatTensor_resize2d(self.native, size0, size1)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THFloatTensor_resize2d(__pyx_v_self->native, __pyx_v_size0, __pyx_v_size1);

  /* "PyTorch.pyx":1165
 *     def resize2d(_FloatTensor self, int size0, int size1):
 *         THFloatTensor_resize2d(self.native, size0, size1)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def resize3d(_FloatTensor self, int size0, int size1, int size2):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1163
 *         return self
 * 
 *     def resize2d(_FloatTensor self, int size0, int size1):             # <<<<<<<<<<<<<<
 *         THFloatTensor_resize2d(self.native, size0, size1)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1167
 *         return self
 * 
 *     def resize3d(_FloatTensor self, int size0, int size1, int size2):             # <<<<<<<<<<<<<<
 *         THFloatTensor_resize3d(self.native, size0, size1, size2)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_69resize3d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_69resize3d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  int __pyx_v_size0;
  int __pyx_v_size1;
  int __pyx_v_size2;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resize3d (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_size0,&__pyx_n_s_size1,&__pyx_n_s_size2,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size0)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("resize3d", 1, 3, 3, 1); __PYX_ERR(0, 1167, __pyx_L3_error)
        }
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("resize3d", 1, 3, 3, 2); __PYX_ERR(0, 1167, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "resize3d") < 0)) __PYX_ERR(0, 1167, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_size0 = __Pyx_PyInt_As_int(values[0]); if (unlikely((__pyx_v_size0 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1167, __pyx_L3_error)
    __pyx_v_size1 = __Pyx_PyInt_As_int(values[1]); if (unlikely((__pyx_v_size1 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1167, __pyx_L3_error)
    __pyx_v_size2 = __Pyx_PyInt_As_int(values[2]); if (unlikely((__pyx_v_size2 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1167, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("resize3d", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1167, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._FloatTensor.resize3d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_68resize3d(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self), __pyx_v_size0, __pyx_v_size1, __pyx_v_size2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_68resize3d(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, int __pyx_v_size0, int __pyx_v_size1, int __pyx_v_size2) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resize3d", 0);

  /* "PyTorch.pyx":1168
 * 
 *     def resize3d(_FloatTensor self, int size0, int size1, int size2):
 *         THFloatTensor_resize3d(self.native, size0, size1, size2)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THFloatTensor_resize3d(__pyx_v_self->native, __pyx_v_size0, __pyx_v_size1, __pyx_v_size2);

  /* "PyTorch.pyx":1169
 *     def resize3d(_FloatTensor self, int size0, int size1, int size2):
 *         THFloatTensor_resize3d(self.native, size0, size1, size2)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def resize4d(_FloatTensor self, int size0, int size1, int size2, int size3):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1167
 *         return self
 * 
 *     def resize3d(_FloatTensor self, int size0, int size1, int size2):             # <<<<<<<<<<<<<<
 *         THFloatTensor_resize3d(self.native, size0, size1, size2)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1171
 *         return self
 * 
 *     def resize4d(_FloatTensor self, int size0, int size1, int size2, int size3):             # <<<<<<<<<<<<<<
 *         THFloatTensor_resize4d(self.native, size0, size1, size2, size3)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_71resize4d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_71resize4d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  int __pyx_v_size0;
  int __pyx_v_size1;
  int __pyx_v_size2;
  int __pyx_v_size3;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resize4d (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_size0,&__pyx_n_s_size1,&__pyx_n_s_size2,&__pyx_n_s_size3,0};
    PyObject* values[4] = {0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size0)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("resize4d", 1, 4, 4, 1); __PYX_ERR(0, 1171, __pyx_L3_error)
        }
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("resize4d", 1, 4, 4, 2); __PYX_ERR(0, 1171, __pyx_L3_error)
        }
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size3)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("resize4d", 1, 4, 4, 3); __PYX_ERR(0, 1171, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "resize4d") < 0)) __PYX_ERR(0, 1171, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 4) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
    }
    __pyx_v_size0 = __Pyx_PyInt_As_int(values[0]); if (unlikely((__pyx_v_size0 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1171, __pyx_L3_error)
    __pyx_v_size1 = __Pyx_PyInt_As_int(values[1]); if (unlikely((__pyx_v_size1 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1171, __pyx_L3_error)
    __pyx_v_size2 = __Pyx_PyInt_As_int(values[2]); if (unlikely((__pyx_v_size2 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1171, __pyx_L3_error)
    __pyx_v_size3 = __Pyx_PyInt_As_int(values[3]); if (unlikely((__pyx_v_size3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1171, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("resize4d", 1, 4, 4, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1171, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._FloatTensor.resize4d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_70resize4d(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self), __pyx_v_size0, __pyx_v_size1, __pyx_v_size2, __pyx_v_size3);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_70resize4d(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, int __pyx_v_size0, int __pyx_v_size1, int __pyx_v_size2, int __pyx_v_size3) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resize4d", 0);

  /* "PyTorch.pyx":1172
 * 
 *     def resize4d(_FloatTensor self, int size0, int size1, int size2, int size3):
 *         THFloatTensor_resize4d(self.native, size0, size1, size2, size3)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THFloatTensor_resize4d(__pyx_v_self->native, __pyx_v_size0, __pyx_v_size1, __pyx_v_size2, __pyx_v_size3);

  /* "PyTorch.pyx":1173
 *     def resize4d(_FloatTensor self, int size0, int size1, int size2, int size3):
 *         THFloatTensor_resize4d(self.native, size0, size1, size2, size3)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def resizeAs(_FloatTensor self, _FloatTensor model):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1171
 *         return self
 * 
 *     def resize4d(_FloatTensor self, int size0, int size1, int size2, int size3):             # <<<<<<<<<<<<<<
 *         THFloatTensor_resize4d(self.native, size0, size1, size2, size3)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1175
 *         return self
 * 
 *     def resizeAs(_FloatTensor self, _FloatTensor model):             # <<<<<<<<<<<<<<
 *         THFloatTensor_resizeAs(self.native, model.native)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_73resizeAs(PyObject *__pyx_v_self, PyObject *__pyx_v_model); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_73resizeAs(PyObject *__pyx_v_self, PyObject *__pyx_v_model) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resizeAs (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_model), __pyx_ptype_7PyTorch__FloatTensor, 1, "model", 0))) __PYX_ERR(0, 1175, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_72resizeAs(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self), ((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_model));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_72resizeAs(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_model) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resizeAs", 0);

  /* "PyTorch.pyx":1176
 * 
 *     def resizeAs(_FloatTensor self, _FloatTensor model):
 *         THFloatTensor_resizeAs(self.native, model.native)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THFloatTensor_resizeAs(__pyx_v_self->native, __pyx_v_model->native);

  /* "PyTorch.pyx":1177
 *     def resizeAs(_FloatTensor self, _FloatTensor model):
 *         THFloatTensor_resizeAs(self.native, model.native)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def resize(_FloatTensor self, Storage._LongStorage size):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1175
 *         return self
 * 
 *     def resizeAs(_FloatTensor self, _FloatTensor model):             # <<<<<<<<<<<<<<
 *         THFloatTensor_resizeAs(self.native, model.native)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1179
 *         return self
 * 
 *     def resize(_FloatTensor self, Storage._LongStorage size):             # <<<<<<<<<<<<<<
 * #        # print('_FloatTensor.resize size:', size)
 *         if len(size) == 0:
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_75resize(PyObject *__pyx_v_self, PyObject *__pyx_v_size); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_75resize(PyObject *__pyx_v_self, PyObject *__pyx_v_size) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resize (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_size), __pyx_ptype_7Storage__LongStorage, 1, "size", 0))) __PYX_ERR(0, 1179, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_74resize(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self), ((struct __pyx_obj_7Storage__LongStorage *)__pyx_v_size));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_74resize(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, struct __pyx_obj_7Storage__LongStorage *__pyx_v_size) {
  int __pyx_v_dims;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  Py_ssize_t __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  long __pyx_t_4;
  long __pyx_t_5;
  long __pyx_t_6;
  long __pyx_t_7;
  PyObject *__pyx_t_8 = NULL;
  __Pyx_RefNannySetupContext("resize", 0);

  /* "PyTorch.pyx":1181
 *     def resize(_FloatTensor self, Storage._LongStorage size):
 * #        # print('_FloatTensor.resize size:', size)
 *         if len(size) == 0:             # <<<<<<<<<<<<<<
 *             return self
 *         cdef int dims = len(size)
 */
  __pyx_t_1 = PyObject_Length(((PyObject *)__pyx_v_size)); if (unlikely(__pyx_t_1 == -1)) __PYX_ERR(0, 1181, __pyx_L1_error)
  __pyx_t_2 = ((__pyx_t_1 == 0) != 0);
  if (__pyx_t_2) {

    /* "PyTorch.pyx":1182
 * #        # print('_FloatTensor.resize size:', size)
 *         if len(size) == 0:
 *             return self             # <<<<<<<<<<<<<<
 *         cdef int dims = len(size)
 * #        # print('_FloatTensor.resize dims:', dims)
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(((PyObject *)__pyx_v_self));
    __pyx_r = ((PyObject *)__pyx_v_self);
    goto __pyx_L0;

    /* "PyTorch.pyx":1181
 *     def resize(_FloatTensor self, Storage._LongStorage size):
 * #        # print('_FloatTensor.resize size:', size)
 *         if len(size) == 0:             # <<<<<<<<<<<<<<
 *             return self
 *         cdef int dims = len(size)
 */
  }

  /* "PyTorch.pyx":1183
 *         if len(size) == 0:
 *             return self
 *         cdef int dims = len(size)             # <<<<<<<<<<<<<<
 * #        # print('_FloatTensor.resize dims:', dims)
 *         if dims == 1:
 */
  __pyx_t_1 = PyObject_Length(((PyObject *)__pyx_v_size)); if (unlikely(__pyx_t_1 == -1)) __PYX_ERR(0, 1183, __pyx_L1_error)
  __pyx_v_dims = __pyx_t_1;

  /* "PyTorch.pyx":1185
 *         cdef int dims = len(size)
 * #        # print('_FloatTensor.resize dims:', dims)
 *         if dims == 1:             # <<<<<<<<<<<<<<
 *             THFloatTensor_resize1d(self.native, size[0])
 *         elif dims == 2:
 */
  switch (__pyx_v_dims) {
    case 1:

    /* "PyTorch.pyx":1186
 * #        # print('_FloatTensor.resize dims:', dims)
 *         if dims == 1:
 *             THFloatTensor_resize1d(self.native, size[0])             # <<<<<<<<<<<<<<
 *         elif dims == 2:
 *             THFloatTensor_resize2d(self.native, size[0], size[1])
 */
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1186, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_4 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1186, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    THFloatTensor_resize1d(__pyx_v_self->native, __pyx_t_4);

    /* "PyTorch.pyx":1185
 *         cdef int dims = len(size)
 * #        # print('_FloatTensor.resize dims:', dims)
 *         if dims == 1:             # <<<<<<<<<<<<<<
 *             THFloatTensor_resize1d(self.native, size[0])
 *         elif dims == 2:
 */
    break;

    /* "PyTorch.pyx":1187
 *         if dims == 1:
 *             THFloatTensor_resize1d(self.native, size[0])
 *         elif dims == 2:             # <<<<<<<<<<<<<<
 *             THFloatTensor_resize2d(self.native, size[0], size[1])
 *         elif dims == 3:
 */
    case 2:

    /* "PyTorch.pyx":1188
 *             THFloatTensor_resize1d(self.native, size[0])
 *         elif dims == 2:
 *             THFloatTensor_resize2d(self.native, size[0], size[1])             # <<<<<<<<<<<<<<
 *         elif dims == 3:
 *             THFloatTensor_resize3d(self.native, size[0], size[1], size[2])
 */
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1188, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_4 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1188, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1188, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_5 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_5 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1188, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    THFloatTensor_resize2d(__pyx_v_self->native, __pyx_t_4, __pyx_t_5);

    /* "PyTorch.pyx":1187
 *         if dims == 1:
 *             THFloatTensor_resize1d(self.native, size[0])
 *         elif dims == 2:             # <<<<<<<<<<<<<<
 *             THFloatTensor_resize2d(self.native, size[0], size[1])
 *         elif dims == 3:
 */
    break;

    /* "PyTorch.pyx":1189
 *         elif dims == 2:
 *             THFloatTensor_resize2d(self.native, size[0], size[1])
 *         elif dims == 3:             # <<<<<<<<<<<<<<
 *             THFloatTensor_resize3d(self.native, size[0], size[1], size[2])
 *         elif dims == 4:
 */
    case 3:

    /* "PyTorch.pyx":1190
 *             THFloatTensor_resize2d(self.native, size[0], size[1])
 *         elif dims == 3:
 *             THFloatTensor_resize3d(self.native, size[0], size[1], size[2])             # <<<<<<<<<<<<<<
 *         elif dims == 4:
 *             THFloatTensor_resize4d(self.native, size[0], size[1], size[2], size[3])
 */
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1190, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_5 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_5 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1190, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1190, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_4 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1190, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1190, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_6 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_6 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1190, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    THFloatTensor_resize3d(__pyx_v_self->native, __pyx_t_5, __pyx_t_4, __pyx_t_6);

    /* "PyTorch.pyx":1189
 *         elif dims == 2:
 *             THFloatTensor_resize2d(self.native, size[0], size[1])
 *         elif dims == 3:             # <<<<<<<<<<<<<<
 *             THFloatTensor_resize3d(self.native, size[0], size[1], size[2])
 *         elif dims == 4:
 */
    break;

    /* "PyTorch.pyx":1191
 *         elif dims == 3:
 *             THFloatTensor_resize3d(self.native, size[0], size[1], size[2])
 *         elif dims == 4:             # <<<<<<<<<<<<<<
 *             THFloatTensor_resize4d(self.native, size[0], size[1], size[2], size[3])
 *         else:
 */
    case 4:

    /* "PyTorch.pyx":1192
 *             THFloatTensor_resize3d(self.native, size[0], size[1], size[2])
 *         elif dims == 4:
 *             THFloatTensor_resize4d(self.native, size[0], size[1], size[2], size[3])             # <<<<<<<<<<<<<<
 *         else:
 *             raise Exception('Not implemented for dims=' + str(dims))
 */
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1192, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_6 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_6 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1192, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1192, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_4 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1192, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1192, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_5 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_5 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1192, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 3, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1192, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_7 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_7 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1192, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    THFloatTensor_resize4d(__pyx_v_self->native, __pyx_t_6, __pyx_t_4, __pyx_t_5, __pyx_t_7);

    /* "PyTorch.pyx":1191
 *         elif dims == 3:
 *             THFloatTensor_resize3d(self.native, size[0], size[1], size[2])
 *         elif dims == 4:             # <<<<<<<<<<<<<<
 *             THFloatTensor_resize4d(self.native, size[0], size[1], size[2], size[3])
 *         else:
 */
    break;
    default:

    /* "PyTorch.pyx":1194
 *             THFloatTensor_resize4d(self.native, size[0], size[1], size[2], size[3])
 *         else:
 *             raise Exception('Not implemented for dims=' + str(dims))             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
    __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_dims); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1194, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_8 = PyTuple_New(1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1194, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_GIVEREF(__pyx_t_3);
    PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_t_3);
    __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_PyObject_Call(((PyObject *)(&PyString_Type)), __pyx_t_8, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1194, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_8 = PyNumber_Add(__pyx_kp_s_Not_implemented_for_dims, __pyx_t_3); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1194, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1194, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_GIVEREF(__pyx_t_8);
    PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_8);
    __pyx_t_8 = 0;
    __pyx_t_8 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_t_3, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1194, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_Raise(__pyx_t_8, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __PYX_ERR(0, 1194, __pyx_L1_error)
    break;
  }

  /* "PyTorch.pyx":1195
 *         else:
 *             raise Exception('Not implemented for dims=' + str(dims))
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     @staticmethod
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1179
 *         return self
 * 
 *     def resize(_FloatTensor self, Storage._LongStorage size):             # <<<<<<<<<<<<<<
 * #        # print('_FloatTensor.resize size:', size)
 *         if len(size) == 0:
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("PyTorch._FloatTensor.resize", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1198
 * 
 *     @staticmethod
 *     def newWithStorage(Storage._FloatStorage storage, offset, Storage._LongStorage size, Storage._LongStorage stride):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THFloatTensor *newTensorC = THFloatTensor_newWithStorage(storage.native, offset, size.native, stride.native)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_77newWithStorage(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_7PyTorch_12_FloatTensor_77newWithStorage = {"newWithStorage", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_77newWithStorage, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_77newWithStorage(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  struct __pyx_obj_7Storage__FloatStorage *__pyx_v_storage = 0;
  PyObject *__pyx_v_offset = 0;
  struct __pyx_obj_7Storage__LongStorage *__pyx_v_size = 0;
  struct __pyx_obj_7Storage__LongStorage *__pyx_v_stride = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("newWithStorage (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_storage,&__pyx_n_s_offset,&__pyx_n_s_size,&__pyx_n_s_stride,0};
    PyObject* values[4] = {0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_storage)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_offset)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage", 1, 4, 4, 1); __PYX_ERR(0, 1198, __pyx_L3_error)
        }
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage", 1, 4, 4, 2); __PYX_ERR(0, 1198, __pyx_L3_error)
        }
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage", 1, 4, 4, 3); __PYX_ERR(0, 1198, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "newWithStorage") < 0)) __PYX_ERR(0, 1198, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 4) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
    }
    __pyx_v_storage = ((struct __pyx_obj_7Storage__FloatStorage *)values[0]);
    __pyx_v_offset = values[1];
    __pyx_v_size = ((struct __pyx_obj_7Storage__LongStorage *)values[2]);
    __pyx_v_stride = ((struct __pyx_obj_7Storage__LongStorage *)values[3]);
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("newWithStorage", 1, 4, 4, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1198, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._FloatTensor.newWithStorage", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_storage), __pyx_ptype_7Storage__FloatStorage, 1, "storage", 0))) __PYX_ERR(0, 1198, __pyx_L1_error)
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_size), __pyx_ptype_7Storage__LongStorage, 1, "size", 0))) __PYX_ERR(0, 1198, __pyx_L1_error)
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_stride), __pyx_ptype_7Storage__LongStorage, 1, "stride", 0))) __PYX_ERR(0, 1198, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_76newWithStorage(__pyx_v_storage, __pyx_v_offset, __pyx_v_size, __pyx_v_stride);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_76newWithStorage(struct __pyx_obj_7Storage__FloatStorage *__pyx_v_storage, PyObject *__pyx_v_offset, struct __pyx_obj_7Storage__LongStorage *__pyx_v_size, struct __pyx_obj_7Storage__LongStorage *__pyx_v_stride) {
  struct THFloatTensor *__pyx_v_newTensorC;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  long __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  struct __pyx_opt_args_7PyTorch__FloatTensor_fromNative __pyx_t_3;
  __Pyx_RefNannySetupContext("newWithStorage", 0);

  /* "PyTorch.pyx":1200
 *     def newWithStorage(Storage._FloatStorage storage, offset, Storage._LongStorage size, Storage._LongStorage stride):
 * #        # print('allocate tensor')
 *         cdef THFloatTensor *newTensorC = THFloatTensor_newWithStorage(storage.native, offset, size.native, stride.native)             # <<<<<<<<<<<<<<
 *         return _FloatTensor_fromNative(newTensorC, False)
 * 
 */
  __pyx_t_1 = __Pyx_PyInt_As_long(__pyx_v_offset); if (unlikely((__pyx_t_1 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1200, __pyx_L1_error)
  __pyx_v_newTensorC = THFloatTensor_newWithStorage(__pyx_v_storage->native, __pyx_t_1, __pyx_v_size->native, __pyx_v_stride->native);

  /* "PyTorch.pyx":1201
 * #        # print('allocate tensor')
 *         cdef THFloatTensor *newTensorC = THFloatTensor_newWithStorage(storage.native, offset, size.native, stride.native)
 *         return _FloatTensor_fromNative(newTensorC, False)             # <<<<<<<<<<<<<<
 * 
 *     @staticmethod
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_3.__pyx_n = 1;
  __pyx_t_3.retain = Py_False;
  __pyx_t_2 = __pyx_f_7PyTorch__FloatTensor_fromNative(__pyx_v_newTensorC, &__pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1201, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":1198
 * 
 *     @staticmethod
 *     def newWithStorage(Storage._FloatStorage storage, offset, Storage._LongStorage size, Storage._LongStorage stride):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THFloatTensor *newTensorC = THFloatTensor_newWithStorage(storage.native, offset, size.native, stride.native)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("PyTorch._FloatTensor.newWithStorage", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1204
 * 
 *     @staticmethod
 *     def newWithStorage1d(Storage._FloatStorage storage, offset, size0, stride0):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THFloatTensor *newTensorC = THFloatTensor_newWithStorage1d(storage.native, offset, size0, stride0)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_79newWithStorage1d(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_7PyTorch_12_FloatTensor_79newWithStorage1d = {"newWithStorage1d", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_79newWithStorage1d, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_79newWithStorage1d(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  struct __pyx_obj_7Storage__FloatStorage *__pyx_v_storage = 0;
  PyObject *__pyx_v_offset = 0;
  PyObject *__pyx_v_size0 = 0;
  PyObject *__pyx_v_stride0 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("newWithStorage1d (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_storage,&__pyx_n_s_offset,&__pyx_n_s_size0,&__pyx_n_s_stride0,0};
    PyObject* values[4] = {0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_storage)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_offset)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage1d", 1, 4, 4, 1); __PYX_ERR(0, 1204, __pyx_L3_error)
        }
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size0)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage1d", 1, 4, 4, 2); __PYX_ERR(0, 1204, __pyx_L3_error)
        }
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride0)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage1d", 1, 4, 4, 3); __PYX_ERR(0, 1204, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "newWithStorage1d") < 0)) __PYX_ERR(0, 1204, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 4) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
    }
    __pyx_v_storage = ((struct __pyx_obj_7Storage__FloatStorage *)values[0]);
    __pyx_v_offset = values[1];
    __pyx_v_size0 = values[2];
    __pyx_v_stride0 = values[3];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("newWithStorage1d", 1, 4, 4, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1204, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._FloatTensor.newWithStorage1d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_storage), __pyx_ptype_7Storage__FloatStorage, 1, "storage", 0))) __PYX_ERR(0, 1204, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_78newWithStorage1d(__pyx_v_storage, __pyx_v_offset, __pyx_v_size0, __pyx_v_stride0);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_78newWithStorage1d(struct __pyx_obj_7Storage__FloatStorage *__pyx_v_storage, PyObject *__pyx_v_offset, PyObject *__pyx_v_size0, PyObject *__pyx_v_stride0) {
  struct THFloatTensor *__pyx_v_newTensorC;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  long __pyx_t_1;
  long __pyx_t_2;
  long __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  struct __pyx_opt_args_7PyTorch__FloatTensor_fromNative __pyx_t_5;
  __Pyx_RefNannySetupContext("newWithStorage1d", 0);

  /* "PyTorch.pyx":1206
 *     def newWithStorage1d(Storage._FloatStorage storage, offset, size0, stride0):
 * #        # print('allocate tensor')
 *         cdef THFloatTensor *newTensorC = THFloatTensor_newWithStorage1d(storage.native, offset, size0, stride0)             # <<<<<<<<<<<<<<
 *         return _FloatTensor_fromNative(newTensorC, False)
 * 
 */
  __pyx_t_1 = __Pyx_PyInt_As_long(__pyx_v_offset); if (unlikely((__pyx_t_1 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1206, __pyx_L1_error)
  __pyx_t_2 = __Pyx_PyInt_As_long(__pyx_v_size0); if (unlikely((__pyx_t_2 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1206, __pyx_L1_error)
  __pyx_t_3 = __Pyx_PyInt_As_long(__pyx_v_stride0); if (unlikely((__pyx_t_3 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1206, __pyx_L1_error)
  __pyx_v_newTensorC = THFloatTensor_newWithStorage1d(__pyx_v_storage->native, __pyx_t_1, __pyx_t_2, __pyx_t_3);

  /* "PyTorch.pyx":1207
 * #        # print('allocate tensor')
 *         cdef THFloatTensor *newTensorC = THFloatTensor_newWithStorage1d(storage.native, offset, size0, stride0)
 *         return _FloatTensor_fromNative(newTensorC, False)             # <<<<<<<<<<<<<<
 * 
 *     @staticmethod
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_5.__pyx_n = 1;
  __pyx_t_5.retain = Py_False;
  __pyx_t_4 = __pyx_f_7PyTorch__FloatTensor_fromNative(__pyx_v_newTensorC, &__pyx_t_5); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1207, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_r = __pyx_t_4;
  __pyx_t_4 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":1204
 * 
 *     @staticmethod
 *     def newWithStorage1d(Storage._FloatStorage storage, offset, size0, stride0):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THFloatTensor *newTensorC = THFloatTensor_newWithStorage1d(storage.native, offset, size0, stride0)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("PyTorch._FloatTensor.newWithStorage1d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1210
 * 
 *     @staticmethod
 *     def newWithStorage2d(Storage._FloatStorage storage, offset, size0, stride0, size1, stride1):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THFloatTensor *newTensorC = THFloatTensor_newWithStorage2d(storage.native, offset, size0, stride0, size1, stride1)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_81newWithStorage2d(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_7PyTorch_12_FloatTensor_81newWithStorage2d = {"newWithStorage2d", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_81newWithStorage2d, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_81newWithStorage2d(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  struct __pyx_obj_7Storage__FloatStorage *__pyx_v_storage = 0;
  PyObject *__pyx_v_offset = 0;
  PyObject *__pyx_v_size0 = 0;
  PyObject *__pyx_v_stride0 = 0;
  PyObject *__pyx_v_size1 = 0;
  PyObject *__pyx_v_stride1 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("newWithStorage2d (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_storage,&__pyx_n_s_offset,&__pyx_n_s_size0,&__pyx_n_s_stride0,&__pyx_n_s_size1,&__pyx_n_s_stride1,0};
    PyObject* values[6] = {0,0,0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_storage)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_offset)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage2d", 1, 6, 6, 1); __PYX_ERR(0, 1210, __pyx_L3_error)
        }
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size0)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage2d", 1, 6, 6, 2); __PYX_ERR(0, 1210, __pyx_L3_error)
        }
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride0)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage2d", 1, 6, 6, 3); __PYX_ERR(0, 1210, __pyx_L3_error)
        }
        case  4:
        if (likely((values[4] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage2d", 1, 6, 6, 4); __PYX_ERR(0, 1210, __pyx_L3_error)
        }
        case  5:
        if (likely((values[5] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage2d", 1, 6, 6, 5); __PYX_ERR(0, 1210, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "newWithStorage2d") < 0)) __PYX_ERR(0, 1210, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 6) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
      values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
      values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
    }
    __pyx_v_storage = ((struct __pyx_obj_7Storage__FloatStorage *)values[0]);
    __pyx_v_offset = values[1];
    __pyx_v_size0 = values[2];
    __pyx_v_stride0 = values[3];
    __pyx_v_size1 = values[4];
    __pyx_v_stride1 = values[5];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("newWithStorage2d", 1, 6, 6, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1210, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._FloatTensor.newWithStorage2d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_storage), __pyx_ptype_7Storage__FloatStorage, 1, "storage", 0))) __PYX_ERR(0, 1210, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_80newWithStorage2d(__pyx_v_storage, __pyx_v_offset, __pyx_v_size0, __pyx_v_stride0, __pyx_v_size1, __pyx_v_stride1);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_80newWithStorage2d(struct __pyx_obj_7Storage__FloatStorage *__pyx_v_storage, PyObject *__pyx_v_offset, PyObject *__pyx_v_size0, PyObject *__pyx_v_stride0, PyObject *__pyx_v_size1, PyObject *__pyx_v_stride1) {
  struct THFloatTensor *__pyx_v_newTensorC;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  long __pyx_t_1;
  long __pyx_t_2;
  long __pyx_t_3;
  long __pyx_t_4;
  long __pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  struct __pyx_opt_args_7PyTorch__FloatTensor_fromNative __pyx_t_7;
  __Pyx_RefNannySetupContext("newWithStorage2d", 0);

  /* "PyTorch.pyx":1212
 *     def newWithStorage2d(Storage._FloatStorage storage, offset, size0, stride0, size1, stride1):
 * #        # print('allocate tensor')
 *         cdef THFloatTensor *newTensorC = THFloatTensor_newWithStorage2d(storage.native, offset, size0, stride0, size1, stride1)             # <<<<<<<<<<<<<<
 *         return _FloatTensor_fromNative(newTensorC, False)
 * 
 */
  __pyx_t_1 = __Pyx_PyInt_As_long(__pyx_v_offset); if (unlikely((__pyx_t_1 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1212, __pyx_L1_error)
  __pyx_t_2 = __Pyx_PyInt_As_long(__pyx_v_size0); if (unlikely((__pyx_t_2 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1212, __pyx_L1_error)
  __pyx_t_3 = __Pyx_PyInt_As_long(__pyx_v_stride0); if (unlikely((__pyx_t_3 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1212, __pyx_L1_error)
  __pyx_t_4 = __Pyx_PyInt_As_long(__pyx_v_size1); if (unlikely((__pyx_t_4 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1212, __pyx_L1_error)
  __pyx_t_5 = __Pyx_PyInt_As_long(__pyx_v_stride1); if (unlikely((__pyx_t_5 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1212, __pyx_L1_error)
  __pyx_v_newTensorC = THFloatTensor_newWithStorage2d(__pyx_v_storage->native, __pyx_t_1, __pyx_t_2, __pyx_t_3, __pyx_t_4, __pyx_t_5);

  /* "PyTorch.pyx":1213
 * #        # print('allocate tensor')
 *         cdef THFloatTensor *newTensorC = THFloatTensor_newWithStorage2d(storage.native, offset, size0, stride0, size1, stride1)
 *         return _FloatTensor_fromNative(newTensorC, False)             # <<<<<<<<<<<<<<
 * 
 *     @staticmethod
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_7.__pyx_n = 1;
  __pyx_t_7.retain = Py_False;
  __pyx_t_6 = __pyx_f_7PyTorch__FloatTensor_fromNative(__pyx_v_newTensorC, &__pyx_t_7); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1213, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_r = __pyx_t_6;
  __pyx_t_6 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":1210
 * 
 *     @staticmethod
 *     def newWithStorage2d(Storage._FloatStorage storage, offset, size0, stride0, size1, stride1):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THFloatTensor *newTensorC = THFloatTensor_newWithStorage2d(storage.native, offset, size0, stride0, size1, stride1)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("PyTorch._FloatTensor.newWithStorage2d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1216
 * 
 *     @staticmethod
 *     def newWithStorage3d(Storage._FloatStorage storage, offset, size0, stride0, size1, stride1, size2, stride2):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THFloatTensor *newTensorC = THFloatTensor_newWithStorage3d(storage.native, offset, size0, stride0, size1, stride1,
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_83newWithStorage3d(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_7PyTorch_12_FloatTensor_83newWithStorage3d = {"newWithStorage3d", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_83newWithStorage3d, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_83newWithStorage3d(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  struct __pyx_obj_7Storage__FloatStorage *__pyx_v_storage = 0;
  PyObject *__pyx_v_offset = 0;
  PyObject *__pyx_v_size0 = 0;
  PyObject *__pyx_v_stride0 = 0;
  PyObject *__pyx_v_size1 = 0;
  PyObject *__pyx_v_stride1 = 0;
  PyObject *__pyx_v_size2 = 0;
  PyObject *__pyx_v_stride2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("newWithStorage3d (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_storage,&__pyx_n_s_offset,&__pyx_n_s_size0,&__pyx_n_s_stride0,&__pyx_n_s_size1,&__pyx_n_s_stride1,&__pyx_n_s_size2,&__pyx_n_s_stride2,0};
    PyObject* values[8] = {0,0,0,0,0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  8: values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_storage)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_offset)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage3d", 1, 8, 8, 1); __PYX_ERR(0, 1216, __pyx_L3_error)
        }
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size0)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage3d", 1, 8, 8, 2); __PYX_ERR(0, 1216, __pyx_L3_error)
        }
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride0)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage3d", 1, 8, 8, 3); __PYX_ERR(0, 1216, __pyx_L3_error)
        }
        case  4:
        if (likely((values[4] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage3d", 1, 8, 8, 4); __PYX_ERR(0, 1216, __pyx_L3_error)
        }
        case  5:
        if (likely((values[5] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage3d", 1, 8, 8, 5); __PYX_ERR(0, 1216, __pyx_L3_error)
        }
        case  6:
        if (likely((values[6] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage3d", 1, 8, 8, 6); __PYX_ERR(0, 1216, __pyx_L3_error)
        }
        case  7:
        if (likely((values[7] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage3d", 1, 8, 8, 7); __PYX_ERR(0, 1216, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "newWithStorage3d") < 0)) __PYX_ERR(0, 1216, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 8) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
      values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
      values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
      values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
      values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
    }
    __pyx_v_storage = ((struct __pyx_obj_7Storage__FloatStorage *)values[0]);
    __pyx_v_offset = values[1];
    __pyx_v_size0 = values[2];
    __pyx_v_stride0 = values[3];
    __pyx_v_size1 = values[4];
    __pyx_v_stride1 = values[5];
    __pyx_v_size2 = values[6];
    __pyx_v_stride2 = values[7];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("newWithStorage3d", 1, 8, 8, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1216, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._FloatTensor.newWithStorage3d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_storage), __pyx_ptype_7Storage__FloatStorage, 1, "storage", 0))) __PYX_ERR(0, 1216, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_82newWithStorage3d(__pyx_v_storage, __pyx_v_offset, __pyx_v_size0, __pyx_v_stride0, __pyx_v_size1, __pyx_v_stride1, __pyx_v_size2, __pyx_v_stride2);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_82newWithStorage3d(struct __pyx_obj_7Storage__FloatStorage *__pyx_v_storage, PyObject *__pyx_v_offset, PyObject *__pyx_v_size0, PyObject *__pyx_v_stride0, PyObject *__pyx_v_size1, PyObject *__pyx_v_stride1, PyObject *__pyx_v_size2, PyObject *__pyx_v_stride2) {
  struct THFloatTensor *__pyx_v_newTensorC;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  long __pyx_t_1;
  long __pyx_t_2;
  long __pyx_t_3;
  long __pyx_t_4;
  long __pyx_t_5;
  long __pyx_t_6;
  long __pyx_t_7;
  PyObject *__pyx_t_8 = NULL;
  struct __pyx_opt_args_7PyTorch__FloatTensor_fromNative __pyx_t_9;
  __Pyx_RefNannySetupContext("newWithStorage3d", 0);

  /* "PyTorch.pyx":1218
 *     def newWithStorage3d(Storage._FloatStorage storage, offset, size0, stride0, size1, stride1, size2, stride2):
 * #        # print('allocate tensor')
 *         cdef THFloatTensor *newTensorC = THFloatTensor_newWithStorage3d(storage.native, offset, size0, stride0, size1, stride1,             # <<<<<<<<<<<<<<
 *             size2, stride2)
 *         return _FloatTensor_fromNative(newTensorC, False)
 */
  __pyx_t_1 = __Pyx_PyInt_As_long(__pyx_v_offset); if (unlikely((__pyx_t_1 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1218, __pyx_L1_error)
  __pyx_t_2 = __Pyx_PyInt_As_long(__pyx_v_size0); if (unlikely((__pyx_t_2 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1218, __pyx_L1_error)
  __pyx_t_3 = __Pyx_PyInt_As_long(__pyx_v_stride0); if (unlikely((__pyx_t_3 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1218, __pyx_L1_error)
  __pyx_t_4 = __Pyx_PyInt_As_long(__pyx_v_size1); if (unlikely((__pyx_t_4 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1218, __pyx_L1_error)
  __pyx_t_5 = __Pyx_PyInt_As_long(__pyx_v_stride1); if (unlikely((__pyx_t_5 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1218, __pyx_L1_error)

  /* "PyTorch.pyx":1219
 * #        # print('allocate tensor')
 *         cdef THFloatTensor *newTensorC = THFloatTensor_newWithStorage3d(storage.native, offset, size0, stride0, size1, stride1,
 *             size2, stride2)             # <<<<<<<<<<<<<<
 *         return _FloatTensor_fromNative(newTensorC, False)
 * 
 */
  __pyx_t_6 = __Pyx_PyInt_As_long(__pyx_v_size2); if (unlikely((__pyx_t_6 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1219, __pyx_L1_error)
  __pyx_t_7 = __Pyx_PyInt_As_long(__pyx_v_stride2); if (unlikely((__pyx_t_7 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1219, __pyx_L1_error)

  /* "PyTorch.pyx":1218
 *     def newWithStorage3d(Storage._FloatStorage storage, offset, size0, stride0, size1, stride1, size2, stride2):
 * #        # print('allocate tensor')
 *         cdef THFloatTensor *newTensorC = THFloatTensor_newWithStorage3d(storage.native, offset, size0, stride0, size1, stride1,             # <<<<<<<<<<<<<<
 *             size2, stride2)
 *         return _FloatTensor_fromNative(newTensorC, False)
 */
  __pyx_v_newTensorC = THFloatTensor_newWithStorage3d(__pyx_v_storage->native, __pyx_t_1, __pyx_t_2, __pyx_t_3, __pyx_t_4, __pyx_t_5, __pyx_t_6, __pyx_t_7);

  /* "PyTorch.pyx":1220
 *         cdef THFloatTensor *newTensorC = THFloatTensor_newWithStorage3d(storage.native, offset, size0, stride0, size1, stride1,
 *             size2, stride2)
 *         return _FloatTensor_fromNative(newTensorC, False)             # <<<<<<<<<<<<<<
 * 
 *     @staticmethod
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_9.__pyx_n = 1;
  __pyx_t_9.retain = Py_False;
  __pyx_t_8 = __pyx_f_7PyTorch__FloatTensor_fromNative(__pyx_v_newTensorC, &__pyx_t_9); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1220, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __pyx_r = __pyx_t_8;
  __pyx_t_8 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":1216
 * 
 *     @staticmethod
 *     def newWithStorage3d(Storage._FloatStorage storage, offset, size0, stride0, size1, stride1, size2, stride2):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THFloatTensor *newTensorC = THFloatTensor_newWithStorage3d(storage.native, offset, size0, stride0, size1, stride1,
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("PyTorch._FloatTensor.newWithStorage3d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1223
 * 
 *     @staticmethod
 *     def newWithStorage4d(Storage._FloatStorage storage, offset, size0, stride0, size1, stride1, size2, stride2,             # <<<<<<<<<<<<<<
 *             size3, stride3):
 * #        # print('allocate tensor')
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_85newWithStorage4d(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_7PyTorch_12_FloatTensor_85newWithStorage4d = {"newWithStorage4d", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_85newWithStorage4d, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_85newWithStorage4d(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  struct __pyx_obj_7Storage__FloatStorage *__pyx_v_storage = 0;
  PyObject *__pyx_v_offset = 0;
  PyObject *__pyx_v_size0 = 0;
  PyObject *__pyx_v_stride0 = 0;
  PyObject *__pyx_v_size1 = 0;
  PyObject *__pyx_v_stride1 = 0;
  PyObject *__pyx_v_size2 = 0;
  PyObject *__pyx_v_stride2 = 0;
  PyObject *__pyx_v_size3 = 0;
  PyObject *__pyx_v_stride3 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("newWithStorage4d (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_storage,&__pyx_n_s_offset,&__pyx_n_s_size0,&__pyx_n_s_stride0,&__pyx_n_s_size1,&__pyx_n_s_stride1,&__pyx_n_s_size2,&__pyx_n_s_stride2,&__pyx_n_s_size3,&__pyx_n_s_stride3,0};
    PyObject* values[10] = {0,0,0,0,0,0,0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case 10: values[9] = PyTuple_GET_ITEM(__pyx_args, 9);
        case  9: values[8] = PyTuple_GET_ITEM(__pyx_args, 8);
        case  8: values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_storage)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_offset)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage4d", 1, 10, 10, 1); __PYX_ERR(0, 1223, __pyx_L3_error)
        }
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size0)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage4d", 1, 10, 10, 2); __PYX_ERR(0, 1223, __pyx_L3_error)
        }
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride0)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage4d", 1, 10, 10, 3); __PYX_ERR(0, 1223, __pyx_L3_error)
        }
        case  4:
        if (likely((values[4] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage4d", 1, 10, 10, 4); __PYX_ERR(0, 1223, __pyx_L3_error)
        }
        case  5:
        if (likely((values[5] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage4d", 1, 10, 10, 5); __PYX_ERR(0, 1223, __pyx_L3_error)
        }
        case  6:
        if (likely((values[6] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage4d", 1, 10, 10, 6); __PYX_ERR(0, 1223, __pyx_L3_error)
        }
        case  7:
        if (likely((values[7] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage4d", 1, 10, 10, 7); __PYX_ERR(0, 1223, __pyx_L3_error)
        }
        case  8:
        if (likely((values[8] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size3)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage4d", 1, 10, 10, 8); __PYX_ERR(0, 1223, __pyx_L3_error)
        }
        case  9:
        if (likely((values[9] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride3)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage4d", 1, 10, 10, 9); __PYX_ERR(0, 1223, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "newWithStorage4d") < 0)) __PYX_ERR(0, 1223, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 10) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
      values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
      values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
      values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
      values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
      values[8] = PyTuple_GET_ITEM(__pyx_args, 8);
      values[9] = PyTuple_GET_ITEM(__pyx_args, 9);
    }
    __pyx_v_storage = ((struct __pyx_obj_7Storage__FloatStorage *)values[0]);
    __pyx_v_offset = values[1];
    __pyx_v_size0 = values[2];
    __pyx_v_stride0 = values[3];
    __pyx_v_size1 = values[4];
    __pyx_v_stride1 = values[5];
    __pyx_v_size2 = values[6];
    __pyx_v_stride2 = values[7];
    __pyx_v_size3 = values[8];
    __pyx_v_stride3 = values[9];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("newWithStorage4d", 1, 10, 10, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1223, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._FloatTensor.newWithStorage4d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_storage), __pyx_ptype_7Storage__FloatStorage, 1, "storage", 0))) __PYX_ERR(0, 1223, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_84newWithStorage4d(__pyx_v_storage, __pyx_v_offset, __pyx_v_size0, __pyx_v_stride0, __pyx_v_size1, __pyx_v_stride1, __pyx_v_size2, __pyx_v_stride2, __pyx_v_size3, __pyx_v_stride3);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_84newWithStorage4d(struct __pyx_obj_7Storage__FloatStorage *__pyx_v_storage, PyObject *__pyx_v_offset, PyObject *__pyx_v_size0, PyObject *__pyx_v_stride0, PyObject *__pyx_v_size1, PyObject *__pyx_v_stride1, PyObject *__pyx_v_size2, PyObject *__pyx_v_stride2, PyObject *__pyx_v_size3, PyObject *__pyx_v_stride3) {
  struct THFloatTensor *__pyx_v_newTensorC;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  long __pyx_t_1;
  long __pyx_t_2;
  long __pyx_t_3;
  long __pyx_t_4;
  long __pyx_t_5;
  long __pyx_t_6;
  long __pyx_t_7;
  long __pyx_t_8;
  long __pyx_t_9;
  PyObject *__pyx_t_10 = NULL;
  struct __pyx_opt_args_7PyTorch__FloatTensor_fromNative __pyx_t_11;
  __Pyx_RefNannySetupContext("newWithStorage4d", 0);

  /* "PyTorch.pyx":1226
 *             size3, stride3):
 * #        # print('allocate tensor')
 *         cdef THFloatTensor *newTensorC = THFloatTensor_newWithStorage4d(storage.native, offset, size0, stride0, size1, stride1,             # <<<<<<<<<<<<<<
 *             size2, stride2, size3, stride3)
 *         return _FloatTensor_fromNative(newTensorC, False)
 */
  __pyx_t_1 = __Pyx_PyInt_As_long(__pyx_v_offset); if (unlikely((__pyx_t_1 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1226, __pyx_L1_error)
  __pyx_t_2 = __Pyx_PyInt_As_long(__pyx_v_size0); if (unlikely((__pyx_t_2 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1226, __pyx_L1_error)
  __pyx_t_3 = __Pyx_PyInt_As_long(__pyx_v_stride0); if (unlikely((__pyx_t_3 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1226, __pyx_L1_error)
  __pyx_t_4 = __Pyx_PyInt_As_long(__pyx_v_size1); if (unlikely((__pyx_t_4 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1226, __pyx_L1_error)
  __pyx_t_5 = __Pyx_PyInt_As_long(__pyx_v_stride1); if (unlikely((__pyx_t_5 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1226, __pyx_L1_error)

  /* "PyTorch.pyx":1227
 * #        # print('allocate tensor')
 *         cdef THFloatTensor *newTensorC = THFloatTensor_newWithStorage4d(storage.native, offset, size0, stride0, size1, stride1,
 *             size2, stride2, size3, stride3)             # <<<<<<<<<<<<<<
 *         return _FloatTensor_fromNative(newTensorC, False)
 * 
 */
  __pyx_t_6 = __Pyx_PyInt_As_long(__pyx_v_size2); if (unlikely((__pyx_t_6 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1227, __pyx_L1_error)
  __pyx_t_7 = __Pyx_PyInt_As_long(__pyx_v_stride2); if (unlikely((__pyx_t_7 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1227, __pyx_L1_error)
  __pyx_t_8 = __Pyx_PyInt_As_long(__pyx_v_size3); if (unlikely((__pyx_t_8 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1227, __pyx_L1_error)
  __pyx_t_9 = __Pyx_PyInt_As_long(__pyx_v_stride3); if (unlikely((__pyx_t_9 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1227, __pyx_L1_error)

  /* "PyTorch.pyx":1226
 *             size3, stride3):
 * #        # print('allocate tensor')
 *         cdef THFloatTensor *newTensorC = THFloatTensor_newWithStorage4d(storage.native, offset, size0, stride0, size1, stride1,             # <<<<<<<<<<<<<<
 *             size2, stride2, size3, stride3)
 *         return _FloatTensor_fromNative(newTensorC, False)
 */
  __pyx_v_newTensorC = THFloatTensor_newWithStorage4d(__pyx_v_storage->native, __pyx_t_1, __pyx_t_2, __pyx_t_3, __pyx_t_4, __pyx_t_5, __pyx_t_6, __pyx_t_7, __pyx_t_8, __pyx_t_9);

  /* "PyTorch.pyx":1228
 *         cdef THFloatTensor *newTensorC = THFloatTensor_newWithStorage4d(storage.native, offset, size0, stride0, size1, stride1,
 *             size2, stride2, size3, stride3)
 *         return _FloatTensor_fromNative(newTensorC, False)             # <<<<<<<<<<<<<<
 * 
 *     def clone(_FloatTensor self):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_11.__pyx_n = 1;
  __pyx_t_11.retain = Py_False;
  __pyx_t_10 = __pyx_f_7PyTorch__FloatTensor_fromNative(__pyx_v_newTensorC, &__pyx_t_11); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 1228, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __pyx_r = __pyx_t_10;
  __pyx_t_10 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":1223
 * 
 *     @staticmethod
 *     def newWithStorage4d(Storage._FloatStorage storage, offset, size0, stride0, size1, stride1, size2, stride2,             # <<<<<<<<<<<<<<
 *             size3, stride3):
 * #        # print('allocate tensor')
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_10);
  __Pyx_AddTraceback("PyTorch._FloatTensor.newWithStorage4d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1230
 *         return _FloatTensor_fromNative(newTensorC, False)
 * 
 *     def clone(_FloatTensor self):             # <<<<<<<<<<<<<<
 *         cdef THFloatTensor *newTensorC = THFloatTensor_newClone(self.native)
 *         return _FloatTensor_fromNative(newTensorC, False)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_87clone(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_87clone(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("clone (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_86clone(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_86clone(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self) {
  struct THFloatTensor *__pyx_v_newTensorC;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  struct __pyx_opt_args_7PyTorch__FloatTensor_fromNative __pyx_t_2;
  __Pyx_RefNannySetupContext("clone", 0);

  /* "PyTorch.pyx":1231
 * 
 *     def clone(_FloatTensor self):
 *         cdef THFloatTensor *newTensorC = THFloatTensor_newClone(self.native)             # <<<<<<<<<<<<<<
 *         return _FloatTensor_fromNative(newTensorC, False)
 * 
 */
  __pyx_v_newTensorC = THFloatTensor_newClone(__pyx_v_self->native);

  /* "PyTorch.pyx":1232
 *     def clone(_FloatTensor self):
 *         cdef THFloatTensor *newTensorC = THFloatTensor_newClone(self.native)
 *         return _FloatTensor_fromNative(newTensorC, False)             # <<<<<<<<<<<<<<
 * 
 *     def storage(_FloatTensor self):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2.__pyx_n = 1;
  __pyx_t_2.retain = Py_False;
  __pyx_t_1 = __pyx_f_7PyTorch__FloatTensor_fromNative(__pyx_v_newTensorC, &__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1232, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":1230
 *         return _FloatTensor_fromNative(newTensorC, False)
 * 
 *     def clone(_FloatTensor self):             # <<<<<<<<<<<<<<
 *         cdef THFloatTensor *newTensorC = THFloatTensor_newClone(self.native)
 *         return _FloatTensor_fromNative(newTensorC, False)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._FloatTensor.clone", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1234
 *         return _FloatTensor_fromNative(newTensorC, False)
 * 
 *     def storage(_FloatTensor self):             # <<<<<<<<<<<<<<
 *         cdef Storage.THFloatStorage *storageC = THFloatTensor_storage(self.native)
 *         if storageC == NULL:
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_89storage(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_89storage(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("storage (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_88storage(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_88storage(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self) {
  struct THFloatStorage *__pyx_v_storageC;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("storage", 0);

  /* "PyTorch.pyx":1235
 * 
 *     def storage(_FloatTensor self):
 *         cdef Storage.THFloatStorage *storageC = THFloatTensor_storage(self.native)             # <<<<<<<<<<<<<<
 *         if storageC == NULL:
 *             return None
 */
  __pyx_v_storageC = THFloatTensor_storage(__pyx_v_self->native);

  /* "PyTorch.pyx":1236
 *     def storage(_FloatTensor self):
 *         cdef Storage.THFloatStorage *storageC = THFloatTensor_storage(self.native)
 *         if storageC == NULL:             # <<<<<<<<<<<<<<
 *             return None
 *         return Storage._FloatStorage_fromNative(storageC)
 */
  __pyx_t_1 = ((__pyx_v_storageC == NULL) != 0);
  if (__pyx_t_1) {

    /* "PyTorch.pyx":1237
 *         cdef Storage.THFloatStorage *storageC = THFloatTensor_storage(self.native)
 *         if storageC == NULL:
 *             return None             # <<<<<<<<<<<<<<
 *         return Storage._FloatStorage_fromNative(storageC)
 * 
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(Py_None);
    __pyx_r = Py_None;
    goto __pyx_L0;

    /* "PyTorch.pyx":1236
 *     def storage(_FloatTensor self):
 *         cdef Storage.THFloatStorage *storageC = THFloatTensor_storage(self.native)
 *         if storageC == NULL:             # <<<<<<<<<<<<<<
 *             return None
 *         return Storage._FloatStorage_fromNative(storageC)
 */
  }

  /* "PyTorch.pyx":1238
 *         if storageC == NULL:
 *             return None
 *         return Storage._FloatStorage_fromNative(storageC)             # <<<<<<<<<<<<<<
 * 
 *     def __add__(_FloatTensor self, second):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2 = __pyx_f_7Storage__FloatStorage_fromNative(__pyx_v_storageC, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1238, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":1234
 *         return _FloatTensor_fromNative(newTensorC, False)
 * 
 *     def storage(_FloatTensor self):             # <<<<<<<<<<<<<<
 *         cdef Storage.THFloatStorage *storageC = THFloatTensor_storage(self.native)
 *         if storageC == NULL:
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("PyTorch._FloatTensor.storage", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1240
 *         return Storage._FloatStorage_fromNative(storageC)
 * 
 *     def __add__(_FloatTensor self, second):             # <<<<<<<<<<<<<<
 *         # assume 2d matrix for now?
 *         cdef _FloatTensor res = _FloatTensor.new()
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_91__add__(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_91__add__(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__add__ (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_self), __pyx_ptype_7PyTorch__FloatTensor, 1, "self", 0))) __PYX_ERR(0, 1240, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_90__add__(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self), ((PyObject *)__pyx_v_second));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_90__add__(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, PyObject *__pyx_v_second) {
  struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_res = 0;
  struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_secondTensor = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  int __pyx_t_5;
  float __pyx_t_6;
  __Pyx_RefNannySetupContext("__add__", 0);

  /* "PyTorch.pyx":1242
 *     def __add__(_FloatTensor self, second):
 *         # assume 2d matrix for now?
 *         cdef _FloatTensor res = _FloatTensor.new()             # <<<<<<<<<<<<<<
 *         cdef _FloatTensor secondTensor
 *         if isinstance(second, numbers.Number):
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7PyTorch__FloatTensor), __pyx_n_s_new); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1242, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1242, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1242, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_7PyTorch__FloatTensor))))) __PYX_ERR(0, 1242, __pyx_L1_error)
  __pyx_v_res = ((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":1244
 *         cdef _FloatTensor res = _FloatTensor.new()
 *         cdef _FloatTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THFloatTensor_add(res.native, self.native, second)
 *         else:
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_numbers); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1244, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_Number); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1244, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_4 = PyObject_IsInstance(__pyx_v_second, __pyx_t_2); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 1244, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = (__pyx_t_4 != 0);
  if (__pyx_t_5) {

    /* "PyTorch.pyx":1245
 *         cdef _FloatTensor secondTensor
 *         if isinstance(second, numbers.Number):
 *             THFloatTensor_add(res.native, self.native, second)             # <<<<<<<<<<<<<<
 *         else:
 *             secondTensor = second
 */
    __pyx_t_6 = __pyx_PyFloat_AsFloat(__pyx_v_second); if (unlikely((__pyx_t_6 == (float)-1) && PyErr_Occurred())) __PYX_ERR(0, 1245, __pyx_L1_error)
    THFloatTensor_add(__pyx_v_res->native, __pyx_v_self->native, __pyx_t_6);

    /* "PyTorch.pyx":1244
 *         cdef _FloatTensor res = _FloatTensor.new()
 *         cdef _FloatTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THFloatTensor_add(res.native, self.native, second)
 *         else:
 */
    goto __pyx_L3;
  }

  /* "PyTorch.pyx":1247
 *             THFloatTensor_add(res.native, self.native, second)
 *         else:
 *             secondTensor = second             # <<<<<<<<<<<<<<
 *             THFloatTensor_cadd(res.native, self.native, 1, secondTensor.native)
 *         return res
 */
  /*else*/ {
    if (!(likely(((__pyx_v_second) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_second, __pyx_ptype_7PyTorch__FloatTensor))))) __PYX_ERR(0, 1247, __pyx_L1_error)
    __pyx_t_2 = __pyx_v_second;
    __Pyx_INCREF(__pyx_t_2);
    __pyx_v_secondTensor = ((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_t_2);
    __pyx_t_2 = 0;

    /* "PyTorch.pyx":1248
 *         else:
 *             secondTensor = second
 *             THFloatTensor_cadd(res.native, self.native, 1, secondTensor.native)             # <<<<<<<<<<<<<<
 *         return res
 * 
 */
    THFloatTensor_cadd(__pyx_v_res->native, __pyx_v_self->native, 1.0, __pyx_v_secondTensor->native);
  }
  __pyx_L3:;

  /* "PyTorch.pyx":1249
 *             secondTensor = second
 *             THFloatTensor_cadd(res.native, self.native, 1, secondTensor.native)
 *         return res             # <<<<<<<<<<<<<<
 * 
 *     def cmul(_FloatTensor self, second):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = ((PyObject *)__pyx_v_res);
  goto __pyx_L0;

  /* "PyTorch.pyx":1240
 *         return Storage._FloatStorage_fromNative(storageC)
 * 
 *     def __add__(_FloatTensor self, second):             # <<<<<<<<<<<<<<
 *         # assume 2d matrix for now?
 *         cdef _FloatTensor res = _FloatTensor.new()
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("PyTorch._FloatTensor.__add__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XDECREF((PyObject *)__pyx_v_secondTensor);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1251
 *         return res
 * 
 *     def cmul(_FloatTensor self, second):             # <<<<<<<<<<<<<<
 * #        cdef _FloatTensor res = _FloatTensor.new()
 *         cdef _FloatTensor secondTensor
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_93cmul(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_93cmul(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cmul (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_92cmul(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self), ((PyObject *)__pyx_v_second));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_92cmul(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, PyObject *__pyx_v_second) {
  struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_secondTensor = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("cmul", 0);

  /* "PyTorch.pyx":1254
 * #        cdef _FloatTensor res = _FloatTensor.new()
 *         cdef _FloatTensor secondTensor
 *         secondTensor = second             # <<<<<<<<<<<<<<
 *         THFloatTensor_cmul(self.native, self.native, secondTensor.native)
 *         return self
 */
  if (!(likely(((__pyx_v_second) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_second, __pyx_ptype_7PyTorch__FloatTensor))))) __PYX_ERR(0, 1254, __pyx_L1_error)
  __pyx_t_1 = __pyx_v_second;
  __Pyx_INCREF(__pyx_t_1);
  __pyx_v_secondTensor = ((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":1255
 *         cdef _FloatTensor secondTensor
 *         secondTensor = second
 *         THFloatTensor_cmul(self.native, self.native, secondTensor.native)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THFloatTensor_cmul(__pyx_v_self->native, __pyx_v_self->native, __pyx_v_secondTensor->native);

  /* "PyTorch.pyx":1256
 *         secondTensor = second
 *         THFloatTensor_cmul(self.native, self.native, secondTensor.native)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def __sub__(_FloatTensor self, second):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1251
 *         return res
 * 
 *     def cmul(_FloatTensor self, second):             # <<<<<<<<<<<<<<
 * #        cdef _FloatTensor res = _FloatTensor.new()
 *         cdef _FloatTensor secondTensor
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._FloatTensor.cmul", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_secondTensor);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1258
 *         return self
 * 
 *     def __sub__(_FloatTensor self, second):             # <<<<<<<<<<<<<<
 *         # assume 2d matrix for now?
 *         cdef _FloatTensor res = _FloatTensor.new()
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_95__sub__(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_95__sub__(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__sub__ (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_self), __pyx_ptype_7PyTorch__FloatTensor, 1, "self", 0))) __PYX_ERR(0, 1258, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_94__sub__(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self), ((PyObject *)__pyx_v_second));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_94__sub__(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, PyObject *__pyx_v_second) {
  struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_res = 0;
  struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_secondTensor = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  int __pyx_t_5;
  float __pyx_t_6;
  __Pyx_RefNannySetupContext("__sub__", 0);

  /* "PyTorch.pyx":1260
 *     def __sub__(_FloatTensor self, second):
 *         # assume 2d matrix for now?
 *         cdef _FloatTensor res = _FloatTensor.new()             # <<<<<<<<<<<<<<
 *         cdef _FloatTensor secondTensor
 *         if isinstance(second, numbers.Number):
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7PyTorch__FloatTensor), __pyx_n_s_new); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1260, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1260, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1260, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_7PyTorch__FloatTensor))))) __PYX_ERR(0, 1260, __pyx_L1_error)
  __pyx_v_res = ((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":1262
 *         cdef _FloatTensor res = _FloatTensor.new()
 *         cdef _FloatTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THFloatTensor_add(res.native, self.native, -second)
 *         else:
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_numbers); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1262, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_Number); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1262, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_4 = PyObject_IsInstance(__pyx_v_second, __pyx_t_2); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 1262, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = (__pyx_t_4 != 0);
  if (__pyx_t_5) {

    /* "PyTorch.pyx":1263
 *         cdef _FloatTensor secondTensor
 *         if isinstance(second, numbers.Number):
 *             THFloatTensor_add(res.native, self.native, -second)             # <<<<<<<<<<<<<<
 *         else:
 *             secondTensor = second
 */
    __pyx_t_2 = PyNumber_Negative(__pyx_v_second); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1263, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_6 = __pyx_PyFloat_AsFloat(__pyx_t_2); if (unlikely((__pyx_t_6 == (float)-1) && PyErr_Occurred())) __PYX_ERR(0, 1263, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    THFloatTensor_add(__pyx_v_res->native, __pyx_v_self->native, __pyx_t_6);

    /* "PyTorch.pyx":1262
 *         cdef _FloatTensor res = _FloatTensor.new()
 *         cdef _FloatTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THFloatTensor_add(res.native, self.native, -second)
 *         else:
 */
    goto __pyx_L3;
  }

  /* "PyTorch.pyx":1265
 *             THFloatTensor_add(res.native, self.native, -second)
 *         else:
 *             secondTensor = second             # <<<<<<<<<<<<<<
 *             THFloatTensor_cadd(res.native, self.native, -1, secondTensor.native)
 *         return res
 */
  /*else*/ {
    if (!(likely(((__pyx_v_second) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_second, __pyx_ptype_7PyTorch__FloatTensor))))) __PYX_ERR(0, 1265, __pyx_L1_error)
    __pyx_t_2 = __pyx_v_second;
    __Pyx_INCREF(__pyx_t_2);
    __pyx_v_secondTensor = ((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_t_2);
    __pyx_t_2 = 0;

    /* "PyTorch.pyx":1266
 *         else:
 *             secondTensor = second
 *             THFloatTensor_cadd(res.native, self.native, -1, secondTensor.native)             # <<<<<<<<<<<<<<
 *         return res
 * 
 */
    THFloatTensor_cadd(__pyx_v_res->native, __pyx_v_self->native, -1.0, __pyx_v_secondTensor->native);
  }
  __pyx_L3:;

  /* "PyTorch.pyx":1267
 *             secondTensor = second
 *             THFloatTensor_cadd(res.native, self.native, -1, secondTensor.native)
 *         return res             # <<<<<<<<<<<<<<
 * 
 *     def eq(_FloatTensor self, _FloatTensor second):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = ((PyObject *)__pyx_v_res);
  goto __pyx_L0;

  /* "PyTorch.pyx":1258
 *         return self
 * 
 *     def __sub__(_FloatTensor self, second):             # <<<<<<<<<<<<<<
 *         # assume 2d matrix for now?
 *         cdef _FloatTensor res = _FloatTensor.new()
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("PyTorch._FloatTensor.__sub__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XDECREF((PyObject *)__pyx_v_secondTensor);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1269
 *         return res
 * 
 *     def eq(_FloatTensor self, _FloatTensor second):             # <<<<<<<<<<<<<<
 *         cdef _ByteTensor res = _ByteTensor.new()
 *         THFloatTensor_eqTensor(res.native, self.native, second.native);
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_97eq(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_97eq(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("eq (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_second), __pyx_ptype_7PyTorch__FloatTensor, 1, "second", 0))) __PYX_ERR(0, 1269, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_96eq(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self), ((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_second));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_96eq(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_second) {
  struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_res = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("eq", 0);

  /* "PyTorch.pyx":1270
 * 
 *     def eq(_FloatTensor self, _FloatTensor second):
 *         cdef _ByteTensor res = _ByteTensor.new()             # <<<<<<<<<<<<<<
 *         THFloatTensor_eqTensor(res.native, self.native, second.native);
 *         return res
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7PyTorch__ByteTensor), __pyx_n_s_new); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1270, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1270, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1270, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_7PyTorch__ByteTensor))))) __PYX_ERR(0, 1270, __pyx_L1_error)
  __pyx_v_res = ((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":1271
 *     def eq(_FloatTensor self, _FloatTensor second):
 *         cdef _ByteTensor res = _ByteTensor.new()
 *         THFloatTensor_eqTensor(res.native, self.native, second.native);             # <<<<<<<<<<<<<<
 *         return res
 * 
 */
  THFloatTensor_eqTensor(__pyx_v_res->native, __pyx_v_self->native, __pyx_v_second->native);

  /* "PyTorch.pyx":1272
 *         cdef _ByteTensor res = _ByteTensor.new()
 *         THFloatTensor_eqTensor(res.native, self.native, second.native);
 *         return res             # <<<<<<<<<<<<<<
 * 
 *     def icmin(_FloatTensor self, second):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = ((PyObject *)__pyx_v_res);
  goto __pyx_L0;

  /* "PyTorch.pyx":1269
 *         return res
 * 
 *     def eq(_FloatTensor self, _FloatTensor second):             # <<<<<<<<<<<<<<
 *         cdef _ByteTensor res = _ByteTensor.new()
 *         THFloatTensor_eqTensor(res.native, self.native, second.native);
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("PyTorch._FloatTensor.eq", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1274
 *         return res
 * 
 *     def icmin(_FloatTensor self, second):             # <<<<<<<<<<<<<<
 *       THFloatTensor_cminValue(self.native, self.native, second)
 *       return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_99icmin(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_99icmin(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("icmin (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_98icmin(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self), ((PyObject *)__pyx_v_second));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_98icmin(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  float __pyx_t_1;
  __Pyx_RefNannySetupContext("icmin", 0);

  /* "PyTorch.pyx":1275
 * 
 *     def icmin(_FloatTensor self, second):
 *       THFloatTensor_cminValue(self.native, self.native, second)             # <<<<<<<<<<<<<<
 *       return self
 * 
 */
  __pyx_t_1 = __pyx_PyFloat_AsFloat(__pyx_v_second); if (unlikely((__pyx_t_1 == (float)-1) && PyErr_Occurred())) __PYX_ERR(0, 1275, __pyx_L1_error)
  THFloatTensor_cminValue(__pyx_v_self->native, __pyx_v_self->native, __pyx_t_1);

  /* "PyTorch.pyx":1276
 *     def icmin(_FloatTensor self, second):
 *       THFloatTensor_cminValue(self.native, self.native, second)
 *       return self             # <<<<<<<<<<<<<<
 * 
 *     def icmax(_FloatTensor self, second):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1274
 *         return res
 * 
 *     def icmin(_FloatTensor self, second):             # <<<<<<<<<<<<<<
 *       THFloatTensor_cminValue(self.native, self.native, second)
 *       return self
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("PyTorch._FloatTensor.icmin", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1278
 *       return self
 * 
 *     def icmax(_FloatTensor self, second):             # <<<<<<<<<<<<<<
 *       THFloatTensor_cmaxValue(self.native, self.native, second)
 *       return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_101icmax(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_101icmax(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("icmax (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_100icmax(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self), ((PyObject *)__pyx_v_second));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_100icmax(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  float __pyx_t_1;
  __Pyx_RefNannySetupContext("icmax", 0);

  /* "PyTorch.pyx":1279
 * 
 *     def icmax(_FloatTensor self, second):
 *       THFloatTensor_cmaxValue(self.native, self.native, second)             # <<<<<<<<<<<<<<
 *       return self
 * 
 */
  __pyx_t_1 = __pyx_PyFloat_AsFloat(__pyx_v_second); if (unlikely((__pyx_t_1 == (float)-1) && PyErr_Occurred())) __PYX_ERR(0, 1279, __pyx_L1_error)
  THFloatTensor_cmaxValue(__pyx_v_self->native, __pyx_v_self->native, __pyx_t_1);

  /* "PyTorch.pyx":1280
 *     def icmax(_FloatTensor self, second):
 *       THFloatTensor_cmaxValue(self.native, self.native, second)
 *       return self             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1278
 *       return self
 * 
 *     def icmax(_FloatTensor self, second):             # <<<<<<<<<<<<<<
 *       THFloatTensor_cmaxValue(self.native, self.native, second)
 *       return self
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("PyTorch._FloatTensor.icmax", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1283
 * 
 * 
 *     def __truediv__(_FloatTensor self, second):             # <<<<<<<<<<<<<<
 *         cdef _FloatTensor res = _FloatTensor.new()
 *         cdef _FloatTensor secondTensor
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_103__truediv__(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_103__truediv__(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__truediv__ (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_self), __pyx_ptype_7PyTorch__FloatTensor, 1, "self", 0))) __PYX_ERR(0, 1283, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_102__truediv__(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self), ((PyObject *)__pyx_v_second));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_102__truediv__(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, PyObject *__pyx_v_second) {
  struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_res = 0;
  struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_secondTensor = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  int __pyx_t_5;
  float __pyx_t_6;
  __Pyx_RefNannySetupContext("__truediv__", 0);

  /* "PyTorch.pyx":1284
 * 
 *     def __truediv__(_FloatTensor self, second):
 *         cdef _FloatTensor res = _FloatTensor.new()             # <<<<<<<<<<<<<<
 *         cdef _FloatTensor secondTensor
 *         if isinstance(second, numbers.Number):
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7PyTorch__FloatTensor), __pyx_n_s_new); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1284, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1284, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1284, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_7PyTorch__FloatTensor))))) __PYX_ERR(0, 1284, __pyx_L1_error)
  __pyx_v_res = ((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":1286
 *         cdef _FloatTensor res = _FloatTensor.new()
 *         cdef _FloatTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THFloatTensor_div(res.native, self.native, second)
 *         else:
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_numbers); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1286, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_Number); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1286, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_4 = PyObject_IsInstance(__pyx_v_second, __pyx_t_2); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 1286, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = (__pyx_t_4 != 0);
  if (__pyx_t_5) {

    /* "PyTorch.pyx":1287
 *         cdef _FloatTensor secondTensor
 *         if isinstance(second, numbers.Number):
 *             THFloatTensor_div(res.native, self.native, second)             # <<<<<<<<<<<<<<
 *         else:
 *             secondTensor = second
 */
    __pyx_t_6 = __pyx_PyFloat_AsFloat(__pyx_v_second); if (unlikely((__pyx_t_6 == (float)-1) && PyErr_Occurred())) __PYX_ERR(0, 1287, __pyx_L1_error)
    THFloatTensor_div(__pyx_v_res->native, __pyx_v_self->native, __pyx_t_6);

    /* "PyTorch.pyx":1286
 *         cdef _FloatTensor res = _FloatTensor.new()
 *         cdef _FloatTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THFloatTensor_div(res.native, self.native, second)
 *         else:
 */
    goto __pyx_L3;
  }

  /* "PyTorch.pyx":1289
 *             THFloatTensor_div(res.native, self.native, second)
 *         else:
 *             secondTensor = second             # <<<<<<<<<<<<<<
 *             THFloatTensor_cdiv(res.native, self.native, secondTensor.native)
 *         return res
 */
  /*else*/ {
    if (!(likely(((__pyx_v_second) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_second, __pyx_ptype_7PyTorch__FloatTensor))))) __PYX_ERR(0, 1289, __pyx_L1_error)
    __pyx_t_2 = __pyx_v_second;
    __Pyx_INCREF(__pyx_t_2);
    __pyx_v_secondTensor = ((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_t_2);
    __pyx_t_2 = 0;

    /* "PyTorch.pyx":1290
 *         else:
 *             secondTensor = second
 *             THFloatTensor_cdiv(res.native, self.native, secondTensor.native)             # <<<<<<<<<<<<<<
 *         return res
 * 
 */
    THFloatTensor_cdiv(__pyx_v_res->native, __pyx_v_self->native, __pyx_v_secondTensor->native);
  }
  __pyx_L3:;

  /* "PyTorch.pyx":1291
 *             secondTensor = second
 *             THFloatTensor_cdiv(res.native, self.native, secondTensor.native)
 *         return res             # <<<<<<<<<<<<<<
 * 
 *     def __itruediv__(_FloatTensor self, second):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = ((PyObject *)__pyx_v_res);
  goto __pyx_L0;

  /* "PyTorch.pyx":1283
 * 
 * 
 *     def __truediv__(_FloatTensor self, second):             # <<<<<<<<<<<<<<
 *         cdef _FloatTensor res = _FloatTensor.new()
 *         cdef _FloatTensor secondTensor
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("PyTorch._FloatTensor.__truediv__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XDECREF((PyObject *)__pyx_v_secondTensor);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1293
 *         return res
 * 
 *     def __itruediv__(_FloatTensor self, second):             # <<<<<<<<<<<<<<
 *         cdef _FloatTensor secondTensor
 *         if isinstance(second, numbers.Number):
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_105__itruediv__(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_105__itruediv__(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__itruediv__ (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_104__itruediv__(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self), ((PyObject *)__pyx_v_second));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_104__itruediv__(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, PyObject *__pyx_v_second) {
  struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_secondTensor = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  int __pyx_t_4;
  float __pyx_t_5;
  __Pyx_RefNannySetupContext("__itruediv__", 0);

  /* "PyTorch.pyx":1295
 *     def __itruediv__(_FloatTensor self, second):
 *         cdef _FloatTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THFloatTensor_div(self.native, self.native, second)
 *         else:
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_numbers); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1295, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_Number); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1295, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = PyObject_IsInstance(__pyx_v_second, __pyx_t_2); if (unlikely(__pyx_t_3 == -1)) __PYX_ERR(0, 1295, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_4 = (__pyx_t_3 != 0);
  if (__pyx_t_4) {

    /* "PyTorch.pyx":1296
 *         cdef _FloatTensor secondTensor
 *         if isinstance(second, numbers.Number):
 *             THFloatTensor_div(self.native, self.native, second)             # <<<<<<<<<<<<<<
 *         else:
 *             secondTensor = second
 */
    __pyx_t_5 = __pyx_PyFloat_AsFloat(__pyx_v_second); if (unlikely((__pyx_t_5 == (float)-1) && PyErr_Occurred())) __PYX_ERR(0, 1296, __pyx_L1_error)
    THFloatTensor_div(__pyx_v_self->native, __pyx_v_self->native, __pyx_t_5);

    /* "PyTorch.pyx":1295
 *     def __itruediv__(_FloatTensor self, second):
 *         cdef _FloatTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THFloatTensor_div(self.native, self.native, second)
 *         else:
 */
    goto __pyx_L3;
  }

  /* "PyTorch.pyx":1298
 *             THFloatTensor_div(self.native, self.native, second)
 *         else:
 *             secondTensor = second             # <<<<<<<<<<<<<<
 *             THFloatTensor_cdiv(self.native, self.native, secondTensor.native)
 *         return self
 */
  /*else*/ {
    if (!(likely(((__pyx_v_second) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_second, __pyx_ptype_7PyTorch__FloatTensor))))) __PYX_ERR(0, 1298, __pyx_L1_error)
    __pyx_t_2 = __pyx_v_second;
    __Pyx_INCREF(__pyx_t_2);
    __pyx_v_secondTensor = ((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_t_2);
    __pyx_t_2 = 0;

    /* "PyTorch.pyx":1299
 *         else:
 *             secondTensor = second
 *             THFloatTensor_cdiv(self.native, self.native, secondTensor.native)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
    THFloatTensor_cdiv(__pyx_v_self->native, __pyx_v_self->native, __pyx_v_secondTensor->native);
  }
  __pyx_L3:;

  /* "PyTorch.pyx":1300
 *             secondTensor = second
 *             THFloatTensor_cdiv(self.native, self.native, secondTensor.native)
 *         return self             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1293
 *         return res
 * 
 *     def __itruediv__(_FloatTensor self, second):             # <<<<<<<<<<<<<<
 *         cdef _FloatTensor secondTensor
 *         if isinstance(second, numbers.Number):
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("PyTorch._FloatTensor.__itruediv__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_secondTensor);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1303
 * 
 * 
 *     def __iadd__(_FloatTensor self, second):             # <<<<<<<<<<<<<<
 *         cdef _FloatTensor secondTensor
 *         if isinstance(second, numbers.Number):
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_107__iadd__(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_107__iadd__(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__iadd__ (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_106__iadd__(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self), ((PyObject *)__pyx_v_second));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_106__iadd__(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, PyObject *__pyx_v_second) {
  struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_secondTensor = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  int __pyx_t_4;
  float __pyx_t_5;
  __Pyx_RefNannySetupContext("__iadd__", 0);

  /* "PyTorch.pyx":1305
 *     def __iadd__(_FloatTensor self, second):
 *         cdef _FloatTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THFloatTensor_add(self.native, self.native, second)
 *         else:
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_numbers); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1305, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_Number); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1305, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = PyObject_IsInstance(__pyx_v_second, __pyx_t_2); if (unlikely(__pyx_t_3 == -1)) __PYX_ERR(0, 1305, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_4 = (__pyx_t_3 != 0);
  if (__pyx_t_4) {

    /* "PyTorch.pyx":1306
 *         cdef _FloatTensor secondTensor
 *         if isinstance(second, numbers.Number):
 *             THFloatTensor_add(self.native, self.native, second)             # <<<<<<<<<<<<<<
 *         else:
 *             secondTensor = second
 */
    __pyx_t_5 = __pyx_PyFloat_AsFloat(__pyx_v_second); if (unlikely((__pyx_t_5 == (float)-1) && PyErr_Occurred())) __PYX_ERR(0, 1306, __pyx_L1_error)
    THFloatTensor_add(__pyx_v_self->native, __pyx_v_self->native, __pyx_t_5);

    /* "PyTorch.pyx":1305
 *     def __iadd__(_FloatTensor self, second):
 *         cdef _FloatTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THFloatTensor_add(self.native, self.native, second)
 *         else:
 */
    goto __pyx_L3;
  }

  /* "PyTorch.pyx":1308
 *             THFloatTensor_add(self.native, self.native, second)
 *         else:
 *             secondTensor = second             # <<<<<<<<<<<<<<
 *             THFloatTensor_cadd(self.native, self.native, 1, secondTensor.native)
 *         return self
 */
  /*else*/ {
    if (!(likely(((__pyx_v_second) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_second, __pyx_ptype_7PyTorch__FloatTensor))))) __PYX_ERR(0, 1308, __pyx_L1_error)
    __pyx_t_2 = __pyx_v_second;
    __Pyx_INCREF(__pyx_t_2);
    __pyx_v_secondTensor = ((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_t_2);
    __pyx_t_2 = 0;

    /* "PyTorch.pyx":1309
 *         else:
 *             secondTensor = second
 *             THFloatTensor_cadd(self.native, self.native, 1, secondTensor.native)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
    THFloatTensor_cadd(__pyx_v_self->native, __pyx_v_self->native, 1.0, __pyx_v_secondTensor->native);
  }
  __pyx_L3:;

  /* "PyTorch.pyx":1310
 *             secondTensor = second
 *             THFloatTensor_cadd(self.native, self.native, 1, secondTensor.native)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def __isub__(_FloatTensor self, second):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1303
 * 
 * 
 *     def __iadd__(_FloatTensor self, second):             # <<<<<<<<<<<<<<
 *         cdef _FloatTensor secondTensor
 *         if isinstance(second, numbers.Number):
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("PyTorch._FloatTensor.__iadd__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_secondTensor);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1312
 *         return self
 * 
 *     def __isub__(_FloatTensor self, second):             # <<<<<<<<<<<<<<
 *         cdef _FloatTensor secondTensor
 *         if isinstance(second, numbers.Number):
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_109__isub__(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_109__isub__(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__isub__ (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_108__isub__(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self), ((PyObject *)__pyx_v_second));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_108__isub__(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, PyObject *__pyx_v_second) {
  struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_secondTensor = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  int __pyx_t_4;
  float __pyx_t_5;
  __Pyx_RefNannySetupContext("__isub__", 0);

  /* "PyTorch.pyx":1314
 *     def __isub__(_FloatTensor self, second):
 *         cdef _FloatTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THFloatTensor_add(self.native, self.native, -second)
 *         else:
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_numbers); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1314, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_Number); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1314, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = PyObject_IsInstance(__pyx_v_second, __pyx_t_2); if (unlikely(__pyx_t_3 == -1)) __PYX_ERR(0, 1314, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_4 = (__pyx_t_3 != 0);
  if (__pyx_t_4) {

    /* "PyTorch.pyx":1315
 *         cdef _FloatTensor secondTensor
 *         if isinstance(second, numbers.Number):
 *             THFloatTensor_add(self.native, self.native, -second)             # <<<<<<<<<<<<<<
 *         else:
 *             secondTensor = second
 */
    __pyx_t_2 = PyNumber_Negative(__pyx_v_second); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1315, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_5 = __pyx_PyFloat_AsFloat(__pyx_t_2); if (unlikely((__pyx_t_5 == (float)-1) && PyErr_Occurred())) __PYX_ERR(0, 1315, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    THFloatTensor_add(__pyx_v_self->native, __pyx_v_self->native, __pyx_t_5);

    /* "PyTorch.pyx":1314
 *     def __isub__(_FloatTensor self, second):
 *         cdef _FloatTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THFloatTensor_add(self.native, self.native, -second)
 *         else:
 */
    goto __pyx_L3;
  }

  /* "PyTorch.pyx":1317
 *             THFloatTensor_add(self.native, self.native, -second)
 *         else:
 *             secondTensor = second             # <<<<<<<<<<<<<<
 *             THFloatTensor_cadd(self.native, self.native, -1, secondTensor.native)
 *         return self
 */
  /*else*/ {
    if (!(likely(((__pyx_v_second) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_second, __pyx_ptype_7PyTorch__FloatTensor))))) __PYX_ERR(0, 1317, __pyx_L1_error)
    __pyx_t_2 = __pyx_v_second;
    __Pyx_INCREF(__pyx_t_2);
    __pyx_v_secondTensor = ((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_t_2);
    __pyx_t_2 = 0;

    /* "PyTorch.pyx":1318
 *         else:
 *             secondTensor = second
 *             THFloatTensor_cadd(self.native, self.native, -1, secondTensor.native)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
    THFloatTensor_cadd(__pyx_v_self->native, __pyx_v_self->native, -1.0, __pyx_v_secondTensor->native);
  }
  __pyx_L3:;

  /* "PyTorch.pyx":1319
 *             secondTensor = second
 *             THFloatTensor_cadd(self.native, self.native, -1, secondTensor.native)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def __imul__(_FloatTensor self, float value):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1312
 *         return self
 * 
 *     def __isub__(_FloatTensor self, second):             # <<<<<<<<<<<<<<
 *         cdef _FloatTensor secondTensor
 *         if isinstance(second, numbers.Number):
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("PyTorch._FloatTensor.__isub__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_secondTensor);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1321
 *         return self
 * 
 *     def __imul__(_FloatTensor self, float value):             # <<<<<<<<<<<<<<
 *         THFloatTensor_mul(self.native, self.native, value)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_111__imul__(PyObject *__pyx_v_self, PyObject *__pyx_arg_value); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_111__imul__(PyObject *__pyx_v_self, PyObject *__pyx_arg_value) {
  float __pyx_v_value;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__imul__ (wrapper)", 0);
  assert(__pyx_arg_value); {
    __pyx_v_value = __pyx_PyFloat_AsFloat(__pyx_arg_value); if (unlikely((__pyx_v_value == (float)-1) && PyErr_Occurred())) __PYX_ERR(0, 1321, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._FloatTensor.__imul__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_110__imul__(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self), ((float)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_110__imul__(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, float __pyx_v_value) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__imul__", 0);

  /* "PyTorch.pyx":1322
 * 
 *     def __imul__(_FloatTensor self, float value):
 *         THFloatTensor_mul(self.native, self.native, value)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THFloatTensor_mul(__pyx_v_self->native, __pyx_v_self->native, __pyx_v_value);

  /* "PyTorch.pyx":1323
 *     def __imul__(_FloatTensor self, float value):
 *         THFloatTensor_mul(self.native, self.native, value)
 *         return self             # <<<<<<<<<<<<<<
 * 
 * #    def __mul__(_FloatTensor self, _FloatTensor M2):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1321
 *         return self
 * 
 *     def __imul__(_FloatTensor self, float value):             # <<<<<<<<<<<<<<
 *         THFloatTensor_mul(self.native, self.native, value)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1326
 * 
 * #    def __mul__(_FloatTensor self, _FloatTensor M2):
 *     def __mul__(_FloatTensor self, second):             # <<<<<<<<<<<<<<
 *         cdef _FloatTensor M2
 *         cdef _FloatTensor T
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_113__mul__(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_113__mul__(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__mul__ (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_self), __pyx_ptype_7PyTorch__FloatTensor, 1, "self", 0))) __PYX_ERR(0, 1326, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_112__mul__(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self), ((PyObject *)__pyx_v_second));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_112__mul__(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, PyObject *__pyx_v_second) {
  struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_M2 = 0;
  struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_T = 0;
  struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_res = 0;
  int __pyx_v_resRows;
  int __pyx_v_resCols;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  int __pyx_t_5;
  float __pyx_t_6;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  int __pyx_t_9;
  PyObject *__pyx_t_10 = NULL;
  __Pyx_RefNannySetupContext("__mul__", 0);

  /* "PyTorch.pyx":1333
 *         cdef int resCols
 * 
 *         res = _FloatTensor.new()             # <<<<<<<<<<<<<<
 *         if isinstance(second, numbers.Number):
 *             THFloatTensor_mul(res.native, self.native, second)
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7PyTorch__FloatTensor), __pyx_n_s_new); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1333, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1333, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1333, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_7PyTorch__FloatTensor))))) __PYX_ERR(0, 1333, __pyx_L1_error)
  __pyx_v_res = ((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":1334
 * 
 *         res = _FloatTensor.new()
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THFloatTensor_mul(res.native, self.native, second)
 *             return res
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_numbers); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1334, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_Number); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1334, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_4 = PyObject_IsInstance(__pyx_v_second, __pyx_t_2); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 1334, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = (__pyx_t_4 != 0);
  if (__pyx_t_5) {

    /* "PyTorch.pyx":1335
 *         res = _FloatTensor.new()
 *         if isinstance(second, numbers.Number):
 *             THFloatTensor_mul(res.native, self.native, second)             # <<<<<<<<<<<<<<
 *             return res
 *         else:
 */
    __pyx_t_6 = __pyx_PyFloat_AsFloat(__pyx_v_second); if (unlikely((__pyx_t_6 == (float)-1) && PyErr_Occurred())) __PYX_ERR(0, 1335, __pyx_L1_error)
    THFloatTensor_mul(__pyx_v_res->native, __pyx_v_self->native, __pyx_t_6);

    /* "PyTorch.pyx":1336
 *         if isinstance(second, numbers.Number):
 *             THFloatTensor_mul(res.native, self.native, second)
 *             return res             # <<<<<<<<<<<<<<
 *         else:
 * 
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(((PyObject *)__pyx_v_res));
    __pyx_r = ((PyObject *)__pyx_v_res);
    goto __pyx_L0;

    /* "PyTorch.pyx":1334
 * 
 *         res = _FloatTensor.new()
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THFloatTensor_mul(res.native, self.native, second)
 *             return res
 */
  }

  /* "PyTorch.pyx":1339
 *         else:
 * 
 *             M2 = second             # <<<<<<<<<<<<<<
 *             T = _FloatTensor.new()
 *             resRows = THFloatTensor_size(self.native, 0)
 */
  /*else*/ {
    if (!(likely(((__pyx_v_second) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_second, __pyx_ptype_7PyTorch__FloatTensor))))) __PYX_ERR(0, 1339, __pyx_L1_error)
    __pyx_t_2 = __pyx_v_second;
    __Pyx_INCREF(__pyx_t_2);
    __pyx_v_M2 = ((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_t_2);
    __pyx_t_2 = 0;

    /* "PyTorch.pyx":1340
 * 
 *             M2 = second
 *             T = _FloatTensor.new()             # <<<<<<<<<<<<<<
 *             resRows = THFloatTensor_size(self.native, 0)
 *             resCols = THFloatTensor_size(M2.native, 1)
 */
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7PyTorch__FloatTensor), __pyx_n_s_new); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1340, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_3 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_1))) {
      __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_1);
      if (likely(__pyx_t_3)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
        __Pyx_INCREF(__pyx_t_3);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_1, function);
      }
    }
    if (__pyx_t_3) {
      __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1340, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    } else {
      __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1340, __pyx_L1_error)
    }
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    if (!(likely(((__pyx_t_2) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_2, __pyx_ptype_7PyTorch__FloatTensor))))) __PYX_ERR(0, 1340, __pyx_L1_error)
    __pyx_v_T = ((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_t_2);
    __pyx_t_2 = 0;

    /* "PyTorch.pyx":1341
 *             M2 = second
 *             T = _FloatTensor.new()
 *             resRows = THFloatTensor_size(self.native, 0)             # <<<<<<<<<<<<<<
 *             resCols = THFloatTensor_size(M2.native, 1)
 *             res.resize2d(resRows, resCols)
 */
    __pyx_v_resRows = THFloatTensor_size(__pyx_v_self->native, 0);

    /* "PyTorch.pyx":1342
 *             T = _FloatTensor.new()
 *             resRows = THFloatTensor_size(self.native, 0)
 *             resCols = THFloatTensor_size(M2.native, 1)             # <<<<<<<<<<<<<<
 *             res.resize2d(resRows, resCols)
 *             T.resize2d(resRows, resCols)
 */
    __pyx_v_resCols = THFloatTensor_size(__pyx_v_M2->native, 1);

    /* "PyTorch.pyx":1343
 *             resRows = THFloatTensor_size(self.native, 0)
 *             resCols = THFloatTensor_size(M2.native, 1)
 *             res.resize2d(resRows, resCols)             # <<<<<<<<<<<<<<
 *             T.resize2d(resRows, resCols)
 *             THFloatTensor_addmm(res.native, 0, T.native, 1, self.native, M2.native)
 */
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_res), __pyx_n_s_resize2d); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1343, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_resRows); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1343, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_7 = __Pyx_PyInt_From_int(__pyx_v_resCols); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1343, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_8 = NULL;
    __pyx_t_9 = 0;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_1))) {
      __pyx_t_8 = PyMethod_GET_SELF(__pyx_t_1);
      if (likely(__pyx_t_8)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
        __Pyx_INCREF(__pyx_t_8);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_1, function);
        __pyx_t_9 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_1)) {
      PyObject *__pyx_temp[3] = {__pyx_t_8, __pyx_t_3, __pyx_t_7};
      __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_1, __pyx_temp+1-__pyx_t_9, 2+__pyx_t_9); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1343, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_1)) {
      PyObject *__pyx_temp[3] = {__pyx_t_8, __pyx_t_3, __pyx_t_7};
      __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_1, __pyx_temp+1-__pyx_t_9, 2+__pyx_t_9); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1343, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    } else
    #endif
    {
      __pyx_t_10 = PyTuple_New(2+__pyx_t_9); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 1343, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_10);
      if (__pyx_t_8) {
        __Pyx_GIVEREF(__pyx_t_8); PyTuple_SET_ITEM(__pyx_t_10, 0, __pyx_t_8); __pyx_t_8 = NULL;
      }
      __Pyx_GIVEREF(__pyx_t_3);
      PyTuple_SET_ITEM(__pyx_t_10, 0+__pyx_t_9, __pyx_t_3);
      __Pyx_GIVEREF(__pyx_t_7);
      PyTuple_SET_ITEM(__pyx_t_10, 1+__pyx_t_9, __pyx_t_7);
      __pyx_t_3 = 0;
      __pyx_t_7 = 0;
      __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_10, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1343, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

    /* "PyTorch.pyx":1344
 *             resCols = THFloatTensor_size(M2.native, 1)
 *             res.resize2d(resRows, resCols)
 *             T.resize2d(resRows, resCols)             # <<<<<<<<<<<<<<
 *             THFloatTensor_addmm(res.native, 0, T.native, 1, self.native, M2.native)
 *             return res
 */
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_T), __pyx_n_s_resize2d); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1344, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_10 = __Pyx_PyInt_From_int(__pyx_v_resRows); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 1344, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __pyx_t_7 = __Pyx_PyInt_From_int(__pyx_v_resCols); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1344, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_3 = NULL;
    __pyx_t_9 = 0;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_1))) {
      __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_1);
      if (likely(__pyx_t_3)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
        __Pyx_INCREF(__pyx_t_3);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_1, function);
        __pyx_t_9 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_1)) {
      PyObject *__pyx_temp[3] = {__pyx_t_3, __pyx_t_10, __pyx_t_7};
      __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_1, __pyx_temp+1-__pyx_t_9, 2+__pyx_t_9); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1344, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_1)) {
      PyObject *__pyx_temp[3] = {__pyx_t_3, __pyx_t_10, __pyx_t_7};
      __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_1, __pyx_temp+1-__pyx_t_9, 2+__pyx_t_9); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1344, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    } else
    #endif
    {
      __pyx_t_8 = PyTuple_New(2+__pyx_t_9); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1344, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      if (__pyx_t_3) {
        __Pyx_GIVEREF(__pyx_t_3); PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_t_3); __pyx_t_3 = NULL;
      }
      __Pyx_GIVEREF(__pyx_t_10);
      PyTuple_SET_ITEM(__pyx_t_8, 0+__pyx_t_9, __pyx_t_10);
      __Pyx_GIVEREF(__pyx_t_7);
      PyTuple_SET_ITEM(__pyx_t_8, 1+__pyx_t_9, __pyx_t_7);
      __pyx_t_10 = 0;
      __pyx_t_7 = 0;
      __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_8, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1344, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

    /* "PyTorch.pyx":1345
 *             res.resize2d(resRows, resCols)
 *             T.resize2d(resRows, resCols)
 *             THFloatTensor_addmm(res.native, 0, T.native, 1, self.native, M2.native)             # <<<<<<<<<<<<<<
 *             return res
 * 
 */
    THFloatTensor_addmm(__pyx_v_res->native, 0.0, __pyx_v_T->native, 1.0, __pyx_v_self->native, __pyx_v_M2->native);

    /* "PyTorch.pyx":1346
 *             T.resize2d(resRows, resCols)
 *             THFloatTensor_addmm(res.native, 0, T.native, 1, self.native, M2.native)
 *             return res             # <<<<<<<<<<<<<<
 * 
 * 
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(((PyObject *)__pyx_v_res));
    __pyx_r = ((PyObject *)__pyx_v_res);
    goto __pyx_L0;
  }

  /* "PyTorch.pyx":1326
 * 
 * #    def __mul__(_FloatTensor self, _FloatTensor M2):
 *     def __mul__(_FloatTensor self, second):             # <<<<<<<<<<<<<<
 *         cdef _FloatTensor M2
 *         cdef _FloatTensor T
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_10);
  __Pyx_AddTraceback("PyTorch._FloatTensor.__mul__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_M2);
  __Pyx_XDECREF((PyObject *)__pyx_v_T);
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1351
 *     # ========== random ===============================
 * 
 *     def bernoulli(_FloatTensor self, float p=0.5):             # <<<<<<<<<<<<<<
 *         THFloatTensor_bernoulli(self.native, globalState.generator, p)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_115bernoulli(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_115bernoulli(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  float __pyx_v_p;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("bernoulli (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_p,0};
    PyObject* values[1] = {0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_p);
          if (value) { values[0] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "bernoulli") < 0)) __PYX_ERR(0, 1351, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    if (values[0]) {
      __pyx_v_p = __pyx_PyFloat_AsFloat(values[0]); if (unlikely((__pyx_v_p == (float)-1) && PyErr_Occurred())) __PYX_ERR(0, 1351, __pyx_L3_error)
    } else {
      __pyx_v_p = ((float)0.5);
    }
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("bernoulli", 0, 0, 1, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1351, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._FloatTensor.bernoulli", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_114bernoulli(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self), __pyx_v_p);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_114bernoulli(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, float __pyx_v_p) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("bernoulli", 0);

  /* "PyTorch.pyx":1352
 * 
 *     def bernoulli(_FloatTensor self, float p=0.5):
 *         THFloatTensor_bernoulli(self.native, globalState.generator, p)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THFloatTensor_bernoulli(__pyx_v_self->native, __pyx_v_7PyTorch_globalState->generator, __pyx_v_p);

  /* "PyTorch.pyx":1353
 *     def bernoulli(_FloatTensor self, float p=0.5):
 *         THFloatTensor_bernoulli(self.native, globalState.generator, p)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def geometric(_FloatTensor self, float p=0.5):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1351
 *     # ========== random ===============================
 * 
 *     def bernoulli(_FloatTensor self, float p=0.5):             # <<<<<<<<<<<<<<
 *         THFloatTensor_bernoulli(self.native, globalState.generator, p)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1355
 *         return self
 * 
 *     def geometric(_FloatTensor self, float p=0.5):             # <<<<<<<<<<<<<<
 *         THFloatTensor_geometric(self.native, globalState.generator, p)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_117geometric(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_117geometric(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  float __pyx_v_p;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("geometric (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_p,0};
    PyObject* values[1] = {0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_p);
          if (value) { values[0] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "geometric") < 0)) __PYX_ERR(0, 1355, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    if (values[0]) {
      __pyx_v_p = __pyx_PyFloat_AsFloat(values[0]); if (unlikely((__pyx_v_p == (float)-1) && PyErr_Occurred())) __PYX_ERR(0, 1355, __pyx_L3_error)
    } else {
      __pyx_v_p = ((float)0.5);
    }
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("geometric", 0, 0, 1, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1355, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._FloatTensor.geometric", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_116geometric(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self), __pyx_v_p);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_116geometric(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, float __pyx_v_p) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("geometric", 0);

  /* "PyTorch.pyx":1356
 * 
 *     def geometric(_FloatTensor self, float p=0.5):
 *         THFloatTensor_geometric(self.native, globalState.generator, p)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THFloatTensor_geometric(__pyx_v_self->native, __pyx_v_7PyTorch_globalState->generator, __pyx_v_p);

  /* "PyTorch.pyx":1357
 *     def geometric(_FloatTensor self, float p=0.5):
 *         THFloatTensor_geometric(self.native, globalState.generator, p)
 *         return self             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1355
 *         return self
 * 
 *     def geometric(_FloatTensor self, float p=0.5):             # <<<<<<<<<<<<<<
 *         THFloatTensor_geometric(self.native, globalState.generator, p)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1360
 * 
 * 
 *     def normal(_FloatTensor self, float mean=0, float stdv=1):             # <<<<<<<<<<<<<<
 *         THFloatTensor_normal(self.native, globalState.generator, mean, stdv)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_119normal(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_119normal(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  float __pyx_v_mean;
  float __pyx_v_stdv;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("normal (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_mean,&__pyx_n_s_stdv,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_mean);
          if (value) { values[0] = value; kw_args--; }
        }
        case  1:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stdv);
          if (value) { values[1] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "normal") < 0)) __PYX_ERR(0, 1360, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    if (values[0]) {
      __pyx_v_mean = __pyx_PyFloat_AsFloat(values[0]); if (unlikely((__pyx_v_mean == (float)-1) && PyErr_Occurred())) __PYX_ERR(0, 1360, __pyx_L3_error)
    } else {
      __pyx_v_mean = ((float)0.0);
    }
    if (values[1]) {
      __pyx_v_stdv = __pyx_PyFloat_AsFloat(values[1]); if (unlikely((__pyx_v_stdv == (float)-1) && PyErr_Occurred())) __PYX_ERR(0, 1360, __pyx_L3_error)
    } else {
      __pyx_v_stdv = ((float)1.0);
    }
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("normal", 0, 0, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1360, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._FloatTensor.normal", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_118normal(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self), __pyx_v_mean, __pyx_v_stdv);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_118normal(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, float __pyx_v_mean, float __pyx_v_stdv) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("normal", 0);

  /* "PyTorch.pyx":1361
 * 
 *     def normal(_FloatTensor self, float mean=0, float stdv=1):
 *         THFloatTensor_normal(self.native, globalState.generator, mean, stdv)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THFloatTensor_normal(__pyx_v_self->native, __pyx_v_7PyTorch_globalState->generator, __pyx_v_mean, __pyx_v_stdv);

  /* "PyTorch.pyx":1362
 *     def normal(_FloatTensor self, float mean=0, float stdv=1):
 *         THFloatTensor_normal(self.native, globalState.generator, mean, stdv)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def exponential(_FloatTensor self, float _lambda=1):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1360
 * 
 * 
 *     def normal(_FloatTensor self, float mean=0, float stdv=1):             # <<<<<<<<<<<<<<
 *         THFloatTensor_normal(self.native, globalState.generator, mean, stdv)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1364
 *         return self
 * 
 *     def exponential(_FloatTensor self, float _lambda=1):             # <<<<<<<<<<<<<<
 *         THFloatTensor_exponential(self.native, globalState.generator, _lambda)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_121exponential(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_121exponential(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  float __pyx_v__lambda;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("exponential (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_lambda,0};
    PyObject* values[1] = {0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_lambda);
          if (value) { values[0] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "exponential") < 0)) __PYX_ERR(0, 1364, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    if (values[0]) {
      __pyx_v__lambda = __pyx_PyFloat_AsFloat(values[0]); if (unlikely((__pyx_v__lambda == (float)-1) && PyErr_Occurred())) __PYX_ERR(0, 1364, __pyx_L3_error)
    } else {
      __pyx_v__lambda = ((float)1.0);
    }
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("exponential", 0, 0, 1, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1364, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._FloatTensor.exponential", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_120exponential(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self), __pyx_v__lambda);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_120exponential(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, float __pyx_v__lambda) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("exponential", 0);

  /* "PyTorch.pyx":1365
 * 
 *     def exponential(_FloatTensor self, float _lambda=1):
 *         THFloatTensor_exponential(self.native, globalState.generator, _lambda)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THFloatTensor_exponential(__pyx_v_self->native, __pyx_v_7PyTorch_globalState->generator, __pyx_v__lambda);

  /* "PyTorch.pyx":1366
 *     def exponential(_FloatTensor self, float _lambda=1):
 *         THFloatTensor_exponential(self.native, globalState.generator, _lambda)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def cauchy(_FloatTensor self, float median=0, float sigma=1):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1364
 *         return self
 * 
 *     def exponential(_FloatTensor self, float _lambda=1):             # <<<<<<<<<<<<<<
 *         THFloatTensor_exponential(self.native, globalState.generator, _lambda)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1368
 *         return self
 * 
 *     def cauchy(_FloatTensor self, float median=0, float sigma=1):             # <<<<<<<<<<<<<<
 *         THFloatTensor_cauchy(self.native, globalState.generator, median, sigma)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_123cauchy(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_123cauchy(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  float __pyx_v_median;
  float __pyx_v_sigma;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cauchy (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_median,&__pyx_n_s_sigma,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_median);
          if (value) { values[0] = value; kw_args--; }
        }
        case  1:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_sigma);
          if (value) { values[1] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cauchy") < 0)) __PYX_ERR(0, 1368, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    if (values[0]) {
      __pyx_v_median = __pyx_PyFloat_AsFloat(values[0]); if (unlikely((__pyx_v_median == (float)-1) && PyErr_Occurred())) __PYX_ERR(0, 1368, __pyx_L3_error)
    } else {
      __pyx_v_median = ((float)0.0);
    }
    if (values[1]) {
      __pyx_v_sigma = __pyx_PyFloat_AsFloat(values[1]); if (unlikely((__pyx_v_sigma == (float)-1) && PyErr_Occurred())) __PYX_ERR(0, 1368, __pyx_L3_error)
    } else {
      __pyx_v_sigma = ((float)1.0);
    }
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cauchy", 0, 0, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1368, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._FloatTensor.cauchy", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_122cauchy(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self), __pyx_v_median, __pyx_v_sigma);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_122cauchy(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, float __pyx_v_median, float __pyx_v_sigma) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cauchy", 0);

  /* "PyTorch.pyx":1369
 * 
 *     def cauchy(_FloatTensor self, float median=0, float sigma=1):
 *         THFloatTensor_cauchy(self.native, globalState.generator, median, sigma)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THFloatTensor_cauchy(__pyx_v_self->native, __pyx_v_7PyTorch_globalState->generator, __pyx_v_median, __pyx_v_sigma);

  /* "PyTorch.pyx":1370
 *     def cauchy(_FloatTensor self, float median=0, float sigma=1):
 *         THFloatTensor_cauchy(self.native, globalState.generator, median, sigma)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def logNormal(_FloatTensor self, float mean=1, float stdv=2):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1368
 *         return self
 * 
 *     def cauchy(_FloatTensor self, float median=0, float sigma=1):             # <<<<<<<<<<<<<<
 *         THFloatTensor_cauchy(self.native, globalState.generator, median, sigma)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1372
 *         return self
 * 
 *     def logNormal(_FloatTensor self, float mean=1, float stdv=2):             # <<<<<<<<<<<<<<
 *         THFloatTensor_logNormal(self.native, globalState.generator, mean, stdv)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_125logNormal(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_125logNormal(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  float __pyx_v_mean;
  float __pyx_v_stdv;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("logNormal (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_mean,&__pyx_n_s_stdv,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_mean);
          if (value) { values[0] = value; kw_args--; }
        }
        case  1:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stdv);
          if (value) { values[1] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "logNormal") < 0)) __PYX_ERR(0, 1372, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    if (values[0]) {
      __pyx_v_mean = __pyx_PyFloat_AsFloat(values[0]); if (unlikely((__pyx_v_mean == (float)-1) && PyErr_Occurred())) __PYX_ERR(0, 1372, __pyx_L3_error)
    } else {
      __pyx_v_mean = ((float)1.0);
    }
    if (values[1]) {
      __pyx_v_stdv = __pyx_PyFloat_AsFloat(values[1]); if (unlikely((__pyx_v_stdv == (float)-1) && PyErr_Occurred())) __PYX_ERR(0, 1372, __pyx_L3_error)
    } else {
      __pyx_v_stdv = ((float)2.0);
    }
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("logNormal", 0, 0, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1372, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._FloatTensor.logNormal", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_124logNormal(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self), __pyx_v_mean, __pyx_v_stdv);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_124logNormal(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, float __pyx_v_mean, float __pyx_v_stdv) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("logNormal", 0);

  /* "PyTorch.pyx":1373
 * 
 *     def logNormal(_FloatTensor self, float mean=1, float stdv=2):
 *         THFloatTensor_logNormal(self.native, globalState.generator, mean, stdv)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THFloatTensor_logNormal(__pyx_v_self->native, __pyx_v_7PyTorch_globalState->generator, __pyx_v_mean, __pyx_v_stdv);

  /* "PyTorch.pyx":1374
 *     def logNormal(_FloatTensor self, float mean=1, float stdv=2):
 *         THFloatTensor_logNormal(self.native, globalState.generator, mean, stdv)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def uniform(_FloatTensor self, float a=0, float b=1):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1372
 *         return self
 * 
 *     def logNormal(_FloatTensor self, float mean=1, float stdv=2):             # <<<<<<<<<<<<<<
 *         THFloatTensor_logNormal(self.native, globalState.generator, mean, stdv)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1376
 *         return self
 * 
 *     def uniform(_FloatTensor self, float a=0, float b=1):             # <<<<<<<<<<<<<<
 *         THFloatTensor_uniform(self.native, globalState.generator, a, b)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_127uniform(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_12_FloatTensor_127uniform(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  float __pyx_v_a;
  float __pyx_v_b;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("uniform (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_a,&__pyx_n_s_b,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_a);
          if (value) { values[0] = value; kw_args--; }
        }
        case  1:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_b);
          if (value) { values[1] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "uniform") < 0)) __PYX_ERR(0, 1376, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    if (values[0]) {
      __pyx_v_a = __pyx_PyFloat_AsFloat(values[0]); if (unlikely((__pyx_v_a == (float)-1) && PyErr_Occurred())) __PYX_ERR(0, 1376, __pyx_L3_error)
    } else {
      __pyx_v_a = ((float)0.0);
    }
    if (values[1]) {
      __pyx_v_b = __pyx_PyFloat_AsFloat(values[1]); if (unlikely((__pyx_v_b == (float)-1) && PyErr_Occurred())) __PYX_ERR(0, 1376, __pyx_L3_error)
    } else {
      __pyx_v_b = ((float)1.0);
    }
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("uniform", 0, 0, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1376, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._FloatTensor.uniform", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_12_FloatTensor_126uniform(((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_self), __pyx_v_a, __pyx_v_b);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_FloatTensor_126uniform(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_self, float __pyx_v_a, float __pyx_v_b) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("uniform", 0);

  /* "PyTorch.pyx":1377
 * 
 *     def uniform(_FloatTensor self, float a=0, float b=1):
 *         THFloatTensor_uniform(self.native, globalState.generator, a, b)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THFloatTensor_uniform(__pyx_v_self->native, __pyx_v_7PyTorch_globalState->generator, __pyx_v_a, __pyx_v_b);

  /* "PyTorch.pyx":1378
 *     def uniform(_FloatTensor self, float a=0, float b=1):
 *         THFloatTensor_uniform(self.native, globalState.generator, a, b)
 *         return self             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1376
 *         return self
 * 
 *     def uniform(_FloatTensor self, float a=0, float b=1):             # <<<<<<<<<<<<<<
 *         THFloatTensor_uniform(self.native, globalState.generator, a, b)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1382
 * 
 * #    @staticmethod
 * cdef _FloatTensor_fromNative(THFloatTensor *tensorC, retain=True):             # <<<<<<<<<<<<<<
 *     if retain:
 *         THFloatTensor_retain(tensorC)
 */

static PyObject *__pyx_f_7PyTorch__FloatTensor_fromNative(struct THFloatTensor *__pyx_v_tensorC, struct __pyx_opt_args_7PyTorch__FloatTensor_fromNative *__pyx_optional_args) {
  PyObject *__pyx_v_retain = ((PyObject *)Py_True);
  struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_tensor = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("_FloatTensor_fromNative", 0);
  if (__pyx_optional_args) {
    if (__pyx_optional_args->__pyx_n > 0) {
      __pyx_v_retain = __pyx_optional_args->retain;
    }
  }

  /* "PyTorch.pyx":1383
 * #    @staticmethod
 * cdef _FloatTensor_fromNative(THFloatTensor *tensorC, retain=True):
 *     if retain:             # <<<<<<<<<<<<<<
 *         THFloatTensor_retain(tensorC)
 *     tensor = _FloatTensor(_allocate=False)
 */
  __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_v_retain); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(0, 1383, __pyx_L1_error)
  if (__pyx_t_1) {

    /* "PyTorch.pyx":1384
 * cdef _FloatTensor_fromNative(THFloatTensor *tensorC, retain=True):
 *     if retain:
 *         THFloatTensor_retain(tensorC)             # <<<<<<<<<<<<<<
 *     tensor = _FloatTensor(_allocate=False)
 *     tensor.native = tensorC
 */
    THFloatTensor_retain(__pyx_v_tensorC);

    /* "PyTorch.pyx":1383
 * #    @staticmethod
 * cdef _FloatTensor_fromNative(THFloatTensor *tensorC, retain=True):
 *     if retain:             # <<<<<<<<<<<<<<
 *         THFloatTensor_retain(tensorC)
 *     tensor = _FloatTensor(_allocate=False)
 */
  }

  /* "PyTorch.pyx":1385
 *     if retain:
 *         THFloatTensor_retain(tensorC)
 *     tensor = _FloatTensor(_allocate=False)             # <<<<<<<<<<<<<<
 *     tensor.native = tensorC
 *     return tensor
 */
  __pyx_t_2 = PyDict_New(); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1385, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_t_2, __pyx_n_s_allocate, Py_False) < 0) __PYX_ERR(0, 1385, __pyx_L1_error)
  __pyx_t_3 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_7PyTorch__FloatTensor), __pyx_empty_tuple, __pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1385, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_tensor = ((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_t_3);
  __pyx_t_3 = 0;

  /* "PyTorch.pyx":1386
 *         THFloatTensor_retain(tensorC)
 *     tensor = _FloatTensor(_allocate=False)
 *     tensor.native = tensorC             # <<<<<<<<<<<<<<
 *     return tensor
 * 
 */
  __pyx_v_tensor->native = __pyx_v_tensorC;

  /* "PyTorch.pyx":1387
 *     tensor = _FloatTensor(_allocate=False)
 *     tensor.native = tensorC
 *     return tensor             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_tensor));
  __pyx_r = ((PyObject *)__pyx_v_tensor);
  goto __pyx_L0;

  /* "PyTorch.pyx":1382
 * 
 * #    @staticmethod
 * cdef _FloatTensor_fromNative(THFloatTensor *tensorC, retain=True):             # <<<<<<<<<<<<<<
 *     if retain:
 *         THFloatTensor_retain(tensorC)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("PyTorch._FloatTensor_fromNative", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_tensor);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1390
 * 
 * 
 * def _asFloatTensor(myarray):             # <<<<<<<<<<<<<<
 *     cdef float[:] myarraymv
 *     cdef Storage._FloatStorage storage
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_5_asFloatTensor(PyObject *__pyx_self, PyObject *__pyx_v_myarray); /*proto*/
static PyMethodDef __pyx_mdef_7PyTorch_5_asFloatTensor = {"_asFloatTensor", (PyCFunction)__pyx_pw_7PyTorch_5_asFloatTensor, METH_O, 0};
static PyObject *__pyx_pw_7PyTorch_5_asFloatTensor(PyObject *__pyx_self, PyObject *__pyx_v_myarray) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_asFloatTensor (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_4_asFloatTensor(__pyx_self, ((PyObject *)__pyx_v_myarray));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_4_asFloatTensor(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_myarray) {
  __Pyx_memviewslice __pyx_v_myarraymv = { 0, 0, { 0 }, { 0 }, { 0 } };
  struct __pyx_obj_7Storage__FloatStorage *__pyx_v_storage = 0;
  PyObject *__pyx_v_dims = NULL;
  PyObject *__pyx_v_totalSize = NULL;
  PyObject *__pyx_v_size = NULL;
  PyObject *__pyx_v_stride = NULL;
  PyObject *__pyx_v_strideSoFar = NULL;
  PyObject *__pyx_v_d = NULL;
  PyObject *__pyx_v_tensor = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  int __pyx_t_4;
  Py_ssize_t __pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *(*__pyx_t_8)(PyObject *);
  __Pyx_memviewslice __pyx_t_9 = { 0, 0, { 0 }, { 0 }, { 0 } };
  PyObject *__pyx_t_10 = NULL;
  int __pyx_t_11;
  __Pyx_RefNannySetupContext("_asFloatTensor", 0);

  /* "PyTorch.pyx":1393
 *     cdef float[:] myarraymv
 *     cdef Storage._FloatStorage storage
 *     if str(type(myarray)) in ["<type 'numpy.ndarray'>", "<class 'numpy.ndarray'>"]:             # <<<<<<<<<<<<<<
 *         dims = len(myarray.shape)
 *         if dims >= 1:
 */
  __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1393, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_INCREF(((PyObject *)Py_TYPE(__pyx_v_myarray)));
  __Pyx_GIVEREF(((PyObject *)Py_TYPE(__pyx_v_myarray)));
  PyTuple_SET_ITEM(__pyx_t_1, 0, ((PyObject *)Py_TYPE(__pyx_v_myarray)));
  __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)(&PyString_Type)), __pyx_t_1, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1393, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_4 = (__Pyx_PyString_Equals(__pyx_t_2, __pyx_kp_s_type_numpy_ndarray, Py_EQ)); if (unlikely(__pyx_t_4 < 0)) __PYX_ERR(0, 1393, __pyx_L1_error)
  if (!__pyx_t_4) {
  } else {
    __pyx_t_3 = __pyx_t_4;
    goto __pyx_L4_bool_binop_done;
  }
  __pyx_t_4 = (__Pyx_PyString_Equals(__pyx_t_2, __pyx_kp_s_class_numpy_ndarray, Py_EQ)); if (unlikely(__pyx_t_4 < 0)) __PYX_ERR(0, 1393, __pyx_L1_error)
  __pyx_t_3 = __pyx_t_4;
  __pyx_L4_bool_binop_done:;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_4 = (__pyx_t_3 != 0);
  if (__pyx_t_4) {

    /* "PyTorch.pyx":1394
 *     cdef Storage._FloatStorage storage
 *     if str(type(myarray)) in ["<type 'numpy.ndarray'>", "<class 'numpy.ndarray'>"]:
 *         dims = len(myarray.shape)             # <<<<<<<<<<<<<<
 *         if dims >= 1:
 *             totalSize = 1
 */
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_myarray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1394, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_5 = PyObject_Length(__pyx_t_2); if (unlikely(__pyx_t_5 == -1)) __PYX_ERR(0, 1394, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = PyInt_FromSsize_t(__pyx_t_5); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1394, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_v_dims = __pyx_t_2;
    __pyx_t_2 = 0;

    /* "PyTorch.pyx":1395
 *     if str(type(myarray)) in ["<type 'numpy.ndarray'>", "<class 'numpy.ndarray'>"]:
 *         dims = len(myarray.shape)
 *         if dims >= 1:             # <<<<<<<<<<<<<<
 *             totalSize = 1
 *             size = Storage._LongStorage.newWithSize(dims)
 */
    __pyx_t_2 = PyObject_RichCompare(__pyx_v_dims, __pyx_int_1, Py_GE); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1395, __pyx_L1_error)
    __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely(__pyx_t_4 < 0)) __PYX_ERR(0, 1395, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    if (__pyx_t_4) {

      /* "PyTorch.pyx":1396
 *         dims = len(myarray.shape)
 *         if dims >= 1:
 *             totalSize = 1             # <<<<<<<<<<<<<<
 *             size = Storage._LongStorage.newWithSize(dims)
 *             stride = Storage._LongStorage.newWithSize(dims)
 */
      __Pyx_INCREF(__pyx_int_1);
      __pyx_v_totalSize = __pyx_int_1;

      /* "PyTorch.pyx":1397
 *         if dims >= 1:
 *             totalSize = 1
 *             size = Storage._LongStorage.newWithSize(dims)             # <<<<<<<<<<<<<<
 *             stride = Storage._LongStorage.newWithSize(dims)
 *             strideSoFar = 1
 */
      __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7Storage__LongStorage), __pyx_n_s_newWithSize); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1397, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_6 = NULL;
      if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_1))) {
        __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_1);
        if (likely(__pyx_t_6)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
          __Pyx_INCREF(__pyx_t_6);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_1, function);
        }
      }
      if (!__pyx_t_6) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_v_dims); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1397, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
      } else {
        #if CYTHON_FAST_PYCALL
        if (PyFunction_Check(__pyx_t_1)) {
          PyObject *__pyx_temp[2] = {__pyx_t_6, __pyx_v_dims};
          __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_1, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1397, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
          __Pyx_GOTREF(__pyx_t_2);
        } else
        #endif
        #if CYTHON_FAST_PYCCALL
        if (__Pyx_PyFastCFunction_Check(__pyx_t_1)) {
          PyObject *__pyx_temp[2] = {__pyx_t_6, __pyx_v_dims};
          __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_1, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1397, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
          __Pyx_GOTREF(__pyx_t_2);
        } else
        #endif
        {
          __pyx_t_7 = PyTuple_New(1+1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1397, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_7);
          __Pyx_GIVEREF(__pyx_t_6); PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_6); __pyx_t_6 = NULL;
          __Pyx_INCREF(__pyx_v_dims);
          __Pyx_GIVEREF(__pyx_v_dims);
          PyTuple_SET_ITEM(__pyx_t_7, 0+1, __pyx_v_dims);
          __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_7, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1397, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        }
      }
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_v_size = __pyx_t_2;
      __pyx_t_2 = 0;

      /* "PyTorch.pyx":1398
 *             totalSize = 1
 *             size = Storage._LongStorage.newWithSize(dims)
 *             stride = Storage._LongStorage.newWithSize(dims)             # <<<<<<<<<<<<<<
 *             strideSoFar = 1
 *             for d in range(dims - 1, -1, -1):
 */
      __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7Storage__LongStorage), __pyx_n_s_newWithSize); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1398, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_7 = NULL;
      if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_1))) {
        __pyx_t_7 = PyMethod_GET_SELF(__pyx_t_1);
        if (likely(__pyx_t_7)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
          __Pyx_INCREF(__pyx_t_7);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_1, function);
        }
      }
      if (!__pyx_t_7) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_v_dims); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1398, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
      } else {
        #if CYTHON_FAST_PYCALL
        if (PyFunction_Check(__pyx_t_1)) {
          PyObject *__pyx_temp[2] = {__pyx_t_7, __pyx_v_dims};
          __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_1, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1398, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
          __Pyx_GOTREF(__pyx_t_2);
        } else
        #endif
        #if CYTHON_FAST_PYCCALL
        if (__Pyx_PyFastCFunction_Check(__pyx_t_1)) {
          PyObject *__pyx_temp[2] = {__pyx_t_7, __pyx_v_dims};
          __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_1, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1398, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
          __Pyx_GOTREF(__pyx_t_2);
        } else
        #endif
        {
          __pyx_t_6 = PyTuple_New(1+1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1398, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_6);
          __Pyx_GIVEREF(__pyx_t_7); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_7); __pyx_t_7 = NULL;
          __Pyx_INCREF(__pyx_v_dims);
          __Pyx_GIVEREF(__pyx_v_dims);
          PyTuple_SET_ITEM(__pyx_t_6, 0+1, __pyx_v_dims);
          __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_6, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1398, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
        }
      }
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_v_stride = __pyx_t_2;
      __pyx_t_2 = 0;

      /* "PyTorch.pyx":1399
 *             size = Storage._LongStorage.newWithSize(dims)
 *             stride = Storage._LongStorage.newWithSize(dims)
 *             strideSoFar = 1             # <<<<<<<<<<<<<<
 *             for d in range(dims - 1, -1, -1):
 *                 totalSize *= myarray.shape[d]
 */
      __Pyx_INCREF(__pyx_int_1);
      __pyx_v_strideSoFar = __pyx_int_1;

      /* "PyTorch.pyx":1400
 *             stride = Storage._LongStorage.newWithSize(dims)
 *             strideSoFar = 1
 *             for d in range(dims - 1, -1, -1):             # <<<<<<<<<<<<<<
 *                 totalSize *= myarray.shape[d]
 *                 size[d] = myarray.shape[d]
 */
      __pyx_t_2 = __Pyx_PyInt_SubtractObjC(__pyx_v_dims, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1400, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_1 = PyTuple_New(3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1400, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_GIVEREF(__pyx_t_2);
      PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_2);
      __Pyx_INCREF(__pyx_int_neg_1);
      __Pyx_GIVEREF(__pyx_int_neg_1);
      PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_int_neg_1);
      __Pyx_INCREF(__pyx_int_neg_1);
      __Pyx_GIVEREF(__pyx_int_neg_1);
      PyTuple_SET_ITEM(__pyx_t_1, 2, __pyx_int_neg_1);
      __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_range, __pyx_t_1, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1400, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      if (likely(PyList_CheckExact(__pyx_t_2)) || PyTuple_CheckExact(__pyx_t_2)) {
        __pyx_t_1 = __pyx_t_2; __Pyx_INCREF(__pyx_t_1); __pyx_t_5 = 0;
        __pyx_t_8 = NULL;
      } else {
        __pyx_t_5 = -1; __pyx_t_1 = PyObject_GetIter(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1400, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __pyx_t_8 = Py_TYPE(__pyx_t_1)->tp_iternext; if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1400, __pyx_L1_error)
      }
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      for (;;) {
        if (likely(!__pyx_t_8)) {
          if (likely(PyList_CheckExact(__pyx_t_1))) {
            if (__pyx_t_5 >= PyList_GET_SIZE(__pyx_t_1)) break;
            #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
            __pyx_t_2 = PyList_GET_ITEM(__pyx_t_1, __pyx_t_5); __Pyx_INCREF(__pyx_t_2); __pyx_t_5++; if (unlikely(0 < 0)) __PYX_ERR(0, 1400, __pyx_L1_error)
            #else
            __pyx_t_2 = PySequence_ITEM(__pyx_t_1, __pyx_t_5); __pyx_t_5++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1400, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_2);
            #endif
          } else {
            if (__pyx_t_5 >= PyTuple_GET_SIZE(__pyx_t_1)) break;
            #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
            __pyx_t_2 = PyTuple_GET_ITEM(__pyx_t_1, __pyx_t_5); __Pyx_INCREF(__pyx_t_2); __pyx_t_5++; if (unlikely(0 < 0)) __PYX_ERR(0, 1400, __pyx_L1_error)
            #else
            __pyx_t_2 = PySequence_ITEM(__pyx_t_1, __pyx_t_5); __pyx_t_5++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1400, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_2);
            #endif
          }
        } else {
          __pyx_t_2 = __pyx_t_8(__pyx_t_1);
          if (unlikely(!__pyx_t_2)) {
            PyObject* exc_type = PyErr_Occurred();
            if (exc_type) {
              if (likely(exc_type == PyExc_StopIteration || PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
              else __PYX_ERR(0, 1400, __pyx_L1_error)
            }
            break;
          }
          __Pyx_GOTREF(__pyx_t_2);
        }
        __Pyx_XDECREF_SET(__pyx_v_d, __pyx_t_2);
        __pyx_t_2 = 0;

        /* "PyTorch.pyx":1401
 *             strideSoFar = 1
 *             for d in range(dims - 1, -1, -1):
 *                 totalSize *= myarray.shape[d]             # <<<<<<<<<<<<<<
 *                 size[d] = myarray.shape[d]
 *                 stride[d] = strideSoFar
 */
        __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_myarray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1401, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __pyx_t_6 = PyObject_GetItem(__pyx_t_2, __pyx_v_d); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1401, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        __pyx_t_2 = PyNumber_InPlaceMultiply(__pyx_v_totalSize, __pyx_t_6); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1401, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_DECREF_SET(__pyx_v_totalSize, __pyx_t_2);
        __pyx_t_2 = 0;

        /* "PyTorch.pyx":1402
 *             for d in range(dims - 1, -1, -1):
 *                 totalSize *= myarray.shape[d]
 *                 size[d] = myarray.shape[d]             # <<<<<<<<<<<<<<
 *                 stride[d] = strideSoFar
 *                 strideSoFar *= size[d]
 */
        __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_myarray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1402, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __pyx_t_6 = PyObject_GetItem(__pyx_t_2, __pyx_v_d); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1402, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        if (unlikely(PyObject_SetItem(__pyx_v_size, __pyx_v_d, __pyx_t_6) < 0)) __PYX_ERR(0, 1402, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;

        /* "PyTorch.pyx":1403
 *                 totalSize *= myarray.shape[d]
 *                 size[d] = myarray.shape[d]
 *                 stride[d] = strideSoFar             # <<<<<<<<<<<<<<
 *                 strideSoFar *= size[d]
 *             myarraymv = myarray.reshape(totalSize)
 */
        if (unlikely(PyObject_SetItem(__pyx_v_stride, __pyx_v_d, __pyx_v_strideSoFar) < 0)) __PYX_ERR(0, 1403, __pyx_L1_error)

        /* "PyTorch.pyx":1404
 *                 size[d] = myarray.shape[d]
 *                 stride[d] = strideSoFar
 *                 strideSoFar *= size[d]             # <<<<<<<<<<<<<<
 *             myarraymv = myarray.reshape(totalSize)
 *             storage = Storage._FloatStorage.newWithData(myarraymv)
 */
        __pyx_t_6 = PyObject_GetItem(__pyx_v_size, __pyx_v_d); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1404, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __pyx_t_2 = PyNumber_InPlaceMultiply(__pyx_v_strideSoFar, __pyx_t_6); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1404, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_DECREF_SET(__pyx_v_strideSoFar, __pyx_t_2);
        __pyx_t_2 = 0;

        /* "PyTorch.pyx":1400
 *             stride = Storage._LongStorage.newWithSize(dims)
 *             strideSoFar = 1
 *             for d in range(dims - 1, -1, -1):             # <<<<<<<<<<<<<<
 *                 totalSize *= myarray.shape[d]
 *                 size[d] = myarray.shape[d]
 */
      }
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

      /* "PyTorch.pyx":1405
 *                 stride[d] = strideSoFar
 *                 strideSoFar *= size[d]
 *             myarraymv = myarray.reshape(totalSize)             # <<<<<<<<<<<<<<
 *             storage = Storage._FloatStorage.newWithData(myarraymv)
 *             Storage.THFloatStorage_retain(storage.native) # since newWithData takes ownership
 */
      __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_myarray, __pyx_n_s_reshape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1405, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_6 = NULL;
      if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
        __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_2);
        if (likely(__pyx_t_6)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
          __Pyx_INCREF(__pyx_t_6);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_2, function);
        }
      }
      if (!__pyx_t_6) {
        __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_v_totalSize); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1405, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
      } else {
        #if CYTHON_FAST_PYCALL
        if (PyFunction_Check(__pyx_t_2)) {
          PyObject *__pyx_temp[2] = {__pyx_t_6, __pyx_v_totalSize};
          __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1405, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
          __Pyx_GOTREF(__pyx_t_1);
        } else
        #endif
        #if CYTHON_FAST_PYCCALL
        if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
          PyObject *__pyx_temp[2] = {__pyx_t_6, __pyx_v_totalSize};
          __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1405, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
          __Pyx_GOTREF(__pyx_t_1);
        } else
        #endif
        {
          __pyx_t_7 = PyTuple_New(1+1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1405, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_7);
          __Pyx_GIVEREF(__pyx_t_6); PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_6); __pyx_t_6 = NULL;
          __Pyx_INCREF(__pyx_v_totalSize);
          __Pyx_GIVEREF(__pyx_v_totalSize);
          PyTuple_SET_ITEM(__pyx_t_7, 0+1, __pyx_v_totalSize);
          __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_7, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1405, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_1);
          __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        }
      }
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_9 = __Pyx_PyObject_to_MemoryviewSlice_ds_float(__pyx_t_1);
      if (unlikely(!__pyx_t_9.memview)) __PYX_ERR(0, 1405, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_v_myarraymv = __pyx_t_9;
      __pyx_t_9.memview = NULL;
      __pyx_t_9.data = NULL;

      /* "PyTorch.pyx":1406
 *                 strideSoFar *= size[d]
 *             myarraymv = myarray.reshape(totalSize)
 *             storage = Storage._FloatStorage.newWithData(myarraymv)             # <<<<<<<<<<<<<<
 *             Storage.THFloatStorage_retain(storage.native) # since newWithData takes ownership
 * 
 */
      __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7Storage__FloatStorage), __pyx_n_s_newWithData); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1406, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_7 = __pyx_memoryview_fromslice(__pyx_v_myarraymv, 1, (PyObject *(*)(char *)) __pyx_memview_get_float, (int (*)(char *, PyObject *)) __pyx_memview_set_float, 0);; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1406, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __pyx_t_6 = NULL;
      if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
        __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_2);
        if (likely(__pyx_t_6)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
          __Pyx_INCREF(__pyx_t_6);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_2, function);
        }
      }
      if (!__pyx_t_6) {
        __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_7); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1406, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        __Pyx_GOTREF(__pyx_t_1);
      } else {
        #if CYTHON_FAST_PYCALL
        if (PyFunction_Check(__pyx_t_2)) {
          PyObject *__pyx_temp[2] = {__pyx_t_6, __pyx_t_7};
          __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1406, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
          __Pyx_GOTREF(__pyx_t_1);
          __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        } else
        #endif
        #if CYTHON_FAST_PYCCALL
        if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
          PyObject *__pyx_temp[2] = {__pyx_t_6, __pyx_t_7};
          __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1406, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
          __Pyx_GOTREF(__pyx_t_1);
          __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        } else
        #endif
        {
          __pyx_t_10 = PyTuple_New(1+1); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 1406, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_10);
          __Pyx_GIVEREF(__pyx_t_6); PyTuple_SET_ITEM(__pyx_t_10, 0, __pyx_t_6); __pyx_t_6 = NULL;
          __Pyx_GIVEREF(__pyx_t_7);
          PyTuple_SET_ITEM(__pyx_t_10, 0+1, __pyx_t_7);
          __pyx_t_7 = 0;
          __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_10, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1406, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_1);
          __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
        }
      }
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_7Storage__FloatStorage))))) __PYX_ERR(0, 1406, __pyx_L1_error)
      __pyx_v_storage = ((struct __pyx_obj_7Storage__FloatStorage *)__pyx_t_1);
      __pyx_t_1 = 0;

      /* "PyTorch.pyx":1407
 *             myarraymv = myarray.reshape(totalSize)
 *             storage = Storage._FloatStorage.newWithData(myarraymv)
 *             Storage.THFloatStorage_retain(storage.native) # since newWithData takes ownership             # <<<<<<<<<<<<<<
 * 
 *             tensor = _FloatTensor.newWithStorage(storage, 0, size, stride)
 */
      THFloatStorage_retain(__pyx_v_storage->native);

      /* "PyTorch.pyx":1409
 *             Storage.THFloatStorage_retain(storage.native) # since newWithData takes ownership
 * 
 *             tensor = _FloatTensor.newWithStorage(storage, 0, size, stride)             # <<<<<<<<<<<<<<
 *             return tensor
 *         else:
 */
      __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7PyTorch__FloatTensor), __pyx_n_s_newWithStorage); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1409, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_10 = NULL;
      __pyx_t_11 = 0;
      if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
        __pyx_t_10 = PyMethod_GET_SELF(__pyx_t_2);
        if (likely(__pyx_t_10)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
          __Pyx_INCREF(__pyx_t_10);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_2, function);
          __pyx_t_11 = 1;
        }
      }
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[5] = {__pyx_t_10, ((PyObject *)__pyx_v_storage), __pyx_int_0, __pyx_v_size, __pyx_v_stride};
        __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_11, 4+__pyx_t_11); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1409, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
        __Pyx_GOTREF(__pyx_t_1);
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[5] = {__pyx_t_10, ((PyObject *)__pyx_v_storage), __pyx_int_0, __pyx_v_size, __pyx_v_stride};
        __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_11, 4+__pyx_t_11); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1409, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
        __Pyx_GOTREF(__pyx_t_1);
      } else
      #endif
      {
        __pyx_t_7 = PyTuple_New(4+__pyx_t_11); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1409, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        if (__pyx_t_10) {
          __Pyx_GIVEREF(__pyx_t_10); PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_10); __pyx_t_10 = NULL;
        }
        __Pyx_INCREF(((PyObject *)__pyx_v_storage));
        __Pyx_GIVEREF(((PyObject *)__pyx_v_storage));
        PyTuple_SET_ITEM(__pyx_t_7, 0+__pyx_t_11, ((PyObject *)__pyx_v_storage));
        __Pyx_INCREF(__pyx_int_0);
        __Pyx_GIVEREF(__pyx_int_0);
        PyTuple_SET_ITEM(__pyx_t_7, 1+__pyx_t_11, __pyx_int_0);
        __Pyx_INCREF(__pyx_v_size);
        __Pyx_GIVEREF(__pyx_v_size);
        PyTuple_SET_ITEM(__pyx_t_7, 2+__pyx_t_11, __pyx_v_size);
        __Pyx_INCREF(__pyx_v_stride);
        __Pyx_GIVEREF(__pyx_v_stride);
        PyTuple_SET_ITEM(__pyx_t_7, 3+__pyx_t_11, __pyx_v_stride);
        __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_7, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1409, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      }
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_v_tensor = __pyx_t_1;
      __pyx_t_1 = 0;

      /* "PyTorch.pyx":1410
 * 
 *             tensor = _FloatTensor.newWithStorage(storage, 0, size, stride)
 *             return tensor             # <<<<<<<<<<<<<<
 *         else:
 *             raise Exception('dims == {dims} not implemented; please raise an issue'.format(
 */
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_v_tensor);
      __pyx_r = __pyx_v_tensor;
      goto __pyx_L0;

      /* "PyTorch.pyx":1395
 *     if str(type(myarray)) in ["<type 'numpy.ndarray'>", "<class 'numpy.ndarray'>"]:
 *         dims = len(myarray.shape)
 *         if dims >= 1:             # <<<<<<<<<<<<<<
 *             totalSize = 1
 *             size = Storage._LongStorage.newWithSize(dims)
 */
    }

    /* "PyTorch.pyx":1412
 *             return tensor
 *         else:
 *             raise Exception('dims == {dims} not implemented; please raise an issue'.format(             # <<<<<<<<<<<<<<
 *                 dims=dims))
 *     elif isinstance(myarray, array.array):
 */
    /*else*/ {
      __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_kp_s_dims_dims_not_implemented_please, __pyx_n_s_format); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1412, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);

      /* "PyTorch.pyx":1413
 *         else:
 *             raise Exception('dims == {dims} not implemented; please raise an issue'.format(
 *                 dims=dims))             # <<<<<<<<<<<<<<
 *     elif isinstance(myarray, array.array):
 *         myarraymv = myarray
 */
      __pyx_t_2 = PyDict_New(); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1413, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      if (PyDict_SetItem(__pyx_t_2, __pyx_n_s_dims, __pyx_v_dims) < 0) __PYX_ERR(0, 1413, __pyx_L1_error)

      /* "PyTorch.pyx":1412
 *             return tensor
 *         else:
 *             raise Exception('dims == {dims} not implemented; please raise an issue'.format(             # <<<<<<<<<<<<<<
 *                 dims=dims))
 *     elif isinstance(myarray, array.array):
 */
      __pyx_t_7 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_empty_tuple, __pyx_t_2); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1412, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = PyTuple_New(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1412, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_GIVEREF(__pyx_t_7);
      PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_7);
      __pyx_t_7 = 0;
      __pyx_t_7 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_t_2, NULL); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1412, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_Raise(__pyx_t_7, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __PYX_ERR(0, 1412, __pyx_L1_error)
    }

    /* "PyTorch.pyx":1393
 *     cdef float[:] myarraymv
 *     cdef Storage._FloatStorage storage
 *     if str(type(myarray)) in ["<type 'numpy.ndarray'>", "<class 'numpy.ndarray'>"]:             # <<<<<<<<<<<<<<
 *         dims = len(myarray.shape)
 *         if dims >= 1:
 */
  }

  /* "PyTorch.pyx":1414
 *             raise Exception('dims == {dims} not implemented; please raise an issue'.format(
 *                 dims=dims))
 *     elif isinstance(myarray, array.array):             # <<<<<<<<<<<<<<
 *         myarraymv = myarray
 *         storage = Storage._FloatStorage.newWithData(myarraymv)
 */
  __pyx_t_7 = __Pyx_GetModuleGlobalName(__pyx_n_s_array); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1414, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_7, __pyx_n_s_array); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1414, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_4 = PyObject_IsInstance(__pyx_v_myarray, __pyx_t_2); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 1414, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_3 = (__pyx_t_4 != 0);
  if (__pyx_t_3) {

    /* "PyTorch.pyx":1415
 *                 dims=dims))
 *     elif isinstance(myarray, array.array):
 *         myarraymv = myarray             # <<<<<<<<<<<<<<
 *         storage = Storage._FloatStorage.newWithData(myarraymv)
 *         Storage.THFloatStorage_retain(storage.native) # since newWithData takes ownership
 */
    __pyx_t_9 = __Pyx_PyObject_to_MemoryviewSlice_ds_float(__pyx_v_myarray);
    if (unlikely(!__pyx_t_9.memview)) __PYX_ERR(0, 1415, __pyx_L1_error)
    __pyx_v_myarraymv = __pyx_t_9;
    __pyx_t_9.memview = NULL;
    __pyx_t_9.data = NULL;

    /* "PyTorch.pyx":1416
 *     elif isinstance(myarray, array.array):
 *         myarraymv = myarray
 *         storage = Storage._FloatStorage.newWithData(myarraymv)             # <<<<<<<<<<<<<<
 *         Storage.THFloatStorage_retain(storage.native) # since newWithData takes ownership
 *         tensor = _FloatTensor.newWithStorage1d(storage, 0, len(myarray), 1)
 */
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7Storage__FloatStorage), __pyx_n_s_newWithData); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1416, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_1 = __pyx_memoryview_fromslice(__pyx_v_myarraymv, 1, (PyObject *(*)(char *)) __pyx_memview_get_float, (int (*)(char *, PyObject *)) __pyx_memview_set_float, 0);; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1416, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_10 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_7))) {
      __pyx_t_10 = PyMethod_GET_SELF(__pyx_t_7);
      if (likely(__pyx_t_10)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_7);
        __Pyx_INCREF(__pyx_t_10);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_7, function);
      }
    }
    if (!__pyx_t_10) {
      __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_7, __pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1416, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_GOTREF(__pyx_t_2);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_7)) {
        PyObject *__pyx_temp[2] = {__pyx_t_10, __pyx_t_1};
        __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_7, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1416, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_7)) {
        PyObject *__pyx_temp[2] = {__pyx_t_10, __pyx_t_1};
        __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_7, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1416, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      } else
      #endif
      {
        __pyx_t_6 = PyTuple_New(1+1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1416, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __Pyx_GIVEREF(__pyx_t_10); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_10); __pyx_t_10 = NULL;
        __Pyx_GIVEREF(__pyx_t_1);
        PyTuple_SET_ITEM(__pyx_t_6, 0+1, __pyx_t_1);
        __pyx_t_1 = 0;
        __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_7, __pyx_t_6, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1416, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    if (!(likely(((__pyx_t_2) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_2, __pyx_ptype_7Storage__FloatStorage))))) __PYX_ERR(0, 1416, __pyx_L1_error)
    __pyx_v_storage = ((struct __pyx_obj_7Storage__FloatStorage *)__pyx_t_2);
    __pyx_t_2 = 0;

    /* "PyTorch.pyx":1417
 *         myarraymv = myarray
 *         storage = Storage._FloatStorage.newWithData(myarraymv)
 *         Storage.THFloatStorage_retain(storage.native) # since newWithData takes ownership             # <<<<<<<<<<<<<<
 *         tensor = _FloatTensor.newWithStorage1d(storage, 0, len(myarray), 1)
 *         return tensor
 */
    THFloatStorage_retain(__pyx_v_storage->native);

    /* "PyTorch.pyx":1418
 *         storage = Storage._FloatStorage.newWithData(myarraymv)
 *         Storage.THFloatStorage_retain(storage.native) # since newWithData takes ownership
 *         tensor = _FloatTensor.newWithStorage1d(storage, 0, len(myarray), 1)             # <<<<<<<<<<<<<<
 *         return tensor
 *     else:
 */
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7PyTorch__FloatTensor), __pyx_n_s_newWithStorage1d); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1418, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_5 = PyObject_Length(__pyx_v_myarray); if (unlikely(__pyx_t_5 == -1)) __PYX_ERR(0, 1418, __pyx_L1_error)
    __pyx_t_6 = PyInt_FromSsize_t(__pyx_t_5); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1418, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_1 = NULL;
    __pyx_t_11 = 0;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_7))) {
      __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_7);
      if (likely(__pyx_t_1)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_7);
        __Pyx_INCREF(__pyx_t_1);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_7, function);
        __pyx_t_11 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_7)) {
      PyObject *__pyx_temp[5] = {__pyx_t_1, ((PyObject *)__pyx_v_storage), __pyx_int_0, __pyx_t_6, __pyx_int_1};
      __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_7, __pyx_temp+1-__pyx_t_11, 4+__pyx_t_11); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1418, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_7)) {
      PyObject *__pyx_temp[5] = {__pyx_t_1, ((PyObject *)__pyx_v_storage), __pyx_int_0, __pyx_t_6, __pyx_int_1};
      __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_7, __pyx_temp+1-__pyx_t_11, 4+__pyx_t_11); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1418, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    } else
    #endif
    {
      __pyx_t_10 = PyTuple_New(4+__pyx_t_11); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 1418, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_10);
      if (__pyx_t_1) {
        __Pyx_GIVEREF(__pyx_t_1); PyTuple_SET_ITEM(__pyx_t_10, 0, __pyx_t_1); __pyx_t_1 = NULL;
      }
      __Pyx_INCREF(((PyObject *)__pyx_v_storage));
      __Pyx_GIVEREF(((PyObject *)__pyx_v_storage));
      PyTuple_SET_ITEM(__pyx_t_10, 0+__pyx_t_11, ((PyObject *)__pyx_v_storage));
      __Pyx_INCREF(__pyx_int_0);
      __Pyx_GIVEREF(__pyx_int_0);
      PyTuple_SET_ITEM(__pyx_t_10, 1+__pyx_t_11, __pyx_int_0);
      __Pyx_GIVEREF(__pyx_t_6);
      PyTuple_SET_ITEM(__pyx_t_10, 2+__pyx_t_11, __pyx_t_6);
      __Pyx_INCREF(__pyx_int_1);
      __Pyx_GIVEREF(__pyx_int_1);
      PyTuple_SET_ITEM(__pyx_t_10, 3+__pyx_t_11, __pyx_int_1);
      __pyx_t_6 = 0;
      __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_7, __pyx_t_10, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1418, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    }
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_v_tensor = __pyx_t_2;
    __pyx_t_2 = 0;

    /* "PyTorch.pyx":1419
 *         Storage.THFloatStorage_retain(storage.native) # since newWithData takes ownership
 *         tensor = _FloatTensor.newWithStorage1d(storage, 0, len(myarray), 1)
 *         return tensor             # <<<<<<<<<<<<<<
 *     else:
 *         raise Exception("not implemented")
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(__pyx_v_tensor);
    __pyx_r = __pyx_v_tensor;
    goto __pyx_L0;

    /* "PyTorch.pyx":1414
 *             raise Exception('dims == {dims} not implemented; please raise an issue'.format(
 *                 dims=dims))
 *     elif isinstance(myarray, array.array):             # <<<<<<<<<<<<<<
 *         myarraymv = myarray
 *         storage = Storage._FloatStorage.newWithData(myarraymv)
 */
  }

  /* "PyTorch.pyx":1421
 *         return tensor
 *     else:
 *         raise Exception("not implemented")             # <<<<<<<<<<<<<<
 * 
 * 
 */
  /*else*/ {
    __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_tuple__24, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1421, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(0, 1421, __pyx_L1_error)
  }

  /* "PyTorch.pyx":1390
 * 
 * 
 * def _asFloatTensor(myarray):             # <<<<<<<<<<<<<<
 *     cdef float[:] myarraymv
 *     cdef Storage._FloatStorage storage
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __PYX_XDEC_MEMVIEW(&__pyx_t_9, 1);
  __Pyx_XDECREF(__pyx_t_10);
  __Pyx_AddTraceback("PyTorch._asFloatTensor", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __PYX_XDEC_MEMVIEW(&__pyx_v_myarraymv, 1);
  __Pyx_XDECREF((PyObject *)__pyx_v_storage);
  __Pyx_XDECREF(__pyx_v_dims);
  __Pyx_XDECREF(__pyx_v_totalSize);
  __Pyx_XDECREF(__pyx_v_size);
  __Pyx_XDECREF(__pyx_v_stride);
  __Pyx_XDECREF(__pyx_v_strideSoFar);
  __Pyx_XDECREF(__pyx_v_d);
  __Pyx_XDECREF(__pyx_v_tensor);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1433
 * #        self.thFloatTensor = tensorC
 * 
 *     def __cinit__(self, *args, _allocate=True):             # <<<<<<<<<<<<<<
 * #        cdef _DoubleTensor childobject
 *         cdef THDoubleTensor *newTensorC
 */

/* Python wrapper */
static int __pyx_pw_7PyTorch_13_DoubleTensor_1__cinit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static int __pyx_pw_7PyTorch_13_DoubleTensor_1__cinit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v__allocate = 0;
  PyObject *__pyx_v_args = 0;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__cinit__ (wrapper)", 0);
  if (PyTuple_GET_SIZE(__pyx_args) > 0) {
    __pyx_v_args = PyTuple_GetSlice(__pyx_args, 0, PyTuple_GET_SIZE(__pyx_args));
    if (unlikely(!__pyx_v_args)) {
      __Pyx_RefNannyFinishContext();
      return -1;
    }
    __Pyx_GOTREF(__pyx_v_args);
  } else {
    __pyx_v_args = __pyx_empty_tuple; __Pyx_INCREF(__pyx_empty_tuple);
  }
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_allocate,0};
    PyObject* values[1] = {0};
    values[0] = ((PyObject *)Py_True);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        default:
        case  0: break;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      if (kw_args == 1) {
        const Py_ssize_t index = 0;
        PyObject* value = PyDict_GetItem(__pyx_kwds, *__pyx_pyargnames[index]);
        if (value) { values[index] = value; kw_args--; }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, 0, "__cinit__") < 0)) __PYX_ERR(0, 1433, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) < 0) {
      goto __pyx_L5_argtuple_error;
    } else {
    }
    __pyx_v__allocate = values[0];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__cinit__", 0, 0, 0, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1433, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_DECREF(__pyx_v_args); __pyx_v_args = 0;
  __Pyx_AddTraceback("PyTorch._DoubleTensor.__cinit__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return -1;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor___cinit__(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self), __pyx_v__allocate, __pyx_v_args);

  /* function exit code */
  __Pyx_XDECREF(__pyx_v_args);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_7PyTorch_13_DoubleTensor___cinit__(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, PyObject *__pyx_v__allocate, PyObject *__pyx_v_args) {
  struct THDoubleTensor *__pyx_v_newTensorC;
  struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_templateObject = 0;
  PyObject *__pyx_v_arg = NULL;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  Py_ssize_t __pyx_t_4;
  int __pyx_t_5;
  int __pyx_t_6;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  long __pyx_t_10;
  long __pyx_t_11;
  long __pyx_t_12;
  long __pyx_t_13;
  __Pyx_RefNannySetupContext("__cinit__", 0);

  /* "PyTorch.pyx":1437
 *         cdef THDoubleTensor *newTensorC
 *         cdef _DoubleTensor templateObject
 *         logger.debug('DoubleTensor.__cinit__')             # <<<<<<<<<<<<<<
 * #        cdef THDoubleStorage *storageC
 * #        cdef long addr
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_logger); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1437, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_debug); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1437, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_tuple__25, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1437, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "PyTorch.pyx":1442
 * #        if len(kwargs) > 0:
 * #            raise Exception('cannot provide arguments to initializer')
 *         if _allocate:             # <<<<<<<<<<<<<<
 *             if len(args) == 1 and isinstance(args[0], _LongStorage):  # it's a size tensor
 *                self.native = THDoubleTensor_new()
 */
  __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_v__allocate); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 1442, __pyx_L1_error)
  if (__pyx_t_3) {

    /* "PyTorch.pyx":1443
 * #            raise Exception('cannot provide arguments to initializer')
 *         if _allocate:
 *             if len(args) == 1 and isinstance(args[0], _LongStorage):  # it's a size tensor             # <<<<<<<<<<<<<<
 *                self.native = THDoubleTensor_new()
 *                self.resize(args[0])
 */
    __pyx_t_4 = PyTuple_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 1443, __pyx_L1_error)
    __pyx_t_5 = ((__pyx_t_4 == 1) != 0);
    if (__pyx_t_5) {
    } else {
      __pyx_t_3 = __pyx_t_5;
      goto __pyx_L5_bool_binop_done;
    }
    __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1443, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_LongStorage); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1443, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_5 = PyObject_IsInstance(__pyx_t_1, __pyx_t_2); if (unlikely(__pyx_t_5 == -1)) __PYX_ERR(0, 1443, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_6 = (__pyx_t_5 != 0);
    __pyx_t_3 = __pyx_t_6;
    __pyx_L5_bool_binop_done:;
    if (__pyx_t_3) {

      /* "PyTorch.pyx":1444
 *         if _allocate:
 *             if len(args) == 1 and isinstance(args[0], _LongStorage):  # it's a size tensor
 *                self.native = THDoubleTensor_new()             # <<<<<<<<<<<<<<
 *                self.resize(args[0])
 *                return
 */
      __pyx_v_self->native = THDoubleTensor_new();

      /* "PyTorch.pyx":1445
 *             if len(args) == 1 and isinstance(args[0], _LongStorage):  # it's a size tensor
 *                self.native = THDoubleTensor_new()
 *                self.resize(args[0])             # <<<<<<<<<<<<<<
 *                return
 *             if len(args) == 1 and isinstance(args[0], _DoubleTensor):
 */
      __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_resize); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1445, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_7 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1445, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __pyx_t_8 = NULL;
      if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_1))) {
        __pyx_t_8 = PyMethod_GET_SELF(__pyx_t_1);
        if (likely(__pyx_t_8)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
          __Pyx_INCREF(__pyx_t_8);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_1, function);
        }
      }
      if (!__pyx_t_8) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_t_7); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1445, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        __Pyx_GOTREF(__pyx_t_2);
      } else {
        #if CYTHON_FAST_PYCALL
        if (PyFunction_Check(__pyx_t_1)) {
          PyObject *__pyx_temp[2] = {__pyx_t_8, __pyx_t_7};
          __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_1, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1445, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        } else
        #endif
        #if CYTHON_FAST_PYCCALL
        if (__Pyx_PyFastCFunction_Check(__pyx_t_1)) {
          PyObject *__pyx_temp[2] = {__pyx_t_8, __pyx_t_7};
          __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_1, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1445, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        } else
        #endif
        {
          __pyx_t_9 = PyTuple_New(1+1); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 1445, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_9);
          __Pyx_GIVEREF(__pyx_t_8); PyTuple_SET_ITEM(__pyx_t_9, 0, __pyx_t_8); __pyx_t_8 = NULL;
          __Pyx_GIVEREF(__pyx_t_7);
          PyTuple_SET_ITEM(__pyx_t_9, 0+1, __pyx_t_7);
          __pyx_t_7 = 0;
          __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_9, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1445, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
        }
      }
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

      /* "PyTorch.pyx":1446
 *                self.native = THDoubleTensor_new()
 *                self.resize(args[0])
 *                return             # <<<<<<<<<<<<<<
 *             if len(args) == 1 and isinstance(args[0], _DoubleTensor):
 *                templateObject = args[0]
 */
      __pyx_r = 0;
      goto __pyx_L0;

      /* "PyTorch.pyx":1443
 * #            raise Exception('cannot provide arguments to initializer')
 *         if _allocate:
 *             if len(args) == 1 and isinstance(args[0], _LongStorage):  # it's a size tensor             # <<<<<<<<<<<<<<
 *                self.native = THDoubleTensor_new()
 *                self.resize(args[0])
 */
    }

    /* "PyTorch.pyx":1447
 *                self.resize(args[0])
 *                return
 *             if len(args) == 1 and isinstance(args[0], _DoubleTensor):             # <<<<<<<<<<<<<<
 *                templateObject = args[0]
 *                newTensorC = THDoubleTensor_newClone(templateObject.native)
 */
    __pyx_t_4 = PyTuple_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 1447, __pyx_L1_error)
    __pyx_t_6 = ((__pyx_t_4 == 1) != 0);
    if (__pyx_t_6) {
    } else {
      __pyx_t_3 = __pyx_t_6;
      goto __pyx_L8_bool_binop_done;
    }
    __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1447, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_6 = __Pyx_TypeCheck(__pyx_t_2, __pyx_ptype_7PyTorch__DoubleTensor); 
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_5 = (__pyx_t_6 != 0);
    __pyx_t_3 = __pyx_t_5;
    __pyx_L8_bool_binop_done:;
    if (__pyx_t_3) {

      /* "PyTorch.pyx":1448
 *                return
 *             if len(args) == 1 and isinstance(args[0], _DoubleTensor):
 *                templateObject = args[0]             # <<<<<<<<<<<<<<
 *                newTensorC = THDoubleTensor_newClone(templateObject.native)
 *                self.native = newTensorC
 */
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1448, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      if (!(likely(((__pyx_t_2) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_2, __pyx_ptype_7PyTorch__DoubleTensor))))) __PYX_ERR(0, 1448, __pyx_L1_error)
      __pyx_v_templateObject = ((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_t_2);
      __pyx_t_2 = 0;

      /* "PyTorch.pyx":1449
 *             if len(args) == 1 and isinstance(args[0], _DoubleTensor):
 *                templateObject = args[0]
 *                newTensorC = THDoubleTensor_newClone(templateObject.native)             # <<<<<<<<<<<<<<
 *                self.native = newTensorC
 *                return
 */
      __pyx_v_newTensorC = THDoubleTensor_newClone(__pyx_v_templateObject->native);

      /* "PyTorch.pyx":1450
 *                templateObject = args[0]
 *                newTensorC = THDoubleTensor_newClone(templateObject.native)
 *                self.native = newTensorC             # <<<<<<<<<<<<<<
 *                return
 *             for arg in args:
 */
      __pyx_v_self->native = __pyx_v_newTensorC;

      /* "PyTorch.pyx":1451
 *                newTensorC = THDoubleTensor_newClone(templateObject.native)
 *                self.native = newTensorC
 *                return             # <<<<<<<<<<<<<<
 *             for arg in args:
 *                 if not isinstance(arg, int):
 */
      __pyx_r = 0;
      goto __pyx_L0;

      /* "PyTorch.pyx":1447
 *                self.resize(args[0])
 *                return
 *             if len(args) == 1 and isinstance(args[0], _DoubleTensor):             # <<<<<<<<<<<<<<
 *                templateObject = args[0]
 *                newTensorC = THDoubleTensor_newClone(templateObject.native)
 */
    }

    /* "PyTorch.pyx":1452
 *                self.native = newTensorC
 *                return
 *             for arg in args:             # <<<<<<<<<<<<<<
 *                 if not isinstance(arg, int):
 *                     raise Exception('cannot provide arguments to initializer')
 */
    __pyx_t_2 = __pyx_v_args; __Pyx_INCREF(__pyx_t_2); __pyx_t_4 = 0;
    for (;;) {
      if (__pyx_t_4 >= PyTuple_GET_SIZE(__pyx_t_2)) break;
      #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
      __pyx_t_1 = PyTuple_GET_ITEM(__pyx_t_2, __pyx_t_4); __Pyx_INCREF(__pyx_t_1); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 1452, __pyx_L1_error)
      #else
      __pyx_t_1 = PySequence_ITEM(__pyx_t_2, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1452, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      #endif
      __Pyx_XDECREF_SET(__pyx_v_arg, __pyx_t_1);
      __pyx_t_1 = 0;

      /* "PyTorch.pyx":1453
 *                return
 *             for arg in args:
 *                 if not isinstance(arg, int):             # <<<<<<<<<<<<<<
 *                     raise Exception('cannot provide arguments to initializer')
 *             if len(args) == 0:
 */
      __pyx_t_3 = PyInt_Check(__pyx_v_arg); 
      __pyx_t_5 = ((!(__pyx_t_3 != 0)) != 0);
      if (__pyx_t_5) {

        /* "PyTorch.pyx":1454
 *             for arg in args:
 *                 if not isinstance(arg, int):
 *                     raise Exception('cannot provide arguments to initializer')             # <<<<<<<<<<<<<<
 *             if len(args) == 0:
 *                 # print('no args, calling THDoubleTensor_new()')
 */
        __pyx_t_1 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_tuple__26, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1454, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_Raise(__pyx_t_1, 0, 0, 0);
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        __PYX_ERR(0, 1454, __pyx_L1_error)

        /* "PyTorch.pyx":1453
 *                return
 *             for arg in args:
 *                 if not isinstance(arg, int):             # <<<<<<<<<<<<<<
 *                     raise Exception('cannot provide arguments to initializer')
 *             if len(args) == 0:
 */
      }

      /* "PyTorch.pyx":1452
 *                self.native = newTensorC
 *                return
 *             for arg in args:             # <<<<<<<<<<<<<<
 *                 if not isinstance(arg, int):
 *                     raise Exception('cannot provide arguments to initializer')
 */
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

    /* "PyTorch.pyx":1455
 *                 if not isinstance(arg, int):
 *                     raise Exception('cannot provide arguments to initializer')
 *             if len(args) == 0:             # <<<<<<<<<<<<<<
 *                 # print('no args, calling THDoubleTensor_new()')
 *                 self.native = THDoubleTensor_new()
 */
    __pyx_t_4 = PyTuple_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 1455, __pyx_L1_error)
    __pyx_t_5 = ((__pyx_t_4 == 0) != 0);
    if (__pyx_t_5) {

      /* "PyTorch.pyx":1457
 *             if len(args) == 0:
 *                 # print('no args, calling THDoubleTensor_new()')
 *                 self.native = THDoubleTensor_new()             # <<<<<<<<<<<<<<
 *             elif len(args) == 1:
 *                 # print('new tensor 1d length', args[0])
 */
      __pyx_v_self->native = THDoubleTensor_new();

      /* "PyTorch.pyx":1455
 *                 if not isinstance(arg, int):
 *                     raise Exception('cannot provide arguments to initializer')
 *             if len(args) == 0:             # <<<<<<<<<<<<<<
 *                 # print('no args, calling THDoubleTensor_new()')
 *                 self.native = THDoubleTensor_new()
 */
      goto __pyx_L13;
    }

    /* "PyTorch.pyx":1458
 *                 # print('no args, calling THDoubleTensor_new()')
 *                 self.native = THDoubleTensor_new()
 *             elif len(args) == 1:             # <<<<<<<<<<<<<<
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THDoubleTensor_newWithSize1d(args[0])
 */
    __pyx_t_4 = PyTuple_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 1458, __pyx_L1_error)
    __pyx_t_5 = ((__pyx_t_4 == 1) != 0);
    if (__pyx_t_5) {

      /* "PyTorch.pyx":1460
 *             elif len(args) == 1:
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THDoubleTensor_newWithSize1d(args[0])             # <<<<<<<<<<<<<<
 *             elif len(args) == 2:
 *                 # print('args=2')
 */
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1460, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_10 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_10 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1460, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_v_self->native = THDoubleTensor_newWithSize1d(__pyx_t_10);

      /* "PyTorch.pyx":1458
 *                 # print('no args, calling THDoubleTensor_new()')
 *                 self.native = THDoubleTensor_new()
 *             elif len(args) == 1:             # <<<<<<<<<<<<<<
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THDoubleTensor_newWithSize1d(args[0])
 */
      goto __pyx_L13;
    }

    /* "PyTorch.pyx":1461
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THDoubleTensor_newWithSize1d(args[0])
 *             elif len(args) == 2:             # <<<<<<<<<<<<<<
 *                 # print('args=2')
 *                 self.native = THDoubleTensor_newWithSize2d(args[0], args[1])
 */
    __pyx_t_4 = PyTuple_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 1461, __pyx_L1_error)
    __pyx_t_5 = ((__pyx_t_4 == 2) != 0);
    if (__pyx_t_5) {

      /* "PyTorch.pyx":1463
 *             elif len(args) == 2:
 *                 # print('args=2')
 *                 self.native = THDoubleTensor_newWithSize2d(args[0], args[1])             # <<<<<<<<<<<<<<
 *             elif len(args) == 3:
 *                 # print('new tensor 1d length', args[0])
 */
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1463, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_10 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_10 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1463, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1463, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_11 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_11 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1463, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_v_self->native = THDoubleTensor_newWithSize2d(__pyx_t_10, __pyx_t_11);

      /* "PyTorch.pyx":1461
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THDoubleTensor_newWithSize1d(args[0])
 *             elif len(args) == 2:             # <<<<<<<<<<<<<<
 *                 # print('args=2')
 *                 self.native = THDoubleTensor_newWithSize2d(args[0], args[1])
 */
      goto __pyx_L13;
    }

    /* "PyTorch.pyx":1464
 *                 # print('args=2')
 *                 self.native = THDoubleTensor_newWithSize2d(args[0], args[1])
 *             elif len(args) == 3:             # <<<<<<<<<<<<<<
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THDoubleTensor_newWithSize3d(args[0], args[1], args[2])
 */
    __pyx_t_4 = PyTuple_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 1464, __pyx_L1_error)
    __pyx_t_5 = ((__pyx_t_4 == 3) != 0);
    if (__pyx_t_5) {

      /* "PyTorch.pyx":1466
 *             elif len(args) == 3:
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THDoubleTensor_newWithSize3d(args[0], args[1], args[2])             # <<<<<<<<<<<<<<
 *             elif len(args) == 4:
 *                 # print('new tensor 1d length', args[0])
 */
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1466, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_11 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_11 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1466, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1466, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_10 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_10 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1466, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1466, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_12 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_12 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1466, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_v_self->native = THDoubleTensor_newWithSize3d(__pyx_t_11, __pyx_t_10, __pyx_t_12);

      /* "PyTorch.pyx":1464
 *                 # print('args=2')
 *                 self.native = THDoubleTensor_newWithSize2d(args[0], args[1])
 *             elif len(args) == 3:             # <<<<<<<<<<<<<<
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THDoubleTensor_newWithSize3d(args[0], args[1], args[2])
 */
      goto __pyx_L13;
    }

    /* "PyTorch.pyx":1467
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THDoubleTensor_newWithSize3d(args[0], args[1], args[2])
 *             elif len(args) == 4:             # <<<<<<<<<<<<<<
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THDoubleTensor_newWithSize4d(args[0], args[1], args[2], args[3])
 */
    __pyx_t_4 = PyTuple_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 1467, __pyx_L1_error)
    __pyx_t_5 = ((__pyx_t_4 == 4) != 0);
    if (__pyx_t_5) {

      /* "PyTorch.pyx":1469
 *             elif len(args) == 4:
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THDoubleTensor_newWithSize4d(args[0], args[1], args[2], args[3])             # <<<<<<<<<<<<<<
 *             else:
 *                 logger.error('Raising exception...')
 */
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1469, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_12 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_12 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1469, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1469, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_10 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_10 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1469, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1469, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_11 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_11 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1469, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 3, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1469, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_13 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_13 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1469, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_v_self->native = THDoubleTensor_newWithSize4d(__pyx_t_12, __pyx_t_10, __pyx_t_11, __pyx_t_13);

      /* "PyTorch.pyx":1467
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THDoubleTensor_newWithSize3d(args[0], args[1], args[2])
 *             elif len(args) == 4:             # <<<<<<<<<<<<<<
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THDoubleTensor_newWithSize4d(args[0], args[1], args[2], args[3])
 */
      goto __pyx_L13;
    }

    /* "PyTorch.pyx":1471
 *                 self.native = THDoubleTensor_newWithSize4d(args[0], args[1], args[2], args[3])
 *             else:
 *                 logger.error('Raising exception...')             # <<<<<<<<<<<<<<
 *                 raise Exception('Not implemented, len(args)=' + str(len(args)))
 * #        else:
 */
    /*else*/ {
      __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_logger); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1471, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_error); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1471, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_tuple__27, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1471, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

      /* "PyTorch.pyx":1472
 *             else:
 *                 logger.error('Raising exception...')
 *                 raise Exception('Not implemented, len(args)=' + str(len(args)))             # <<<<<<<<<<<<<<
 * #        else:
 * #            if len(args) > 0:
 */
      __pyx_t_4 = PyTuple_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 1472, __pyx_L1_error)
      __pyx_t_2 = PyInt_FromSsize_t(__pyx_t_4); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1472, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1472, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_GIVEREF(__pyx_t_2);
      PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_2);
      __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)(&PyString_Type)), __pyx_t_1, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1472, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_t_1 = PyNumber_Add(__pyx_kp_s_Not_implemented_len_args, __pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1472, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = PyTuple_New(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1472, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_GIVEREF(__pyx_t_1);
      PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_1);
      __pyx_t_1 = 0;
      __pyx_t_1 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_t_2, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1472, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_Raise(__pyx_t_1, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __PYX_ERR(0, 1472, __pyx_L1_error)
    }
    __pyx_L13:;

    /* "PyTorch.pyx":1442
 * #        if len(kwargs) > 0:
 * #            raise Exception('cannot provide arguments to initializer')
 *         if _allocate:             # <<<<<<<<<<<<<<
 *             if len(args) == 1 and isinstance(args[0], _LongStorage):  # it's a size tensor
 *                self.native = THDoubleTensor_new()
 */
  }

  /* "PyTorch.pyx":1433
 * #        self.thFloatTensor = tensorC
 * 
 *     def __cinit__(self, *args, _allocate=True):             # <<<<<<<<<<<<<<
 * #        cdef _DoubleTensor childobject
 *         cdef THDoubleTensor *newTensorC
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.__cinit__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_templateObject);
  __Pyx_XDECREF(__pyx_v_arg);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1491
 * #        self.storage = storage
 * 
 *     def __dealloc__(self):             # <<<<<<<<<<<<<<
 *         cdef int refCount
 * #        cdef int dims
 */

/* Python wrapper */
static void __pyx_pw_7PyTorch_13_DoubleTensor_3__dealloc__(PyObject *__pyx_v_self); /*proto*/
static void __pyx_pw_7PyTorch_13_DoubleTensor_3__dealloc__(PyObject *__pyx_v_self) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__dealloc__ (wrapper)", 0);
  __pyx_pf_7PyTorch_13_DoubleTensor_2__dealloc__(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

static void __pyx_pf_7PyTorch_13_DoubleTensor_2__dealloc__(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self) {
  int __pyx_v_refCount;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("__dealloc__", 0);

  /* "PyTorch.pyx":1498
 * #        cdef THFloatStorage *storage
 * #        logger.debug('__dealloc__ native %s', <long>(self.native) != 0)
 *         if <long>(self.native) != 0:             # <<<<<<<<<<<<<<
 *             refCount = THDoubleTensor_getRefCount(self.native)
 *    #         print('DoubleTensor.dealloc old refcount', refCount)
 */
  __pyx_t_1 = ((((long)__pyx_v_self->native) != 0) != 0);
  if (__pyx_t_1) {

    /* "PyTorch.pyx":1499
 * #        logger.debug('__dealloc__ native %s', <long>(self.native) != 0)
 *         if <long>(self.native) != 0:
 *             refCount = THDoubleTensor_getRefCount(self.native)             # <<<<<<<<<<<<<<
 *    #         print('DoubleTensor.dealloc old refcount', refCount)
 *    #        storage = THFloatTensor_storage(self.thFloatTensor)
 */
    __pyx_v_refCount = THDoubleTensor_getRefCount(__pyx_v_self->native);

    /* "PyTorch.pyx":1510
 *    #        for i in range(dims):
 *    #            # print('   size[', i, ']', THFloatTensor_size(self.thFloatTensor, i))
 *             if refCount < 1:             # <<<<<<<<<<<<<<
 *                 raise Exception('Unallocated an already deallocated tensor... :-O')  # Hmmm, seems this exceptoin wont go anywhere useful... :-P
 *             THDoubleTensor_free(self.native)
 */
    __pyx_t_1 = ((__pyx_v_refCount < 1) != 0);
    if (__pyx_t_1) {

      /* "PyTorch.pyx":1511
 *    #            # print('   size[', i, ']', THFloatTensor_size(self.thFloatTensor, i))
 *             if refCount < 1:
 *                 raise Exception('Unallocated an already deallocated tensor... :-O')  # Hmmm, seems this exceptoin wont go anywhere useful... :-P             # <<<<<<<<<<<<<<
 *             THDoubleTensor_free(self.native)
 *         else:
 */
      __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_tuple__28, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1511, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_Raise(__pyx_t_2, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __PYX_ERR(0, 1511, __pyx_L1_error)

      /* "PyTorch.pyx":1510
 *    #        for i in range(dims):
 *    #            # print('   size[', i, ']', THFloatTensor_size(self.thFloatTensor, i))
 *             if refCount < 1:             # <<<<<<<<<<<<<<
 *                 raise Exception('Unallocated an already deallocated tensor... :-O')  # Hmmm, seems this exceptoin wont go anywhere useful... :-P
 *             THDoubleTensor_free(self.native)
 */
    }

    /* "PyTorch.pyx":1512
 *             if refCount < 1:
 *                 raise Exception('Unallocated an already deallocated tensor... :-O')  # Hmmm, seems this exceptoin wont go anywhere useful... :-P
 *             THDoubleTensor_free(self.native)             # <<<<<<<<<<<<<<
 *         else:
 *             logger.debug('__dealloc__ tensor never allocated')
 */
    THDoubleTensor_free(__pyx_v_self->native);

    /* "PyTorch.pyx":1498
 * #        cdef THFloatStorage *storage
 * #        logger.debug('__dealloc__ native %s', <long>(self.native) != 0)
 *         if <long>(self.native) != 0:             # <<<<<<<<<<<<<<
 *             refCount = THDoubleTensor_getRefCount(self.native)
 *    #         print('DoubleTensor.dealloc old refcount', refCount)
 */
    goto __pyx_L3;
  }

  /* "PyTorch.pyx":1514
 *             THDoubleTensor_free(self.native)
 *         else:
 *             logger.debug('__dealloc__ tensor never allocated')             # <<<<<<<<<<<<<<
 * 
 *     def nElement(_DoubleTensor self):
 */
  /*else*/ {
    __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_logger); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1514, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_debug); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1514, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_tuple__29, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1514, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  }
  __pyx_L3:;

  /* "PyTorch.pyx":1491
 * #        self.storage = storage
 * 
 *     def __dealloc__(self):             # <<<<<<<<<<<<<<
 *         cdef int refCount
 * #        cdef int dims
 */

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_WriteUnraisable("PyTorch._DoubleTensor.__dealloc__", __pyx_clineno, __pyx_lineno, __pyx_filename, 0, 0);
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
}

/* "PyTorch.pyx":1516
 *             logger.debug('__dealloc__ tensor never allocated')
 * 
 *     def nElement(_DoubleTensor self):             # <<<<<<<<<<<<<<
 *         return THDoubleTensor_nElement(self.native)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_5nElement(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_5nElement(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("nElement (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_4nElement(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_4nElement(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("nElement", 0);

  /* "PyTorch.pyx":1517
 * 
 *     def nElement(_DoubleTensor self):
 *         return THDoubleTensor_nElement(self.native)             # <<<<<<<<<<<<<<
 * 
 *     def asNumpyTensor(_DoubleTensor self):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_long(THDoubleTensor_nElement(__pyx_v_self->native)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1517, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":1516
 *             logger.debug('__dealloc__ tensor never allocated')
 * 
 *     def nElement(_DoubleTensor self):             # <<<<<<<<<<<<<<
 *         return THDoubleTensor_nElement(self.native)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.nElement", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1519
 *         return THDoubleTensor_nElement(self.native)
 * 
 *     def asNumpyTensor(_DoubleTensor self):             # <<<<<<<<<<<<<<
 *         cdef Storage._DoubleStorage storage
 *         cdef double *data
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_7asNumpyTensor(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_7asNumpyTensor(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("asNumpyTensor (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_6asNumpyTensor(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_6asNumpyTensor(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self) {
  double *__pyx_v_data;
  struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_contig = 0;
  PyObject *__pyx_v_size = NULL;
  PyObject *__pyx_v_dims = NULL;
  PyObject *__pyx_v_dtype = NULL;
  PyObject *__pyx_v_totalSize = NULL;
  PyObject *__pyx_v_d = NULL;
  PyObject *__pyx_v_myarray = NULL;
  PyObject *__pyx_v_i = NULL;
  PyObject *__pyx_v_shape = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  Py_ssize_t __pyx_t_4;
  int __pyx_t_5;
  int __pyx_t_6;
  PyObject *(*__pyx_t_7)(PyObject *);
  PyObject *__pyx_t_8 = NULL;
  Py_ssize_t __pyx_t_9;
  int __pyx_t_10;
  __Pyx_RefNannySetupContext("asNumpyTensor", 0);

  /* "PyTorch.pyx":1523
 *         cdef double *data
 *         cdef _DoubleTensor contig
 *         size = self.size()             # <<<<<<<<<<<<<<
 *         dims = len(size)
 *         dtype = None
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_size); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1523, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1523, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1523, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_size = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":1524
 *         cdef _DoubleTensor contig
 *         size = self.size()
 *         dims = len(size)             # <<<<<<<<<<<<<<
 *         dtype = None
 *         dtype=np.float64
 */
  __pyx_t_4 = PyObject_Length(__pyx_v_size); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 1524, __pyx_L1_error)
  __pyx_t_1 = PyInt_FromSsize_t(__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1524, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_dims = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":1525
 *         size = self.size()
 *         dims = len(size)
 *         dtype = None             # <<<<<<<<<<<<<<
 *         dtype=np.float64
 * 
 */
  __Pyx_INCREF(Py_None);
  __pyx_v_dtype = Py_None;

  /* "PyTorch.pyx":1526
 *         dims = len(size)
 *         dtype = None
 *         dtype=np.float64             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_np); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1526, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_float64); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1526, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF_SET(__pyx_v_dtype, __pyx_t_2);
  __pyx_t_2 = 0;

  /* "PyTorch.pyx":1529
 * 
 * 
 *         if dtype is None:             # <<<<<<<<<<<<<<
 *           raise Exception("not implemented for Double")
 * #        print('dtype', dtype)
 */
  __pyx_t_5 = (__pyx_v_dtype == Py_None);
  __pyx_t_6 = (__pyx_t_5 != 0);
  if (__pyx_t_6) {

    /* "PyTorch.pyx":1530
 * 
 *         if dtype is None:
 *           raise Exception("not implemented for Double")             # <<<<<<<<<<<<<<
 * #        print('dtype', dtype)
 *         if dims >= 1:
 */
    __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_tuple__30, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1530, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(0, 1530, __pyx_L1_error)

    /* "PyTorch.pyx":1529
 * 
 * 
 *         if dtype is None:             # <<<<<<<<<<<<<<
 *           raise Exception("not implemented for Double")
 * #        print('dtype', dtype)
 */
  }

  /* "PyTorch.pyx":1532
 *           raise Exception("not implemented for Double")
 * #        print('dtype', dtype)
 *         if dims >= 1:             # <<<<<<<<<<<<<<
 *             totalSize = 1
 *             for d in range(dims - 1, -1, -1):
 */
  __pyx_t_2 = PyObject_RichCompare(__pyx_v_dims, __pyx_int_1, Py_GE); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1532, __pyx_L1_error)
  __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely(__pyx_t_6 < 0)) __PYX_ERR(0, 1532, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (__pyx_t_6) {

    /* "PyTorch.pyx":1533
 * #        print('dtype', dtype)
 *         if dims >= 1:
 *             totalSize = 1             # <<<<<<<<<<<<<<
 *             for d in range(dims - 1, -1, -1):
 *                 totalSize *= size[d]
 */
    __Pyx_INCREF(__pyx_int_1);
    __pyx_v_totalSize = __pyx_int_1;

    /* "PyTorch.pyx":1534
 *         if dims >= 1:
 *             totalSize = 1
 *             for d in range(dims - 1, -1, -1):             # <<<<<<<<<<<<<<
 *                 totalSize *= size[d]
 *             myarray = np.zeros(totalSize, dtype=dtype)
 */
    __pyx_t_2 = __Pyx_PyInt_SubtractObjC(__pyx_v_dims, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1534, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_1 = PyTuple_New(3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1534, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_GIVEREF(__pyx_t_2);
    PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_2);
    __Pyx_INCREF(__pyx_int_neg_1);
    __Pyx_GIVEREF(__pyx_int_neg_1);
    PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_int_neg_1);
    __Pyx_INCREF(__pyx_int_neg_1);
    __Pyx_GIVEREF(__pyx_int_neg_1);
    PyTuple_SET_ITEM(__pyx_t_1, 2, __pyx_int_neg_1);
    __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_range, __pyx_t_1, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1534, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    if (likely(PyList_CheckExact(__pyx_t_2)) || PyTuple_CheckExact(__pyx_t_2)) {
      __pyx_t_1 = __pyx_t_2; __Pyx_INCREF(__pyx_t_1); __pyx_t_4 = 0;
      __pyx_t_7 = NULL;
    } else {
      __pyx_t_4 = -1; __pyx_t_1 = PyObject_GetIter(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1534, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_7 = Py_TYPE(__pyx_t_1)->tp_iternext; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1534, __pyx_L1_error)
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    for (;;) {
      if (likely(!__pyx_t_7)) {
        if (likely(PyList_CheckExact(__pyx_t_1))) {
          if (__pyx_t_4 >= PyList_GET_SIZE(__pyx_t_1)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_2 = PyList_GET_ITEM(__pyx_t_1, __pyx_t_4); __Pyx_INCREF(__pyx_t_2); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 1534, __pyx_L1_error)
          #else
          __pyx_t_2 = PySequence_ITEM(__pyx_t_1, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1534, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          #endif
        } else {
          if (__pyx_t_4 >= PyTuple_GET_SIZE(__pyx_t_1)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_2 = PyTuple_GET_ITEM(__pyx_t_1, __pyx_t_4); __Pyx_INCREF(__pyx_t_2); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 1534, __pyx_L1_error)
          #else
          __pyx_t_2 = PySequence_ITEM(__pyx_t_1, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1534, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          #endif
        }
      } else {
        __pyx_t_2 = __pyx_t_7(__pyx_t_1);
        if (unlikely(!__pyx_t_2)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(exc_type == PyExc_StopIteration || PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 1534, __pyx_L1_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_2);
      }
      __Pyx_XDECREF_SET(__pyx_v_d, __pyx_t_2);
      __pyx_t_2 = 0;

      /* "PyTorch.pyx":1535
 *             totalSize = 1
 *             for d in range(dims - 1, -1, -1):
 *                 totalSize *= size[d]             # <<<<<<<<<<<<<<
 *             myarray = np.zeros(totalSize, dtype=dtype)
 *             contig = self.contiguous()
 */
      __pyx_t_2 = PyObject_GetItem(__pyx_v_size, __pyx_v_d); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1535, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_3 = PyNumber_InPlaceMultiply(__pyx_v_totalSize, __pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1535, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_DECREF_SET(__pyx_v_totalSize, __pyx_t_3);
      __pyx_t_3 = 0;

      /* "PyTorch.pyx":1534
 *         if dims >= 1:
 *             totalSize = 1
 *             for d in range(dims - 1, -1, -1):             # <<<<<<<<<<<<<<
 *                 totalSize *= size[d]
 *             myarray = np.zeros(totalSize, dtype=dtype)
 */
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "PyTorch.pyx":1536
 *             for d in range(dims - 1, -1, -1):
 *                 totalSize *= size[d]
 *             myarray = np.zeros(totalSize, dtype=dtype)             # <<<<<<<<<<<<<<
 *             contig = self.contiguous()
 *             data = contig.data()
 */
    __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_np); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1536, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_zeros); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1536, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1536, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_INCREF(__pyx_v_totalSize);
    __Pyx_GIVEREF(__pyx_v_totalSize);
    PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_v_totalSize);
    __pyx_t_2 = PyDict_New(); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1536, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    if (PyDict_SetItem(__pyx_t_2, __pyx_n_s_dtype, __pyx_v_dtype) < 0) __PYX_ERR(0, 1536, __pyx_L1_error)
    __pyx_t_8 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_1, __pyx_t_2); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1536, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_v_myarray = __pyx_t_8;
    __pyx_t_8 = 0;

    /* "PyTorch.pyx":1537
 *                 totalSize *= size[d]
 *             myarray = np.zeros(totalSize, dtype=dtype)
 *             contig = self.contiguous()             # <<<<<<<<<<<<<<
 *             data = contig.data()
 *             for i in range(totalSize):
 */
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_contiguous); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1537, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_1 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
      __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_2);
      if (likely(__pyx_t_1)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
        __Pyx_INCREF(__pyx_t_1);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_2, function);
      }
    }
    if (__pyx_t_1) {
      __pyx_t_8 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1537, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    } else {
      __pyx_t_8 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1537, __pyx_L1_error)
    }
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    if (!(likely(((__pyx_t_8) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_8, __pyx_ptype_7PyTorch__DoubleTensor))))) __PYX_ERR(0, 1537, __pyx_L1_error)
    __pyx_v_contig = ((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_t_8);
    __pyx_t_8 = 0;

    /* "PyTorch.pyx":1538
 *             myarray = np.zeros(totalSize, dtype=dtype)
 *             contig = self.contiguous()
 *             data = contig.data()             # <<<<<<<<<<<<<<
 *             for i in range(totalSize):
 *                 myarray[i] = data[i]
 */
    __pyx_v_data = ((struct __pyx_vtabstruct_7PyTorch__DoubleTensor *)__pyx_v_contig->__pyx_vtab)->data(__pyx_v_contig);

    /* "PyTorch.pyx":1539
 *             contig = self.contiguous()
 *             data = contig.data()
 *             for i in range(totalSize):             # <<<<<<<<<<<<<<
 *                 myarray[i] = data[i]
 *             shape = []
 */
    __pyx_t_8 = PyTuple_New(1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1539, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_INCREF(__pyx_v_totalSize);
    __Pyx_GIVEREF(__pyx_v_totalSize);
    PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_v_totalSize);
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_range, __pyx_t_8, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1539, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    if (likely(PyList_CheckExact(__pyx_t_2)) || PyTuple_CheckExact(__pyx_t_2)) {
      __pyx_t_8 = __pyx_t_2; __Pyx_INCREF(__pyx_t_8); __pyx_t_4 = 0;
      __pyx_t_7 = NULL;
    } else {
      __pyx_t_4 = -1; __pyx_t_8 = PyObject_GetIter(__pyx_t_2); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1539, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_7 = Py_TYPE(__pyx_t_8)->tp_iternext; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1539, __pyx_L1_error)
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    for (;;) {
      if (likely(!__pyx_t_7)) {
        if (likely(PyList_CheckExact(__pyx_t_8))) {
          if (__pyx_t_4 >= PyList_GET_SIZE(__pyx_t_8)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_2 = PyList_GET_ITEM(__pyx_t_8, __pyx_t_4); __Pyx_INCREF(__pyx_t_2); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 1539, __pyx_L1_error)
          #else
          __pyx_t_2 = PySequence_ITEM(__pyx_t_8, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1539, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          #endif
        } else {
          if (__pyx_t_4 >= PyTuple_GET_SIZE(__pyx_t_8)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_2 = PyTuple_GET_ITEM(__pyx_t_8, __pyx_t_4); __Pyx_INCREF(__pyx_t_2); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 1539, __pyx_L1_error)
          #else
          __pyx_t_2 = PySequence_ITEM(__pyx_t_8, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1539, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          #endif
        }
      } else {
        __pyx_t_2 = __pyx_t_7(__pyx_t_8);
        if (unlikely(!__pyx_t_2)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(exc_type == PyExc_StopIteration || PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 1539, __pyx_L1_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_2);
      }
      __Pyx_XDECREF_SET(__pyx_v_i, __pyx_t_2);
      __pyx_t_2 = 0;

      /* "PyTorch.pyx":1540
 *             data = contig.data()
 *             for i in range(totalSize):
 *                 myarray[i] = data[i]             # <<<<<<<<<<<<<<
 *             shape = []
 *             for d in range(dims):
 */
      __pyx_t_9 = __Pyx_PyIndex_AsSsize_t(__pyx_v_i); if (unlikely((__pyx_t_9 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 1540, __pyx_L1_error)
      __pyx_t_2 = PyFloat_FromDouble((__pyx_v_data[__pyx_t_9])); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1540, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      if (unlikely(PyObject_SetItem(__pyx_v_myarray, __pyx_v_i, __pyx_t_2) < 0)) __PYX_ERR(0, 1540, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

      /* "PyTorch.pyx":1539
 *             contig = self.contiguous()
 *             data = contig.data()
 *             for i in range(totalSize):             # <<<<<<<<<<<<<<
 *                 myarray[i] = data[i]
 *             shape = []
 */
    }
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;

    /* "PyTorch.pyx":1541
 *             for i in range(totalSize):
 *                 myarray[i] = data[i]
 *             shape = []             # <<<<<<<<<<<<<<
 *             for d in range(dims):
 *                 shape.append(size[d])
 */
    __pyx_t_8 = PyList_New(0); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1541, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_v_shape = ((PyObject*)__pyx_t_8);
    __pyx_t_8 = 0;

    /* "PyTorch.pyx":1542
 *                 myarray[i] = data[i]
 *             shape = []
 *             for d in range(dims):             # <<<<<<<<<<<<<<
 *                 shape.append(size[d])
 *             return myarray.reshape(shape)
 */
    __pyx_t_8 = PyTuple_New(1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1542, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_INCREF(__pyx_v_dims);
    __Pyx_GIVEREF(__pyx_v_dims);
    PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_v_dims);
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_range, __pyx_t_8, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1542, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    if (likely(PyList_CheckExact(__pyx_t_2)) || PyTuple_CheckExact(__pyx_t_2)) {
      __pyx_t_8 = __pyx_t_2; __Pyx_INCREF(__pyx_t_8); __pyx_t_4 = 0;
      __pyx_t_7 = NULL;
    } else {
      __pyx_t_4 = -1; __pyx_t_8 = PyObject_GetIter(__pyx_t_2); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1542, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_7 = Py_TYPE(__pyx_t_8)->tp_iternext; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1542, __pyx_L1_error)
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    for (;;) {
      if (likely(!__pyx_t_7)) {
        if (likely(PyList_CheckExact(__pyx_t_8))) {
          if (__pyx_t_4 >= PyList_GET_SIZE(__pyx_t_8)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_2 = PyList_GET_ITEM(__pyx_t_8, __pyx_t_4); __Pyx_INCREF(__pyx_t_2); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 1542, __pyx_L1_error)
          #else
          __pyx_t_2 = PySequence_ITEM(__pyx_t_8, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1542, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          #endif
        } else {
          if (__pyx_t_4 >= PyTuple_GET_SIZE(__pyx_t_8)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_2 = PyTuple_GET_ITEM(__pyx_t_8, __pyx_t_4); __Pyx_INCREF(__pyx_t_2); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 1542, __pyx_L1_error)
          #else
          __pyx_t_2 = PySequence_ITEM(__pyx_t_8, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1542, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          #endif
        }
      } else {
        __pyx_t_2 = __pyx_t_7(__pyx_t_8);
        if (unlikely(!__pyx_t_2)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(exc_type == PyExc_StopIteration || PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 1542, __pyx_L1_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_2);
      }
      __Pyx_XDECREF_SET(__pyx_v_d, __pyx_t_2);
      __pyx_t_2 = 0;

      /* "PyTorch.pyx":1543
 *             shape = []
 *             for d in range(dims):
 *                 shape.append(size[d])             # <<<<<<<<<<<<<<
 *             return myarray.reshape(shape)
 *         else:
 */
      __pyx_t_2 = PyObject_GetItem(__pyx_v_size, __pyx_v_d); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1543, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_10 = __Pyx_PyList_Append(__pyx_v_shape, __pyx_t_2); if (unlikely(__pyx_t_10 == -1)) __PYX_ERR(0, 1543, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

      /* "PyTorch.pyx":1542
 *                 myarray[i] = data[i]
 *             shape = []
 *             for d in range(dims):             # <<<<<<<<<<<<<<
 *                 shape.append(size[d])
 *             return myarray.reshape(shape)
 */
    }
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;

    /* "PyTorch.pyx":1544
 *             for d in range(dims):
 *                 shape.append(size[d])
 *             return myarray.reshape(shape)             # <<<<<<<<<<<<<<
 *         else:
 *             raise Exception('Not implemented for dims = {dims}'.format(dims=dims))
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_myarray, __pyx_n_s_reshape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1544, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_1 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
      __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_2);
      if (likely(__pyx_t_1)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
        __Pyx_INCREF(__pyx_t_1);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_2, function);
      }
    }
    if (!__pyx_t_1) {
      __pyx_t_8 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_v_shape); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1544, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[2] = {__pyx_t_1, __pyx_v_shape};
        __pyx_t_8 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1544, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
        __Pyx_GOTREF(__pyx_t_8);
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[2] = {__pyx_t_1, __pyx_v_shape};
        __pyx_t_8 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1544, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
        __Pyx_GOTREF(__pyx_t_8);
      } else
      #endif
      {
        __pyx_t_3 = PyTuple_New(1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1544, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_GIVEREF(__pyx_t_1); PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_1); __pyx_t_1 = NULL;
        __Pyx_INCREF(__pyx_v_shape);
        __Pyx_GIVEREF(__pyx_v_shape);
        PyTuple_SET_ITEM(__pyx_t_3, 0+1, __pyx_v_shape);
        __pyx_t_8 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_3, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1544, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_r = __pyx_t_8;
    __pyx_t_8 = 0;
    goto __pyx_L0;

    /* "PyTorch.pyx":1532
 *           raise Exception("not implemented for Double")
 * #        print('dtype', dtype)
 *         if dims >= 1:             # <<<<<<<<<<<<<<
 *             totalSize = 1
 *             for d in range(dims - 1, -1, -1):
 */
  }

  /* "PyTorch.pyx":1546
 *             return myarray.reshape(shape)
 *         else:
 *             raise Exception('Not implemented for dims = {dims}'.format(dims=dims))             # <<<<<<<<<<<<<<
 * 
 *     @property
 */
  /*else*/ {
    __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_kp_s_Not_implemented_for_dims_dims, __pyx_n_s_format); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1546, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_2 = PyDict_New(); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1546, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    if (PyDict_SetItem(__pyx_t_2, __pyx_n_s_dims, __pyx_v_dims) < 0) __PYX_ERR(0, 1546, __pyx_L1_error)
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_8, __pyx_empty_tuple, __pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1546, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = PyTuple_New(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1546, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_GIVEREF(__pyx_t_3);
    PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_3);
    __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_t_2, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1546, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(0, 1546, __pyx_L1_error)
  }

  /* "PyTorch.pyx":1519
 *         return THDoubleTensor_nElement(self.native)
 * 
 *     def asNumpyTensor(_DoubleTensor self):             # <<<<<<<<<<<<<<
 *         cdef Storage._DoubleStorage storage
 *         cdef double *data
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.asNumpyTensor", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_contig);
  __Pyx_XDECREF(__pyx_v_size);
  __Pyx_XDECREF(__pyx_v_dims);
  __Pyx_XDECREF(__pyx_v_dtype);
  __Pyx_XDECREF(__pyx_v_totalSize);
  __Pyx_XDECREF(__pyx_v_d);
  __Pyx_XDECREF(__pyx_v_myarray);
  __Pyx_XDECREF(__pyx_v_i);
  __Pyx_XDECREF(__pyx_v_shape);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1549
 * 
 *     @property
 *     def refCount(_DoubleTensor self):             # <<<<<<<<<<<<<<
 *         return THDoubleTensor_getRefCount(self.native)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_8refCount_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_8refCount_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_8refCount___get__(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_8refCount___get__(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "PyTorch.pyx":1550
 *     @property
 *     def refCount(_DoubleTensor self):
 *         return THDoubleTensor_getRefCount(self.native)             # <<<<<<<<<<<<<<
 * 
 *     cdef double *data(_DoubleTensor self):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_int(THDoubleTensor_getRefCount(__pyx_v_self->native)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1550, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":1549
 * 
 *     @property
 *     def refCount(_DoubleTensor self):             # <<<<<<<<<<<<<<
 *         return THDoubleTensor_getRefCount(self.native)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.refCount.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1552
 *         return THDoubleTensor_getRefCount(self.native)
 * 
 *     cdef double *data(_DoubleTensor self):             # <<<<<<<<<<<<<<
 *         return THDoubleTensor_data(self.native)
 * 
 */

static double *__pyx_f_7PyTorch_13_DoubleTensor_data(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self) {
  double *__pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("data", 0);

  /* "PyTorch.pyx":1553
 * 
 *     cdef double *data(_DoubleTensor self):
 *         return THDoubleTensor_data(self.native)             # <<<<<<<<<<<<<<
 * 
 *     cpdef int dims(self):
 */
  __pyx_r = THDoubleTensor_data(__pyx_v_self->native);
  goto __pyx_L0;

  /* "PyTorch.pyx":1552
 *         return THDoubleTensor_getRefCount(self.native)
 * 
 *     cdef double *data(_DoubleTensor self):             # <<<<<<<<<<<<<<
 *         return THDoubleTensor_data(self.native)
 * 
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1555
 *         return THDoubleTensor_data(self.native)
 * 
 *     cpdef int dims(self):             # <<<<<<<<<<<<<<
 *         return THDoubleTensor_nDimension(self.native)
 * 
 */

static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_9dims(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static int __pyx_f_7PyTorch_13_DoubleTensor_dims(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, int __pyx_skip_dispatch) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  int __pyx_t_5;
  __Pyx_RefNannySetupContext("dims", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_dims); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1555, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_9dims)) {
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_3 = __pyx_t_1; __pyx_t_4 = NULL;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
        __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
        if (likely(__pyx_t_4)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
          __Pyx_INCREF(__pyx_t_4);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_3, function);
        }
      }
      if (__pyx_t_4) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_4); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1555, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else {
        __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1555, __pyx_L1_error)
      }
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_5 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_5 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1555, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_r = __pyx_t_5;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "PyTorch.pyx":1556
 * 
 *     cpdef int dims(self):
 *         return THDoubleTensor_nDimension(self.native)             # <<<<<<<<<<<<<<
 * 
 *     cpdef set1d(self, int x0, double value):
 */
  __pyx_r = THDoubleTensor_nDimension(__pyx_v_self->native);
  goto __pyx_L0;

  /* "PyTorch.pyx":1555
 *         return THDoubleTensor_data(self.native)
 * 
 *     cpdef int dims(self):             # <<<<<<<<<<<<<<
 *         return THDoubleTensor_nDimension(self.native)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_WriteUnraisable("PyTorch._DoubleTensor.dims", __pyx_clineno, __pyx_lineno, __pyx_filename, 0, 0);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_9dims(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_9dims(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("dims (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_8dims(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_8dims(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("dims", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_f_7PyTorch_13_DoubleTensor_dims(__pyx_v_self, 1)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1555, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.dims", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1558
 *         return THDoubleTensor_nDimension(self.native)
 * 
 *     cpdef set1d(self, int x0, double value):             # <<<<<<<<<<<<<<
 *         THDoubleTensor_set1d(self.native, x0, value)
 * 
 */

static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_11set1d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_f_7PyTorch_13_DoubleTensor_set1d(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, int __pyx_v_x0, double __pyx_v_value, int __pyx_skip_dispatch) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  int __pyx_t_7;
  PyObject *__pyx_t_8 = NULL;
  __Pyx_RefNannySetupContext("set1d", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_set1d); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1558, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_11set1d)) {
      __Pyx_XDECREF(__pyx_r);
      __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_x0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1558, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_4 = PyFloat_FromDouble(__pyx_v_value); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1558, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_5 = __pyx_t_1; __pyx_t_6 = NULL;
      __pyx_t_7 = 0;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
        __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_5);
        if (likely(__pyx_t_6)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
          __Pyx_INCREF(__pyx_t_6);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_5, function);
          __pyx_t_7 = 1;
        }
      }
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_5)) {
        PyObject *__pyx_temp[3] = {__pyx_t_6, __pyx_t_3, __pyx_t_4};
        __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_7, 2+__pyx_t_7); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1558, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
        PyObject *__pyx_temp[3] = {__pyx_t_6, __pyx_t_3, __pyx_t_4};
        __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_7, 2+__pyx_t_7); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1558, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else
      #endif
      {
        __pyx_t_8 = PyTuple_New(2+__pyx_t_7); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1558, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        if (__pyx_t_6) {
          __Pyx_GIVEREF(__pyx_t_6); PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_t_6); __pyx_t_6 = NULL;
        }
        __Pyx_GIVEREF(__pyx_t_3);
        PyTuple_SET_ITEM(__pyx_t_8, 0+__pyx_t_7, __pyx_t_3);
        __Pyx_GIVEREF(__pyx_t_4);
        PyTuple_SET_ITEM(__pyx_t_8, 1+__pyx_t_7, __pyx_t_4);
        __pyx_t_3 = 0;
        __pyx_t_4 = 0;
        __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_8, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1558, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      }
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __pyx_r = __pyx_t_2;
      __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "PyTorch.pyx":1559
 * 
 *     cpdef set1d(self, int x0, double value):
 *         THDoubleTensor_set1d(self.native, x0, value)             # <<<<<<<<<<<<<<
 * 
 *     cpdef set2d(self, int x0, int x1, double value):
 */
  THDoubleTensor_set1d(__pyx_v_self->native, __pyx_v_x0, __pyx_v_value);

  /* "PyTorch.pyx":1558
 *         return THDoubleTensor_nDimension(self.native)
 * 
 *     cpdef set1d(self, int x0, double value):             # <<<<<<<<<<<<<<
 *         THDoubleTensor_set1d(self.native, x0, value)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.set1d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_11set1d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_11set1d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  int __pyx_v_x0;
  double __pyx_v_value;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("set1d (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_x0,&__pyx_n_s_value,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_x0)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_value)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("set1d", 1, 2, 2, 1); __PYX_ERR(0, 1558, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "set1d") < 0)) __PYX_ERR(0, 1558, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_x0 = __Pyx_PyInt_As_int(values[0]); if (unlikely((__pyx_v_x0 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1558, __pyx_L3_error)
    __pyx_v_value = __pyx_PyFloat_AsDouble(values[1]); if (unlikely((__pyx_v_value == (double)-1) && PyErr_Occurred())) __PYX_ERR(0, 1558, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("set1d", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1558, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._DoubleTensor.set1d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_10set1d(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self), __pyx_v_x0, __pyx_v_value);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_10set1d(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, int __pyx_v_x0, double __pyx_v_value) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("set1d", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_7PyTorch_13_DoubleTensor_set1d(__pyx_v_self, __pyx_v_x0, __pyx_v_value, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1558, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.set1d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1561
 *         THDoubleTensor_set1d(self.native, x0, value)
 * 
 *     cpdef set2d(self, int x0, int x1, double value):             # <<<<<<<<<<<<<<
 *         THDoubleTensor_set2d(self.native, x0, x1, value)
 * 
 */

static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_13set2d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_f_7PyTorch_13_DoubleTensor_set2d(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_v_x1, double __pyx_v_value, int __pyx_skip_dispatch) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  int __pyx_t_8;
  PyObject *__pyx_t_9 = NULL;
  __Pyx_RefNannySetupContext("set2d", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_set2d); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1561, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_13set2d)) {
      __Pyx_XDECREF(__pyx_r);
      __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_x0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1561, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_4 = __Pyx_PyInt_From_int(__pyx_v_x1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1561, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_t_5 = PyFloat_FromDouble(__pyx_v_value); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 1561, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_6 = __pyx_t_1; __pyx_t_7 = NULL;
      __pyx_t_8 = 0;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_6))) {
        __pyx_t_7 = PyMethod_GET_SELF(__pyx_t_6);
        if (likely(__pyx_t_7)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
          __Pyx_INCREF(__pyx_t_7);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_6, function);
          __pyx_t_8 = 1;
        }
      }
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_6)) {
        PyObject *__pyx_temp[4] = {__pyx_t_7, __pyx_t_3, __pyx_t_4, __pyx_t_5};
        __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_8, 3+__pyx_t_8); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1561, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_6)) {
        PyObject *__pyx_temp[4] = {__pyx_t_7, __pyx_t_3, __pyx_t_4, __pyx_t_5};
        __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_8, 3+__pyx_t_8); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1561, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      } else
      #endif
      {
        __pyx_t_9 = PyTuple_New(3+__pyx_t_8); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 1561, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_9);
        if (__pyx_t_7) {
          __Pyx_GIVEREF(__pyx_t_7); PyTuple_SET_ITEM(__pyx_t_9, 0, __pyx_t_7); __pyx_t_7 = NULL;
        }
        __Pyx_GIVEREF(__pyx_t_3);
        PyTuple_SET_ITEM(__pyx_t_9, 0+__pyx_t_8, __pyx_t_3);
        __Pyx_GIVEREF(__pyx_t_4);
        PyTuple_SET_ITEM(__pyx_t_9, 1+__pyx_t_8, __pyx_t_4);
        __Pyx_GIVEREF(__pyx_t_5);
        PyTuple_SET_ITEM(__pyx_t_9, 2+__pyx_t_8, __pyx_t_5);
        __pyx_t_3 = 0;
        __pyx_t_4 = 0;
        __pyx_t_5 = 0;
        __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_9, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1561, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      }
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_r = __pyx_t_2;
      __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "PyTorch.pyx":1562
 * 
 *     cpdef set2d(self, int x0, int x1, double value):
 *         THDoubleTensor_set2d(self.native, x0, x1, value)             # <<<<<<<<<<<<<<
 * 
 *     cpdef double get1d(self, int x0):
 */
  THDoubleTensor_set2d(__pyx_v_self->native, __pyx_v_x0, __pyx_v_x1, __pyx_v_value);

  /* "PyTorch.pyx":1561
 *         THDoubleTensor_set1d(self.native, x0, value)
 * 
 *     cpdef set2d(self, int x0, int x1, double value):             # <<<<<<<<<<<<<<
 *         THDoubleTensor_set2d(self.native, x0, x1, value)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.set2d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_13set2d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_13set2d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  int __pyx_v_x0;
  int __pyx_v_x1;
  double __pyx_v_value;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("set2d (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_x0,&__pyx_n_s_x1,&__pyx_n_s_value,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_x0)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_x1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("set2d", 1, 3, 3, 1); __PYX_ERR(0, 1561, __pyx_L3_error)
        }
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_value)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("set2d", 1, 3, 3, 2); __PYX_ERR(0, 1561, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "set2d") < 0)) __PYX_ERR(0, 1561, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_x0 = __Pyx_PyInt_As_int(values[0]); if (unlikely((__pyx_v_x0 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1561, __pyx_L3_error)
    __pyx_v_x1 = __Pyx_PyInt_As_int(values[1]); if (unlikely((__pyx_v_x1 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1561, __pyx_L3_error)
    __pyx_v_value = __pyx_PyFloat_AsDouble(values[2]); if (unlikely((__pyx_v_value == (double)-1) && PyErr_Occurred())) __PYX_ERR(0, 1561, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("set2d", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1561, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._DoubleTensor.set2d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_12set2d(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self), __pyx_v_x0, __pyx_v_x1, __pyx_v_value);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_12set2d(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_v_x1, double __pyx_v_value) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("set2d", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_7PyTorch_13_DoubleTensor_set2d(__pyx_v_self, __pyx_v_x0, __pyx_v_x1, __pyx_v_value, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1561, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.set2d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1564
 *         THDoubleTensor_set2d(self.native, x0, x1, value)
 * 
 *     cpdef double get1d(self, int x0):             # <<<<<<<<<<<<<<
 *         return THDoubleTensor_get1d(self.native, x0)
 * 
 */

static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_15get1d(PyObject *__pyx_v_self, PyObject *__pyx_arg_x0); /*proto*/
static double __pyx_f_7PyTorch_13_DoubleTensor_get1d(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_skip_dispatch) {
  double __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  double __pyx_t_7;
  __Pyx_RefNannySetupContext("get1d", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_get1d); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1564, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_15get1d)) {
      __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_x0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1564, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_4 = __pyx_t_1; __pyx_t_5 = NULL;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_4))) {
        __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_4);
        if (likely(__pyx_t_5)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
          __Pyx_INCREF(__pyx_t_5);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_4, function);
        }
      }
      if (!__pyx_t_5) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1564, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_GOTREF(__pyx_t_2);
      } else {
        #if CYTHON_FAST_PYCALL
        if (PyFunction_Check(__pyx_t_4)) {
          PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_t_3};
          __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_4, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1564, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        } else
        #endif
        #if CYTHON_FAST_PYCCALL
        if (__Pyx_PyFastCFunction_Check(__pyx_t_4)) {
          PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_t_3};
          __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_4, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1564, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        } else
        #endif
        {
          __pyx_t_6 = PyTuple_New(1+1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1564, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_6);
          __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_5); __pyx_t_5 = NULL;
          __Pyx_GIVEREF(__pyx_t_3);
          PyTuple_SET_ITEM(__pyx_t_6, 0+1, __pyx_t_3);
          __pyx_t_3 = 0;
          __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_4, __pyx_t_6, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1564, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
        }
      }
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_7 = __pyx_PyFloat_AsDouble(__pyx_t_2); if (unlikely((__pyx_t_7 == (double)-1) && PyErr_Occurred())) __PYX_ERR(0, 1564, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_r = __pyx_t_7;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "PyTorch.pyx":1565
 * 
 *     cpdef double get1d(self, int x0):
 *         return THDoubleTensor_get1d(self.native, x0)             # <<<<<<<<<<<<<<
 * 
 *     cpdef double get2d(self, int x0, int x1):
 */
  __pyx_r = THDoubleTensor_get1d(__pyx_v_self->native, __pyx_v_x0);
  goto __pyx_L0;

  /* "PyTorch.pyx":1564
 *         THDoubleTensor_set2d(self.native, x0, x1, value)
 * 
 *     cpdef double get1d(self, int x0):             # <<<<<<<<<<<<<<
 *         return THDoubleTensor_get1d(self.native, x0)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_WriteUnraisable("PyTorch._DoubleTensor.get1d", __pyx_clineno, __pyx_lineno, __pyx_filename, 0, 0);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_15get1d(PyObject *__pyx_v_self, PyObject *__pyx_arg_x0); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_15get1d(PyObject *__pyx_v_self, PyObject *__pyx_arg_x0) {
  int __pyx_v_x0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("get1d (wrapper)", 0);
  assert(__pyx_arg_x0); {
    __pyx_v_x0 = __Pyx_PyInt_As_int(__pyx_arg_x0); if (unlikely((__pyx_v_x0 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1564, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._DoubleTensor.get1d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_14get1d(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self), ((int)__pyx_v_x0));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_14get1d(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, int __pyx_v_x0) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("get1d", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyFloat_FromDouble(__pyx_f_7PyTorch_13_DoubleTensor_get1d(__pyx_v_self, __pyx_v_x0, 1)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1564, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.get1d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1567
 *         return THDoubleTensor_get1d(self.native, x0)
 * 
 *     cpdef double get2d(self, int x0, int x1):             # <<<<<<<<<<<<<<
 *         return THDoubleTensor_get2d(self.native, x0, x1)
 * 
 */

static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_17get2d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static double __pyx_f_7PyTorch_13_DoubleTensor_get2d(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_v_x1, int __pyx_skip_dispatch) {
  double __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  int __pyx_t_7;
  PyObject *__pyx_t_8 = NULL;
  double __pyx_t_9;
  __Pyx_RefNannySetupContext("get2d", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_get2d); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1567, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_17get2d)) {
      __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_x0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1567, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_4 = __Pyx_PyInt_From_int(__pyx_v_x1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1567, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_5 = __pyx_t_1; __pyx_t_6 = NULL;
      __pyx_t_7 = 0;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
        __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_5);
        if (likely(__pyx_t_6)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
          __Pyx_INCREF(__pyx_t_6);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_5, function);
          __pyx_t_7 = 1;
        }
      }
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_5)) {
        PyObject *__pyx_temp[3] = {__pyx_t_6, __pyx_t_3, __pyx_t_4};
        __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_7, 2+__pyx_t_7); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1567, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
        PyObject *__pyx_temp[3] = {__pyx_t_6, __pyx_t_3, __pyx_t_4};
        __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_7, 2+__pyx_t_7); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1567, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else
      #endif
      {
        __pyx_t_8 = PyTuple_New(2+__pyx_t_7); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1567, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        if (__pyx_t_6) {
          __Pyx_GIVEREF(__pyx_t_6); PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_t_6); __pyx_t_6 = NULL;
        }
        __Pyx_GIVEREF(__pyx_t_3);
        PyTuple_SET_ITEM(__pyx_t_8, 0+__pyx_t_7, __pyx_t_3);
        __Pyx_GIVEREF(__pyx_t_4);
        PyTuple_SET_ITEM(__pyx_t_8, 1+__pyx_t_7, __pyx_t_4);
        __pyx_t_3 = 0;
        __pyx_t_4 = 0;
        __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_8, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1567, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      }
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __pyx_t_9 = __pyx_PyFloat_AsDouble(__pyx_t_2); if (unlikely((__pyx_t_9 == (double)-1) && PyErr_Occurred())) __PYX_ERR(0, 1567, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_r = __pyx_t_9;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "PyTorch.pyx":1568
 * 
 *     cpdef double get2d(self, int x0, int x1):
 *         return THDoubleTensor_get2d(self.native, x0, x1)             # <<<<<<<<<<<<<<
 * 
 *     cpdef int isContiguous(_DoubleTensor self):
 */
  __pyx_r = THDoubleTensor_get2d(__pyx_v_self->native, __pyx_v_x0, __pyx_v_x1);
  goto __pyx_L0;

  /* "PyTorch.pyx":1567
 *         return THDoubleTensor_get1d(self.native, x0)
 * 
 *     cpdef double get2d(self, int x0, int x1):             # <<<<<<<<<<<<<<
 *         return THDoubleTensor_get2d(self.native, x0, x1)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_WriteUnraisable("PyTorch._DoubleTensor.get2d", __pyx_clineno, __pyx_lineno, __pyx_filename, 0, 0);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_17get2d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_17get2d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  int __pyx_v_x0;
  int __pyx_v_x1;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("get2d (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_x0,&__pyx_n_s_x1,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_x0)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_x1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("get2d", 1, 2, 2, 1); __PYX_ERR(0, 1567, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "get2d") < 0)) __PYX_ERR(0, 1567, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_x0 = __Pyx_PyInt_As_int(values[0]); if (unlikely((__pyx_v_x0 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1567, __pyx_L3_error)
    __pyx_v_x1 = __Pyx_PyInt_As_int(values[1]); if (unlikely((__pyx_v_x1 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1567, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("get2d", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1567, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._DoubleTensor.get2d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_16get2d(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self), __pyx_v_x0, __pyx_v_x1);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_16get2d(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_v_x1) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("get2d", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyFloat_FromDouble(__pyx_f_7PyTorch_13_DoubleTensor_get2d(__pyx_v_self, __pyx_v_x0, __pyx_v_x1, 1)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1567, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.get2d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1570
 *         return THDoubleTensor_get2d(self.native, x0, x1)
 * 
 *     cpdef int isContiguous(_DoubleTensor self):             # <<<<<<<<<<<<<<
 *         return THDoubleTensor_isContiguous(self.native)
 * 
 */

static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_19isContiguous(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static int __pyx_f_7PyTorch_13_DoubleTensor_isContiguous(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, int __pyx_skip_dispatch) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  int __pyx_t_5;
  __Pyx_RefNannySetupContext("isContiguous", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_isContiguous); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1570, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_19isContiguous)) {
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_3 = __pyx_t_1; __pyx_t_4 = NULL;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
        __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
        if (likely(__pyx_t_4)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
          __Pyx_INCREF(__pyx_t_4);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_3, function);
        }
      }
      if (__pyx_t_4) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_4); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1570, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else {
        __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1570, __pyx_L1_error)
      }
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_5 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_5 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1570, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_r = __pyx_t_5;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "PyTorch.pyx":1571
 * 
 *     cpdef int isContiguous(_DoubleTensor self):
 *         return THDoubleTensor_isContiguous(self.native)             # <<<<<<<<<<<<<<
 * 
 *     cpdef double max(self):
 */
  __pyx_r = THDoubleTensor_isContiguous(__pyx_v_self->native);
  goto __pyx_L0;

  /* "PyTorch.pyx":1570
 *         return THDoubleTensor_get2d(self.native, x0, x1)
 * 
 *     cpdef int isContiguous(_DoubleTensor self):             # <<<<<<<<<<<<<<
 *         return THDoubleTensor_isContiguous(self.native)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_WriteUnraisable("PyTorch._DoubleTensor.isContiguous", __pyx_clineno, __pyx_lineno, __pyx_filename, 0, 0);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_19isContiguous(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_19isContiguous(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("isContiguous (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_18isContiguous(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_18isContiguous(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("isContiguous", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_f_7PyTorch_13_DoubleTensor_isContiguous(__pyx_v_self, 1)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1570, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.isContiguous", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1573
 *         return THDoubleTensor_isContiguous(self.native)
 * 
 *     cpdef double max(self):             # <<<<<<<<<<<<<<
 *         return THDoubleTensor_maxall(self.native)
 * 
 */

static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_21max(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static double __pyx_f_7PyTorch_13_DoubleTensor_max(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, int __pyx_skip_dispatch) {
  double __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  double __pyx_t_5;
  __Pyx_RefNannySetupContext("max", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_max); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1573, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_21max)) {
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_3 = __pyx_t_1; __pyx_t_4 = NULL;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
        __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
        if (likely(__pyx_t_4)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
          __Pyx_INCREF(__pyx_t_4);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_3, function);
        }
      }
      if (__pyx_t_4) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_4); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1573, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else {
        __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1573, __pyx_L1_error)
      }
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_5 = __pyx_PyFloat_AsDouble(__pyx_t_2); if (unlikely((__pyx_t_5 == (double)-1) && PyErr_Occurred())) __PYX_ERR(0, 1573, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_r = __pyx_t_5;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "PyTorch.pyx":1574
 * 
 *     cpdef double max(self):
 *         return THDoubleTensor_maxall(self.native)             # <<<<<<<<<<<<<<
 * 
 *     cpdef double min(self):
 */
  __pyx_r = THDoubleTensor_maxall(__pyx_v_self->native);
  goto __pyx_L0;

  /* "PyTorch.pyx":1573
 *         return THDoubleTensor_isContiguous(self.native)
 * 
 *     cpdef double max(self):             # <<<<<<<<<<<<<<
 *         return THDoubleTensor_maxall(self.native)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_WriteUnraisable("PyTorch._DoubleTensor.max", __pyx_clineno, __pyx_lineno, __pyx_filename, 0, 0);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_21max(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_21max(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("max (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_20max(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_20max(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("max", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyFloat_FromDouble(__pyx_f_7PyTorch_13_DoubleTensor_max(__pyx_v_self, 1)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1573, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.max", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1576
 *         return THDoubleTensor_maxall(self.native)
 * 
 *     cpdef double min(self):             # <<<<<<<<<<<<<<
 *         return THDoubleTensor_minall(self.native)
 * 
 */

static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_23min(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static double __pyx_f_7PyTorch_13_DoubleTensor_min(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, int __pyx_skip_dispatch) {
  double __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  double __pyx_t_5;
  __Pyx_RefNannySetupContext("min", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_min); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1576, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_23min)) {
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_3 = __pyx_t_1; __pyx_t_4 = NULL;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
        __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
        if (likely(__pyx_t_4)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
          __Pyx_INCREF(__pyx_t_4);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_3, function);
        }
      }
      if (__pyx_t_4) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_4); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1576, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else {
        __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1576, __pyx_L1_error)
      }
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_5 = __pyx_PyFloat_AsDouble(__pyx_t_2); if (unlikely((__pyx_t_5 == (double)-1) && PyErr_Occurred())) __PYX_ERR(0, 1576, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_r = __pyx_t_5;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "PyTorch.pyx":1577
 * 
 *     cpdef double min(self):
 *         return THDoubleTensor_minall(self.native)             # <<<<<<<<<<<<<<
 * 
 *     def __repr__(_DoubleTensor self):
 */
  __pyx_r = THDoubleTensor_minall(__pyx_v_self->native);
  goto __pyx_L0;

  /* "PyTorch.pyx":1576
 *         return THDoubleTensor_maxall(self.native)
 * 
 *     cpdef double min(self):             # <<<<<<<<<<<<<<
 *         return THDoubleTensor_minall(self.native)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_WriteUnraisable("PyTorch._DoubleTensor.min", __pyx_clineno, __pyx_lineno, __pyx_filename, 0, 0);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_23min(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_23min(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("min (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_22min(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_22min(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("min", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyFloat_FromDouble(__pyx_f_7PyTorch_13_DoubleTensor_min(__pyx_v_self, 1)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1576, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.min", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1579
 *         return THDoubleTensor_minall(self.native)
 * 
 *     def __repr__(_DoubleTensor self):             # <<<<<<<<<<<<<<
 *         return self.as_string(self)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_25__repr__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_25__repr__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__repr__ (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_24__repr__(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_24__repr__(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  __Pyx_RefNannySetupContext("__repr__", 0);

  /* "PyTorch.pyx":1580
 * 
 *     def __repr__(_DoubleTensor self):
 *         return self.as_string(self)             # <<<<<<<<<<<<<<
 * 
 *     def as_string(_DoubleTensor self, show_size=True):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_as_string); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1580, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (!__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, ((PyObject *)__pyx_v_self)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1580, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
  } else {
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_2)) {
      PyObject *__pyx_temp[2] = {__pyx_t_3, ((PyObject *)__pyx_v_self)};
      __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1580, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_GOTREF(__pyx_t_1);
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
      PyObject *__pyx_temp[2] = {__pyx_t_3, ((PyObject *)__pyx_v_self)};
      __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1580, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_GOTREF(__pyx_t_1);
    } else
    #endif
    {
      __pyx_t_4 = PyTuple_New(1+1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1580, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_GIVEREF(__pyx_t_3); PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_3); __pyx_t_3 = NULL;
      __Pyx_INCREF(((PyObject *)__pyx_v_self));
      __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
      PyTuple_SET_ITEM(__pyx_t_4, 0+1, ((PyObject *)__pyx_v_self));
      __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_4, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1580, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    }
  }
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":1579
 *         return THDoubleTensor_minall(self.native)
 * 
 *     def __repr__(_DoubleTensor self):             # <<<<<<<<<<<<<<
 *         return self.as_string(self)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.__repr__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1582
 *         return self.as_string(self)
 * 
 *     def as_string(_DoubleTensor self, show_size=True):             # <<<<<<<<<<<<<<
 *         # assume 2d matrix for now
 *         cdef int size0
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_27as_string(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_27as_string(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_show_size = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("as_string (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_show_size,0};
    PyObject* values[1] = {0};
    values[0] = ((PyObject *)Py_True);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_show_size);
          if (value) { values[0] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "as_string") < 0)) __PYX_ERR(0, 1582, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_show_size = values[0];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("as_string", 0, 0, 1, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1582, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._DoubleTensor.as_string", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_26as_string(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self), __pyx_v_show_size);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_26as_string(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, PyObject *__pyx_v_show_size) {
  int __pyx_v_size0;
  int __pyx_v_size1;
  int __pyx_v_dims;
  PyObject *__pyx_v_res = NULL;
  int __pyx_v_r;
  PyObject *__pyx_v_thisline = NULL;
  int __pyx_v_c;
  PyObject *__pyx_v_d = NULL;
  int __pyx_v_first;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  int __pyx_t_3;
  int __pyx_t_4;
  int __pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  Py_ssize_t __pyx_t_9;
  PyObject *(*__pyx_t_10)(PyObject *);
  PyObject *__pyx_t_11 = NULL;
  __Pyx_RefNannySetupContext("as_string", 0);

  /* "PyTorch.pyx":1586
 *         cdef int size0
 *         cdef int size1
 *         dims = self.dims()             # <<<<<<<<<<<<<<
 *         if dims == 0:
 *             return '[torch.DoubleTensor with no dimension]\n'
 */
  __pyx_v_dims = ((struct __pyx_vtabstruct_7PyTorch__DoubleTensor *)__pyx_v_self->__pyx_vtab)->dims(__pyx_v_self, 0);

  /* "PyTorch.pyx":1587
 *         cdef int size1
 *         dims = self.dims()
 *         if dims == 0:             # <<<<<<<<<<<<<<
 *             return '[torch.DoubleTensor with no dimension]\n'
 *         elif dims == 2:
 */
  switch (__pyx_v_dims) {
    case 0:

    /* "PyTorch.pyx":1588
 *         dims = self.dims()
 *         if dims == 0:
 *             return '[torch.DoubleTensor with no dimension]\n'             # <<<<<<<<<<<<<<
 *         elif dims == 2:
 *             size0 = THDoubleTensor_size(self.native, 0)
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(__pyx_kp_s_torch_DoubleTensor_with_no_dime);
    __pyx_r = __pyx_kp_s_torch_DoubleTensor_with_no_dime;
    goto __pyx_L0;

    /* "PyTorch.pyx":1587
 *         cdef int size1
 *         dims = self.dims()
 *         if dims == 0:             # <<<<<<<<<<<<<<
 *             return '[torch.DoubleTensor with no dimension]\n'
 *         elif dims == 2:
 */
    break;

    /* "PyTorch.pyx":1589
 *         if dims == 0:
 *             return '[torch.DoubleTensor with no dimension]\n'
 *         elif dims == 2:             # <<<<<<<<<<<<<<
 *             size0 = THDoubleTensor_size(self.native, 0)
 *             size1 = THDoubleTensor_size(self.native, 1)
 */
    case 2:

    /* "PyTorch.pyx":1590
 *             return '[torch.DoubleTensor with no dimension]\n'
 *         elif dims == 2:
 *             size0 = THDoubleTensor_size(self.native, 0)             # <<<<<<<<<<<<<<
 *             size1 = THDoubleTensor_size(self.native, 1)
 *             res = ''
 */
    __pyx_v_size0 = THDoubleTensor_size(__pyx_v_self->native, 0);

    /* "PyTorch.pyx":1591
 *         elif dims == 2:
 *             size0 = THDoubleTensor_size(self.native, 0)
 *             size1 = THDoubleTensor_size(self.native, 1)             # <<<<<<<<<<<<<<
 *             res = ''
 *             for r in range(size0):
 */
    __pyx_v_size1 = THDoubleTensor_size(__pyx_v_self->native, 1);

    /* "PyTorch.pyx":1592
 *             size0 = THDoubleTensor_size(self.native, 0)
 *             size1 = THDoubleTensor_size(self.native, 1)
 *             res = ''             # <<<<<<<<<<<<<<
 *             for r in range(size0):
 *                 thisline = ''
 */
    __Pyx_INCREF(__pyx_kp_s__7);
    __pyx_v_res = __pyx_kp_s__7;

    /* "PyTorch.pyx":1593
 *             size1 = THDoubleTensor_size(self.native, 1)
 *             res = ''
 *             for r in range(size0):             # <<<<<<<<<<<<<<
 *                 thisline = ''
 *                 for c in range(size1):
 */
    __pyx_t_1 = __pyx_v_size0;
    for (__pyx_t_2 = 0; __pyx_t_2 < __pyx_t_1; __pyx_t_2+=1) {
      __pyx_v_r = __pyx_t_2;

      /* "PyTorch.pyx":1594
 *             res = ''
 *             for r in range(size0):
 *                 thisline = ''             # <<<<<<<<<<<<<<
 *                 for c in range(size1):
 *                     if c > 0:
 */
      __Pyx_INCREF(__pyx_kp_s__7);
      __Pyx_XDECREF_SET(__pyx_v_thisline, __pyx_kp_s__7);

      /* "PyTorch.pyx":1595
 *             for r in range(size0):
 *                 thisline = ''
 *                 for c in range(size1):             # <<<<<<<<<<<<<<
 *                     if c > 0:
 *                         thisline += ' '
 */
      __pyx_t_3 = __pyx_v_size1;
      for (__pyx_t_4 = 0; __pyx_t_4 < __pyx_t_3; __pyx_t_4+=1) {
        __pyx_v_c = __pyx_t_4;

        /* "PyTorch.pyx":1596
 *                 thisline = ''
 *                 for c in range(size1):
 *                     if c > 0:             # <<<<<<<<<<<<<<
 *                         thisline += ' '
 * 
 */
        __pyx_t_5 = ((__pyx_v_c > 0) != 0);
        if (__pyx_t_5) {

          /* "PyTorch.pyx":1597
 *                 for c in range(size1):
 *                     if c > 0:
 *                         thisline += ' '             # <<<<<<<<<<<<<<
 * 
 *                     thisline += str(self.get2d(r,c),)
 */
          __pyx_t_6 = PyNumber_InPlaceAdd(__pyx_v_thisline, __pyx_kp_s__8); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1597, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_6);
          __Pyx_DECREF_SET(__pyx_v_thisline, __pyx_t_6);
          __pyx_t_6 = 0;

          /* "PyTorch.pyx":1596
 *                 thisline = ''
 *                 for c in range(size1):
 *                     if c > 0:             # <<<<<<<<<<<<<<
 *                         thisline += ' '
 * 
 */
        }

        /* "PyTorch.pyx":1599
 *                         thisline += ' '
 * 
 *                     thisline += str(self.get2d(r,c),)             # <<<<<<<<<<<<<<
 * 
 *                 res += thisline + '\n'
 */
        __pyx_t_6 = PyFloat_FromDouble(((struct __pyx_vtabstruct_7PyTorch__DoubleTensor *)__pyx_v_self->__pyx_vtab)->get2d(__pyx_v_self, __pyx_v_r, __pyx_v_c, 0)); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1599, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __pyx_t_7 = PyTuple_New(1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1599, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        __Pyx_GIVEREF(__pyx_t_6);
        PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_6);
        __pyx_t_6 = 0;
        __pyx_t_6 = __Pyx_PyObject_Call(((PyObject *)(&PyString_Type)), __pyx_t_7, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1599, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        __pyx_t_7 = PyNumber_InPlaceAdd(__pyx_v_thisline, __pyx_t_6); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1599, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_DECREF_SET(__pyx_v_thisline, __pyx_t_7);
        __pyx_t_7 = 0;
      }

      /* "PyTorch.pyx":1601
 *                     thisline += str(self.get2d(r,c),)
 * 
 *                 res += thisline + '\n'             # <<<<<<<<<<<<<<
 *             if show_size:
 *                 res += '[torch.DoubleTensor of size ' + ('%.0f' % size0) + 'x' + str(size1) + ']\n'
 */
      __pyx_t_7 = PyNumber_Add(__pyx_v_thisline, __pyx_kp_s__9); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1601, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __pyx_t_6 = PyNumber_InPlaceAdd(__pyx_v_res, __pyx_t_7); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1601, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_DECREF_SET(__pyx_v_res, __pyx_t_6);
      __pyx_t_6 = 0;
    }

    /* "PyTorch.pyx":1602
 * 
 *                 res += thisline + '\n'
 *             if show_size:             # <<<<<<<<<<<<<<
 *                 res += '[torch.DoubleTensor of size ' + ('%.0f' % size0) + 'x' + str(size1) + ']\n'
 *             return res
 */
    __pyx_t_5 = __Pyx_PyObject_IsTrue(__pyx_v_show_size); if (unlikely(__pyx_t_5 < 0)) __PYX_ERR(0, 1602, __pyx_L1_error)
    if (__pyx_t_5) {

      /* "PyTorch.pyx":1603
 *                 res += thisline + '\n'
 *             if show_size:
 *                 res += '[torch.DoubleTensor of size ' + ('%.0f' % size0) + 'x' + str(size1) + ']\n'             # <<<<<<<<<<<<<<
 *             return res
 *         elif dims == 1:
 */
      __pyx_t_6 = __Pyx_PyInt_From_int(__pyx_v_size0); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1603, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __pyx_t_7 = __Pyx_PyString_Format(__pyx_kp_s_0f, __pyx_t_6); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1603, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_6 = PyNumber_Add(__pyx_kp_s_torch_DoubleTensor_of_size, __pyx_t_7); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1603, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __pyx_t_7 = PyNumber_Add(__pyx_t_6, __pyx_n_s_x); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1603, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_6 = __Pyx_PyInt_From_int(__pyx_v_size1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1603, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __pyx_t_8 = PyTuple_New(1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1603, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_GIVEREF(__pyx_t_6);
      PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_t_6);
      __pyx_t_6 = 0;
      __pyx_t_6 = __Pyx_PyObject_Call(((PyObject *)(&PyString_Type)), __pyx_t_8, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1603, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_8 = PyNumber_Add(__pyx_t_7, __pyx_t_6); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1603, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_6 = PyNumber_Add(__pyx_t_8, __pyx_kp_s__10); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1603, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_8 = PyNumber_InPlaceAdd(__pyx_v_res, __pyx_t_6); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1603, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_DECREF_SET(__pyx_v_res, __pyx_t_8);
      __pyx_t_8 = 0;

      /* "PyTorch.pyx":1602
 * 
 *                 res += thisline + '\n'
 *             if show_size:             # <<<<<<<<<<<<<<
 *                 res += '[torch.DoubleTensor of size ' + ('%.0f' % size0) + 'x' + str(size1) + ']\n'
 *             return res
 */
    }

    /* "PyTorch.pyx":1604
 *             if show_size:
 *                 res += '[torch.DoubleTensor of size ' + ('%.0f' % size0) + 'x' + str(size1) + ']\n'
 *             return res             # <<<<<<<<<<<<<<
 *         elif dims == 1:
 *             size0 = THDoubleTensor_size(self.native, 0)
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(__pyx_v_res);
    __pyx_r = __pyx_v_res;
    goto __pyx_L0;

    /* "PyTorch.pyx":1589
 *         if dims == 0:
 *             return '[torch.DoubleTensor with no dimension]\n'
 *         elif dims == 2:             # <<<<<<<<<<<<<<
 *             size0 = THDoubleTensor_size(self.native, 0)
 *             size1 = THDoubleTensor_size(self.native, 1)
 */
    break;

    /* "PyTorch.pyx":1605
 *                 res += '[torch.DoubleTensor of size ' + ('%.0f' % size0) + 'x' + str(size1) + ']\n'
 *             return res
 *         elif dims == 1:             # <<<<<<<<<<<<<<
 *             size0 = THDoubleTensor_size(self.native, 0)
 *             res = ''
 */
    case 1:

    /* "PyTorch.pyx":1606
 *             return res
 *         elif dims == 1:
 *             size0 = THDoubleTensor_size(self.native, 0)             # <<<<<<<<<<<<<<
 *             res = ''
 *             thisline = ''
 */
    __pyx_v_size0 = THDoubleTensor_size(__pyx_v_self->native, 0);

    /* "PyTorch.pyx":1607
 *         elif dims == 1:
 *             size0 = THDoubleTensor_size(self.native, 0)
 *             res = ''             # <<<<<<<<<<<<<<
 *             thisline = ''
 *             for c in range(size0):
 */
    __Pyx_INCREF(__pyx_kp_s__7);
    __pyx_v_res = __pyx_kp_s__7;

    /* "PyTorch.pyx":1608
 *             size0 = THDoubleTensor_size(self.native, 0)
 *             res = ''
 *             thisline = ''             # <<<<<<<<<<<<<<
 *             for c in range(size0):
 *                 if c > 0:
 */
    __Pyx_INCREF(__pyx_kp_s__7);
    __pyx_v_thisline = __pyx_kp_s__7;

    /* "PyTorch.pyx":1609
 *             res = ''
 *             thisline = ''
 *             for c in range(size0):             # <<<<<<<<<<<<<<
 *                 if c > 0:
 *                     thisline += ' '
 */
    __pyx_t_1 = __pyx_v_size0;
    for (__pyx_t_2 = 0; __pyx_t_2 < __pyx_t_1; __pyx_t_2+=1) {
      __pyx_v_c = __pyx_t_2;

      /* "PyTorch.pyx":1610
 *             thisline = ''
 *             for c in range(size0):
 *                 if c > 0:             # <<<<<<<<<<<<<<
 *                     thisline += ' '
 * 
 */
      __pyx_t_5 = ((__pyx_v_c > 0) != 0);
      if (__pyx_t_5) {

        /* "PyTorch.pyx":1611
 *             for c in range(size0):
 *                 if c > 0:
 *                     thisline += ' '             # <<<<<<<<<<<<<<
 * 
 *                 thisline += str(self.get1d(c))
 */
        __pyx_t_8 = PyNumber_InPlaceAdd(__pyx_v_thisline, __pyx_kp_s__8); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1611, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        __Pyx_DECREF_SET(__pyx_v_thisline, __pyx_t_8);
        __pyx_t_8 = 0;

        /* "PyTorch.pyx":1610
 *             thisline = ''
 *             for c in range(size0):
 *                 if c > 0:             # <<<<<<<<<<<<<<
 *                     thisline += ' '
 * 
 */
      }

      /* "PyTorch.pyx":1613
 *                     thisline += ' '
 * 
 *                 thisline += str(self.get1d(c))             # <<<<<<<<<<<<<<
 * 
 *             res += thisline + '\n'
 */
      __pyx_t_8 = PyFloat_FromDouble(((struct __pyx_vtabstruct_7PyTorch__DoubleTensor *)__pyx_v_self->__pyx_vtab)->get1d(__pyx_v_self, __pyx_v_c, 0)); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1613, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_6 = PyTuple_New(1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1613, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_GIVEREF(__pyx_t_8);
      PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_8);
      __pyx_t_8 = 0;
      __pyx_t_8 = __Pyx_PyObject_Call(((PyObject *)(&PyString_Type)), __pyx_t_6, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1613, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_6 = PyNumber_InPlaceAdd(__pyx_v_thisline, __pyx_t_8); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1613, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_DECREF_SET(__pyx_v_thisline, __pyx_t_6);
      __pyx_t_6 = 0;
    }

    /* "PyTorch.pyx":1615
 *                 thisline += str(self.get1d(c))
 * 
 *             res += thisline + '\n'             # <<<<<<<<<<<<<<
 *             if show_size:
 *                 res += '[torch.DoubleTensor of size ' + str(size0) + ']\n'
 */
    __pyx_t_6 = PyNumber_Add(__pyx_v_thisline, __pyx_kp_s__9); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1615, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_8 = PyNumber_InPlaceAdd(__pyx_v_res, __pyx_t_6); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1615, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_DECREF_SET(__pyx_v_res, __pyx_t_8);
    __pyx_t_8 = 0;

    /* "PyTorch.pyx":1616
 * 
 *             res += thisline + '\n'
 *             if show_size:             # <<<<<<<<<<<<<<
 *                 res += '[torch.DoubleTensor of size ' + str(size0) + ']\n'
 *             return res
 */
    __pyx_t_5 = __Pyx_PyObject_IsTrue(__pyx_v_show_size); if (unlikely(__pyx_t_5 < 0)) __PYX_ERR(0, 1616, __pyx_L1_error)
    if (__pyx_t_5) {

      /* "PyTorch.pyx":1617
 *             res += thisline + '\n'
 *             if show_size:
 *                 res += '[torch.DoubleTensor of size ' + str(size0) + ']\n'             # <<<<<<<<<<<<<<
 *             return res
 *         elif dims == 3:
 */
      __pyx_t_8 = __Pyx_PyInt_From_int(__pyx_v_size0); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1617, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_6 = PyTuple_New(1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1617, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_GIVEREF(__pyx_t_8);
      PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_8);
      __pyx_t_8 = 0;
      __pyx_t_8 = __Pyx_PyObject_Call(((PyObject *)(&PyString_Type)), __pyx_t_6, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1617, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_6 = PyNumber_Add(__pyx_kp_s_torch_DoubleTensor_of_size, __pyx_t_8); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1617, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_8 = PyNumber_Add(__pyx_t_6, __pyx_kp_s__10); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1617, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_6 = PyNumber_InPlaceAdd(__pyx_v_res, __pyx_t_8); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1617, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_DECREF_SET(__pyx_v_res, __pyx_t_6);
      __pyx_t_6 = 0;

      /* "PyTorch.pyx":1616
 * 
 *             res += thisline + '\n'
 *             if show_size:             # <<<<<<<<<<<<<<
 *                 res += '[torch.DoubleTensor of size ' + str(size0) + ']\n'
 *             return res
 */
    }

    /* "PyTorch.pyx":1618
 *             if show_size:
 *                 res += '[torch.DoubleTensor of size ' + str(size0) + ']\n'
 *             return res             # <<<<<<<<<<<<<<
 *         elif dims == 3:
 *             res = ''
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(__pyx_v_res);
    __pyx_r = __pyx_v_res;
    goto __pyx_L0;

    /* "PyTorch.pyx":1605
 *                 res += '[torch.DoubleTensor of size ' + ('%.0f' % size0) + 'x' + str(size1) + ']\n'
 *             return res
 *         elif dims == 1:             # <<<<<<<<<<<<<<
 *             size0 = THDoubleTensor_size(self.native, 0)
 *             res = ''
 */
    break;

    /* "PyTorch.pyx":1619
 *                 res += '[torch.DoubleTensor of size ' + str(size0) + ']\n'
 *             return res
 *         elif dims == 3:             # <<<<<<<<<<<<<<
 *             res = ''
 *             for d in range(self.size()[0]):
 */
    case 3:

    /* "PyTorch.pyx":1620
 *             return res
 *         elif dims == 3:
 *             res = ''             # <<<<<<<<<<<<<<
 *             for d in range(self.size()[0]):
 *                 res += '(' + str(d) + ',.,.) =\n'
 */
    __Pyx_INCREF(__pyx_kp_s__7);
    __pyx_v_res = __pyx_kp_s__7;

    /* "PyTorch.pyx":1621
 *         elif dims == 3:
 *             res = ''
 *             for d in range(self.size()[0]):             # <<<<<<<<<<<<<<
 *                 res += '(' + str(d) + ',.,.) =\n'
 *                 res += self[d].as_string(show_size=False)
 */
    __pyx_t_8 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_size); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1621, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_7 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_8))) {
      __pyx_t_7 = PyMethod_GET_SELF(__pyx_t_8);
      if (likely(__pyx_t_7)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_8);
        __Pyx_INCREF(__pyx_t_7);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_8, function);
      }
    }
    if (__pyx_t_7) {
      __pyx_t_6 = __Pyx_PyObject_CallOneArg(__pyx_t_8, __pyx_t_7); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1621, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    } else {
      __pyx_t_6 = __Pyx_PyObject_CallNoArg(__pyx_t_8); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1621, __pyx_L1_error)
    }
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_6, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1621, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_6 = PyTuple_New(1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1621, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_GIVEREF(__pyx_t_8);
    PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_8);
    __pyx_t_8 = 0;
    __pyx_t_8 = __Pyx_PyObject_Call(__pyx_builtin_range, __pyx_t_6, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1621, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    if (likely(PyList_CheckExact(__pyx_t_8)) || PyTuple_CheckExact(__pyx_t_8)) {
      __pyx_t_6 = __pyx_t_8; __Pyx_INCREF(__pyx_t_6); __pyx_t_9 = 0;
      __pyx_t_10 = NULL;
    } else {
      __pyx_t_9 = -1; __pyx_t_6 = PyObject_GetIter(__pyx_t_8); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1621, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __pyx_t_10 = Py_TYPE(__pyx_t_6)->tp_iternext; if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 1621, __pyx_L1_error)
    }
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    for (;;) {
      if (likely(!__pyx_t_10)) {
        if (likely(PyList_CheckExact(__pyx_t_6))) {
          if (__pyx_t_9 >= PyList_GET_SIZE(__pyx_t_6)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_8 = PyList_GET_ITEM(__pyx_t_6, __pyx_t_9); __Pyx_INCREF(__pyx_t_8); __pyx_t_9++; if (unlikely(0 < 0)) __PYX_ERR(0, 1621, __pyx_L1_error)
          #else
          __pyx_t_8 = PySequence_ITEM(__pyx_t_6, __pyx_t_9); __pyx_t_9++; if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1621, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_8);
          #endif
        } else {
          if (__pyx_t_9 >= PyTuple_GET_SIZE(__pyx_t_6)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_8 = PyTuple_GET_ITEM(__pyx_t_6, __pyx_t_9); __Pyx_INCREF(__pyx_t_8); __pyx_t_9++; if (unlikely(0 < 0)) __PYX_ERR(0, 1621, __pyx_L1_error)
          #else
          __pyx_t_8 = PySequence_ITEM(__pyx_t_6, __pyx_t_9); __pyx_t_9++; if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1621, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_8);
          #endif
        }
      } else {
        __pyx_t_8 = __pyx_t_10(__pyx_t_6);
        if (unlikely(!__pyx_t_8)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(exc_type == PyExc_StopIteration || PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 1621, __pyx_L1_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_8);
      }
      __Pyx_XDECREF_SET(__pyx_v_d, __pyx_t_8);
      __pyx_t_8 = 0;

      /* "PyTorch.pyx":1622
 *             res = ''
 *             for d in range(self.size()[0]):
 *                 res += '(' + str(d) + ',.,.) =\n'             # <<<<<<<<<<<<<<
 *                 res += self[d].as_string(show_size=False)
 *             res += '\ntorch.DoubleTensor of size '
 */
      __pyx_t_8 = PyTuple_New(1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1622, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_INCREF(__pyx_v_d);
      __Pyx_GIVEREF(__pyx_v_d);
      PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_v_d);
      __pyx_t_7 = __Pyx_PyObject_Call(((PyObject *)(&PyString_Type)), __pyx_t_8, NULL); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1622, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_8 = PyNumber_Add(__pyx_kp_s__11, __pyx_t_7); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1622, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __pyx_t_7 = PyNumber_Add(__pyx_t_8, __pyx_kp_s__12); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1622, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_8 = PyNumber_InPlaceAdd(__pyx_v_res, __pyx_t_7); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1622, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_DECREF_SET(__pyx_v_res, __pyx_t_8);
      __pyx_t_8 = 0;

      /* "PyTorch.pyx":1623
 *             for d in range(self.size()[0]):
 *                 res += '(' + str(d) + ',.,.) =\n'
 *                 res += self[d].as_string(show_size=False)             # <<<<<<<<<<<<<<
 *             res += '\ntorch.DoubleTensor of size '
 *             first = True
 */
      __pyx_t_8 = PyObject_GetItem(((PyObject *)__pyx_v_self), __pyx_v_d); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1623, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_t_8, __pyx_n_s_as_string); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1623, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_8 = PyDict_New(); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1623, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      if (PyDict_SetItem(__pyx_t_8, __pyx_n_s_show_size, Py_False) < 0) __PYX_ERR(0, 1623, __pyx_L1_error)
      __pyx_t_11 = __Pyx_PyObject_Call(__pyx_t_7, __pyx_empty_tuple, __pyx_t_8); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 1623, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_11);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_8 = PyNumber_InPlaceAdd(__pyx_v_res, __pyx_t_11); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1623, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
      __Pyx_DECREF_SET(__pyx_v_res, __pyx_t_8);
      __pyx_t_8 = 0;

      /* "PyTorch.pyx":1621
 *         elif dims == 3:
 *             res = ''
 *             for d in range(self.size()[0]):             # <<<<<<<<<<<<<<
 *                 res += '(' + str(d) + ',.,.) =\n'
 *                 res += self[d].as_string(show_size=False)
 */
    }
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;

    /* "PyTorch.pyx":1624
 *                 res += '(' + str(d) + ',.,.) =\n'
 *                 res += self[d].as_string(show_size=False)
 *             res += '\ntorch.DoubleTensor of size '             # <<<<<<<<<<<<<<
 *             first = True
 *             for d in self.size():
 */
    __pyx_t_6 = PyNumber_InPlaceAdd(__pyx_v_res, __pyx_kp_s_torch_DoubleTensor_of_size_2); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1624, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF_SET(__pyx_v_res, __pyx_t_6);
    __pyx_t_6 = 0;

    /* "PyTorch.pyx":1625
 *                 res += self[d].as_string(show_size=False)
 *             res += '\ntorch.DoubleTensor of size '
 *             first = True             # <<<<<<<<<<<<<<
 *             for d in self.size():
 *                if not first:
 */
    __pyx_v_first = 1;

    /* "PyTorch.pyx":1626
 *             res += '\ntorch.DoubleTensor of size '
 *             first = True
 *             for d in self.size():             # <<<<<<<<<<<<<<
 *                if not first:
 *                   res += 'x'
 */
    __pyx_t_8 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_size); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1626, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_11 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_8))) {
      __pyx_t_11 = PyMethod_GET_SELF(__pyx_t_8);
      if (likely(__pyx_t_11)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_8);
        __Pyx_INCREF(__pyx_t_11);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_8, function);
      }
    }
    if (__pyx_t_11) {
      __pyx_t_6 = __Pyx_PyObject_CallOneArg(__pyx_t_8, __pyx_t_11); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1626, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
    } else {
      __pyx_t_6 = __Pyx_PyObject_CallNoArg(__pyx_t_8); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1626, __pyx_L1_error)
    }
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    if (likely(PyList_CheckExact(__pyx_t_6)) || PyTuple_CheckExact(__pyx_t_6)) {
      __pyx_t_8 = __pyx_t_6; __Pyx_INCREF(__pyx_t_8); __pyx_t_9 = 0;
      __pyx_t_10 = NULL;
    } else {
      __pyx_t_9 = -1; __pyx_t_8 = PyObject_GetIter(__pyx_t_6); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1626, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_10 = Py_TYPE(__pyx_t_8)->tp_iternext; if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 1626, __pyx_L1_error)
    }
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    for (;;) {
      if (likely(!__pyx_t_10)) {
        if (likely(PyList_CheckExact(__pyx_t_8))) {
          if (__pyx_t_9 >= PyList_GET_SIZE(__pyx_t_8)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_6 = PyList_GET_ITEM(__pyx_t_8, __pyx_t_9); __Pyx_INCREF(__pyx_t_6); __pyx_t_9++; if (unlikely(0 < 0)) __PYX_ERR(0, 1626, __pyx_L1_error)
          #else
          __pyx_t_6 = PySequence_ITEM(__pyx_t_8, __pyx_t_9); __pyx_t_9++; if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1626, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_6);
          #endif
        } else {
          if (__pyx_t_9 >= PyTuple_GET_SIZE(__pyx_t_8)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_6 = PyTuple_GET_ITEM(__pyx_t_8, __pyx_t_9); __Pyx_INCREF(__pyx_t_6); __pyx_t_9++; if (unlikely(0 < 0)) __PYX_ERR(0, 1626, __pyx_L1_error)
          #else
          __pyx_t_6 = PySequence_ITEM(__pyx_t_8, __pyx_t_9); __pyx_t_9++; if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1626, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_6);
          #endif
        }
      } else {
        __pyx_t_6 = __pyx_t_10(__pyx_t_8);
        if (unlikely(!__pyx_t_6)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(exc_type == PyExc_StopIteration || PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 1626, __pyx_L1_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_6);
      }
      __Pyx_XDECREF_SET(__pyx_v_d, __pyx_t_6);
      __pyx_t_6 = 0;

      /* "PyTorch.pyx":1627
 *             first = True
 *             for d in self.size():
 *                if not first:             # <<<<<<<<<<<<<<
 *                   res += 'x'
 *                res += str(d)
 */
      __pyx_t_5 = ((!(__pyx_v_first != 0)) != 0);
      if (__pyx_t_5) {

        /* "PyTorch.pyx":1628
 *             for d in self.size():
 *                if not first:
 *                   res += 'x'             # <<<<<<<<<<<<<<
 *                res += str(d)
 *                first = False
 */
        __pyx_t_6 = PyNumber_InPlaceAdd(__pyx_v_res, __pyx_n_s_x); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1628, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __Pyx_DECREF_SET(__pyx_v_res, __pyx_t_6);
        __pyx_t_6 = 0;

        /* "PyTorch.pyx":1627
 *             first = True
 *             for d in self.size():
 *                if not first:             # <<<<<<<<<<<<<<
 *                   res += 'x'
 *                res += str(d)
 */
      }

      /* "PyTorch.pyx":1629
 *                if not first:
 *                   res += 'x'
 *                res += str(d)             # <<<<<<<<<<<<<<
 *                first = False
 *             res += ']'
 */
      __pyx_t_6 = PyTuple_New(1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1629, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_INCREF(__pyx_v_d);
      __Pyx_GIVEREF(__pyx_v_d);
      PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_v_d);
      __pyx_t_11 = __Pyx_PyObject_Call(((PyObject *)(&PyString_Type)), __pyx_t_6, NULL); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 1629, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_11);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_6 = PyNumber_InPlaceAdd(__pyx_v_res, __pyx_t_11); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1629, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
      __Pyx_DECREF_SET(__pyx_v_res, __pyx_t_6);
      __pyx_t_6 = 0;

      /* "PyTorch.pyx":1630
 *                   res += 'x'
 *                res += str(d)
 *                first = False             # <<<<<<<<<<<<<<
 *             res += ']'
 *             return res
 */
      __pyx_v_first = 0;

      /* "PyTorch.pyx":1626
 *             res += '\ntorch.DoubleTensor of size '
 *             first = True
 *             for d in self.size():             # <<<<<<<<<<<<<<
 *                if not first:
 *                   res += 'x'
 */
    }
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;

    /* "PyTorch.pyx":1631
 *                res += str(d)
 *                first = False
 *             res += ']'             # <<<<<<<<<<<<<<
 *             return res
 *         else:
 */
    __pyx_t_8 = PyNumber_InPlaceAdd(__pyx_v_res, __pyx_kp_s__13); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1631, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF_SET(__pyx_v_res, __pyx_t_8);
    __pyx_t_8 = 0;

    /* "PyTorch.pyx":1632
 *                first = False
 *             res += ']'
 *             return res             # <<<<<<<<<<<<<<
 *         else:
 *             raise Exception("Not implemented: dims > 2")
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(__pyx_v_res);
    __pyx_r = __pyx_v_res;
    goto __pyx_L0;

    /* "PyTorch.pyx":1619
 *                 res += '[torch.DoubleTensor of size ' + str(size0) + ']\n'
 *             return res
 *         elif dims == 3:             # <<<<<<<<<<<<<<
 *             res = ''
 *             for d in range(self.size()[0]):
 */
    break;
    default:

    /* "PyTorch.pyx":1634
 *             return res
 *         else:
 *             raise Exception("Not implemented: dims > 2")             # <<<<<<<<<<<<<<
 * 
 *     def __getitem__(_DoubleTensor self, int index):
 */
    __pyx_t_8 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_tuple__31, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1634, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_Raise(__pyx_t_8, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __PYX_ERR(0, 1634, __pyx_L1_error)
    break;
  }

  /* "PyTorch.pyx":1582
 *         return self.as_string(self)
 * 
 *     def as_string(_DoubleTensor self, show_size=True):             # <<<<<<<<<<<<<<
 *         # assume 2d matrix for now
 *         cdef int size0
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_11);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.as_string", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_res);
  __Pyx_XDECREF(__pyx_v_thisline);
  __Pyx_XDECREF(__pyx_v_d);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1636
 *             raise Exception("Not implemented: dims > 2")
 * 
 *     def __getitem__(_DoubleTensor self, int index):             # <<<<<<<<<<<<<<
 *         if self.dims() == 1:
 *             return self.get1d(index)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_29__getitem__(PyObject *__pyx_v_self, PyObject *__pyx_arg_index); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_29__getitem__(PyObject *__pyx_v_self, PyObject *__pyx_arg_index) {
  int __pyx_v_index;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__getitem__ (wrapper)", 0);
  assert(__pyx_arg_index); {
    __pyx_v_index = __Pyx_PyInt_As_int(__pyx_arg_index); if (unlikely((__pyx_v_index == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1636, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._DoubleTensor.__getitem__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_28__getitem__(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self), ((int)__pyx_v_index));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_28__getitem__(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, int __pyx_v_index) {
  struct THDoubleTensor *__pyx_v_res;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  struct __pyx_opt_args_7PyTorch__DoubleTensor_fromNative __pyx_t_3;
  __Pyx_RefNannySetupContext("__getitem__", 0);

  /* "PyTorch.pyx":1637
 * 
 *     def __getitem__(_DoubleTensor self, int index):
 *         if self.dims() == 1:             # <<<<<<<<<<<<<<
 *             return self.get1d(index)
 *         cdef THDoubleTensor *res = THDoubleTensor_newSelect(self.native, 0, index)
 */
  __pyx_t_1 = ((((struct __pyx_vtabstruct_7PyTorch__DoubleTensor *)__pyx_v_self->__pyx_vtab)->dims(__pyx_v_self, 0) == 1) != 0);
  if (__pyx_t_1) {

    /* "PyTorch.pyx":1638
 *     def __getitem__(_DoubleTensor self, int index):
 *         if self.dims() == 1:
 *             return self.get1d(index)             # <<<<<<<<<<<<<<
 *         cdef THDoubleTensor *res = THDoubleTensor_newSelect(self.native, 0, index)
 *         return _DoubleTensor_fromNative(res, False)
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_2 = PyFloat_FromDouble(((struct __pyx_vtabstruct_7PyTorch__DoubleTensor *)__pyx_v_self->__pyx_vtab)->get1d(__pyx_v_self, __pyx_v_index, 0)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1638, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_r = __pyx_t_2;
    __pyx_t_2 = 0;
    goto __pyx_L0;

    /* "PyTorch.pyx":1637
 * 
 *     def __getitem__(_DoubleTensor self, int index):
 *         if self.dims() == 1:             # <<<<<<<<<<<<<<
 *             return self.get1d(index)
 *         cdef THDoubleTensor *res = THDoubleTensor_newSelect(self.native, 0, index)
 */
  }

  /* "PyTorch.pyx":1639
 *         if self.dims() == 1:
 *             return self.get1d(index)
 *         cdef THDoubleTensor *res = THDoubleTensor_newSelect(self.native, 0, index)             # <<<<<<<<<<<<<<
 *         return _DoubleTensor_fromNative(res, False)
 * 
 */
  __pyx_v_res = THDoubleTensor_newSelect(__pyx_v_self->native, 0, __pyx_v_index);

  /* "PyTorch.pyx":1640
 *             return self.get1d(index)
 *         cdef THDoubleTensor *res = THDoubleTensor_newSelect(self.native, 0, index)
 *         return _DoubleTensor_fromNative(res, False)             # <<<<<<<<<<<<<<
 * 
 *     def __setitem__(_DoubleTensor self, int index, double value):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_3.__pyx_n = 1;
  __pyx_t_3.retain = Py_False;
  __pyx_t_2 = __pyx_f_7PyTorch__DoubleTensor_fromNative(__pyx_v_res, &__pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1640, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":1636
 *             raise Exception("Not implemented: dims > 2")
 * 
 *     def __getitem__(_DoubleTensor self, int index):             # <<<<<<<<<<<<<<
 *         if self.dims() == 1:
 *             return self.get1d(index)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.__getitem__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1642
 *         return _DoubleTensor_fromNative(res, False)
 * 
 *     def __setitem__(_DoubleTensor self, int index, double value):             # <<<<<<<<<<<<<<
 *         if self.dims() == 1:
 *             self.set1d(index, value)
 */

/* Python wrapper */
static int __pyx_pw_7PyTorch_13_DoubleTensor_31__setitem__(PyObject *__pyx_v_self, PyObject *__pyx_arg_index, PyObject *__pyx_arg_value); /*proto*/
static int __pyx_pw_7PyTorch_13_DoubleTensor_31__setitem__(PyObject *__pyx_v_self, PyObject *__pyx_arg_index, PyObject *__pyx_arg_value) {
  int __pyx_v_index;
  double __pyx_v_value;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__setitem__ (wrapper)", 0);
  assert(__pyx_arg_index); {
    __pyx_v_index = __Pyx_PyInt_As_int(__pyx_arg_index); if (unlikely((__pyx_v_index == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1642, __pyx_L3_error)
  }
  assert(__pyx_arg_value); {
    __pyx_v_value = __pyx_PyFloat_AsDouble(__pyx_arg_value); if (unlikely((__pyx_v_value == (double)-1) && PyErr_Occurred())) __PYX_ERR(0, 1642, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._DoubleTensor.__setitem__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return -1;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_30__setitem__(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self), ((int)__pyx_v_index), ((double)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_7PyTorch_13_DoubleTensor_30__setitem__(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, int __pyx_v_index, double __pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("__setitem__", 0);

  /* "PyTorch.pyx":1643
 * 
 *     def __setitem__(_DoubleTensor self, int index, double value):
 *         if self.dims() == 1:             # <<<<<<<<<<<<<<
 *             self.set1d(index, value)
 *         else:
 */
  __pyx_t_1 = ((((struct __pyx_vtabstruct_7PyTorch__DoubleTensor *)__pyx_v_self->__pyx_vtab)->dims(__pyx_v_self, 0) == 1) != 0);
  if (__pyx_t_1) {

    /* "PyTorch.pyx":1644
 *     def __setitem__(_DoubleTensor self, int index, double value):
 *         if self.dims() == 1:
 *             self.set1d(index, value)             # <<<<<<<<<<<<<<
 *         else:
 *             raise Exception("not implemented")
 */
    __pyx_t_2 = ((struct __pyx_vtabstruct_7PyTorch__DoubleTensor *)__pyx_v_self->__pyx_vtab)->set1d(__pyx_v_self, __pyx_v_index, __pyx_v_value, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1644, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

    /* "PyTorch.pyx":1643
 * 
 *     def __setitem__(_DoubleTensor self, int index, double value):
 *         if self.dims() == 1:             # <<<<<<<<<<<<<<
 *             self.set1d(index, value)
 *         else:
 */
    goto __pyx_L3;
  }

  /* "PyTorch.pyx":1646
 *             self.set1d(index, value)
 *         else:
 *             raise Exception("not implemented")             # <<<<<<<<<<<<<<
 * 
 *     def fill(_DoubleTensor self, double value):
 */
  /*else*/ {
    __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_tuple__32, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1646, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(0, 1646, __pyx_L1_error)
  }
  __pyx_L3:;

  /* "PyTorch.pyx":1642
 *         return _DoubleTensor_fromNative(res, False)
 * 
 *     def __setitem__(_DoubleTensor self, int index, double value):             # <<<<<<<<<<<<<<
 *         if self.dims() == 1:
 *             self.set1d(index, value)
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.__setitem__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1648
 *             raise Exception("not implemented")
 * 
 *     def fill(_DoubleTensor self, double value):             # <<<<<<<<<<<<<<
 *         THDoubleTensor_fill(self.native, value)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_33fill(PyObject *__pyx_v_self, PyObject *__pyx_arg_value); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_33fill(PyObject *__pyx_v_self, PyObject *__pyx_arg_value) {
  double __pyx_v_value;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("fill (wrapper)", 0);
  assert(__pyx_arg_value); {
    __pyx_v_value = __pyx_PyFloat_AsDouble(__pyx_arg_value); if (unlikely((__pyx_v_value == (double)-1) && PyErr_Occurred())) __PYX_ERR(0, 1648, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._DoubleTensor.fill", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_32fill(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self), ((double)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_32fill(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, double __pyx_v_value) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("fill", 0);

  /* "PyTorch.pyx":1649
 * 
 *     def fill(_DoubleTensor self, double value):
 *         THDoubleTensor_fill(self.native, value)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THDoubleTensor_fill(__pyx_v_self->native, __pyx_v_value);

  /* "PyTorch.pyx":1650
 *     def fill(_DoubleTensor self, double value):
 *         THDoubleTensor_fill(self.native, value)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def sum(_DoubleTensor self):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1648
 *             raise Exception("not implemented")
 * 
 *     def fill(_DoubleTensor self, double value):             # <<<<<<<<<<<<<<
 *         THDoubleTensor_fill(self.native, value)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1652
 *         return self
 * 
 *     def sum(_DoubleTensor self):             # <<<<<<<<<<<<<<
 *         cdef double result = THDoubleTensor_sumall(self.native)
 *         return result
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_35sum(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_35sum(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("sum (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_34sum(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_34sum(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self) {
  double __pyx_v_result;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("sum", 0);

  /* "PyTorch.pyx":1653
 * 
 *     def sum(_DoubleTensor self):
 *         cdef double result = THDoubleTensor_sumall(self.native)             # <<<<<<<<<<<<<<
 *         return result
 * 
 */
  __pyx_v_result = THDoubleTensor_sumall(__pyx_v_self->native);

  /* "PyTorch.pyx":1654
 *     def sum(_DoubleTensor self):
 *         cdef double result = THDoubleTensor_sumall(self.native)
 *         return result             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyFloat_FromDouble(__pyx_v_result); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1654, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":1652
 *         return self
 * 
 *     def sum(_DoubleTensor self):             # <<<<<<<<<<<<<<
 *         cdef double result = THDoubleTensor_sumall(self.native)
 *         return result
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.sum", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1658
 * 
 * 
 *     def itanh(_DoubleTensor self):             # <<<<<<<<<<<<<<
 *         THDoubleTensor_tanh(self.native, self.native)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_37itanh(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_37itanh(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("itanh (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_36itanh(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_36itanh(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("itanh", 0);

  /* "PyTorch.pyx":1659
 * 
 *     def itanh(_DoubleTensor self):
 *         THDoubleTensor_tanh(self.native, self.native)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THDoubleTensor_tanh(__pyx_v_self->native, __pyx_v_self->native);

  /* "PyTorch.pyx":1660
 *     def itanh(_DoubleTensor self):
 *         THDoubleTensor_tanh(self.native, self.native)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def isigmoid(_DoubleTensor self):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1658
 * 
 * 
 *     def itanh(_DoubleTensor self):             # <<<<<<<<<<<<<<
 *         THDoubleTensor_tanh(self.native, self.native)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1662
 *         return self
 * 
 *     def isigmoid(_DoubleTensor self):             # <<<<<<<<<<<<<<
 *         THDoubleTensor_sigmoid(self.native, self.native)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_39isigmoid(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_39isigmoid(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("isigmoid (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_38isigmoid(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_38isigmoid(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("isigmoid", 0);

  /* "PyTorch.pyx":1663
 * 
 *     def isigmoid(_DoubleTensor self):
 *         THDoubleTensor_sigmoid(self.native, self.native)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THDoubleTensor_sigmoid(__pyx_v_self->native, __pyx_v_self->native);

  /* "PyTorch.pyx":1664
 *     def isigmoid(_DoubleTensor self):
 *         THDoubleTensor_sigmoid(self.native, self.native)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def icinv(_DoubleTensor self):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1662
 *         return self
 * 
 *     def isigmoid(_DoubleTensor self):             # <<<<<<<<<<<<<<
 *         THDoubleTensor_sigmoid(self.native, self.native)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1666
 *         return self
 * 
 *     def icinv(_DoubleTensor self):             # <<<<<<<<<<<<<<
 *         THDoubleTensor_cinv(self.native, self.native)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_41icinv(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_41icinv(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("icinv (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_40icinv(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_40icinv(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("icinv", 0);

  /* "PyTorch.pyx":1667
 * 
 *     def icinv(_DoubleTensor self):
 *         THDoubleTensor_cinv(self.native, self.native)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THDoubleTensor_cinv(__pyx_v_self->native, __pyx_v_self->native);

  /* "PyTorch.pyx":1668
 *     def icinv(_DoubleTensor self):
 *         THDoubleTensor_cinv(self.native, self.native)
 *         return self             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1666
 *         return self
 * 
 *     def icinv(_DoubleTensor self):             # <<<<<<<<<<<<<<
 *         THDoubleTensor_cinv(self.native, self.native)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1671
 * 
 * 
 *     def tanh(_DoubleTensor self):             # <<<<<<<<<<<<<<
 *         cdef _DoubleTensor res = _DoubleTensor.new()
 *         THDoubleTensor_tanh(res.native, self.native)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_43tanh(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_43tanh(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("tanh (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_42tanh(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_42tanh(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self) {
  struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_res = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("tanh", 0);

  /* "PyTorch.pyx":1672
 * 
 *     def tanh(_DoubleTensor self):
 *         cdef _DoubleTensor res = _DoubleTensor.new()             # <<<<<<<<<<<<<<
 *         THDoubleTensor_tanh(res.native, self.native)
 *         return res
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7PyTorch__DoubleTensor), __pyx_n_s_new); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1672, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1672, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1672, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_7PyTorch__DoubleTensor))))) __PYX_ERR(0, 1672, __pyx_L1_error)
  __pyx_v_res = ((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":1673
 *     def tanh(_DoubleTensor self):
 *         cdef _DoubleTensor res = _DoubleTensor.new()
 *         THDoubleTensor_tanh(res.native, self.native)             # <<<<<<<<<<<<<<
 *         return res
 * 
 */
  THDoubleTensor_tanh(__pyx_v_res->native, __pyx_v_self->native);

  /* "PyTorch.pyx":1674
 *         cdef _DoubleTensor res = _DoubleTensor.new()
 *         THDoubleTensor_tanh(res.native, self.native)
 *         return res             # <<<<<<<<<<<<<<
 * 
 *     def sigmoid(_DoubleTensor self):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = ((PyObject *)__pyx_v_res);
  goto __pyx_L0;

  /* "PyTorch.pyx":1671
 * 
 * 
 *     def tanh(_DoubleTensor self):             # <<<<<<<<<<<<<<
 *         cdef _DoubleTensor res = _DoubleTensor.new()
 *         THDoubleTensor_tanh(res.native, self.native)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.tanh", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1676
 *         return res
 * 
 *     def sigmoid(_DoubleTensor self):             # <<<<<<<<<<<<<<
 *         cdef _DoubleTensor res = _DoubleTensor.new()
 *         THDoubleTensor_sigmoid(res.native, self.native)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_45sigmoid(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_45sigmoid(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("sigmoid (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_44sigmoid(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_44sigmoid(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self) {
  struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_res = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("sigmoid", 0);

  /* "PyTorch.pyx":1677
 * 
 *     def sigmoid(_DoubleTensor self):
 *         cdef _DoubleTensor res = _DoubleTensor.new()             # <<<<<<<<<<<<<<
 *         THDoubleTensor_sigmoid(res.native, self.native)
 *         return res
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7PyTorch__DoubleTensor), __pyx_n_s_new); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1677, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1677, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1677, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_7PyTorch__DoubleTensor))))) __PYX_ERR(0, 1677, __pyx_L1_error)
  __pyx_v_res = ((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":1678
 *     def sigmoid(_DoubleTensor self):
 *         cdef _DoubleTensor res = _DoubleTensor.new()
 *         THDoubleTensor_sigmoid(res.native, self.native)             # <<<<<<<<<<<<<<
 *         return res
 * 
 */
  THDoubleTensor_sigmoid(__pyx_v_res->native, __pyx_v_self->native);

  /* "PyTorch.pyx":1679
 *         cdef _DoubleTensor res = _DoubleTensor.new()
 *         THDoubleTensor_sigmoid(res.native, self.native)
 *         return res             # <<<<<<<<<<<<<<
 * 
 *     def cinv(_DoubleTensor self):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = ((PyObject *)__pyx_v_res);
  goto __pyx_L0;

  /* "PyTorch.pyx":1676
 *         return res
 * 
 *     def sigmoid(_DoubleTensor self):             # <<<<<<<<<<<<<<
 *         cdef _DoubleTensor res = _DoubleTensor.new()
 *         THDoubleTensor_sigmoid(res.native, self.native)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.sigmoid", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1681
 *         return res
 * 
 *     def cinv(_DoubleTensor self):             # <<<<<<<<<<<<<<
 *         cdef _DoubleTensor res = _DoubleTensor.new()
 *         THDoubleTensor_cinv(res.native, self.native)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_47cinv(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_47cinv(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cinv (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_46cinv(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_46cinv(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self) {
  struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_res = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("cinv", 0);

  /* "PyTorch.pyx":1682
 * 
 *     def cinv(_DoubleTensor self):
 *         cdef _DoubleTensor res = _DoubleTensor.new()             # <<<<<<<<<<<<<<
 *         THDoubleTensor_cinv(res.native, self.native)
 *         return res
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7PyTorch__DoubleTensor), __pyx_n_s_new); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1682, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1682, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1682, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_7PyTorch__DoubleTensor))))) __PYX_ERR(0, 1682, __pyx_L1_error)
  __pyx_v_res = ((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":1683
 *     def cinv(_DoubleTensor self):
 *         cdef _DoubleTensor res = _DoubleTensor.new()
 *         THDoubleTensor_cinv(res.native, self.native)             # <<<<<<<<<<<<<<
 *         return res
 * 
 */
  THDoubleTensor_cinv(__pyx_v_res->native, __pyx_v_self->native);

  /* "PyTorch.pyx":1684
 *         cdef _DoubleTensor res = _DoubleTensor.new()
 *         THDoubleTensor_cinv(res.native, self.native)
 *         return res             # <<<<<<<<<<<<<<
 * 
 *     def neg(_DoubleTensor self):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = ((PyObject *)__pyx_v_res);
  goto __pyx_L0;

  /* "PyTorch.pyx":1681
 *         return res
 * 
 *     def cinv(_DoubleTensor self):             # <<<<<<<<<<<<<<
 *         cdef _DoubleTensor res = _DoubleTensor.new()
 *         THDoubleTensor_cinv(res.native, self.native)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.cinv", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1686
 *         return res
 * 
 *     def neg(_DoubleTensor self):             # <<<<<<<<<<<<<<
 *         cdef _DoubleTensor res = _DoubleTensor.new()
 *         THDoubleTensor_neg(res.native, self.native)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_49neg(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_49neg(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("neg (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_48neg(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_48neg(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self) {
  struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_res = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("neg", 0);

  /* "PyTorch.pyx":1687
 * 
 *     def neg(_DoubleTensor self):
 *         cdef _DoubleTensor res = _DoubleTensor.new()             # <<<<<<<<<<<<<<
 *         THDoubleTensor_neg(res.native, self.native)
 *         return res
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7PyTorch__DoubleTensor), __pyx_n_s_new); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1687, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1687, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1687, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_7PyTorch__DoubleTensor))))) __PYX_ERR(0, 1687, __pyx_L1_error)
  __pyx_v_res = ((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":1688
 *     def neg(_DoubleTensor self):
 *         cdef _DoubleTensor res = _DoubleTensor.new()
 *         THDoubleTensor_neg(res.native, self.native)             # <<<<<<<<<<<<<<
 *         return res
 * 
 */
  THDoubleTensor_neg(__pyx_v_res->native, __pyx_v_self->native);

  /* "PyTorch.pyx":1689
 *         cdef _DoubleTensor res = _DoubleTensor.new()
 *         THDoubleTensor_neg(res.native, self.native)
 *         return res             # <<<<<<<<<<<<<<
 * 
 *     def ineg(_DoubleTensor self):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = ((PyObject *)__pyx_v_res);
  goto __pyx_L0;

  /* "PyTorch.pyx":1686
 *         return res
 * 
 *     def neg(_DoubleTensor self):             # <<<<<<<<<<<<<<
 *         cdef _DoubleTensor res = _DoubleTensor.new()
 *         THDoubleTensor_neg(res.native, self.native)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.neg", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1691
 *         return res
 * 
 *     def ineg(_DoubleTensor self):             # <<<<<<<<<<<<<<
 *         THDoubleTensor_neg(self.native, self.native)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_51ineg(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_51ineg(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("ineg (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_50ineg(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_50ineg(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("ineg", 0);

  /* "PyTorch.pyx":1692
 * 
 *     def ineg(_DoubleTensor self):
 *         THDoubleTensor_neg(self.native, self.native)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THDoubleTensor_neg(__pyx_v_self->native, __pyx_v_self->native);

  /* "PyTorch.pyx":1693
 *     def ineg(_DoubleTensor self):
 *         THDoubleTensor_neg(self.native, self.native)
 *         return self             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1691
 *         return res
 * 
 *     def ineg(_DoubleTensor self):             # <<<<<<<<<<<<<<
 *         THDoubleTensor_neg(self.native, self.native)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1698
 * 
 * 
 *     def abs(_DoubleTensor self):             # <<<<<<<<<<<<<<
 *         cdef _DoubleTensor res = _DoubleTensor.new()
 *         THDoubleTensor_abs(res.native, self.native)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_53abs(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_53abs(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("abs (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_52abs(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_52abs(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self) {
  struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_res = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("abs", 0);

  /* "PyTorch.pyx":1699
 * 
 *     def abs(_DoubleTensor self):
 *         cdef _DoubleTensor res = _DoubleTensor.new()             # <<<<<<<<<<<<<<
 *         THDoubleTensor_abs(res.native, self.native)
 *         return res
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7PyTorch__DoubleTensor), __pyx_n_s_new); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1699, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1699, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1699, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_7PyTorch__DoubleTensor))))) __PYX_ERR(0, 1699, __pyx_L1_error)
  __pyx_v_res = ((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":1700
 *     def abs(_DoubleTensor self):
 *         cdef _DoubleTensor res = _DoubleTensor.new()
 *         THDoubleTensor_abs(res.native, self.native)             # <<<<<<<<<<<<<<
 *         return res
 * 
 */
  THDoubleTensor_abs(__pyx_v_res->native, __pyx_v_self->native);

  /* "PyTorch.pyx":1701
 *         cdef _DoubleTensor res = _DoubleTensor.new()
 *         THDoubleTensor_abs(res.native, self.native)
 *         return res             # <<<<<<<<<<<<<<
 * 
 *     def iabs(_DoubleTensor self):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = ((PyObject *)__pyx_v_res);
  goto __pyx_L0;

  /* "PyTorch.pyx":1698
 * 
 * 
 *     def abs(_DoubleTensor self):             # <<<<<<<<<<<<<<
 *         cdef _DoubleTensor res = _DoubleTensor.new()
 *         THDoubleTensor_abs(res.native, self.native)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.abs", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1703
 *         return res
 * 
 *     def iabs(_DoubleTensor self):             # <<<<<<<<<<<<<<
 *         THDoubleTensor_abs(self.native, self.native)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_55iabs(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_55iabs(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("iabs (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_54iabs(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_54iabs(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("iabs", 0);

  /* "PyTorch.pyx":1704
 * 
 *     def iabs(_DoubleTensor self):
 *         THDoubleTensor_abs(self.native, self.native)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THDoubleTensor_abs(__pyx_v_self->native, __pyx_v_self->native);

  /* "PyTorch.pyx":1705
 *     def iabs(_DoubleTensor self):
 *         THDoubleTensor_abs(self.native, self.native)
 *         return self             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1703
 *         return res
 * 
 *     def iabs(_DoubleTensor self):             # <<<<<<<<<<<<<<
 *         THDoubleTensor_abs(self.native, self.native)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1709
 * 
 * 
 *     def size(_DoubleTensor self):             # <<<<<<<<<<<<<<
 *         cdef int dims = self.dims()
 * #        cdef LongStorage size
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_57size(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_57size(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("size (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_56size(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_56size(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self) {
  int __pyx_v_dims;
  PyObject *__pyx_v_size = NULL;
  int __pyx_v_d;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  int __pyx_t_7;
  int __pyx_t_8;
  __Pyx_RefNannySetupContext("size", 0);

  /* "PyTorch.pyx":1710
 * 
 *     def size(_DoubleTensor self):
 *         cdef int dims = self.dims()             # <<<<<<<<<<<<<<
 * #        cdef LongStorage size
 *         if dims > 0:
 */
  __pyx_v_dims = ((struct __pyx_vtabstruct_7PyTorch__DoubleTensor *)__pyx_v_self->__pyx_vtab)->dims(__pyx_v_self, 0);

  /* "PyTorch.pyx":1712
 *         cdef int dims = self.dims()
 * #        cdef LongStorage size
 *         if dims > 0:             # <<<<<<<<<<<<<<
 *             size = _LongStorage(dims)
 *             for d in range(dims):
 */
  __pyx_t_1 = ((__pyx_v_dims > 0) != 0);
  if (__pyx_t_1) {

    /* "PyTorch.pyx":1713
 * #        cdef LongStorage size
 *         if dims > 0:
 *             size = _LongStorage(dims)             # <<<<<<<<<<<<<<
 *             for d in range(dims):
 *                 size[d] = THDoubleTensor_size(self.native, d)
 */
    __pyx_t_3 = __Pyx_GetModuleGlobalName(__pyx_n_s_LongStorage); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1713, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = __Pyx_PyInt_From_int(__pyx_v_dims); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1713, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_5 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
      __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_3);
      if (likely(__pyx_t_5)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
        __Pyx_INCREF(__pyx_t_5);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_3, function);
      }
    }
    if (!__pyx_t_5) {
      __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_4); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1713, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_GOTREF(__pyx_t_2);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_3)) {
        PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_t_4};
        __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1713, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
        PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_t_4};
        __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1713, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else
      #endif
      {
        __pyx_t_6 = PyTuple_New(1+1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1713, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_5); __pyx_t_5 = NULL;
        __Pyx_GIVEREF(__pyx_t_4);
        PyTuple_SET_ITEM(__pyx_t_6, 0+1, __pyx_t_4);
        __pyx_t_4 = 0;
        __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_6, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1713, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_v_size = __pyx_t_2;
    __pyx_t_2 = 0;

    /* "PyTorch.pyx":1714
 *         if dims > 0:
 *             size = _LongStorage(dims)
 *             for d in range(dims):             # <<<<<<<<<<<<<<
 *                 size[d] = THDoubleTensor_size(self.native, d)
 *             return size
 */
    __pyx_t_7 = __pyx_v_dims;
    for (__pyx_t_8 = 0; __pyx_t_8 < __pyx_t_7; __pyx_t_8+=1) {
      __pyx_v_d = __pyx_t_8;

      /* "PyTorch.pyx":1715
 *             size = _LongStorage(dims)
 *             for d in range(dims):
 *                 size[d] = THDoubleTensor_size(self.native, d)             # <<<<<<<<<<<<<<
 *             return size
 *         else:
 */
      __pyx_t_2 = __Pyx_PyInt_From_long(THDoubleTensor_size(__pyx_v_self->native, __pyx_v_d)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1715, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      if (unlikely(__Pyx_SetItemInt(__pyx_v_size, __pyx_v_d, __pyx_t_2, int, 1, __Pyx_PyInt_From_int, 0, 1, 1) < 0)) __PYX_ERR(0, 1715, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    }

    /* "PyTorch.pyx":1716
 *             for d in range(dims):
 *                 size[d] = THDoubleTensor_size(self.native, d)
 *             return size             # <<<<<<<<<<<<<<
 *         else:
 *             return None  # not sure how to handle this yet
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(__pyx_v_size);
    __pyx_r = __pyx_v_size;
    goto __pyx_L0;

    /* "PyTorch.pyx":1712
 *         cdef int dims = self.dims()
 * #        cdef LongStorage size
 *         if dims > 0:             # <<<<<<<<<<<<<<
 *             size = _LongStorage(dims)
 *             for d in range(dims):
 */
  }

  /* "PyTorch.pyx":1718
 *             return size
 *         else:
 *             return None  # not sure how to handle this yet             # <<<<<<<<<<<<<<
 * 
 *     @staticmethod
 */
  /*else*/ {
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(Py_None);
    __pyx_r = Py_None;
    goto __pyx_L0;
  }

  /* "PyTorch.pyx":1709
 * 
 * 
 *     def size(_DoubleTensor self):             # <<<<<<<<<<<<<<
 *         cdef int dims = self.dims()
 * #        cdef LongStorage size
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.size", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_size);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1721
 * 
 *     @staticmethod
 *     def new():             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         return _DoubleTensor()
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_59new(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_7PyTorch_13_DoubleTensor_59new = {"new", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_59new, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_59new(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("new (wrapper)", 0);
  if (unlikely(PyTuple_GET_SIZE(__pyx_args) > 0)) {
    __Pyx_RaiseArgtupleInvalid("new", 1, 0, 0, PyTuple_GET_SIZE(__pyx_args)); return NULL;}
  if (unlikely(__pyx_kwds) && unlikely(PyDict_Size(__pyx_kwds) > 0) && unlikely(!__Pyx_CheckKeywordStrings(__pyx_kwds, "new", 0))) return NULL;
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_58new();

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_58new() {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("new", 0);

  /* "PyTorch.pyx":1723
 *     def new():
 * #        # print('allocate tensor')
 *         return _DoubleTensor()             # <<<<<<<<<<<<<<
 * #        return _FloatTensor_fromNative(newTensorC, False)
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_7PyTorch__DoubleTensor), __pyx_empty_tuple, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1723, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":1721
 * 
 *     @staticmethod
 *     def new():             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         return _DoubleTensor()
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.new", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1726
 * #        return _FloatTensor_fromNative(newTensorC, False)
 * 
 *     def narrow(_DoubleTensor self, int dimension, long firstIndex, long size):             # <<<<<<<<<<<<<<
 *         cdef THDoubleTensor *narrowedC = THDoubleTensor_newNarrow(self.native, dimension, firstIndex, size)
 *         return _DoubleTensor_fromNative(narrowedC, retain=False)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_61narrow(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_61narrow(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  int __pyx_v_dimension;
  long __pyx_v_firstIndex;
  long __pyx_v_size;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("narrow (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_dimension,&__pyx_n_s_firstIndex,&__pyx_n_s_size,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_dimension)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_firstIndex)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("narrow", 1, 3, 3, 1); __PYX_ERR(0, 1726, __pyx_L3_error)
        }
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("narrow", 1, 3, 3, 2); __PYX_ERR(0, 1726, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "narrow") < 0)) __PYX_ERR(0, 1726, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_dimension = __Pyx_PyInt_As_int(values[0]); if (unlikely((__pyx_v_dimension == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1726, __pyx_L3_error)
    __pyx_v_firstIndex = __Pyx_PyInt_As_long(values[1]); if (unlikely((__pyx_v_firstIndex == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1726, __pyx_L3_error)
    __pyx_v_size = __Pyx_PyInt_As_long(values[2]); if (unlikely((__pyx_v_size == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1726, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("narrow", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1726, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._DoubleTensor.narrow", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_60narrow(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self), __pyx_v_dimension, __pyx_v_firstIndex, __pyx_v_size);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_60narrow(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, int __pyx_v_dimension, long __pyx_v_firstIndex, long __pyx_v_size) {
  struct THDoubleTensor *__pyx_v_narrowedC;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  struct __pyx_opt_args_7PyTorch__DoubleTensor_fromNative __pyx_t_2;
  __Pyx_RefNannySetupContext("narrow", 0);

  /* "PyTorch.pyx":1727
 * 
 *     def narrow(_DoubleTensor self, int dimension, long firstIndex, long size):
 *         cdef THDoubleTensor *narrowedC = THDoubleTensor_newNarrow(self.native, dimension, firstIndex, size)             # <<<<<<<<<<<<<<
 *         return _DoubleTensor_fromNative(narrowedC, retain=False)
 * 
 */
  __pyx_v_narrowedC = THDoubleTensor_newNarrow(__pyx_v_self->native, __pyx_v_dimension, __pyx_v_firstIndex, __pyx_v_size);

  /* "PyTorch.pyx":1728
 *     def narrow(_DoubleTensor self, int dimension, long firstIndex, long size):
 *         cdef THDoubleTensor *narrowedC = THDoubleTensor_newNarrow(self.native, dimension, firstIndex, size)
 *         return _DoubleTensor_fromNative(narrowedC, retain=False)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2.__pyx_n = 1;
  __pyx_t_2.retain = Py_False;
  __pyx_t_1 = __pyx_f_7PyTorch__DoubleTensor_fromNative(__pyx_v_narrowedC, &__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1728, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":1726
 * #        return _FloatTensor_fromNative(newTensorC, False)
 * 
 *     def narrow(_DoubleTensor self, int dimension, long firstIndex, long size):             # <<<<<<<<<<<<<<
 *         cdef THDoubleTensor *narrowedC = THDoubleTensor_newNarrow(self.native, dimension, firstIndex, size)
 *         return _DoubleTensor_fromNative(narrowedC, retain=False)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.narrow", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1731
 * 
 * 
 *     def contiguous(_DoubleTensor self):             # <<<<<<<<<<<<<<
 *         cdef THDoubleTensor *newTensorC = THDoubleTensor_newContiguous(self.native)
 *         return _DoubleTensor_fromNative(newTensorC, retain=False)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_63contiguous(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_63contiguous(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("contiguous (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_62contiguous(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_62contiguous(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self) {
  struct THDoubleTensor *__pyx_v_newTensorC;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  struct __pyx_opt_args_7PyTorch__DoubleTensor_fromNative __pyx_t_2;
  __Pyx_RefNannySetupContext("contiguous", 0);

  /* "PyTorch.pyx":1732
 * 
 *     def contiguous(_DoubleTensor self):
 *         cdef THDoubleTensor *newTensorC = THDoubleTensor_newContiguous(self.native)             # <<<<<<<<<<<<<<
 *         return _DoubleTensor_fromNative(newTensorC, retain=False)
 * 
 */
  __pyx_v_newTensorC = THDoubleTensor_newContiguous(__pyx_v_self->native);

  /* "PyTorch.pyx":1733
 *     def contiguous(_DoubleTensor self):
 *         cdef THDoubleTensor *newTensorC = THDoubleTensor_newContiguous(self.native)
 *         return _DoubleTensor_fromNative(newTensorC, retain=False)             # <<<<<<<<<<<<<<
 * 
 *     def resize1d(_DoubleTensor self, int size0):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2.__pyx_n = 1;
  __pyx_t_2.retain = Py_False;
  __pyx_t_1 = __pyx_f_7PyTorch__DoubleTensor_fromNative(__pyx_v_newTensorC, &__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1733, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":1731
 * 
 * 
 *     def contiguous(_DoubleTensor self):             # <<<<<<<<<<<<<<
 *         cdef THDoubleTensor *newTensorC = THDoubleTensor_newContiguous(self.native)
 *         return _DoubleTensor_fromNative(newTensorC, retain=False)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.contiguous", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1735
 *         return _DoubleTensor_fromNative(newTensorC, retain=False)
 * 
 *     def resize1d(_DoubleTensor self, int size0):             # <<<<<<<<<<<<<<
 *         THDoubleTensor_resize1d(self.native, size0)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_65resize1d(PyObject *__pyx_v_self, PyObject *__pyx_arg_size0); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_65resize1d(PyObject *__pyx_v_self, PyObject *__pyx_arg_size0) {
  int __pyx_v_size0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resize1d (wrapper)", 0);
  assert(__pyx_arg_size0); {
    __pyx_v_size0 = __Pyx_PyInt_As_int(__pyx_arg_size0); if (unlikely((__pyx_v_size0 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1735, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._DoubleTensor.resize1d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_64resize1d(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self), ((int)__pyx_v_size0));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_64resize1d(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, int __pyx_v_size0) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resize1d", 0);

  /* "PyTorch.pyx":1736
 * 
 *     def resize1d(_DoubleTensor self, int size0):
 *         THDoubleTensor_resize1d(self.native, size0)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THDoubleTensor_resize1d(__pyx_v_self->native, __pyx_v_size0);

  /* "PyTorch.pyx":1737
 *     def resize1d(_DoubleTensor self, int size0):
 *         THDoubleTensor_resize1d(self.native, size0)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def resize2d(_DoubleTensor self, int size0, int size1):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1735
 *         return _DoubleTensor_fromNative(newTensorC, retain=False)
 * 
 *     def resize1d(_DoubleTensor self, int size0):             # <<<<<<<<<<<<<<
 *         THDoubleTensor_resize1d(self.native, size0)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1739
 *         return self
 * 
 *     def resize2d(_DoubleTensor self, int size0, int size1):             # <<<<<<<<<<<<<<
 *         THDoubleTensor_resize2d(self.native, size0, size1)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_67resize2d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_67resize2d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  int __pyx_v_size0;
  int __pyx_v_size1;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resize2d (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_size0,&__pyx_n_s_size1,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size0)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("resize2d", 1, 2, 2, 1); __PYX_ERR(0, 1739, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "resize2d") < 0)) __PYX_ERR(0, 1739, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_size0 = __Pyx_PyInt_As_int(values[0]); if (unlikely((__pyx_v_size0 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1739, __pyx_L3_error)
    __pyx_v_size1 = __Pyx_PyInt_As_int(values[1]); if (unlikely((__pyx_v_size1 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1739, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("resize2d", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1739, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._DoubleTensor.resize2d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_66resize2d(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self), __pyx_v_size0, __pyx_v_size1);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_66resize2d(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, int __pyx_v_size0, int __pyx_v_size1) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resize2d", 0);

  /* "PyTorch.pyx":1740
 * 
 *     def resize2d(_DoubleTensor self, int size0, int size1):
 *         THDoubleTensor_resize2d(self.native, size0, size1)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THDoubleTensor_resize2d(__pyx_v_self->native, __pyx_v_size0, __pyx_v_size1);

  /* "PyTorch.pyx":1741
 *     def resize2d(_DoubleTensor self, int size0, int size1):
 *         THDoubleTensor_resize2d(self.native, size0, size1)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def resize3d(_DoubleTensor self, int size0, int size1, int size2):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1739
 *         return self
 * 
 *     def resize2d(_DoubleTensor self, int size0, int size1):             # <<<<<<<<<<<<<<
 *         THDoubleTensor_resize2d(self.native, size0, size1)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1743
 *         return self
 * 
 *     def resize3d(_DoubleTensor self, int size0, int size1, int size2):             # <<<<<<<<<<<<<<
 *         THDoubleTensor_resize3d(self.native, size0, size1, size2)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_69resize3d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_69resize3d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  int __pyx_v_size0;
  int __pyx_v_size1;
  int __pyx_v_size2;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resize3d (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_size0,&__pyx_n_s_size1,&__pyx_n_s_size2,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size0)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("resize3d", 1, 3, 3, 1); __PYX_ERR(0, 1743, __pyx_L3_error)
        }
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("resize3d", 1, 3, 3, 2); __PYX_ERR(0, 1743, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "resize3d") < 0)) __PYX_ERR(0, 1743, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_size0 = __Pyx_PyInt_As_int(values[0]); if (unlikely((__pyx_v_size0 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1743, __pyx_L3_error)
    __pyx_v_size1 = __Pyx_PyInt_As_int(values[1]); if (unlikely((__pyx_v_size1 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1743, __pyx_L3_error)
    __pyx_v_size2 = __Pyx_PyInt_As_int(values[2]); if (unlikely((__pyx_v_size2 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1743, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("resize3d", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1743, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._DoubleTensor.resize3d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_68resize3d(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self), __pyx_v_size0, __pyx_v_size1, __pyx_v_size2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_68resize3d(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, int __pyx_v_size0, int __pyx_v_size1, int __pyx_v_size2) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resize3d", 0);

  /* "PyTorch.pyx":1744
 * 
 *     def resize3d(_DoubleTensor self, int size0, int size1, int size2):
 *         THDoubleTensor_resize3d(self.native, size0, size1, size2)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THDoubleTensor_resize3d(__pyx_v_self->native, __pyx_v_size0, __pyx_v_size1, __pyx_v_size2);

  /* "PyTorch.pyx":1745
 *     def resize3d(_DoubleTensor self, int size0, int size1, int size2):
 *         THDoubleTensor_resize3d(self.native, size0, size1, size2)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def resize4d(_DoubleTensor self, int size0, int size1, int size2, int size3):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1743
 *         return self
 * 
 *     def resize3d(_DoubleTensor self, int size0, int size1, int size2):             # <<<<<<<<<<<<<<
 *         THDoubleTensor_resize3d(self.native, size0, size1, size2)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1747
 *         return self
 * 
 *     def resize4d(_DoubleTensor self, int size0, int size1, int size2, int size3):             # <<<<<<<<<<<<<<
 *         THDoubleTensor_resize4d(self.native, size0, size1, size2, size3)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_71resize4d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_71resize4d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  int __pyx_v_size0;
  int __pyx_v_size1;
  int __pyx_v_size2;
  int __pyx_v_size3;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resize4d (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_size0,&__pyx_n_s_size1,&__pyx_n_s_size2,&__pyx_n_s_size3,0};
    PyObject* values[4] = {0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size0)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("resize4d", 1, 4, 4, 1); __PYX_ERR(0, 1747, __pyx_L3_error)
        }
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("resize4d", 1, 4, 4, 2); __PYX_ERR(0, 1747, __pyx_L3_error)
        }
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size3)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("resize4d", 1, 4, 4, 3); __PYX_ERR(0, 1747, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "resize4d") < 0)) __PYX_ERR(0, 1747, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 4) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
    }
    __pyx_v_size0 = __Pyx_PyInt_As_int(values[0]); if (unlikely((__pyx_v_size0 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1747, __pyx_L3_error)
    __pyx_v_size1 = __Pyx_PyInt_As_int(values[1]); if (unlikely((__pyx_v_size1 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1747, __pyx_L3_error)
    __pyx_v_size2 = __Pyx_PyInt_As_int(values[2]); if (unlikely((__pyx_v_size2 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1747, __pyx_L3_error)
    __pyx_v_size3 = __Pyx_PyInt_As_int(values[3]); if (unlikely((__pyx_v_size3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1747, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("resize4d", 1, 4, 4, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1747, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._DoubleTensor.resize4d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_70resize4d(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self), __pyx_v_size0, __pyx_v_size1, __pyx_v_size2, __pyx_v_size3);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_70resize4d(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, int __pyx_v_size0, int __pyx_v_size1, int __pyx_v_size2, int __pyx_v_size3) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resize4d", 0);

  /* "PyTorch.pyx":1748
 * 
 *     def resize4d(_DoubleTensor self, int size0, int size1, int size2, int size3):
 *         THDoubleTensor_resize4d(self.native, size0, size1, size2, size3)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THDoubleTensor_resize4d(__pyx_v_self->native, __pyx_v_size0, __pyx_v_size1, __pyx_v_size2, __pyx_v_size3);

  /* "PyTorch.pyx":1749
 *     def resize4d(_DoubleTensor self, int size0, int size1, int size2, int size3):
 *         THDoubleTensor_resize4d(self.native, size0, size1, size2, size3)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def resizeAs(_DoubleTensor self, _DoubleTensor model):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1747
 *         return self
 * 
 *     def resize4d(_DoubleTensor self, int size0, int size1, int size2, int size3):             # <<<<<<<<<<<<<<
 *         THDoubleTensor_resize4d(self.native, size0, size1, size2, size3)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1751
 *         return self
 * 
 *     def resizeAs(_DoubleTensor self, _DoubleTensor model):             # <<<<<<<<<<<<<<
 *         THDoubleTensor_resizeAs(self.native, model.native)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_73resizeAs(PyObject *__pyx_v_self, PyObject *__pyx_v_model); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_73resizeAs(PyObject *__pyx_v_self, PyObject *__pyx_v_model) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resizeAs (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_model), __pyx_ptype_7PyTorch__DoubleTensor, 1, "model", 0))) __PYX_ERR(0, 1751, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_72resizeAs(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self), ((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_model));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_72resizeAs(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_model) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resizeAs", 0);

  /* "PyTorch.pyx":1752
 * 
 *     def resizeAs(_DoubleTensor self, _DoubleTensor model):
 *         THDoubleTensor_resizeAs(self.native, model.native)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THDoubleTensor_resizeAs(__pyx_v_self->native, __pyx_v_model->native);

  /* "PyTorch.pyx":1753
 *     def resizeAs(_DoubleTensor self, _DoubleTensor model):
 *         THDoubleTensor_resizeAs(self.native, model.native)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def resize(_DoubleTensor self, Storage._LongStorage size):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1751
 *         return self
 * 
 *     def resizeAs(_DoubleTensor self, _DoubleTensor model):             # <<<<<<<<<<<<<<
 *         THDoubleTensor_resizeAs(self.native, model.native)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1755
 *         return self
 * 
 *     def resize(_DoubleTensor self, Storage._LongStorage size):             # <<<<<<<<<<<<<<
 * #        # print('_FloatTensor.resize size:', size)
 *         if len(size) == 0:
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_75resize(PyObject *__pyx_v_self, PyObject *__pyx_v_size); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_75resize(PyObject *__pyx_v_self, PyObject *__pyx_v_size) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resize (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_size), __pyx_ptype_7Storage__LongStorage, 1, "size", 0))) __PYX_ERR(0, 1755, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_74resize(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self), ((struct __pyx_obj_7Storage__LongStorage *)__pyx_v_size));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_74resize(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, struct __pyx_obj_7Storage__LongStorage *__pyx_v_size) {
  int __pyx_v_dims;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  Py_ssize_t __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  long __pyx_t_4;
  long __pyx_t_5;
  long __pyx_t_6;
  long __pyx_t_7;
  PyObject *__pyx_t_8 = NULL;
  __Pyx_RefNannySetupContext("resize", 0);

  /* "PyTorch.pyx":1757
 *     def resize(_DoubleTensor self, Storage._LongStorage size):
 * #        # print('_FloatTensor.resize size:', size)
 *         if len(size) == 0:             # <<<<<<<<<<<<<<
 *             return self
 *         cdef int dims = len(size)
 */
  __pyx_t_1 = PyObject_Length(((PyObject *)__pyx_v_size)); if (unlikely(__pyx_t_1 == -1)) __PYX_ERR(0, 1757, __pyx_L1_error)
  __pyx_t_2 = ((__pyx_t_1 == 0) != 0);
  if (__pyx_t_2) {

    /* "PyTorch.pyx":1758
 * #        # print('_FloatTensor.resize size:', size)
 *         if len(size) == 0:
 *             return self             # <<<<<<<<<<<<<<
 *         cdef int dims = len(size)
 * #        # print('_FloatTensor.resize dims:', dims)
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(((PyObject *)__pyx_v_self));
    __pyx_r = ((PyObject *)__pyx_v_self);
    goto __pyx_L0;

    /* "PyTorch.pyx":1757
 *     def resize(_DoubleTensor self, Storage._LongStorage size):
 * #        # print('_FloatTensor.resize size:', size)
 *         if len(size) == 0:             # <<<<<<<<<<<<<<
 *             return self
 *         cdef int dims = len(size)
 */
  }

  /* "PyTorch.pyx":1759
 *         if len(size) == 0:
 *             return self
 *         cdef int dims = len(size)             # <<<<<<<<<<<<<<
 * #        # print('_FloatTensor.resize dims:', dims)
 *         if dims == 1:
 */
  __pyx_t_1 = PyObject_Length(((PyObject *)__pyx_v_size)); if (unlikely(__pyx_t_1 == -1)) __PYX_ERR(0, 1759, __pyx_L1_error)
  __pyx_v_dims = __pyx_t_1;

  /* "PyTorch.pyx":1761
 *         cdef int dims = len(size)
 * #        # print('_FloatTensor.resize dims:', dims)
 *         if dims == 1:             # <<<<<<<<<<<<<<
 *             THDoubleTensor_resize1d(self.native, size[0])
 *         elif dims == 2:
 */
  switch (__pyx_v_dims) {
    case 1:

    /* "PyTorch.pyx":1762
 * #        # print('_FloatTensor.resize dims:', dims)
 *         if dims == 1:
 *             THDoubleTensor_resize1d(self.native, size[0])             # <<<<<<<<<<<<<<
 *         elif dims == 2:
 *             THDoubleTensor_resize2d(self.native, size[0], size[1])
 */
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1762, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_4 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1762, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    THDoubleTensor_resize1d(__pyx_v_self->native, __pyx_t_4);

    /* "PyTorch.pyx":1761
 *         cdef int dims = len(size)
 * #        # print('_FloatTensor.resize dims:', dims)
 *         if dims == 1:             # <<<<<<<<<<<<<<
 *             THDoubleTensor_resize1d(self.native, size[0])
 *         elif dims == 2:
 */
    break;

    /* "PyTorch.pyx":1763
 *         if dims == 1:
 *             THDoubleTensor_resize1d(self.native, size[0])
 *         elif dims == 2:             # <<<<<<<<<<<<<<
 *             THDoubleTensor_resize2d(self.native, size[0], size[1])
 *         elif dims == 3:
 */
    case 2:

    /* "PyTorch.pyx":1764
 *             THDoubleTensor_resize1d(self.native, size[0])
 *         elif dims == 2:
 *             THDoubleTensor_resize2d(self.native, size[0], size[1])             # <<<<<<<<<<<<<<
 *         elif dims == 3:
 *             THDoubleTensor_resize3d(self.native, size[0], size[1], size[2])
 */
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1764, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_4 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1764, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1764, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_5 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_5 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1764, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    THDoubleTensor_resize2d(__pyx_v_self->native, __pyx_t_4, __pyx_t_5);

    /* "PyTorch.pyx":1763
 *         if dims == 1:
 *             THDoubleTensor_resize1d(self.native, size[0])
 *         elif dims == 2:             # <<<<<<<<<<<<<<
 *             THDoubleTensor_resize2d(self.native, size[0], size[1])
 *         elif dims == 3:
 */
    break;

    /* "PyTorch.pyx":1765
 *         elif dims == 2:
 *             THDoubleTensor_resize2d(self.native, size[0], size[1])
 *         elif dims == 3:             # <<<<<<<<<<<<<<
 *             THDoubleTensor_resize3d(self.native, size[0], size[1], size[2])
 *         elif dims == 4:
 */
    case 3:

    /* "PyTorch.pyx":1766
 *             THDoubleTensor_resize2d(self.native, size[0], size[1])
 *         elif dims == 3:
 *             THDoubleTensor_resize3d(self.native, size[0], size[1], size[2])             # <<<<<<<<<<<<<<
 *         elif dims == 4:
 *             THDoubleTensor_resize4d(self.native, size[0], size[1], size[2], size[3])
 */
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1766, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_5 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_5 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1766, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1766, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_4 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1766, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1766, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_6 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_6 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1766, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    THDoubleTensor_resize3d(__pyx_v_self->native, __pyx_t_5, __pyx_t_4, __pyx_t_6);

    /* "PyTorch.pyx":1765
 *         elif dims == 2:
 *             THDoubleTensor_resize2d(self.native, size[0], size[1])
 *         elif dims == 3:             # <<<<<<<<<<<<<<
 *             THDoubleTensor_resize3d(self.native, size[0], size[1], size[2])
 *         elif dims == 4:
 */
    break;

    /* "PyTorch.pyx":1767
 *         elif dims == 3:
 *             THDoubleTensor_resize3d(self.native, size[0], size[1], size[2])
 *         elif dims == 4:             # <<<<<<<<<<<<<<
 *             THDoubleTensor_resize4d(self.native, size[0], size[1], size[2], size[3])
 *         else:
 */
    case 4:

    /* "PyTorch.pyx":1768
 *             THDoubleTensor_resize3d(self.native, size[0], size[1], size[2])
 *         elif dims == 4:
 *             THDoubleTensor_resize4d(self.native, size[0], size[1], size[2], size[3])             # <<<<<<<<<<<<<<
 *         else:
 *             raise Exception('Not implemented for dims=' + str(dims))
 */
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1768, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_6 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_6 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1768, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1768, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_4 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1768, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1768, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_5 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_5 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1768, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 3, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1768, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_7 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_7 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1768, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    THDoubleTensor_resize4d(__pyx_v_self->native, __pyx_t_6, __pyx_t_4, __pyx_t_5, __pyx_t_7);

    /* "PyTorch.pyx":1767
 *         elif dims == 3:
 *             THDoubleTensor_resize3d(self.native, size[0], size[1], size[2])
 *         elif dims == 4:             # <<<<<<<<<<<<<<
 *             THDoubleTensor_resize4d(self.native, size[0], size[1], size[2], size[3])
 *         else:
 */
    break;
    default:

    /* "PyTorch.pyx":1770
 *             THDoubleTensor_resize4d(self.native, size[0], size[1], size[2], size[3])
 *         else:
 *             raise Exception('Not implemented for dims=' + str(dims))             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
    __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_dims); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1770, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_8 = PyTuple_New(1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1770, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_GIVEREF(__pyx_t_3);
    PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_t_3);
    __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_PyObject_Call(((PyObject *)(&PyString_Type)), __pyx_t_8, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1770, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_8 = PyNumber_Add(__pyx_kp_s_Not_implemented_for_dims, __pyx_t_3); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1770, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1770, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_GIVEREF(__pyx_t_8);
    PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_8);
    __pyx_t_8 = 0;
    __pyx_t_8 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_t_3, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1770, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_Raise(__pyx_t_8, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __PYX_ERR(0, 1770, __pyx_L1_error)
    break;
  }

  /* "PyTorch.pyx":1771
 *         else:
 *             raise Exception('Not implemented for dims=' + str(dims))
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     @staticmethod
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1755
 *         return self
 * 
 *     def resize(_DoubleTensor self, Storage._LongStorage size):             # <<<<<<<<<<<<<<
 * #        # print('_FloatTensor.resize size:', size)
 *         if len(size) == 0:
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.resize", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1774
 * 
 *     @staticmethod
 *     def newWithStorage(Storage._DoubleStorage storage, offset, Storage._LongStorage size, Storage._LongStorage stride):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THDoubleTensor *newTensorC = THDoubleTensor_newWithStorage(storage.native, offset, size.native, stride.native)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_77newWithStorage(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_7PyTorch_13_DoubleTensor_77newWithStorage = {"newWithStorage", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_77newWithStorage, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_77newWithStorage(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  struct __pyx_obj_7Storage__DoubleStorage *__pyx_v_storage = 0;
  PyObject *__pyx_v_offset = 0;
  struct __pyx_obj_7Storage__LongStorage *__pyx_v_size = 0;
  struct __pyx_obj_7Storage__LongStorage *__pyx_v_stride = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("newWithStorage (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_storage,&__pyx_n_s_offset,&__pyx_n_s_size,&__pyx_n_s_stride,0};
    PyObject* values[4] = {0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_storage)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_offset)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage", 1, 4, 4, 1); __PYX_ERR(0, 1774, __pyx_L3_error)
        }
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage", 1, 4, 4, 2); __PYX_ERR(0, 1774, __pyx_L3_error)
        }
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage", 1, 4, 4, 3); __PYX_ERR(0, 1774, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "newWithStorage") < 0)) __PYX_ERR(0, 1774, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 4) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
    }
    __pyx_v_storage = ((struct __pyx_obj_7Storage__DoubleStorage *)values[0]);
    __pyx_v_offset = values[1];
    __pyx_v_size = ((struct __pyx_obj_7Storage__LongStorage *)values[2]);
    __pyx_v_stride = ((struct __pyx_obj_7Storage__LongStorage *)values[3]);
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("newWithStorage", 1, 4, 4, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1774, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._DoubleTensor.newWithStorage", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_storage), __pyx_ptype_7Storage__DoubleStorage, 1, "storage", 0))) __PYX_ERR(0, 1774, __pyx_L1_error)
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_size), __pyx_ptype_7Storage__LongStorage, 1, "size", 0))) __PYX_ERR(0, 1774, __pyx_L1_error)
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_stride), __pyx_ptype_7Storage__LongStorage, 1, "stride", 0))) __PYX_ERR(0, 1774, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_76newWithStorage(__pyx_v_storage, __pyx_v_offset, __pyx_v_size, __pyx_v_stride);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_76newWithStorage(struct __pyx_obj_7Storage__DoubleStorage *__pyx_v_storage, PyObject *__pyx_v_offset, struct __pyx_obj_7Storage__LongStorage *__pyx_v_size, struct __pyx_obj_7Storage__LongStorage *__pyx_v_stride) {
  struct THDoubleTensor *__pyx_v_newTensorC;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  long __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  struct __pyx_opt_args_7PyTorch__DoubleTensor_fromNative __pyx_t_3;
  __Pyx_RefNannySetupContext("newWithStorage", 0);

  /* "PyTorch.pyx":1776
 *     def newWithStorage(Storage._DoubleStorage storage, offset, Storage._LongStorage size, Storage._LongStorage stride):
 * #        # print('allocate tensor')
 *         cdef THDoubleTensor *newTensorC = THDoubleTensor_newWithStorage(storage.native, offset, size.native, stride.native)             # <<<<<<<<<<<<<<
 *         return _DoubleTensor_fromNative(newTensorC, False)
 * 
 */
  __pyx_t_1 = __Pyx_PyInt_As_long(__pyx_v_offset); if (unlikely((__pyx_t_1 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1776, __pyx_L1_error)
  __pyx_v_newTensorC = THDoubleTensor_newWithStorage(__pyx_v_storage->native, __pyx_t_1, __pyx_v_size->native, __pyx_v_stride->native);

  /* "PyTorch.pyx":1777
 * #        # print('allocate tensor')
 *         cdef THDoubleTensor *newTensorC = THDoubleTensor_newWithStorage(storage.native, offset, size.native, stride.native)
 *         return _DoubleTensor_fromNative(newTensorC, False)             # <<<<<<<<<<<<<<
 * 
 *     @staticmethod
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_3.__pyx_n = 1;
  __pyx_t_3.retain = Py_False;
  __pyx_t_2 = __pyx_f_7PyTorch__DoubleTensor_fromNative(__pyx_v_newTensorC, &__pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1777, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":1774
 * 
 *     @staticmethod
 *     def newWithStorage(Storage._DoubleStorage storage, offset, Storage._LongStorage size, Storage._LongStorage stride):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THDoubleTensor *newTensorC = THDoubleTensor_newWithStorage(storage.native, offset, size.native, stride.native)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.newWithStorage", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1780
 * 
 *     @staticmethod
 *     def newWithStorage1d(Storage._DoubleStorage storage, offset, size0, stride0):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THDoubleTensor *newTensorC = THDoubleTensor_newWithStorage1d(storage.native, offset, size0, stride0)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_79newWithStorage1d(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_7PyTorch_13_DoubleTensor_79newWithStorage1d = {"newWithStorage1d", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_79newWithStorage1d, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_79newWithStorage1d(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  struct __pyx_obj_7Storage__DoubleStorage *__pyx_v_storage = 0;
  PyObject *__pyx_v_offset = 0;
  PyObject *__pyx_v_size0 = 0;
  PyObject *__pyx_v_stride0 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("newWithStorage1d (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_storage,&__pyx_n_s_offset,&__pyx_n_s_size0,&__pyx_n_s_stride0,0};
    PyObject* values[4] = {0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_storage)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_offset)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage1d", 1, 4, 4, 1); __PYX_ERR(0, 1780, __pyx_L3_error)
        }
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size0)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage1d", 1, 4, 4, 2); __PYX_ERR(0, 1780, __pyx_L3_error)
        }
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride0)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage1d", 1, 4, 4, 3); __PYX_ERR(0, 1780, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "newWithStorage1d") < 0)) __PYX_ERR(0, 1780, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 4) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
    }
    __pyx_v_storage = ((struct __pyx_obj_7Storage__DoubleStorage *)values[0]);
    __pyx_v_offset = values[1];
    __pyx_v_size0 = values[2];
    __pyx_v_stride0 = values[3];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("newWithStorage1d", 1, 4, 4, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1780, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._DoubleTensor.newWithStorage1d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_storage), __pyx_ptype_7Storage__DoubleStorage, 1, "storage", 0))) __PYX_ERR(0, 1780, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_78newWithStorage1d(__pyx_v_storage, __pyx_v_offset, __pyx_v_size0, __pyx_v_stride0);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_78newWithStorage1d(struct __pyx_obj_7Storage__DoubleStorage *__pyx_v_storage, PyObject *__pyx_v_offset, PyObject *__pyx_v_size0, PyObject *__pyx_v_stride0) {
  struct THDoubleTensor *__pyx_v_newTensorC;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  long __pyx_t_1;
  long __pyx_t_2;
  long __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  struct __pyx_opt_args_7PyTorch__DoubleTensor_fromNative __pyx_t_5;
  __Pyx_RefNannySetupContext("newWithStorage1d", 0);

  /* "PyTorch.pyx":1782
 *     def newWithStorage1d(Storage._DoubleStorage storage, offset, size0, stride0):
 * #        # print('allocate tensor')
 *         cdef THDoubleTensor *newTensorC = THDoubleTensor_newWithStorage1d(storage.native, offset, size0, stride0)             # <<<<<<<<<<<<<<
 *         return _DoubleTensor_fromNative(newTensorC, False)
 * 
 */
  __pyx_t_1 = __Pyx_PyInt_As_long(__pyx_v_offset); if (unlikely((__pyx_t_1 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1782, __pyx_L1_error)
  __pyx_t_2 = __Pyx_PyInt_As_long(__pyx_v_size0); if (unlikely((__pyx_t_2 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1782, __pyx_L1_error)
  __pyx_t_3 = __Pyx_PyInt_As_long(__pyx_v_stride0); if (unlikely((__pyx_t_3 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1782, __pyx_L1_error)
  __pyx_v_newTensorC = THDoubleTensor_newWithStorage1d(__pyx_v_storage->native, __pyx_t_1, __pyx_t_2, __pyx_t_3);

  /* "PyTorch.pyx":1783
 * #        # print('allocate tensor')
 *         cdef THDoubleTensor *newTensorC = THDoubleTensor_newWithStorage1d(storage.native, offset, size0, stride0)
 *         return _DoubleTensor_fromNative(newTensorC, False)             # <<<<<<<<<<<<<<
 * 
 *     @staticmethod
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_5.__pyx_n = 1;
  __pyx_t_5.retain = Py_False;
  __pyx_t_4 = __pyx_f_7PyTorch__DoubleTensor_fromNative(__pyx_v_newTensorC, &__pyx_t_5); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1783, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_r = __pyx_t_4;
  __pyx_t_4 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":1780
 * 
 *     @staticmethod
 *     def newWithStorage1d(Storage._DoubleStorage storage, offset, size0, stride0):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THDoubleTensor *newTensorC = THDoubleTensor_newWithStorage1d(storage.native, offset, size0, stride0)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.newWithStorage1d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1786
 * 
 *     @staticmethod
 *     def newWithStorage2d(Storage._DoubleStorage storage, offset, size0, stride0, size1, stride1):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THDoubleTensor *newTensorC = THDoubleTensor_newWithStorage2d(storage.native, offset, size0, stride0, size1, stride1)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_81newWithStorage2d(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_7PyTorch_13_DoubleTensor_81newWithStorage2d = {"newWithStorage2d", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_81newWithStorage2d, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_81newWithStorage2d(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  struct __pyx_obj_7Storage__DoubleStorage *__pyx_v_storage = 0;
  PyObject *__pyx_v_offset = 0;
  PyObject *__pyx_v_size0 = 0;
  PyObject *__pyx_v_stride0 = 0;
  PyObject *__pyx_v_size1 = 0;
  PyObject *__pyx_v_stride1 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("newWithStorage2d (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_storage,&__pyx_n_s_offset,&__pyx_n_s_size0,&__pyx_n_s_stride0,&__pyx_n_s_size1,&__pyx_n_s_stride1,0};
    PyObject* values[6] = {0,0,0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_storage)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_offset)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage2d", 1, 6, 6, 1); __PYX_ERR(0, 1786, __pyx_L3_error)
        }
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size0)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage2d", 1, 6, 6, 2); __PYX_ERR(0, 1786, __pyx_L3_error)
        }
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride0)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage2d", 1, 6, 6, 3); __PYX_ERR(0, 1786, __pyx_L3_error)
        }
        case  4:
        if (likely((values[4] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage2d", 1, 6, 6, 4); __PYX_ERR(0, 1786, __pyx_L3_error)
        }
        case  5:
        if (likely((values[5] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage2d", 1, 6, 6, 5); __PYX_ERR(0, 1786, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "newWithStorage2d") < 0)) __PYX_ERR(0, 1786, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 6) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
      values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
      values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
    }
    __pyx_v_storage = ((struct __pyx_obj_7Storage__DoubleStorage *)values[0]);
    __pyx_v_offset = values[1];
    __pyx_v_size0 = values[2];
    __pyx_v_stride0 = values[3];
    __pyx_v_size1 = values[4];
    __pyx_v_stride1 = values[5];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("newWithStorage2d", 1, 6, 6, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1786, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._DoubleTensor.newWithStorage2d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_storage), __pyx_ptype_7Storage__DoubleStorage, 1, "storage", 0))) __PYX_ERR(0, 1786, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_80newWithStorage2d(__pyx_v_storage, __pyx_v_offset, __pyx_v_size0, __pyx_v_stride0, __pyx_v_size1, __pyx_v_stride1);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_80newWithStorage2d(struct __pyx_obj_7Storage__DoubleStorage *__pyx_v_storage, PyObject *__pyx_v_offset, PyObject *__pyx_v_size0, PyObject *__pyx_v_stride0, PyObject *__pyx_v_size1, PyObject *__pyx_v_stride1) {
  struct THDoubleTensor *__pyx_v_newTensorC;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  long __pyx_t_1;
  long __pyx_t_2;
  long __pyx_t_3;
  long __pyx_t_4;
  long __pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  struct __pyx_opt_args_7PyTorch__DoubleTensor_fromNative __pyx_t_7;
  __Pyx_RefNannySetupContext("newWithStorage2d", 0);

  /* "PyTorch.pyx":1788
 *     def newWithStorage2d(Storage._DoubleStorage storage, offset, size0, stride0, size1, stride1):
 * #        # print('allocate tensor')
 *         cdef THDoubleTensor *newTensorC = THDoubleTensor_newWithStorage2d(storage.native, offset, size0, stride0, size1, stride1)             # <<<<<<<<<<<<<<
 *         return _DoubleTensor_fromNative(newTensorC, False)
 * 
 */
  __pyx_t_1 = __Pyx_PyInt_As_long(__pyx_v_offset); if (unlikely((__pyx_t_1 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1788, __pyx_L1_error)
  __pyx_t_2 = __Pyx_PyInt_As_long(__pyx_v_size0); if (unlikely((__pyx_t_2 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1788, __pyx_L1_error)
  __pyx_t_3 = __Pyx_PyInt_As_long(__pyx_v_stride0); if (unlikely((__pyx_t_3 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1788, __pyx_L1_error)
  __pyx_t_4 = __Pyx_PyInt_As_long(__pyx_v_size1); if (unlikely((__pyx_t_4 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1788, __pyx_L1_error)
  __pyx_t_5 = __Pyx_PyInt_As_long(__pyx_v_stride1); if (unlikely((__pyx_t_5 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1788, __pyx_L1_error)
  __pyx_v_newTensorC = THDoubleTensor_newWithStorage2d(__pyx_v_storage->native, __pyx_t_1, __pyx_t_2, __pyx_t_3, __pyx_t_4, __pyx_t_5);

  /* "PyTorch.pyx":1789
 * #        # print('allocate tensor')
 *         cdef THDoubleTensor *newTensorC = THDoubleTensor_newWithStorage2d(storage.native, offset, size0, stride0, size1, stride1)
 *         return _DoubleTensor_fromNative(newTensorC, False)             # <<<<<<<<<<<<<<
 * 
 *     @staticmethod
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_7.__pyx_n = 1;
  __pyx_t_7.retain = Py_False;
  __pyx_t_6 = __pyx_f_7PyTorch__DoubleTensor_fromNative(__pyx_v_newTensorC, &__pyx_t_7); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1789, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_r = __pyx_t_6;
  __pyx_t_6 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":1786
 * 
 *     @staticmethod
 *     def newWithStorage2d(Storage._DoubleStorage storage, offset, size0, stride0, size1, stride1):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THDoubleTensor *newTensorC = THDoubleTensor_newWithStorage2d(storage.native, offset, size0, stride0, size1, stride1)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.newWithStorage2d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1792
 * 
 *     @staticmethod
 *     def newWithStorage3d(Storage._DoubleStorage storage, offset, size0, stride0, size1, stride1, size2, stride2):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THDoubleTensor *newTensorC = THDoubleTensor_newWithStorage3d(storage.native, offset, size0, stride0, size1, stride1,
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_83newWithStorage3d(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_7PyTorch_13_DoubleTensor_83newWithStorage3d = {"newWithStorage3d", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_83newWithStorage3d, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_83newWithStorage3d(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  struct __pyx_obj_7Storage__DoubleStorage *__pyx_v_storage = 0;
  PyObject *__pyx_v_offset = 0;
  PyObject *__pyx_v_size0 = 0;
  PyObject *__pyx_v_stride0 = 0;
  PyObject *__pyx_v_size1 = 0;
  PyObject *__pyx_v_stride1 = 0;
  PyObject *__pyx_v_size2 = 0;
  PyObject *__pyx_v_stride2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("newWithStorage3d (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_storage,&__pyx_n_s_offset,&__pyx_n_s_size0,&__pyx_n_s_stride0,&__pyx_n_s_size1,&__pyx_n_s_stride1,&__pyx_n_s_size2,&__pyx_n_s_stride2,0};
    PyObject* values[8] = {0,0,0,0,0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  8: values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_storage)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_offset)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage3d", 1, 8, 8, 1); __PYX_ERR(0, 1792, __pyx_L3_error)
        }
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size0)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage3d", 1, 8, 8, 2); __PYX_ERR(0, 1792, __pyx_L3_error)
        }
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride0)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage3d", 1, 8, 8, 3); __PYX_ERR(0, 1792, __pyx_L3_error)
        }
        case  4:
        if (likely((values[4] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage3d", 1, 8, 8, 4); __PYX_ERR(0, 1792, __pyx_L3_error)
        }
        case  5:
        if (likely((values[5] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage3d", 1, 8, 8, 5); __PYX_ERR(0, 1792, __pyx_L3_error)
        }
        case  6:
        if (likely((values[6] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage3d", 1, 8, 8, 6); __PYX_ERR(0, 1792, __pyx_L3_error)
        }
        case  7:
        if (likely((values[7] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage3d", 1, 8, 8, 7); __PYX_ERR(0, 1792, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "newWithStorage3d") < 0)) __PYX_ERR(0, 1792, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 8) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
      values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
      values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
      values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
      values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
    }
    __pyx_v_storage = ((struct __pyx_obj_7Storage__DoubleStorage *)values[0]);
    __pyx_v_offset = values[1];
    __pyx_v_size0 = values[2];
    __pyx_v_stride0 = values[3];
    __pyx_v_size1 = values[4];
    __pyx_v_stride1 = values[5];
    __pyx_v_size2 = values[6];
    __pyx_v_stride2 = values[7];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("newWithStorage3d", 1, 8, 8, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1792, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._DoubleTensor.newWithStorage3d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_storage), __pyx_ptype_7Storage__DoubleStorage, 1, "storage", 0))) __PYX_ERR(0, 1792, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_82newWithStorage3d(__pyx_v_storage, __pyx_v_offset, __pyx_v_size0, __pyx_v_stride0, __pyx_v_size1, __pyx_v_stride1, __pyx_v_size2, __pyx_v_stride2);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_82newWithStorage3d(struct __pyx_obj_7Storage__DoubleStorage *__pyx_v_storage, PyObject *__pyx_v_offset, PyObject *__pyx_v_size0, PyObject *__pyx_v_stride0, PyObject *__pyx_v_size1, PyObject *__pyx_v_stride1, PyObject *__pyx_v_size2, PyObject *__pyx_v_stride2) {
  struct THDoubleTensor *__pyx_v_newTensorC;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  long __pyx_t_1;
  long __pyx_t_2;
  long __pyx_t_3;
  long __pyx_t_4;
  long __pyx_t_5;
  long __pyx_t_6;
  long __pyx_t_7;
  PyObject *__pyx_t_8 = NULL;
  struct __pyx_opt_args_7PyTorch__DoubleTensor_fromNative __pyx_t_9;
  __Pyx_RefNannySetupContext("newWithStorage3d", 0);

  /* "PyTorch.pyx":1794
 *     def newWithStorage3d(Storage._DoubleStorage storage, offset, size0, stride0, size1, stride1, size2, stride2):
 * #        # print('allocate tensor')
 *         cdef THDoubleTensor *newTensorC = THDoubleTensor_newWithStorage3d(storage.native, offset, size0, stride0, size1, stride1,             # <<<<<<<<<<<<<<
 *             size2, stride2)
 *         return _DoubleTensor_fromNative(newTensorC, False)
 */
  __pyx_t_1 = __Pyx_PyInt_As_long(__pyx_v_offset); if (unlikely((__pyx_t_1 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1794, __pyx_L1_error)
  __pyx_t_2 = __Pyx_PyInt_As_long(__pyx_v_size0); if (unlikely((__pyx_t_2 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1794, __pyx_L1_error)
  __pyx_t_3 = __Pyx_PyInt_As_long(__pyx_v_stride0); if (unlikely((__pyx_t_3 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1794, __pyx_L1_error)
  __pyx_t_4 = __Pyx_PyInt_As_long(__pyx_v_size1); if (unlikely((__pyx_t_4 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1794, __pyx_L1_error)
  __pyx_t_5 = __Pyx_PyInt_As_long(__pyx_v_stride1); if (unlikely((__pyx_t_5 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1794, __pyx_L1_error)

  /* "PyTorch.pyx":1795
 * #        # print('allocate tensor')
 *         cdef THDoubleTensor *newTensorC = THDoubleTensor_newWithStorage3d(storage.native, offset, size0, stride0, size1, stride1,
 *             size2, stride2)             # <<<<<<<<<<<<<<
 *         return _DoubleTensor_fromNative(newTensorC, False)
 * 
 */
  __pyx_t_6 = __Pyx_PyInt_As_long(__pyx_v_size2); if (unlikely((__pyx_t_6 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1795, __pyx_L1_error)
  __pyx_t_7 = __Pyx_PyInt_As_long(__pyx_v_stride2); if (unlikely((__pyx_t_7 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1795, __pyx_L1_error)

  /* "PyTorch.pyx":1794
 *     def newWithStorage3d(Storage._DoubleStorage storage, offset, size0, stride0, size1, stride1, size2, stride2):
 * #        # print('allocate tensor')
 *         cdef THDoubleTensor *newTensorC = THDoubleTensor_newWithStorage3d(storage.native, offset, size0, stride0, size1, stride1,             # <<<<<<<<<<<<<<
 *             size2, stride2)
 *         return _DoubleTensor_fromNative(newTensorC, False)
 */
  __pyx_v_newTensorC = THDoubleTensor_newWithStorage3d(__pyx_v_storage->native, __pyx_t_1, __pyx_t_2, __pyx_t_3, __pyx_t_4, __pyx_t_5, __pyx_t_6, __pyx_t_7);

  /* "PyTorch.pyx":1796
 *         cdef THDoubleTensor *newTensorC = THDoubleTensor_newWithStorage3d(storage.native, offset, size0, stride0, size1, stride1,
 *             size2, stride2)
 *         return _DoubleTensor_fromNative(newTensorC, False)             # <<<<<<<<<<<<<<
 * 
 *     @staticmethod
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_9.__pyx_n = 1;
  __pyx_t_9.retain = Py_False;
  __pyx_t_8 = __pyx_f_7PyTorch__DoubleTensor_fromNative(__pyx_v_newTensorC, &__pyx_t_9); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1796, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __pyx_r = __pyx_t_8;
  __pyx_t_8 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":1792
 * 
 *     @staticmethod
 *     def newWithStorage3d(Storage._DoubleStorage storage, offset, size0, stride0, size1, stride1, size2, stride2):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THDoubleTensor *newTensorC = THDoubleTensor_newWithStorage3d(storage.native, offset, size0, stride0, size1, stride1,
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.newWithStorage3d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1799
 * 
 *     @staticmethod
 *     def newWithStorage4d(Storage._DoubleStorage storage, offset, size0, stride0, size1, stride1, size2, stride2,             # <<<<<<<<<<<<<<
 *             size3, stride3):
 * #        # print('allocate tensor')
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_85newWithStorage4d(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_7PyTorch_13_DoubleTensor_85newWithStorage4d = {"newWithStorage4d", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_85newWithStorage4d, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_85newWithStorage4d(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  struct __pyx_obj_7Storage__DoubleStorage *__pyx_v_storage = 0;
  PyObject *__pyx_v_offset = 0;
  PyObject *__pyx_v_size0 = 0;
  PyObject *__pyx_v_stride0 = 0;
  PyObject *__pyx_v_size1 = 0;
  PyObject *__pyx_v_stride1 = 0;
  PyObject *__pyx_v_size2 = 0;
  PyObject *__pyx_v_stride2 = 0;
  PyObject *__pyx_v_size3 = 0;
  PyObject *__pyx_v_stride3 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("newWithStorage4d (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_storage,&__pyx_n_s_offset,&__pyx_n_s_size0,&__pyx_n_s_stride0,&__pyx_n_s_size1,&__pyx_n_s_stride1,&__pyx_n_s_size2,&__pyx_n_s_stride2,&__pyx_n_s_size3,&__pyx_n_s_stride3,0};
    PyObject* values[10] = {0,0,0,0,0,0,0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case 10: values[9] = PyTuple_GET_ITEM(__pyx_args, 9);
        case  9: values[8] = PyTuple_GET_ITEM(__pyx_args, 8);
        case  8: values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_storage)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_offset)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage4d", 1, 10, 10, 1); __PYX_ERR(0, 1799, __pyx_L3_error)
        }
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size0)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage4d", 1, 10, 10, 2); __PYX_ERR(0, 1799, __pyx_L3_error)
        }
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride0)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage4d", 1, 10, 10, 3); __PYX_ERR(0, 1799, __pyx_L3_error)
        }
        case  4:
        if (likely((values[4] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage4d", 1, 10, 10, 4); __PYX_ERR(0, 1799, __pyx_L3_error)
        }
        case  5:
        if (likely((values[5] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage4d", 1, 10, 10, 5); __PYX_ERR(0, 1799, __pyx_L3_error)
        }
        case  6:
        if (likely((values[6] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage4d", 1, 10, 10, 6); __PYX_ERR(0, 1799, __pyx_L3_error)
        }
        case  7:
        if (likely((values[7] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage4d", 1, 10, 10, 7); __PYX_ERR(0, 1799, __pyx_L3_error)
        }
        case  8:
        if (likely((values[8] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size3)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage4d", 1, 10, 10, 8); __PYX_ERR(0, 1799, __pyx_L3_error)
        }
        case  9:
        if (likely((values[9] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride3)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage4d", 1, 10, 10, 9); __PYX_ERR(0, 1799, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "newWithStorage4d") < 0)) __PYX_ERR(0, 1799, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 10) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
      values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
      values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
      values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
      values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
      values[8] = PyTuple_GET_ITEM(__pyx_args, 8);
      values[9] = PyTuple_GET_ITEM(__pyx_args, 9);
    }
    __pyx_v_storage = ((struct __pyx_obj_7Storage__DoubleStorage *)values[0]);
    __pyx_v_offset = values[1];
    __pyx_v_size0 = values[2];
    __pyx_v_stride0 = values[3];
    __pyx_v_size1 = values[4];
    __pyx_v_stride1 = values[5];
    __pyx_v_size2 = values[6];
    __pyx_v_stride2 = values[7];
    __pyx_v_size3 = values[8];
    __pyx_v_stride3 = values[9];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("newWithStorage4d", 1, 10, 10, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1799, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._DoubleTensor.newWithStorage4d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_storage), __pyx_ptype_7Storage__DoubleStorage, 1, "storage", 0))) __PYX_ERR(0, 1799, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_84newWithStorage4d(__pyx_v_storage, __pyx_v_offset, __pyx_v_size0, __pyx_v_stride0, __pyx_v_size1, __pyx_v_stride1, __pyx_v_size2, __pyx_v_stride2, __pyx_v_size3, __pyx_v_stride3);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_84newWithStorage4d(struct __pyx_obj_7Storage__DoubleStorage *__pyx_v_storage, PyObject *__pyx_v_offset, PyObject *__pyx_v_size0, PyObject *__pyx_v_stride0, PyObject *__pyx_v_size1, PyObject *__pyx_v_stride1, PyObject *__pyx_v_size2, PyObject *__pyx_v_stride2, PyObject *__pyx_v_size3, PyObject *__pyx_v_stride3) {
  struct THDoubleTensor *__pyx_v_newTensorC;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  long __pyx_t_1;
  long __pyx_t_2;
  long __pyx_t_3;
  long __pyx_t_4;
  long __pyx_t_5;
  long __pyx_t_6;
  long __pyx_t_7;
  long __pyx_t_8;
  long __pyx_t_9;
  PyObject *__pyx_t_10 = NULL;
  struct __pyx_opt_args_7PyTorch__DoubleTensor_fromNative __pyx_t_11;
  __Pyx_RefNannySetupContext("newWithStorage4d", 0);

  /* "PyTorch.pyx":1802
 *             size3, stride3):
 * #        # print('allocate tensor')
 *         cdef THDoubleTensor *newTensorC = THDoubleTensor_newWithStorage4d(storage.native, offset, size0, stride0, size1, stride1,             # <<<<<<<<<<<<<<
 *             size2, stride2, size3, stride3)
 *         return _DoubleTensor_fromNative(newTensorC, False)
 */
  __pyx_t_1 = __Pyx_PyInt_As_long(__pyx_v_offset); if (unlikely((__pyx_t_1 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1802, __pyx_L1_error)
  __pyx_t_2 = __Pyx_PyInt_As_long(__pyx_v_size0); if (unlikely((__pyx_t_2 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1802, __pyx_L1_error)
  __pyx_t_3 = __Pyx_PyInt_As_long(__pyx_v_stride0); if (unlikely((__pyx_t_3 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1802, __pyx_L1_error)
  __pyx_t_4 = __Pyx_PyInt_As_long(__pyx_v_size1); if (unlikely((__pyx_t_4 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1802, __pyx_L1_error)
  __pyx_t_5 = __Pyx_PyInt_As_long(__pyx_v_stride1); if (unlikely((__pyx_t_5 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1802, __pyx_L1_error)

  /* "PyTorch.pyx":1803
 * #        # print('allocate tensor')
 *         cdef THDoubleTensor *newTensorC = THDoubleTensor_newWithStorage4d(storage.native, offset, size0, stride0, size1, stride1,
 *             size2, stride2, size3, stride3)             # <<<<<<<<<<<<<<
 *         return _DoubleTensor_fromNative(newTensorC, False)
 * 
 */
  __pyx_t_6 = __Pyx_PyInt_As_long(__pyx_v_size2); if (unlikely((__pyx_t_6 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1803, __pyx_L1_error)
  __pyx_t_7 = __Pyx_PyInt_As_long(__pyx_v_stride2); if (unlikely((__pyx_t_7 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1803, __pyx_L1_error)
  __pyx_t_8 = __Pyx_PyInt_As_long(__pyx_v_size3); if (unlikely((__pyx_t_8 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1803, __pyx_L1_error)
  __pyx_t_9 = __Pyx_PyInt_As_long(__pyx_v_stride3); if (unlikely((__pyx_t_9 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 1803, __pyx_L1_error)

  /* "PyTorch.pyx":1802
 *             size3, stride3):
 * #        # print('allocate tensor')
 *         cdef THDoubleTensor *newTensorC = THDoubleTensor_newWithStorage4d(storage.native, offset, size0, stride0, size1, stride1,             # <<<<<<<<<<<<<<
 *             size2, stride2, size3, stride3)
 *         return _DoubleTensor_fromNative(newTensorC, False)
 */
  __pyx_v_newTensorC = THDoubleTensor_newWithStorage4d(__pyx_v_storage->native, __pyx_t_1, __pyx_t_2, __pyx_t_3, __pyx_t_4, __pyx_t_5, __pyx_t_6, __pyx_t_7, __pyx_t_8, __pyx_t_9);

  /* "PyTorch.pyx":1804
 *         cdef THDoubleTensor *newTensorC = THDoubleTensor_newWithStorage4d(storage.native, offset, size0, stride0, size1, stride1,
 *             size2, stride2, size3, stride3)
 *         return _DoubleTensor_fromNative(newTensorC, False)             # <<<<<<<<<<<<<<
 * 
 *     def clone(_DoubleTensor self):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_11.__pyx_n = 1;
  __pyx_t_11.retain = Py_False;
  __pyx_t_10 = __pyx_f_7PyTorch__DoubleTensor_fromNative(__pyx_v_newTensorC, &__pyx_t_11); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 1804, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __pyx_r = __pyx_t_10;
  __pyx_t_10 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":1799
 * 
 *     @staticmethod
 *     def newWithStorage4d(Storage._DoubleStorage storage, offset, size0, stride0, size1, stride1, size2, stride2,             # <<<<<<<<<<<<<<
 *             size3, stride3):
 * #        # print('allocate tensor')
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_10);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.newWithStorage4d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1806
 *         return _DoubleTensor_fromNative(newTensorC, False)
 * 
 *     def clone(_DoubleTensor self):             # <<<<<<<<<<<<<<
 *         cdef THDoubleTensor *newTensorC = THDoubleTensor_newClone(self.native)
 *         return _DoubleTensor_fromNative(newTensorC, False)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_87clone(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_87clone(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("clone (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_86clone(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_86clone(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self) {
  struct THDoubleTensor *__pyx_v_newTensorC;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  struct __pyx_opt_args_7PyTorch__DoubleTensor_fromNative __pyx_t_2;
  __Pyx_RefNannySetupContext("clone", 0);

  /* "PyTorch.pyx":1807
 * 
 *     def clone(_DoubleTensor self):
 *         cdef THDoubleTensor *newTensorC = THDoubleTensor_newClone(self.native)             # <<<<<<<<<<<<<<
 *         return _DoubleTensor_fromNative(newTensorC, False)
 * 
 */
  __pyx_v_newTensorC = THDoubleTensor_newClone(__pyx_v_self->native);

  /* "PyTorch.pyx":1808
 *     def clone(_DoubleTensor self):
 *         cdef THDoubleTensor *newTensorC = THDoubleTensor_newClone(self.native)
 *         return _DoubleTensor_fromNative(newTensorC, False)             # <<<<<<<<<<<<<<
 * 
 *     def storage(_DoubleTensor self):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2.__pyx_n = 1;
  __pyx_t_2.retain = Py_False;
  __pyx_t_1 = __pyx_f_7PyTorch__DoubleTensor_fromNative(__pyx_v_newTensorC, &__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1808, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":1806
 *         return _DoubleTensor_fromNative(newTensorC, False)
 * 
 *     def clone(_DoubleTensor self):             # <<<<<<<<<<<<<<
 *         cdef THDoubleTensor *newTensorC = THDoubleTensor_newClone(self.native)
 *         return _DoubleTensor_fromNative(newTensorC, False)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.clone", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1810
 *         return _DoubleTensor_fromNative(newTensorC, False)
 * 
 *     def storage(_DoubleTensor self):             # <<<<<<<<<<<<<<
 *         cdef Storage.THDoubleStorage *storageC = THDoubleTensor_storage(self.native)
 *         if storageC == NULL:
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_89storage(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_89storage(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("storage (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_88storage(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_88storage(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self) {
  struct THDoubleStorage *__pyx_v_storageC;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("storage", 0);

  /* "PyTorch.pyx":1811
 * 
 *     def storage(_DoubleTensor self):
 *         cdef Storage.THDoubleStorage *storageC = THDoubleTensor_storage(self.native)             # <<<<<<<<<<<<<<
 *         if storageC == NULL:
 *             return None
 */
  __pyx_v_storageC = THDoubleTensor_storage(__pyx_v_self->native);

  /* "PyTorch.pyx":1812
 *     def storage(_DoubleTensor self):
 *         cdef Storage.THDoubleStorage *storageC = THDoubleTensor_storage(self.native)
 *         if storageC == NULL:             # <<<<<<<<<<<<<<
 *             return None
 *         return Storage._DoubleStorage_fromNative(storageC)
 */
  __pyx_t_1 = ((__pyx_v_storageC == NULL) != 0);
  if (__pyx_t_1) {

    /* "PyTorch.pyx":1813
 *         cdef Storage.THDoubleStorage *storageC = THDoubleTensor_storage(self.native)
 *         if storageC == NULL:
 *             return None             # <<<<<<<<<<<<<<
 *         return Storage._DoubleStorage_fromNative(storageC)
 * 
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(Py_None);
    __pyx_r = Py_None;
    goto __pyx_L0;

    /* "PyTorch.pyx":1812
 *     def storage(_DoubleTensor self):
 *         cdef Storage.THDoubleStorage *storageC = THDoubleTensor_storage(self.native)
 *         if storageC == NULL:             # <<<<<<<<<<<<<<
 *             return None
 *         return Storage._DoubleStorage_fromNative(storageC)
 */
  }

  /* "PyTorch.pyx":1814
 *         if storageC == NULL:
 *             return None
 *         return Storage._DoubleStorage_fromNative(storageC)             # <<<<<<<<<<<<<<
 * 
 *     def __add__(_DoubleTensor self, second):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2 = __pyx_f_7Storage__DoubleStorage_fromNative(__pyx_v_storageC, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1814, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":1810
 *         return _DoubleTensor_fromNative(newTensorC, False)
 * 
 *     def storage(_DoubleTensor self):             # <<<<<<<<<<<<<<
 *         cdef Storage.THDoubleStorage *storageC = THDoubleTensor_storage(self.native)
 *         if storageC == NULL:
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.storage", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1816
 *         return Storage._DoubleStorage_fromNative(storageC)
 * 
 *     def __add__(_DoubleTensor self, second):             # <<<<<<<<<<<<<<
 *         # assume 2d matrix for now?
 *         cdef _DoubleTensor res = _DoubleTensor.new()
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_91__add__(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_91__add__(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__add__ (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_self), __pyx_ptype_7PyTorch__DoubleTensor, 1, "self", 0))) __PYX_ERR(0, 1816, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_90__add__(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self), ((PyObject *)__pyx_v_second));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_90__add__(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, PyObject *__pyx_v_second) {
  struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_res = 0;
  struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_secondTensor = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  int __pyx_t_5;
  double __pyx_t_6;
  __Pyx_RefNannySetupContext("__add__", 0);

  /* "PyTorch.pyx":1818
 *     def __add__(_DoubleTensor self, second):
 *         # assume 2d matrix for now?
 *         cdef _DoubleTensor res = _DoubleTensor.new()             # <<<<<<<<<<<<<<
 *         cdef _DoubleTensor secondTensor
 *         if isinstance(second, numbers.Number):
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7PyTorch__DoubleTensor), __pyx_n_s_new); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1818, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1818, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1818, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_7PyTorch__DoubleTensor))))) __PYX_ERR(0, 1818, __pyx_L1_error)
  __pyx_v_res = ((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":1820
 *         cdef _DoubleTensor res = _DoubleTensor.new()
 *         cdef _DoubleTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THDoubleTensor_add(res.native, self.native, second)
 *         else:
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_numbers); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1820, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_Number); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1820, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_4 = PyObject_IsInstance(__pyx_v_second, __pyx_t_2); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 1820, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = (__pyx_t_4 != 0);
  if (__pyx_t_5) {

    /* "PyTorch.pyx":1821
 *         cdef _DoubleTensor secondTensor
 *         if isinstance(second, numbers.Number):
 *             THDoubleTensor_add(res.native, self.native, second)             # <<<<<<<<<<<<<<
 *         else:
 *             secondTensor = second
 */
    __pyx_t_6 = __pyx_PyFloat_AsDouble(__pyx_v_second); if (unlikely((__pyx_t_6 == (double)-1) && PyErr_Occurred())) __PYX_ERR(0, 1821, __pyx_L1_error)
    THDoubleTensor_add(__pyx_v_res->native, __pyx_v_self->native, __pyx_t_6);

    /* "PyTorch.pyx":1820
 *         cdef _DoubleTensor res = _DoubleTensor.new()
 *         cdef _DoubleTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THDoubleTensor_add(res.native, self.native, second)
 *         else:
 */
    goto __pyx_L3;
  }

  /* "PyTorch.pyx":1823
 *             THDoubleTensor_add(res.native, self.native, second)
 *         else:
 *             secondTensor = second             # <<<<<<<<<<<<<<
 *             THDoubleTensor_cadd(res.native, self.native, 1, secondTensor.native)
 *         return res
 */
  /*else*/ {
    if (!(likely(((__pyx_v_second) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_second, __pyx_ptype_7PyTorch__DoubleTensor))))) __PYX_ERR(0, 1823, __pyx_L1_error)
    __pyx_t_2 = __pyx_v_second;
    __Pyx_INCREF(__pyx_t_2);
    __pyx_v_secondTensor = ((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_t_2);
    __pyx_t_2 = 0;

    /* "PyTorch.pyx":1824
 *         else:
 *             secondTensor = second
 *             THDoubleTensor_cadd(res.native, self.native, 1, secondTensor.native)             # <<<<<<<<<<<<<<
 *         return res
 * 
 */
    THDoubleTensor_cadd(__pyx_v_res->native, __pyx_v_self->native, 1.0, __pyx_v_secondTensor->native);
  }
  __pyx_L3:;

  /* "PyTorch.pyx":1825
 *             secondTensor = second
 *             THDoubleTensor_cadd(res.native, self.native, 1, secondTensor.native)
 *         return res             # <<<<<<<<<<<<<<
 * 
 *     def cmul(_DoubleTensor self, second):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = ((PyObject *)__pyx_v_res);
  goto __pyx_L0;

  /* "PyTorch.pyx":1816
 *         return Storage._DoubleStorage_fromNative(storageC)
 * 
 *     def __add__(_DoubleTensor self, second):             # <<<<<<<<<<<<<<
 *         # assume 2d matrix for now?
 *         cdef _DoubleTensor res = _DoubleTensor.new()
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.__add__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XDECREF((PyObject *)__pyx_v_secondTensor);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1827
 *         return res
 * 
 *     def cmul(_DoubleTensor self, second):             # <<<<<<<<<<<<<<
 * #        cdef _DoubleTensor res = _DoubleTensor.new()
 *         cdef _DoubleTensor secondTensor
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_93cmul(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_93cmul(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cmul (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_92cmul(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self), ((PyObject *)__pyx_v_second));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_92cmul(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, PyObject *__pyx_v_second) {
  struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_secondTensor = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("cmul", 0);

  /* "PyTorch.pyx":1830
 * #        cdef _DoubleTensor res = _DoubleTensor.new()
 *         cdef _DoubleTensor secondTensor
 *         secondTensor = second             # <<<<<<<<<<<<<<
 *         THDoubleTensor_cmul(self.native, self.native, secondTensor.native)
 *         return self
 */
  if (!(likely(((__pyx_v_second) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_second, __pyx_ptype_7PyTorch__DoubleTensor))))) __PYX_ERR(0, 1830, __pyx_L1_error)
  __pyx_t_1 = __pyx_v_second;
  __Pyx_INCREF(__pyx_t_1);
  __pyx_v_secondTensor = ((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":1831
 *         cdef _DoubleTensor secondTensor
 *         secondTensor = second
 *         THDoubleTensor_cmul(self.native, self.native, secondTensor.native)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THDoubleTensor_cmul(__pyx_v_self->native, __pyx_v_self->native, __pyx_v_secondTensor->native);

  /* "PyTorch.pyx":1832
 *         secondTensor = second
 *         THDoubleTensor_cmul(self.native, self.native, secondTensor.native)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def __sub__(_DoubleTensor self, second):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1827
 *         return res
 * 
 *     def cmul(_DoubleTensor self, second):             # <<<<<<<<<<<<<<
 * #        cdef _DoubleTensor res = _DoubleTensor.new()
 *         cdef _DoubleTensor secondTensor
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.cmul", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_secondTensor);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1834
 *         return self
 * 
 *     def __sub__(_DoubleTensor self, second):             # <<<<<<<<<<<<<<
 *         # assume 2d matrix for now?
 *         cdef _DoubleTensor res = _DoubleTensor.new()
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_95__sub__(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_95__sub__(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__sub__ (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_self), __pyx_ptype_7PyTorch__DoubleTensor, 1, "self", 0))) __PYX_ERR(0, 1834, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_94__sub__(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self), ((PyObject *)__pyx_v_second));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_94__sub__(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, PyObject *__pyx_v_second) {
  struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_res = 0;
  struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_secondTensor = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  int __pyx_t_5;
  double __pyx_t_6;
  __Pyx_RefNannySetupContext("__sub__", 0);

  /* "PyTorch.pyx":1836
 *     def __sub__(_DoubleTensor self, second):
 *         # assume 2d matrix for now?
 *         cdef _DoubleTensor res = _DoubleTensor.new()             # <<<<<<<<<<<<<<
 *         cdef _DoubleTensor secondTensor
 *         if isinstance(second, numbers.Number):
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7PyTorch__DoubleTensor), __pyx_n_s_new); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1836, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1836, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1836, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_7PyTorch__DoubleTensor))))) __PYX_ERR(0, 1836, __pyx_L1_error)
  __pyx_v_res = ((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":1838
 *         cdef _DoubleTensor res = _DoubleTensor.new()
 *         cdef _DoubleTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THDoubleTensor_add(res.native, self.native, -second)
 *         else:
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_numbers); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1838, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_Number); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1838, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_4 = PyObject_IsInstance(__pyx_v_second, __pyx_t_2); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 1838, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = (__pyx_t_4 != 0);
  if (__pyx_t_5) {

    /* "PyTorch.pyx":1839
 *         cdef _DoubleTensor secondTensor
 *         if isinstance(second, numbers.Number):
 *             THDoubleTensor_add(res.native, self.native, -second)             # <<<<<<<<<<<<<<
 *         else:
 *             secondTensor = second
 */
    __pyx_t_2 = PyNumber_Negative(__pyx_v_second); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1839, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_6 = __pyx_PyFloat_AsDouble(__pyx_t_2); if (unlikely((__pyx_t_6 == (double)-1) && PyErr_Occurred())) __PYX_ERR(0, 1839, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    THDoubleTensor_add(__pyx_v_res->native, __pyx_v_self->native, __pyx_t_6);

    /* "PyTorch.pyx":1838
 *         cdef _DoubleTensor res = _DoubleTensor.new()
 *         cdef _DoubleTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THDoubleTensor_add(res.native, self.native, -second)
 *         else:
 */
    goto __pyx_L3;
  }

  /* "PyTorch.pyx":1841
 *             THDoubleTensor_add(res.native, self.native, -second)
 *         else:
 *             secondTensor = second             # <<<<<<<<<<<<<<
 *             THDoubleTensor_cadd(res.native, self.native, -1, secondTensor.native)
 *         return res
 */
  /*else*/ {
    if (!(likely(((__pyx_v_second) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_second, __pyx_ptype_7PyTorch__DoubleTensor))))) __PYX_ERR(0, 1841, __pyx_L1_error)
    __pyx_t_2 = __pyx_v_second;
    __Pyx_INCREF(__pyx_t_2);
    __pyx_v_secondTensor = ((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_t_2);
    __pyx_t_2 = 0;

    /* "PyTorch.pyx":1842
 *         else:
 *             secondTensor = second
 *             THDoubleTensor_cadd(res.native, self.native, -1, secondTensor.native)             # <<<<<<<<<<<<<<
 *         return res
 * 
 */
    THDoubleTensor_cadd(__pyx_v_res->native, __pyx_v_self->native, -1.0, __pyx_v_secondTensor->native);
  }
  __pyx_L3:;

  /* "PyTorch.pyx":1843
 *             secondTensor = second
 *             THDoubleTensor_cadd(res.native, self.native, -1, secondTensor.native)
 *         return res             # <<<<<<<<<<<<<<
 * 
 *     def eq(_DoubleTensor self, _DoubleTensor second):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = ((PyObject *)__pyx_v_res);
  goto __pyx_L0;

  /* "PyTorch.pyx":1834
 *         return self
 * 
 *     def __sub__(_DoubleTensor self, second):             # <<<<<<<<<<<<<<
 *         # assume 2d matrix for now?
 *         cdef _DoubleTensor res = _DoubleTensor.new()
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.__sub__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XDECREF((PyObject *)__pyx_v_secondTensor);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1845
 *         return res
 * 
 *     def eq(_DoubleTensor self, _DoubleTensor second):             # <<<<<<<<<<<<<<
 *         cdef _ByteTensor res = _ByteTensor.new()
 *         THDoubleTensor_eqTensor(res.native, self.native, second.native);
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_97eq(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_97eq(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("eq (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_second), __pyx_ptype_7PyTorch__DoubleTensor, 1, "second", 0))) __PYX_ERR(0, 1845, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_96eq(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self), ((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_second));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_96eq(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_second) {
  struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_res = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("eq", 0);

  /* "PyTorch.pyx":1846
 * 
 *     def eq(_DoubleTensor self, _DoubleTensor second):
 *         cdef _ByteTensor res = _ByteTensor.new()             # <<<<<<<<<<<<<<
 *         THDoubleTensor_eqTensor(res.native, self.native, second.native);
 *         return res
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7PyTorch__ByteTensor), __pyx_n_s_new); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1846, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1846, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1846, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_7PyTorch__ByteTensor))))) __PYX_ERR(0, 1846, __pyx_L1_error)
  __pyx_v_res = ((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":1847
 *     def eq(_DoubleTensor self, _DoubleTensor second):
 *         cdef _ByteTensor res = _ByteTensor.new()
 *         THDoubleTensor_eqTensor(res.native, self.native, second.native);             # <<<<<<<<<<<<<<
 *         return res
 * 
 */
  THDoubleTensor_eqTensor(__pyx_v_res->native, __pyx_v_self->native, __pyx_v_second->native);

  /* "PyTorch.pyx":1848
 *         cdef _ByteTensor res = _ByteTensor.new()
 *         THDoubleTensor_eqTensor(res.native, self.native, second.native);
 *         return res             # <<<<<<<<<<<<<<
 * 
 *     def icmin(_DoubleTensor self, second):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = ((PyObject *)__pyx_v_res);
  goto __pyx_L0;

  /* "PyTorch.pyx":1845
 *         return res
 * 
 *     def eq(_DoubleTensor self, _DoubleTensor second):             # <<<<<<<<<<<<<<
 *         cdef _ByteTensor res = _ByteTensor.new()
 *         THDoubleTensor_eqTensor(res.native, self.native, second.native);
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.eq", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1850
 *         return res
 * 
 *     def icmin(_DoubleTensor self, second):             # <<<<<<<<<<<<<<
 *       THDoubleTensor_cminValue(self.native, self.native, second)
 *       return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_99icmin(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_99icmin(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("icmin (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_98icmin(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self), ((PyObject *)__pyx_v_second));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_98icmin(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  double __pyx_t_1;
  __Pyx_RefNannySetupContext("icmin", 0);

  /* "PyTorch.pyx":1851
 * 
 *     def icmin(_DoubleTensor self, second):
 *       THDoubleTensor_cminValue(self.native, self.native, second)             # <<<<<<<<<<<<<<
 *       return self
 * 
 */
  __pyx_t_1 = __pyx_PyFloat_AsDouble(__pyx_v_second); if (unlikely((__pyx_t_1 == (double)-1) && PyErr_Occurred())) __PYX_ERR(0, 1851, __pyx_L1_error)
  THDoubleTensor_cminValue(__pyx_v_self->native, __pyx_v_self->native, __pyx_t_1);

  /* "PyTorch.pyx":1852
 *     def icmin(_DoubleTensor self, second):
 *       THDoubleTensor_cminValue(self.native, self.native, second)
 *       return self             # <<<<<<<<<<<<<<
 * 
 *     def icmax(_DoubleTensor self, second):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1850
 *         return res
 * 
 *     def icmin(_DoubleTensor self, second):             # <<<<<<<<<<<<<<
 *       THDoubleTensor_cminValue(self.native, self.native, second)
 *       return self
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("PyTorch._DoubleTensor.icmin", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1854
 *       return self
 * 
 *     def icmax(_DoubleTensor self, second):             # <<<<<<<<<<<<<<
 *       THDoubleTensor_cmaxValue(self.native, self.native, second)
 *       return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_101icmax(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_101icmax(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("icmax (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_100icmax(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self), ((PyObject *)__pyx_v_second));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_100icmax(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  double __pyx_t_1;
  __Pyx_RefNannySetupContext("icmax", 0);

  /* "PyTorch.pyx":1855
 * 
 *     def icmax(_DoubleTensor self, second):
 *       THDoubleTensor_cmaxValue(self.native, self.native, second)             # <<<<<<<<<<<<<<
 *       return self
 * 
 */
  __pyx_t_1 = __pyx_PyFloat_AsDouble(__pyx_v_second); if (unlikely((__pyx_t_1 == (double)-1) && PyErr_Occurred())) __PYX_ERR(0, 1855, __pyx_L1_error)
  THDoubleTensor_cmaxValue(__pyx_v_self->native, __pyx_v_self->native, __pyx_t_1);

  /* "PyTorch.pyx":1856
 *     def icmax(_DoubleTensor self, second):
 *       THDoubleTensor_cmaxValue(self.native, self.native, second)
 *       return self             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1854
 *       return self
 * 
 *     def icmax(_DoubleTensor self, second):             # <<<<<<<<<<<<<<
 *       THDoubleTensor_cmaxValue(self.native, self.native, second)
 *       return self
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("PyTorch._DoubleTensor.icmax", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1859
 * 
 * 
 *     def __truediv__(_DoubleTensor self, second):             # <<<<<<<<<<<<<<
 *         cdef _DoubleTensor res = _DoubleTensor.new()
 *         cdef _DoubleTensor secondTensor
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_103__truediv__(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_103__truediv__(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__truediv__ (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_self), __pyx_ptype_7PyTorch__DoubleTensor, 1, "self", 0))) __PYX_ERR(0, 1859, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_102__truediv__(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self), ((PyObject *)__pyx_v_second));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_102__truediv__(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, PyObject *__pyx_v_second) {
  struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_res = 0;
  struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_secondTensor = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  int __pyx_t_5;
  double __pyx_t_6;
  __Pyx_RefNannySetupContext("__truediv__", 0);

  /* "PyTorch.pyx":1860
 * 
 *     def __truediv__(_DoubleTensor self, second):
 *         cdef _DoubleTensor res = _DoubleTensor.new()             # <<<<<<<<<<<<<<
 *         cdef _DoubleTensor secondTensor
 *         if isinstance(second, numbers.Number):
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7PyTorch__DoubleTensor), __pyx_n_s_new); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1860, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1860, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1860, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_7PyTorch__DoubleTensor))))) __PYX_ERR(0, 1860, __pyx_L1_error)
  __pyx_v_res = ((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":1862
 *         cdef _DoubleTensor res = _DoubleTensor.new()
 *         cdef _DoubleTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THDoubleTensor_div(res.native, self.native, second)
 *         else:
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_numbers); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1862, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_Number); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1862, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_4 = PyObject_IsInstance(__pyx_v_second, __pyx_t_2); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 1862, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = (__pyx_t_4 != 0);
  if (__pyx_t_5) {

    /* "PyTorch.pyx":1863
 *         cdef _DoubleTensor secondTensor
 *         if isinstance(second, numbers.Number):
 *             THDoubleTensor_div(res.native, self.native, second)             # <<<<<<<<<<<<<<
 *         else:
 *             secondTensor = second
 */
    __pyx_t_6 = __pyx_PyFloat_AsDouble(__pyx_v_second); if (unlikely((__pyx_t_6 == (double)-1) && PyErr_Occurred())) __PYX_ERR(0, 1863, __pyx_L1_error)
    THDoubleTensor_div(__pyx_v_res->native, __pyx_v_self->native, __pyx_t_6);

    /* "PyTorch.pyx":1862
 *         cdef _DoubleTensor res = _DoubleTensor.new()
 *         cdef _DoubleTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THDoubleTensor_div(res.native, self.native, second)
 *         else:
 */
    goto __pyx_L3;
  }

  /* "PyTorch.pyx":1865
 *             THDoubleTensor_div(res.native, self.native, second)
 *         else:
 *             secondTensor = second             # <<<<<<<<<<<<<<
 *             THDoubleTensor_cdiv(res.native, self.native, secondTensor.native)
 *         return res
 */
  /*else*/ {
    if (!(likely(((__pyx_v_second) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_second, __pyx_ptype_7PyTorch__DoubleTensor))))) __PYX_ERR(0, 1865, __pyx_L1_error)
    __pyx_t_2 = __pyx_v_second;
    __Pyx_INCREF(__pyx_t_2);
    __pyx_v_secondTensor = ((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_t_2);
    __pyx_t_2 = 0;

    /* "PyTorch.pyx":1866
 *         else:
 *             secondTensor = second
 *             THDoubleTensor_cdiv(res.native, self.native, secondTensor.native)             # <<<<<<<<<<<<<<
 *         return res
 * 
 */
    THDoubleTensor_cdiv(__pyx_v_res->native, __pyx_v_self->native, __pyx_v_secondTensor->native);
  }
  __pyx_L3:;

  /* "PyTorch.pyx":1867
 *             secondTensor = second
 *             THDoubleTensor_cdiv(res.native, self.native, secondTensor.native)
 *         return res             # <<<<<<<<<<<<<<
 * 
 *     def __itruediv__(_DoubleTensor self, second):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = ((PyObject *)__pyx_v_res);
  goto __pyx_L0;

  /* "PyTorch.pyx":1859
 * 
 * 
 *     def __truediv__(_DoubleTensor self, second):             # <<<<<<<<<<<<<<
 *         cdef _DoubleTensor res = _DoubleTensor.new()
 *         cdef _DoubleTensor secondTensor
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.__truediv__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XDECREF((PyObject *)__pyx_v_secondTensor);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1869
 *         return res
 * 
 *     def __itruediv__(_DoubleTensor self, second):             # <<<<<<<<<<<<<<
 *         cdef _DoubleTensor secondTensor
 *         if isinstance(second, numbers.Number):
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_105__itruediv__(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_105__itruediv__(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__itruediv__ (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_104__itruediv__(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self), ((PyObject *)__pyx_v_second));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_104__itruediv__(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, PyObject *__pyx_v_second) {
  struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_secondTensor = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  int __pyx_t_4;
  double __pyx_t_5;
  __Pyx_RefNannySetupContext("__itruediv__", 0);

  /* "PyTorch.pyx":1871
 *     def __itruediv__(_DoubleTensor self, second):
 *         cdef _DoubleTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THDoubleTensor_div(self.native, self.native, second)
 *         else:
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_numbers); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1871, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_Number); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1871, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = PyObject_IsInstance(__pyx_v_second, __pyx_t_2); if (unlikely(__pyx_t_3 == -1)) __PYX_ERR(0, 1871, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_4 = (__pyx_t_3 != 0);
  if (__pyx_t_4) {

    /* "PyTorch.pyx":1872
 *         cdef _DoubleTensor secondTensor
 *         if isinstance(second, numbers.Number):
 *             THDoubleTensor_div(self.native, self.native, second)             # <<<<<<<<<<<<<<
 *         else:
 *             secondTensor = second
 */
    __pyx_t_5 = __pyx_PyFloat_AsDouble(__pyx_v_second); if (unlikely((__pyx_t_5 == (double)-1) && PyErr_Occurred())) __PYX_ERR(0, 1872, __pyx_L1_error)
    THDoubleTensor_div(__pyx_v_self->native, __pyx_v_self->native, __pyx_t_5);

    /* "PyTorch.pyx":1871
 *     def __itruediv__(_DoubleTensor self, second):
 *         cdef _DoubleTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THDoubleTensor_div(self.native, self.native, second)
 *         else:
 */
    goto __pyx_L3;
  }

  /* "PyTorch.pyx":1874
 *             THDoubleTensor_div(self.native, self.native, second)
 *         else:
 *             secondTensor = second             # <<<<<<<<<<<<<<
 *             THDoubleTensor_cdiv(self.native, self.native, secondTensor.native)
 *         return self
 */
  /*else*/ {
    if (!(likely(((__pyx_v_second) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_second, __pyx_ptype_7PyTorch__DoubleTensor))))) __PYX_ERR(0, 1874, __pyx_L1_error)
    __pyx_t_2 = __pyx_v_second;
    __Pyx_INCREF(__pyx_t_2);
    __pyx_v_secondTensor = ((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_t_2);
    __pyx_t_2 = 0;

    /* "PyTorch.pyx":1875
 *         else:
 *             secondTensor = second
 *             THDoubleTensor_cdiv(self.native, self.native, secondTensor.native)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
    THDoubleTensor_cdiv(__pyx_v_self->native, __pyx_v_self->native, __pyx_v_secondTensor->native);
  }
  __pyx_L3:;

  /* "PyTorch.pyx":1876
 *             secondTensor = second
 *             THDoubleTensor_cdiv(self.native, self.native, secondTensor.native)
 *         return self             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1869
 *         return res
 * 
 *     def __itruediv__(_DoubleTensor self, second):             # <<<<<<<<<<<<<<
 *         cdef _DoubleTensor secondTensor
 *         if isinstance(second, numbers.Number):
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.__itruediv__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_secondTensor);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1879
 * 
 * 
 *     def __iadd__(_DoubleTensor self, second):             # <<<<<<<<<<<<<<
 *         cdef _DoubleTensor secondTensor
 *         if isinstance(second, numbers.Number):
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_107__iadd__(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_107__iadd__(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__iadd__ (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_106__iadd__(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self), ((PyObject *)__pyx_v_second));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_106__iadd__(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, PyObject *__pyx_v_second) {
  struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_secondTensor = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  int __pyx_t_4;
  double __pyx_t_5;
  __Pyx_RefNannySetupContext("__iadd__", 0);

  /* "PyTorch.pyx":1881
 *     def __iadd__(_DoubleTensor self, second):
 *         cdef _DoubleTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THDoubleTensor_add(self.native, self.native, second)
 *         else:
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_numbers); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1881, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_Number); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1881, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = PyObject_IsInstance(__pyx_v_second, __pyx_t_2); if (unlikely(__pyx_t_3 == -1)) __PYX_ERR(0, 1881, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_4 = (__pyx_t_3 != 0);
  if (__pyx_t_4) {

    /* "PyTorch.pyx":1882
 *         cdef _DoubleTensor secondTensor
 *         if isinstance(second, numbers.Number):
 *             THDoubleTensor_add(self.native, self.native, second)             # <<<<<<<<<<<<<<
 *         else:
 *             secondTensor = second
 */
    __pyx_t_5 = __pyx_PyFloat_AsDouble(__pyx_v_second); if (unlikely((__pyx_t_5 == (double)-1) && PyErr_Occurred())) __PYX_ERR(0, 1882, __pyx_L1_error)
    THDoubleTensor_add(__pyx_v_self->native, __pyx_v_self->native, __pyx_t_5);

    /* "PyTorch.pyx":1881
 *     def __iadd__(_DoubleTensor self, second):
 *         cdef _DoubleTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THDoubleTensor_add(self.native, self.native, second)
 *         else:
 */
    goto __pyx_L3;
  }

  /* "PyTorch.pyx":1884
 *             THDoubleTensor_add(self.native, self.native, second)
 *         else:
 *             secondTensor = second             # <<<<<<<<<<<<<<
 *             THDoubleTensor_cadd(self.native, self.native, 1, secondTensor.native)
 *         return self
 */
  /*else*/ {
    if (!(likely(((__pyx_v_second) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_second, __pyx_ptype_7PyTorch__DoubleTensor))))) __PYX_ERR(0, 1884, __pyx_L1_error)
    __pyx_t_2 = __pyx_v_second;
    __Pyx_INCREF(__pyx_t_2);
    __pyx_v_secondTensor = ((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_t_2);
    __pyx_t_2 = 0;

    /* "PyTorch.pyx":1885
 *         else:
 *             secondTensor = second
 *             THDoubleTensor_cadd(self.native, self.native, 1, secondTensor.native)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
    THDoubleTensor_cadd(__pyx_v_self->native, __pyx_v_self->native, 1.0, __pyx_v_secondTensor->native);
  }
  __pyx_L3:;

  /* "PyTorch.pyx":1886
 *             secondTensor = second
 *             THDoubleTensor_cadd(self.native, self.native, 1, secondTensor.native)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def __isub__(_DoubleTensor self, second):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1879
 * 
 * 
 *     def __iadd__(_DoubleTensor self, second):             # <<<<<<<<<<<<<<
 *         cdef _DoubleTensor secondTensor
 *         if isinstance(second, numbers.Number):
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.__iadd__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_secondTensor);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1888
 *         return self
 * 
 *     def __isub__(_DoubleTensor self, second):             # <<<<<<<<<<<<<<
 *         cdef _DoubleTensor secondTensor
 *         if isinstance(second, numbers.Number):
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_109__isub__(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_109__isub__(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__isub__ (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_108__isub__(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self), ((PyObject *)__pyx_v_second));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_108__isub__(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, PyObject *__pyx_v_second) {
  struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_secondTensor = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  int __pyx_t_4;
  double __pyx_t_5;
  __Pyx_RefNannySetupContext("__isub__", 0);

  /* "PyTorch.pyx":1890
 *     def __isub__(_DoubleTensor self, second):
 *         cdef _DoubleTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THDoubleTensor_add(self.native, self.native, -second)
 *         else:
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_numbers); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1890, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_Number); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1890, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = PyObject_IsInstance(__pyx_v_second, __pyx_t_2); if (unlikely(__pyx_t_3 == -1)) __PYX_ERR(0, 1890, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_4 = (__pyx_t_3 != 0);
  if (__pyx_t_4) {

    /* "PyTorch.pyx":1891
 *         cdef _DoubleTensor secondTensor
 *         if isinstance(second, numbers.Number):
 *             THDoubleTensor_add(self.native, self.native, -second)             # <<<<<<<<<<<<<<
 *         else:
 *             secondTensor = second
 */
    __pyx_t_2 = PyNumber_Negative(__pyx_v_second); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1891, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_5 = __pyx_PyFloat_AsDouble(__pyx_t_2); if (unlikely((__pyx_t_5 == (double)-1) && PyErr_Occurred())) __PYX_ERR(0, 1891, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    THDoubleTensor_add(__pyx_v_self->native, __pyx_v_self->native, __pyx_t_5);

    /* "PyTorch.pyx":1890
 *     def __isub__(_DoubleTensor self, second):
 *         cdef _DoubleTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THDoubleTensor_add(self.native, self.native, -second)
 *         else:
 */
    goto __pyx_L3;
  }

  /* "PyTorch.pyx":1893
 *             THDoubleTensor_add(self.native, self.native, -second)
 *         else:
 *             secondTensor = second             # <<<<<<<<<<<<<<
 *             THDoubleTensor_cadd(self.native, self.native, -1, secondTensor.native)
 *         return self
 */
  /*else*/ {
    if (!(likely(((__pyx_v_second) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_second, __pyx_ptype_7PyTorch__DoubleTensor))))) __PYX_ERR(0, 1893, __pyx_L1_error)
    __pyx_t_2 = __pyx_v_second;
    __Pyx_INCREF(__pyx_t_2);
    __pyx_v_secondTensor = ((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_t_2);
    __pyx_t_2 = 0;

    /* "PyTorch.pyx":1894
 *         else:
 *             secondTensor = second
 *             THDoubleTensor_cadd(self.native, self.native, -1, secondTensor.native)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
    THDoubleTensor_cadd(__pyx_v_self->native, __pyx_v_self->native, -1.0, __pyx_v_secondTensor->native);
  }
  __pyx_L3:;

  /* "PyTorch.pyx":1895
 *             secondTensor = second
 *             THDoubleTensor_cadd(self.native, self.native, -1, secondTensor.native)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def __imul__(_DoubleTensor self, double value):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1888
 *         return self
 * 
 *     def __isub__(_DoubleTensor self, second):             # <<<<<<<<<<<<<<
 *         cdef _DoubleTensor secondTensor
 *         if isinstance(second, numbers.Number):
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.__isub__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_secondTensor);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1897
 *         return self
 * 
 *     def __imul__(_DoubleTensor self, double value):             # <<<<<<<<<<<<<<
 *         THDoubleTensor_mul(self.native, self.native, value)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_111__imul__(PyObject *__pyx_v_self, PyObject *__pyx_arg_value); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_111__imul__(PyObject *__pyx_v_self, PyObject *__pyx_arg_value) {
  double __pyx_v_value;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__imul__ (wrapper)", 0);
  assert(__pyx_arg_value); {
    __pyx_v_value = __pyx_PyFloat_AsDouble(__pyx_arg_value); if (unlikely((__pyx_v_value == (double)-1) && PyErr_Occurred())) __PYX_ERR(0, 1897, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._DoubleTensor.__imul__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_110__imul__(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self), ((double)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_110__imul__(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, double __pyx_v_value) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__imul__", 0);

  /* "PyTorch.pyx":1898
 * 
 *     def __imul__(_DoubleTensor self, double value):
 *         THDoubleTensor_mul(self.native, self.native, value)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THDoubleTensor_mul(__pyx_v_self->native, __pyx_v_self->native, __pyx_v_value);

  /* "PyTorch.pyx":1899
 *     def __imul__(_DoubleTensor self, double value):
 *         THDoubleTensor_mul(self.native, self.native, value)
 *         return self             # <<<<<<<<<<<<<<
 * 
 * #    def __mul__(_DoubleTensor self, _DoubleTensor M2):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1897
 *         return self
 * 
 *     def __imul__(_DoubleTensor self, double value):             # <<<<<<<<<<<<<<
 *         THDoubleTensor_mul(self.native, self.native, value)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1902
 * 
 * #    def __mul__(_DoubleTensor self, _DoubleTensor M2):
 *     def __mul__(_DoubleTensor self, second):             # <<<<<<<<<<<<<<
 *         cdef _DoubleTensor M2
 *         cdef _DoubleTensor T
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_113__mul__(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_113__mul__(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__mul__ (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_self), __pyx_ptype_7PyTorch__DoubleTensor, 1, "self", 0))) __PYX_ERR(0, 1902, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_112__mul__(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self), ((PyObject *)__pyx_v_second));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_112__mul__(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, PyObject *__pyx_v_second) {
  struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_M2 = 0;
  struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_T = 0;
  struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_res = 0;
  int __pyx_v_resRows;
  int __pyx_v_resCols;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  int __pyx_t_5;
  double __pyx_t_6;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  int __pyx_t_9;
  PyObject *__pyx_t_10 = NULL;
  __Pyx_RefNannySetupContext("__mul__", 0);

  /* "PyTorch.pyx":1909
 *         cdef int resCols
 * 
 *         res = _DoubleTensor.new()             # <<<<<<<<<<<<<<
 *         if isinstance(second, numbers.Number):
 *             THDoubleTensor_mul(res.native, self.native, second)
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7PyTorch__DoubleTensor), __pyx_n_s_new); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1909, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1909, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1909, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_7PyTorch__DoubleTensor))))) __PYX_ERR(0, 1909, __pyx_L1_error)
  __pyx_v_res = ((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":1910
 * 
 *         res = _DoubleTensor.new()
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THDoubleTensor_mul(res.native, self.native, second)
 *             return res
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_numbers); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1910, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_Number); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1910, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_4 = PyObject_IsInstance(__pyx_v_second, __pyx_t_2); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 1910, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = (__pyx_t_4 != 0);
  if (__pyx_t_5) {

    /* "PyTorch.pyx":1911
 *         res = _DoubleTensor.new()
 *         if isinstance(second, numbers.Number):
 *             THDoubleTensor_mul(res.native, self.native, second)             # <<<<<<<<<<<<<<
 *             return res
 *         else:
 */
    __pyx_t_6 = __pyx_PyFloat_AsDouble(__pyx_v_second); if (unlikely((__pyx_t_6 == (double)-1) && PyErr_Occurred())) __PYX_ERR(0, 1911, __pyx_L1_error)
    THDoubleTensor_mul(__pyx_v_res->native, __pyx_v_self->native, __pyx_t_6);

    /* "PyTorch.pyx":1912
 *         if isinstance(second, numbers.Number):
 *             THDoubleTensor_mul(res.native, self.native, second)
 *             return res             # <<<<<<<<<<<<<<
 *         else:
 * 
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(((PyObject *)__pyx_v_res));
    __pyx_r = ((PyObject *)__pyx_v_res);
    goto __pyx_L0;

    /* "PyTorch.pyx":1910
 * 
 *         res = _DoubleTensor.new()
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THDoubleTensor_mul(res.native, self.native, second)
 *             return res
 */
  }

  /* "PyTorch.pyx":1915
 *         else:
 * 
 *             M2 = second             # <<<<<<<<<<<<<<
 *             T = _DoubleTensor.new()
 *             resRows = THDoubleTensor_size(self.native, 0)
 */
  /*else*/ {
    if (!(likely(((__pyx_v_second) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_second, __pyx_ptype_7PyTorch__DoubleTensor))))) __PYX_ERR(0, 1915, __pyx_L1_error)
    __pyx_t_2 = __pyx_v_second;
    __Pyx_INCREF(__pyx_t_2);
    __pyx_v_M2 = ((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_t_2);
    __pyx_t_2 = 0;

    /* "PyTorch.pyx":1916
 * 
 *             M2 = second
 *             T = _DoubleTensor.new()             # <<<<<<<<<<<<<<
 *             resRows = THDoubleTensor_size(self.native, 0)
 *             resCols = THDoubleTensor_size(M2.native, 1)
 */
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7PyTorch__DoubleTensor), __pyx_n_s_new); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1916, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_3 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_1))) {
      __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_1);
      if (likely(__pyx_t_3)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
        __Pyx_INCREF(__pyx_t_3);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_1, function);
      }
    }
    if (__pyx_t_3) {
      __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1916, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    } else {
      __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1916, __pyx_L1_error)
    }
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    if (!(likely(((__pyx_t_2) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_2, __pyx_ptype_7PyTorch__DoubleTensor))))) __PYX_ERR(0, 1916, __pyx_L1_error)
    __pyx_v_T = ((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_t_2);
    __pyx_t_2 = 0;

    /* "PyTorch.pyx":1917
 *             M2 = second
 *             T = _DoubleTensor.new()
 *             resRows = THDoubleTensor_size(self.native, 0)             # <<<<<<<<<<<<<<
 *             resCols = THDoubleTensor_size(M2.native, 1)
 *             res.resize2d(resRows, resCols)
 */
    __pyx_v_resRows = THDoubleTensor_size(__pyx_v_self->native, 0);

    /* "PyTorch.pyx":1918
 *             T = _DoubleTensor.new()
 *             resRows = THDoubleTensor_size(self.native, 0)
 *             resCols = THDoubleTensor_size(M2.native, 1)             # <<<<<<<<<<<<<<
 *             res.resize2d(resRows, resCols)
 *             T.resize2d(resRows, resCols)
 */
    __pyx_v_resCols = THDoubleTensor_size(__pyx_v_M2->native, 1);

    /* "PyTorch.pyx":1919
 *             resRows = THDoubleTensor_size(self.native, 0)
 *             resCols = THDoubleTensor_size(M2.native, 1)
 *             res.resize2d(resRows, resCols)             # <<<<<<<<<<<<<<
 *             T.resize2d(resRows, resCols)
 *             THDoubleTensor_addmm(res.native, 0, T.native, 1, self.native, M2.native)
 */
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_res), __pyx_n_s_resize2d); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1919, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_resRows); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1919, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_7 = __Pyx_PyInt_From_int(__pyx_v_resCols); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1919, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_8 = NULL;
    __pyx_t_9 = 0;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_1))) {
      __pyx_t_8 = PyMethod_GET_SELF(__pyx_t_1);
      if (likely(__pyx_t_8)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
        __Pyx_INCREF(__pyx_t_8);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_1, function);
        __pyx_t_9 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_1)) {
      PyObject *__pyx_temp[3] = {__pyx_t_8, __pyx_t_3, __pyx_t_7};
      __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_1, __pyx_temp+1-__pyx_t_9, 2+__pyx_t_9); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1919, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_1)) {
      PyObject *__pyx_temp[3] = {__pyx_t_8, __pyx_t_3, __pyx_t_7};
      __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_1, __pyx_temp+1-__pyx_t_9, 2+__pyx_t_9); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1919, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    } else
    #endif
    {
      __pyx_t_10 = PyTuple_New(2+__pyx_t_9); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 1919, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_10);
      if (__pyx_t_8) {
        __Pyx_GIVEREF(__pyx_t_8); PyTuple_SET_ITEM(__pyx_t_10, 0, __pyx_t_8); __pyx_t_8 = NULL;
      }
      __Pyx_GIVEREF(__pyx_t_3);
      PyTuple_SET_ITEM(__pyx_t_10, 0+__pyx_t_9, __pyx_t_3);
      __Pyx_GIVEREF(__pyx_t_7);
      PyTuple_SET_ITEM(__pyx_t_10, 1+__pyx_t_9, __pyx_t_7);
      __pyx_t_3 = 0;
      __pyx_t_7 = 0;
      __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_10, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1919, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

    /* "PyTorch.pyx":1920
 *             resCols = THDoubleTensor_size(M2.native, 1)
 *             res.resize2d(resRows, resCols)
 *             T.resize2d(resRows, resCols)             # <<<<<<<<<<<<<<
 *             THDoubleTensor_addmm(res.native, 0, T.native, 1, self.native, M2.native)
 *             return res
 */
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_T), __pyx_n_s_resize2d); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1920, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_10 = __Pyx_PyInt_From_int(__pyx_v_resRows); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 1920, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __pyx_t_7 = __Pyx_PyInt_From_int(__pyx_v_resCols); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1920, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_3 = NULL;
    __pyx_t_9 = 0;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_1))) {
      __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_1);
      if (likely(__pyx_t_3)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
        __Pyx_INCREF(__pyx_t_3);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_1, function);
        __pyx_t_9 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_1)) {
      PyObject *__pyx_temp[3] = {__pyx_t_3, __pyx_t_10, __pyx_t_7};
      __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_1, __pyx_temp+1-__pyx_t_9, 2+__pyx_t_9); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1920, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_1)) {
      PyObject *__pyx_temp[3] = {__pyx_t_3, __pyx_t_10, __pyx_t_7};
      __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_1, __pyx_temp+1-__pyx_t_9, 2+__pyx_t_9); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1920, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    } else
    #endif
    {
      __pyx_t_8 = PyTuple_New(2+__pyx_t_9); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1920, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      if (__pyx_t_3) {
        __Pyx_GIVEREF(__pyx_t_3); PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_t_3); __pyx_t_3 = NULL;
      }
      __Pyx_GIVEREF(__pyx_t_10);
      PyTuple_SET_ITEM(__pyx_t_8, 0+__pyx_t_9, __pyx_t_10);
      __Pyx_GIVEREF(__pyx_t_7);
      PyTuple_SET_ITEM(__pyx_t_8, 1+__pyx_t_9, __pyx_t_7);
      __pyx_t_10 = 0;
      __pyx_t_7 = 0;
      __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_8, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1920, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

    /* "PyTorch.pyx":1921
 *             res.resize2d(resRows, resCols)
 *             T.resize2d(resRows, resCols)
 *             THDoubleTensor_addmm(res.native, 0, T.native, 1, self.native, M2.native)             # <<<<<<<<<<<<<<
 *             return res
 * 
 */
    THDoubleTensor_addmm(__pyx_v_res->native, 0.0, __pyx_v_T->native, 1.0, __pyx_v_self->native, __pyx_v_M2->native);

    /* "PyTorch.pyx":1922
 *             T.resize2d(resRows, resCols)
 *             THDoubleTensor_addmm(res.native, 0, T.native, 1, self.native, M2.native)
 *             return res             # <<<<<<<<<<<<<<
 * 
 * 
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(((PyObject *)__pyx_v_res));
    __pyx_r = ((PyObject *)__pyx_v_res);
    goto __pyx_L0;
  }

  /* "PyTorch.pyx":1902
 * 
 * #    def __mul__(_DoubleTensor self, _DoubleTensor M2):
 *     def __mul__(_DoubleTensor self, second):             # <<<<<<<<<<<<<<
 *         cdef _DoubleTensor M2
 *         cdef _DoubleTensor T
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_10);
  __Pyx_AddTraceback("PyTorch._DoubleTensor.__mul__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_M2);
  __Pyx_XDECREF((PyObject *)__pyx_v_T);
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1927
 *     # ========== random ===============================
 * 
 *     def bernoulli(_DoubleTensor self, float p=0.5):             # <<<<<<<<<<<<<<
 *         THDoubleTensor_bernoulli(self.native, globalState.generator, p)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_115bernoulli(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_115bernoulli(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  float __pyx_v_p;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("bernoulli (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_p,0};
    PyObject* values[1] = {0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_p);
          if (value) { values[0] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "bernoulli") < 0)) __PYX_ERR(0, 1927, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    if (values[0]) {
      __pyx_v_p = __pyx_PyFloat_AsFloat(values[0]); if (unlikely((__pyx_v_p == (float)-1) && PyErr_Occurred())) __PYX_ERR(0, 1927, __pyx_L3_error)
    } else {
      __pyx_v_p = ((float)0.5);
    }
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("bernoulli", 0, 0, 1, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1927, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._DoubleTensor.bernoulli", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_114bernoulli(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self), __pyx_v_p);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_114bernoulli(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, float __pyx_v_p) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("bernoulli", 0);

  /* "PyTorch.pyx":1928
 * 
 *     def bernoulli(_DoubleTensor self, float p=0.5):
 *         THDoubleTensor_bernoulli(self.native, globalState.generator, p)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THDoubleTensor_bernoulli(__pyx_v_self->native, __pyx_v_7PyTorch_globalState->generator, __pyx_v_p);

  /* "PyTorch.pyx":1929
 *     def bernoulli(_DoubleTensor self, float p=0.5):
 *         THDoubleTensor_bernoulli(self.native, globalState.generator, p)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def geometric(_DoubleTensor self, float p=0.5):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1927
 *     # ========== random ===============================
 * 
 *     def bernoulli(_DoubleTensor self, float p=0.5):             # <<<<<<<<<<<<<<
 *         THDoubleTensor_bernoulli(self.native, globalState.generator, p)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1931
 *         return self
 * 
 *     def geometric(_DoubleTensor self, float p=0.5):             # <<<<<<<<<<<<<<
 *         THDoubleTensor_geometric(self.native, globalState.generator, p)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_117geometric(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_117geometric(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  float __pyx_v_p;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("geometric (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_p,0};
    PyObject* values[1] = {0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_p);
          if (value) { values[0] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "geometric") < 0)) __PYX_ERR(0, 1931, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    if (values[0]) {
      __pyx_v_p = __pyx_PyFloat_AsFloat(values[0]); if (unlikely((__pyx_v_p == (float)-1) && PyErr_Occurred())) __PYX_ERR(0, 1931, __pyx_L3_error)
    } else {
      __pyx_v_p = ((float)0.5);
    }
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("geometric", 0, 0, 1, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1931, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._DoubleTensor.geometric", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_116geometric(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self), __pyx_v_p);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_116geometric(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, float __pyx_v_p) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("geometric", 0);

  /* "PyTorch.pyx":1932
 * 
 *     def geometric(_DoubleTensor self, float p=0.5):
 *         THDoubleTensor_geometric(self.native, globalState.generator, p)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THDoubleTensor_geometric(__pyx_v_self->native, __pyx_v_7PyTorch_globalState->generator, __pyx_v_p);

  /* "PyTorch.pyx":1933
 *     def geometric(_DoubleTensor self, float p=0.5):
 *         THDoubleTensor_geometric(self.native, globalState.generator, p)
 *         return self             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1931
 *         return self
 * 
 *     def geometric(_DoubleTensor self, float p=0.5):             # <<<<<<<<<<<<<<
 *         THDoubleTensor_geometric(self.native, globalState.generator, p)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1936
 * 
 * 
 *     def normal(_DoubleTensor self, double mean=0, double stdv=1):             # <<<<<<<<<<<<<<
 *         THDoubleTensor_normal(self.native, globalState.generator, mean, stdv)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_119normal(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_119normal(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  double __pyx_v_mean;
  double __pyx_v_stdv;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("normal (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_mean,&__pyx_n_s_stdv,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_mean);
          if (value) { values[0] = value; kw_args--; }
        }
        case  1:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stdv);
          if (value) { values[1] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "normal") < 0)) __PYX_ERR(0, 1936, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    if (values[0]) {
      __pyx_v_mean = __pyx_PyFloat_AsDouble(values[0]); if (unlikely((__pyx_v_mean == (double)-1) && PyErr_Occurred())) __PYX_ERR(0, 1936, __pyx_L3_error)
    } else {
      __pyx_v_mean = ((double)0.0);
    }
    if (values[1]) {
      __pyx_v_stdv = __pyx_PyFloat_AsDouble(values[1]); if (unlikely((__pyx_v_stdv == (double)-1) && PyErr_Occurred())) __PYX_ERR(0, 1936, __pyx_L3_error)
    } else {
      __pyx_v_stdv = ((double)1.0);
    }
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("normal", 0, 0, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1936, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._DoubleTensor.normal", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_118normal(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self), __pyx_v_mean, __pyx_v_stdv);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_118normal(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, double __pyx_v_mean, double __pyx_v_stdv) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("normal", 0);

  /* "PyTorch.pyx":1937
 * 
 *     def normal(_DoubleTensor self, double mean=0, double stdv=1):
 *         THDoubleTensor_normal(self.native, globalState.generator, mean, stdv)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THDoubleTensor_normal(__pyx_v_self->native, __pyx_v_7PyTorch_globalState->generator, __pyx_v_mean, __pyx_v_stdv);

  /* "PyTorch.pyx":1938
 *     def normal(_DoubleTensor self, double mean=0, double stdv=1):
 *         THDoubleTensor_normal(self.native, globalState.generator, mean, stdv)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def exponential(_DoubleTensor self, double _lambda=1):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1936
 * 
 * 
 *     def normal(_DoubleTensor self, double mean=0, double stdv=1):             # <<<<<<<<<<<<<<
 *         THDoubleTensor_normal(self.native, globalState.generator, mean, stdv)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1940
 *         return self
 * 
 *     def exponential(_DoubleTensor self, double _lambda=1):             # <<<<<<<<<<<<<<
 *         THDoubleTensor_exponential(self.native, globalState.generator, _lambda)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_121exponential(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_121exponential(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  double __pyx_v__lambda;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("exponential (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_lambda,0};
    PyObject* values[1] = {0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_lambda);
          if (value) { values[0] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "exponential") < 0)) __PYX_ERR(0, 1940, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    if (values[0]) {
      __pyx_v__lambda = __pyx_PyFloat_AsDouble(values[0]); if (unlikely((__pyx_v__lambda == (double)-1) && PyErr_Occurred())) __PYX_ERR(0, 1940, __pyx_L3_error)
    } else {
      __pyx_v__lambda = ((double)1.0);
    }
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("exponential", 0, 0, 1, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1940, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._DoubleTensor.exponential", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_120exponential(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self), __pyx_v__lambda);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_120exponential(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, double __pyx_v__lambda) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("exponential", 0);

  /* "PyTorch.pyx":1941
 * 
 *     def exponential(_DoubleTensor self, double _lambda=1):
 *         THDoubleTensor_exponential(self.native, globalState.generator, _lambda)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THDoubleTensor_exponential(__pyx_v_self->native, __pyx_v_7PyTorch_globalState->generator, __pyx_v__lambda);

  /* "PyTorch.pyx":1942
 *     def exponential(_DoubleTensor self, double _lambda=1):
 *         THDoubleTensor_exponential(self.native, globalState.generator, _lambda)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def cauchy(_DoubleTensor self, double median=0, double sigma=1):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1940
 *         return self
 * 
 *     def exponential(_DoubleTensor self, double _lambda=1):             # <<<<<<<<<<<<<<
 *         THDoubleTensor_exponential(self.native, globalState.generator, _lambda)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1944
 *         return self
 * 
 *     def cauchy(_DoubleTensor self, double median=0, double sigma=1):             # <<<<<<<<<<<<<<
 *         THDoubleTensor_cauchy(self.native, globalState.generator, median, sigma)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_123cauchy(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_123cauchy(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  double __pyx_v_median;
  double __pyx_v_sigma;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cauchy (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_median,&__pyx_n_s_sigma,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_median);
          if (value) { values[0] = value; kw_args--; }
        }
        case  1:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_sigma);
          if (value) { values[1] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cauchy") < 0)) __PYX_ERR(0, 1944, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    if (values[0]) {
      __pyx_v_median = __pyx_PyFloat_AsDouble(values[0]); if (unlikely((__pyx_v_median == (double)-1) && PyErr_Occurred())) __PYX_ERR(0, 1944, __pyx_L3_error)
    } else {
      __pyx_v_median = ((double)0.0);
    }
    if (values[1]) {
      __pyx_v_sigma = __pyx_PyFloat_AsDouble(values[1]); if (unlikely((__pyx_v_sigma == (double)-1) && PyErr_Occurred())) __PYX_ERR(0, 1944, __pyx_L3_error)
    } else {
      __pyx_v_sigma = ((double)1.0);
    }
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cauchy", 0, 0, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1944, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._DoubleTensor.cauchy", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_122cauchy(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self), __pyx_v_median, __pyx_v_sigma);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_122cauchy(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, double __pyx_v_median, double __pyx_v_sigma) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cauchy", 0);

  /* "PyTorch.pyx":1945
 * 
 *     def cauchy(_DoubleTensor self, double median=0, double sigma=1):
 *         THDoubleTensor_cauchy(self.native, globalState.generator, median, sigma)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THDoubleTensor_cauchy(__pyx_v_self->native, __pyx_v_7PyTorch_globalState->generator, __pyx_v_median, __pyx_v_sigma);

  /* "PyTorch.pyx":1946
 *     def cauchy(_DoubleTensor self, double median=0, double sigma=1):
 *         THDoubleTensor_cauchy(self.native, globalState.generator, median, sigma)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def logNormal(_DoubleTensor self, double mean=1, double stdv=2):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1944
 *         return self
 * 
 *     def cauchy(_DoubleTensor self, double median=0, double sigma=1):             # <<<<<<<<<<<<<<
 *         THDoubleTensor_cauchy(self.native, globalState.generator, median, sigma)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1948
 *         return self
 * 
 *     def logNormal(_DoubleTensor self, double mean=1, double stdv=2):             # <<<<<<<<<<<<<<
 *         THDoubleTensor_logNormal(self.native, globalState.generator, mean, stdv)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_125logNormal(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_125logNormal(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  double __pyx_v_mean;
  double __pyx_v_stdv;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("logNormal (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_mean,&__pyx_n_s_stdv,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_mean);
          if (value) { values[0] = value; kw_args--; }
        }
        case  1:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stdv);
          if (value) { values[1] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "logNormal") < 0)) __PYX_ERR(0, 1948, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    if (values[0]) {
      __pyx_v_mean = __pyx_PyFloat_AsDouble(values[0]); if (unlikely((__pyx_v_mean == (double)-1) && PyErr_Occurred())) __PYX_ERR(0, 1948, __pyx_L3_error)
    } else {
      __pyx_v_mean = ((double)1.0);
    }
    if (values[1]) {
      __pyx_v_stdv = __pyx_PyFloat_AsDouble(values[1]); if (unlikely((__pyx_v_stdv == (double)-1) && PyErr_Occurred())) __PYX_ERR(0, 1948, __pyx_L3_error)
    } else {
      __pyx_v_stdv = ((double)2.0);
    }
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("logNormal", 0, 0, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1948, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._DoubleTensor.logNormal", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_124logNormal(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self), __pyx_v_mean, __pyx_v_stdv);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_124logNormal(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, double __pyx_v_mean, double __pyx_v_stdv) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("logNormal", 0);

  /* "PyTorch.pyx":1949
 * 
 *     def logNormal(_DoubleTensor self, double mean=1, double stdv=2):
 *         THDoubleTensor_logNormal(self.native, globalState.generator, mean, stdv)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THDoubleTensor_logNormal(__pyx_v_self->native, __pyx_v_7PyTorch_globalState->generator, __pyx_v_mean, __pyx_v_stdv);

  /* "PyTorch.pyx":1950
 *     def logNormal(_DoubleTensor self, double mean=1, double stdv=2):
 *         THDoubleTensor_logNormal(self.native, globalState.generator, mean, stdv)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def uniform(_DoubleTensor self, double a=0, double b=1):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1948
 *         return self
 * 
 *     def logNormal(_DoubleTensor self, double mean=1, double stdv=2):             # <<<<<<<<<<<<<<
 *         THDoubleTensor_logNormal(self.native, globalState.generator, mean, stdv)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1952
 *         return self
 * 
 *     def uniform(_DoubleTensor self, double a=0, double b=1):             # <<<<<<<<<<<<<<
 *         THDoubleTensor_uniform(self.native, globalState.generator, a, b)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_127uniform(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_13_DoubleTensor_127uniform(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  double __pyx_v_a;
  double __pyx_v_b;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("uniform (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_a,&__pyx_n_s_b,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_a);
          if (value) { values[0] = value; kw_args--; }
        }
        case  1:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_b);
          if (value) { values[1] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "uniform") < 0)) __PYX_ERR(0, 1952, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    if (values[0]) {
      __pyx_v_a = __pyx_PyFloat_AsDouble(values[0]); if (unlikely((__pyx_v_a == (double)-1) && PyErr_Occurred())) __PYX_ERR(0, 1952, __pyx_L3_error)
    } else {
      __pyx_v_a = ((double)0.0);
    }
    if (values[1]) {
      __pyx_v_b = __pyx_PyFloat_AsDouble(values[1]); if (unlikely((__pyx_v_b == (double)-1) && PyErr_Occurred())) __PYX_ERR(0, 1952, __pyx_L3_error)
    } else {
      __pyx_v_b = ((double)1.0);
    }
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("uniform", 0, 0, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1952, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._DoubleTensor.uniform", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_13_DoubleTensor_126uniform(((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_self), __pyx_v_a, __pyx_v_b);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_13_DoubleTensor_126uniform(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_self, double __pyx_v_a, double __pyx_v_b) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("uniform", 0);

  /* "PyTorch.pyx":1953
 * 
 *     def uniform(_DoubleTensor self, double a=0, double b=1):
 *         THDoubleTensor_uniform(self.native, globalState.generator, a, b)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THDoubleTensor_uniform(__pyx_v_self->native, __pyx_v_7PyTorch_globalState->generator, __pyx_v_a, __pyx_v_b);

  /* "PyTorch.pyx":1954
 *     def uniform(_DoubleTensor self, double a=0, double b=1):
 *         THDoubleTensor_uniform(self.native, globalState.generator, a, b)
 *         return self             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":1952
 *         return self
 * 
 *     def uniform(_DoubleTensor self, double a=0, double b=1):             # <<<<<<<<<<<<<<
 *         THDoubleTensor_uniform(self.native, globalState.generator, a, b)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1958
 * 
 * #    @staticmethod
 * cdef _DoubleTensor_fromNative(THDoubleTensor *tensorC, retain=True):             # <<<<<<<<<<<<<<
 *     if retain:
 *         THDoubleTensor_retain(tensorC)
 */

static PyObject *__pyx_f_7PyTorch__DoubleTensor_fromNative(struct THDoubleTensor *__pyx_v_tensorC, struct __pyx_opt_args_7PyTorch__DoubleTensor_fromNative *__pyx_optional_args) {
  PyObject *__pyx_v_retain = ((PyObject *)Py_True);
  struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_tensor = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("_DoubleTensor_fromNative", 0);
  if (__pyx_optional_args) {
    if (__pyx_optional_args->__pyx_n > 0) {
      __pyx_v_retain = __pyx_optional_args->retain;
    }
  }

  /* "PyTorch.pyx":1959
 * #    @staticmethod
 * cdef _DoubleTensor_fromNative(THDoubleTensor *tensorC, retain=True):
 *     if retain:             # <<<<<<<<<<<<<<
 *         THDoubleTensor_retain(tensorC)
 *     tensor = _DoubleTensor(_allocate=False)
 */
  __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_v_retain); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(0, 1959, __pyx_L1_error)
  if (__pyx_t_1) {

    /* "PyTorch.pyx":1960
 * cdef _DoubleTensor_fromNative(THDoubleTensor *tensorC, retain=True):
 *     if retain:
 *         THDoubleTensor_retain(tensorC)             # <<<<<<<<<<<<<<
 *     tensor = _DoubleTensor(_allocate=False)
 *     tensor.native = tensorC
 */
    THDoubleTensor_retain(__pyx_v_tensorC);

    /* "PyTorch.pyx":1959
 * #    @staticmethod
 * cdef _DoubleTensor_fromNative(THDoubleTensor *tensorC, retain=True):
 *     if retain:             # <<<<<<<<<<<<<<
 *         THDoubleTensor_retain(tensorC)
 *     tensor = _DoubleTensor(_allocate=False)
 */
  }

  /* "PyTorch.pyx":1961
 *     if retain:
 *         THDoubleTensor_retain(tensorC)
 *     tensor = _DoubleTensor(_allocate=False)             # <<<<<<<<<<<<<<
 *     tensor.native = tensorC
 *     return tensor
 */
  __pyx_t_2 = PyDict_New(); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1961, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_t_2, __pyx_n_s_allocate, Py_False) < 0) __PYX_ERR(0, 1961, __pyx_L1_error)
  __pyx_t_3 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_7PyTorch__DoubleTensor), __pyx_empty_tuple, __pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1961, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_tensor = ((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_t_3);
  __pyx_t_3 = 0;

  /* "PyTorch.pyx":1962
 *         THDoubleTensor_retain(tensorC)
 *     tensor = _DoubleTensor(_allocate=False)
 *     tensor.native = tensorC             # <<<<<<<<<<<<<<
 *     return tensor
 * 
 */
  __pyx_v_tensor->native = __pyx_v_tensorC;

  /* "PyTorch.pyx":1963
 *     tensor = _DoubleTensor(_allocate=False)
 *     tensor.native = tensorC
 *     return tensor             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_tensor));
  __pyx_r = ((PyObject *)__pyx_v_tensor);
  goto __pyx_L0;

  /* "PyTorch.pyx":1958
 * 
 * #    @staticmethod
 * cdef _DoubleTensor_fromNative(THDoubleTensor *tensorC, retain=True):             # <<<<<<<<<<<<<<
 *     if retain:
 *         THDoubleTensor_retain(tensorC)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("PyTorch._DoubleTensor_fromNative", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_tensor);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":1966
 * 
 * 
 * def _asDoubleTensor(myarray):             # <<<<<<<<<<<<<<
 *     cdef double[:] myarraymv
 *     cdef Storage._DoubleStorage storage
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_7_asDoubleTensor(PyObject *__pyx_self, PyObject *__pyx_v_myarray); /*proto*/
static PyMethodDef __pyx_mdef_7PyTorch_7_asDoubleTensor = {"_asDoubleTensor", (PyCFunction)__pyx_pw_7PyTorch_7_asDoubleTensor, METH_O, 0};
static PyObject *__pyx_pw_7PyTorch_7_asDoubleTensor(PyObject *__pyx_self, PyObject *__pyx_v_myarray) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_asDoubleTensor (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_6_asDoubleTensor(__pyx_self, ((PyObject *)__pyx_v_myarray));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_6_asDoubleTensor(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_myarray) {
  __Pyx_memviewslice __pyx_v_myarraymv = { 0, 0, { 0 }, { 0 }, { 0 } };
  struct __pyx_obj_7Storage__DoubleStorage *__pyx_v_storage = 0;
  PyObject *__pyx_v_dims = NULL;
  PyObject *__pyx_v_totalSize = NULL;
  PyObject *__pyx_v_size = NULL;
  PyObject *__pyx_v_stride = NULL;
  PyObject *__pyx_v_strideSoFar = NULL;
  PyObject *__pyx_v_d = NULL;
  PyObject *__pyx_v_tensor = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  int __pyx_t_4;
  Py_ssize_t __pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *(*__pyx_t_8)(PyObject *);
  __Pyx_memviewslice __pyx_t_9 = { 0, 0, { 0 }, { 0 }, { 0 } };
  PyObject *__pyx_t_10 = NULL;
  int __pyx_t_11;
  __Pyx_RefNannySetupContext("_asDoubleTensor", 0);

  /* "PyTorch.pyx":1969
 *     cdef double[:] myarraymv
 *     cdef Storage._DoubleStorage storage
 *     if str(type(myarray)) in ["<type 'numpy.ndarray'>", "<class 'numpy.ndarray'>"]:             # <<<<<<<<<<<<<<
 *         dims = len(myarray.shape)
 *         if dims >= 1:
 */
  __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1969, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_INCREF(((PyObject *)Py_TYPE(__pyx_v_myarray)));
  __Pyx_GIVEREF(((PyObject *)Py_TYPE(__pyx_v_myarray)));
  PyTuple_SET_ITEM(__pyx_t_1, 0, ((PyObject *)Py_TYPE(__pyx_v_myarray)));
  __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)(&PyString_Type)), __pyx_t_1, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1969, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_4 = (__Pyx_PyString_Equals(__pyx_t_2, __pyx_kp_s_type_numpy_ndarray, Py_EQ)); if (unlikely(__pyx_t_4 < 0)) __PYX_ERR(0, 1969, __pyx_L1_error)
  if (!__pyx_t_4) {
  } else {
    __pyx_t_3 = __pyx_t_4;
    goto __pyx_L4_bool_binop_done;
  }
  __pyx_t_4 = (__Pyx_PyString_Equals(__pyx_t_2, __pyx_kp_s_class_numpy_ndarray, Py_EQ)); if (unlikely(__pyx_t_4 < 0)) __PYX_ERR(0, 1969, __pyx_L1_error)
  __pyx_t_3 = __pyx_t_4;
  __pyx_L4_bool_binop_done:;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_4 = (__pyx_t_3 != 0);
  if (__pyx_t_4) {

    /* "PyTorch.pyx":1970
 *     cdef Storage._DoubleStorage storage
 *     if str(type(myarray)) in ["<type 'numpy.ndarray'>", "<class 'numpy.ndarray'>"]:
 *         dims = len(myarray.shape)             # <<<<<<<<<<<<<<
 *         if dims >= 1:
 *             totalSize = 1
 */
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_myarray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1970, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_5 = PyObject_Length(__pyx_t_2); if (unlikely(__pyx_t_5 == -1)) __PYX_ERR(0, 1970, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = PyInt_FromSsize_t(__pyx_t_5); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1970, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_v_dims = __pyx_t_2;
    __pyx_t_2 = 0;

    /* "PyTorch.pyx":1971
 *     if str(type(myarray)) in ["<type 'numpy.ndarray'>", "<class 'numpy.ndarray'>"]:
 *         dims = len(myarray.shape)
 *         if dims >= 1:             # <<<<<<<<<<<<<<
 *             totalSize = 1
 *             size = Storage._LongStorage.newWithSize(dims)
 */
    __pyx_t_2 = PyObject_RichCompare(__pyx_v_dims, __pyx_int_1, Py_GE); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1971, __pyx_L1_error)
    __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely(__pyx_t_4 < 0)) __PYX_ERR(0, 1971, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    if (__pyx_t_4) {

      /* "PyTorch.pyx":1972
 *         dims = len(myarray.shape)
 *         if dims >= 1:
 *             totalSize = 1             # <<<<<<<<<<<<<<
 *             size = Storage._LongStorage.newWithSize(dims)
 *             stride = Storage._LongStorage.newWithSize(dims)
 */
      __Pyx_INCREF(__pyx_int_1);
      __pyx_v_totalSize = __pyx_int_1;

      /* "PyTorch.pyx":1973
 *         if dims >= 1:
 *             totalSize = 1
 *             size = Storage._LongStorage.newWithSize(dims)             # <<<<<<<<<<<<<<
 *             stride = Storage._LongStorage.newWithSize(dims)
 *             strideSoFar = 1
 */
      __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7Storage__LongStorage), __pyx_n_s_newWithSize); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1973, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_6 = NULL;
      if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_1))) {
        __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_1);
        if (likely(__pyx_t_6)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
          __Pyx_INCREF(__pyx_t_6);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_1, function);
        }
      }
      if (!__pyx_t_6) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_v_dims); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1973, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
      } else {
        #if CYTHON_FAST_PYCALL
        if (PyFunction_Check(__pyx_t_1)) {
          PyObject *__pyx_temp[2] = {__pyx_t_6, __pyx_v_dims};
          __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_1, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1973, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
          __Pyx_GOTREF(__pyx_t_2);
        } else
        #endif
        #if CYTHON_FAST_PYCCALL
        if (__Pyx_PyFastCFunction_Check(__pyx_t_1)) {
          PyObject *__pyx_temp[2] = {__pyx_t_6, __pyx_v_dims};
          __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_1, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1973, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
          __Pyx_GOTREF(__pyx_t_2);
        } else
        #endif
        {
          __pyx_t_7 = PyTuple_New(1+1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1973, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_7);
          __Pyx_GIVEREF(__pyx_t_6); PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_6); __pyx_t_6 = NULL;
          __Pyx_INCREF(__pyx_v_dims);
          __Pyx_GIVEREF(__pyx_v_dims);
          PyTuple_SET_ITEM(__pyx_t_7, 0+1, __pyx_v_dims);
          __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_7, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1973, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        }
      }
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_v_size = __pyx_t_2;
      __pyx_t_2 = 0;

      /* "PyTorch.pyx":1974
 *             totalSize = 1
 *             size = Storage._LongStorage.newWithSize(dims)
 *             stride = Storage._LongStorage.newWithSize(dims)             # <<<<<<<<<<<<<<
 *             strideSoFar = 1
 *             for d in range(dims - 1, -1, -1):
 */
      __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7Storage__LongStorage), __pyx_n_s_newWithSize); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1974, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_7 = NULL;
      if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_1))) {
        __pyx_t_7 = PyMethod_GET_SELF(__pyx_t_1);
        if (likely(__pyx_t_7)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
          __Pyx_INCREF(__pyx_t_7);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_1, function);
        }
      }
      if (!__pyx_t_7) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_v_dims); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1974, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
      } else {
        #if CYTHON_FAST_PYCALL
        if (PyFunction_Check(__pyx_t_1)) {
          PyObject *__pyx_temp[2] = {__pyx_t_7, __pyx_v_dims};
          __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_1, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1974, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
          __Pyx_GOTREF(__pyx_t_2);
        } else
        #endif
        #if CYTHON_FAST_PYCCALL
        if (__Pyx_PyFastCFunction_Check(__pyx_t_1)) {
          PyObject *__pyx_temp[2] = {__pyx_t_7, __pyx_v_dims};
          __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_1, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1974, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
          __Pyx_GOTREF(__pyx_t_2);
        } else
        #endif
        {
          __pyx_t_6 = PyTuple_New(1+1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1974, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_6);
          __Pyx_GIVEREF(__pyx_t_7); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_7); __pyx_t_7 = NULL;
          __Pyx_INCREF(__pyx_v_dims);
          __Pyx_GIVEREF(__pyx_v_dims);
          PyTuple_SET_ITEM(__pyx_t_6, 0+1, __pyx_v_dims);
          __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_6, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1974, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
        }
      }
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_v_stride = __pyx_t_2;
      __pyx_t_2 = 0;

      /* "PyTorch.pyx":1975
 *             size = Storage._LongStorage.newWithSize(dims)
 *             stride = Storage._LongStorage.newWithSize(dims)
 *             strideSoFar = 1             # <<<<<<<<<<<<<<
 *             for d in range(dims - 1, -1, -1):
 *                 totalSize *= myarray.shape[d]
 */
      __Pyx_INCREF(__pyx_int_1);
      __pyx_v_strideSoFar = __pyx_int_1;

      /* "PyTorch.pyx":1976
 *             stride = Storage._LongStorage.newWithSize(dims)
 *             strideSoFar = 1
 *             for d in range(dims - 1, -1, -1):             # <<<<<<<<<<<<<<
 *                 totalSize *= myarray.shape[d]
 *                 size[d] = myarray.shape[d]
 */
      __pyx_t_2 = __Pyx_PyInt_SubtractObjC(__pyx_v_dims, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1976, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_1 = PyTuple_New(3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1976, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_GIVEREF(__pyx_t_2);
      PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_2);
      __Pyx_INCREF(__pyx_int_neg_1);
      __Pyx_GIVEREF(__pyx_int_neg_1);
      PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_int_neg_1);
      __Pyx_INCREF(__pyx_int_neg_1);
      __Pyx_GIVEREF(__pyx_int_neg_1);
      PyTuple_SET_ITEM(__pyx_t_1, 2, __pyx_int_neg_1);
      __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_range, __pyx_t_1, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1976, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      if (likely(PyList_CheckExact(__pyx_t_2)) || PyTuple_CheckExact(__pyx_t_2)) {
        __pyx_t_1 = __pyx_t_2; __Pyx_INCREF(__pyx_t_1); __pyx_t_5 = 0;
        __pyx_t_8 = NULL;
      } else {
        __pyx_t_5 = -1; __pyx_t_1 = PyObject_GetIter(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1976, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __pyx_t_8 = Py_TYPE(__pyx_t_1)->tp_iternext; if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1976, __pyx_L1_error)
      }
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      for (;;) {
        if (likely(!__pyx_t_8)) {
          if (likely(PyList_CheckExact(__pyx_t_1))) {
            if (__pyx_t_5 >= PyList_GET_SIZE(__pyx_t_1)) break;
            #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
            __pyx_t_2 = PyList_GET_ITEM(__pyx_t_1, __pyx_t_5); __Pyx_INCREF(__pyx_t_2); __pyx_t_5++; if (unlikely(0 < 0)) __PYX_ERR(0, 1976, __pyx_L1_error)
            #else
            __pyx_t_2 = PySequence_ITEM(__pyx_t_1, __pyx_t_5); __pyx_t_5++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1976, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_2);
            #endif
          } else {
            if (__pyx_t_5 >= PyTuple_GET_SIZE(__pyx_t_1)) break;
            #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
            __pyx_t_2 = PyTuple_GET_ITEM(__pyx_t_1, __pyx_t_5); __Pyx_INCREF(__pyx_t_2); __pyx_t_5++; if (unlikely(0 < 0)) __PYX_ERR(0, 1976, __pyx_L1_error)
            #else
            __pyx_t_2 = PySequence_ITEM(__pyx_t_1, __pyx_t_5); __pyx_t_5++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1976, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_2);
            #endif
          }
        } else {
          __pyx_t_2 = __pyx_t_8(__pyx_t_1);
          if (unlikely(!__pyx_t_2)) {
            PyObject* exc_type = PyErr_Occurred();
            if (exc_type) {
              if (likely(exc_type == PyExc_StopIteration || PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
              else __PYX_ERR(0, 1976, __pyx_L1_error)
            }
            break;
          }
          __Pyx_GOTREF(__pyx_t_2);
        }
        __Pyx_XDECREF_SET(__pyx_v_d, __pyx_t_2);
        __pyx_t_2 = 0;

        /* "PyTorch.pyx":1977
 *             strideSoFar = 1
 *             for d in range(dims - 1, -1, -1):
 *                 totalSize *= myarray.shape[d]             # <<<<<<<<<<<<<<
 *                 size[d] = myarray.shape[d]
 *                 stride[d] = strideSoFar
 */
        __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_myarray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1977, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __pyx_t_6 = PyObject_GetItem(__pyx_t_2, __pyx_v_d); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1977, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        __pyx_t_2 = PyNumber_InPlaceMultiply(__pyx_v_totalSize, __pyx_t_6); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1977, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_DECREF_SET(__pyx_v_totalSize, __pyx_t_2);
        __pyx_t_2 = 0;

        /* "PyTorch.pyx":1978
 *             for d in range(dims - 1, -1, -1):
 *                 totalSize *= myarray.shape[d]
 *                 size[d] = myarray.shape[d]             # <<<<<<<<<<<<<<
 *                 stride[d] = strideSoFar
 *                 strideSoFar *= size[d]
 */
        __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_myarray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1978, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __pyx_t_6 = PyObject_GetItem(__pyx_t_2, __pyx_v_d); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1978, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        if (unlikely(PyObject_SetItem(__pyx_v_size, __pyx_v_d, __pyx_t_6) < 0)) __PYX_ERR(0, 1978, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;

        /* "PyTorch.pyx":1979
 *                 totalSize *= myarray.shape[d]
 *                 size[d] = myarray.shape[d]
 *                 stride[d] = strideSoFar             # <<<<<<<<<<<<<<
 *                 strideSoFar *= size[d]
 *             myarraymv = myarray.reshape(totalSize)
 */
        if (unlikely(PyObject_SetItem(__pyx_v_stride, __pyx_v_d, __pyx_v_strideSoFar) < 0)) __PYX_ERR(0, 1979, __pyx_L1_error)

        /* "PyTorch.pyx":1980
 *                 size[d] = myarray.shape[d]
 *                 stride[d] = strideSoFar
 *                 strideSoFar *= size[d]             # <<<<<<<<<<<<<<
 *             myarraymv = myarray.reshape(totalSize)
 *             storage = Storage._DoubleStorage.newWithData(myarraymv)
 */
        __pyx_t_6 = PyObject_GetItem(__pyx_v_size, __pyx_v_d); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1980, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __pyx_t_2 = PyNumber_InPlaceMultiply(__pyx_v_strideSoFar, __pyx_t_6); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1980, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_DECREF_SET(__pyx_v_strideSoFar, __pyx_t_2);
        __pyx_t_2 = 0;

        /* "PyTorch.pyx":1976
 *             stride = Storage._LongStorage.newWithSize(dims)
 *             strideSoFar = 1
 *             for d in range(dims - 1, -1, -1):             # <<<<<<<<<<<<<<
 *                 totalSize *= myarray.shape[d]
 *                 size[d] = myarray.shape[d]
 */
      }
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

      /* "PyTorch.pyx":1981
 *                 stride[d] = strideSoFar
 *                 strideSoFar *= size[d]
 *             myarraymv = myarray.reshape(totalSize)             # <<<<<<<<<<<<<<
 *             storage = Storage._DoubleStorage.newWithData(myarraymv)
 *             Storage.THDoubleStorage_retain(storage.native) # since newWithData takes ownership
 */
      __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_myarray, __pyx_n_s_reshape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1981, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_6 = NULL;
      if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
        __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_2);
        if (likely(__pyx_t_6)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
          __Pyx_INCREF(__pyx_t_6);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_2, function);
        }
      }
      if (!__pyx_t_6) {
        __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_v_totalSize); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1981, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
      } else {
        #if CYTHON_FAST_PYCALL
        if (PyFunction_Check(__pyx_t_2)) {
          PyObject *__pyx_temp[2] = {__pyx_t_6, __pyx_v_totalSize};
          __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1981, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
          __Pyx_GOTREF(__pyx_t_1);
        } else
        #endif
        #if CYTHON_FAST_PYCCALL
        if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
          PyObject *__pyx_temp[2] = {__pyx_t_6, __pyx_v_totalSize};
          __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1981, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
          __Pyx_GOTREF(__pyx_t_1);
        } else
        #endif
        {
          __pyx_t_7 = PyTuple_New(1+1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1981, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_7);
          __Pyx_GIVEREF(__pyx_t_6); PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_6); __pyx_t_6 = NULL;
          __Pyx_INCREF(__pyx_v_totalSize);
          __Pyx_GIVEREF(__pyx_v_totalSize);
          PyTuple_SET_ITEM(__pyx_t_7, 0+1, __pyx_v_totalSize);
          __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_7, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1981, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_1);
          __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        }
      }
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_9 = __Pyx_PyObject_to_MemoryviewSlice_ds_double(__pyx_t_1);
      if (unlikely(!__pyx_t_9.memview)) __PYX_ERR(0, 1981, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_v_myarraymv = __pyx_t_9;
      __pyx_t_9.memview = NULL;
      __pyx_t_9.data = NULL;

      /* "PyTorch.pyx":1982
 *                 strideSoFar *= size[d]
 *             myarraymv = myarray.reshape(totalSize)
 *             storage = Storage._DoubleStorage.newWithData(myarraymv)             # <<<<<<<<<<<<<<
 *             Storage.THDoubleStorage_retain(storage.native) # since newWithData takes ownership
 * 
 */
      __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7Storage__DoubleStorage), __pyx_n_s_newWithData); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1982, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_7 = __pyx_memoryview_fromslice(__pyx_v_myarraymv, 1, (PyObject *(*)(char *)) __pyx_memview_get_double, (int (*)(char *, PyObject *)) __pyx_memview_set_double, 0);; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1982, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __pyx_t_6 = NULL;
      if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
        __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_2);
        if (likely(__pyx_t_6)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
          __Pyx_INCREF(__pyx_t_6);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_2, function);
        }
      }
      if (!__pyx_t_6) {
        __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_7); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1982, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        __Pyx_GOTREF(__pyx_t_1);
      } else {
        #if CYTHON_FAST_PYCALL
        if (PyFunction_Check(__pyx_t_2)) {
          PyObject *__pyx_temp[2] = {__pyx_t_6, __pyx_t_7};
          __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1982, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
          __Pyx_GOTREF(__pyx_t_1);
          __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        } else
        #endif
        #if CYTHON_FAST_PYCCALL
        if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
          PyObject *__pyx_temp[2] = {__pyx_t_6, __pyx_t_7};
          __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1982, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
          __Pyx_GOTREF(__pyx_t_1);
          __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        } else
        #endif
        {
          __pyx_t_10 = PyTuple_New(1+1); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 1982, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_10);
          __Pyx_GIVEREF(__pyx_t_6); PyTuple_SET_ITEM(__pyx_t_10, 0, __pyx_t_6); __pyx_t_6 = NULL;
          __Pyx_GIVEREF(__pyx_t_7);
          PyTuple_SET_ITEM(__pyx_t_10, 0+1, __pyx_t_7);
          __pyx_t_7 = 0;
          __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_10, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1982, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_1);
          __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
        }
      }
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_7Storage__DoubleStorage))))) __PYX_ERR(0, 1982, __pyx_L1_error)
      __pyx_v_storage = ((struct __pyx_obj_7Storage__DoubleStorage *)__pyx_t_1);
      __pyx_t_1 = 0;

      /* "PyTorch.pyx":1983
 *             myarraymv = myarray.reshape(totalSize)
 *             storage = Storage._DoubleStorage.newWithData(myarraymv)
 *             Storage.THDoubleStorage_retain(storage.native) # since newWithData takes ownership             # <<<<<<<<<<<<<<
 * 
 *             tensor = _DoubleTensor.newWithStorage(storage, 0, size, stride)
 */
      THDoubleStorage_retain(__pyx_v_storage->native);

      /* "PyTorch.pyx":1985
 *             Storage.THDoubleStorage_retain(storage.native) # since newWithData takes ownership
 * 
 *             tensor = _DoubleTensor.newWithStorage(storage, 0, size, stride)             # <<<<<<<<<<<<<<
 *             return tensor
 *         else:
 */
      __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7PyTorch__DoubleTensor), __pyx_n_s_newWithStorage); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1985, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_10 = NULL;
      __pyx_t_11 = 0;
      if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
        __pyx_t_10 = PyMethod_GET_SELF(__pyx_t_2);
        if (likely(__pyx_t_10)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
          __Pyx_INCREF(__pyx_t_10);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_2, function);
          __pyx_t_11 = 1;
        }
      }
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[5] = {__pyx_t_10, ((PyObject *)__pyx_v_storage), __pyx_int_0, __pyx_v_size, __pyx_v_stride};
        __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_11, 4+__pyx_t_11); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1985, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
        __Pyx_GOTREF(__pyx_t_1);
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[5] = {__pyx_t_10, ((PyObject *)__pyx_v_storage), __pyx_int_0, __pyx_v_size, __pyx_v_stride};
        __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_11, 4+__pyx_t_11); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1985, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
        __Pyx_GOTREF(__pyx_t_1);
      } else
      #endif
      {
        __pyx_t_7 = PyTuple_New(4+__pyx_t_11); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1985, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        if (__pyx_t_10) {
          __Pyx_GIVEREF(__pyx_t_10); PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_10); __pyx_t_10 = NULL;
        }
        __Pyx_INCREF(((PyObject *)__pyx_v_storage));
        __Pyx_GIVEREF(((PyObject *)__pyx_v_storage));
        PyTuple_SET_ITEM(__pyx_t_7, 0+__pyx_t_11, ((PyObject *)__pyx_v_storage));
        __Pyx_INCREF(__pyx_int_0);
        __Pyx_GIVEREF(__pyx_int_0);
        PyTuple_SET_ITEM(__pyx_t_7, 1+__pyx_t_11, __pyx_int_0);
        __Pyx_INCREF(__pyx_v_size);
        __Pyx_GIVEREF(__pyx_v_size);
        PyTuple_SET_ITEM(__pyx_t_7, 2+__pyx_t_11, __pyx_v_size);
        __Pyx_INCREF(__pyx_v_stride);
        __Pyx_GIVEREF(__pyx_v_stride);
        PyTuple_SET_ITEM(__pyx_t_7, 3+__pyx_t_11, __pyx_v_stride);
        __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_7, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1985, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      }
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_v_tensor = __pyx_t_1;
      __pyx_t_1 = 0;

      /* "PyTorch.pyx":1986
 * 
 *             tensor = _DoubleTensor.newWithStorage(storage, 0, size, stride)
 *             return tensor             # <<<<<<<<<<<<<<
 *         else:
 *             raise Exception('dims == {dims} not implemented; please raise an issue'.format(
 */
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_v_tensor);
      __pyx_r = __pyx_v_tensor;
      goto __pyx_L0;

      /* "PyTorch.pyx":1971
 *     if str(type(myarray)) in ["<type 'numpy.ndarray'>", "<class 'numpy.ndarray'>"]:
 *         dims = len(myarray.shape)
 *         if dims >= 1:             # <<<<<<<<<<<<<<
 *             totalSize = 1
 *             size = Storage._LongStorage.newWithSize(dims)
 */
    }

    /* "PyTorch.pyx":1988
 *             return tensor
 *         else:
 *             raise Exception('dims == {dims} not implemented; please raise an issue'.format(             # <<<<<<<<<<<<<<
 *                 dims=dims))
 *     elif isinstance(myarray, array.array):
 */
    /*else*/ {
      __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_kp_s_dims_dims_not_implemented_please, __pyx_n_s_format); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1988, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);

      /* "PyTorch.pyx":1989
 *         else:
 *             raise Exception('dims == {dims} not implemented; please raise an issue'.format(
 *                 dims=dims))             # <<<<<<<<<<<<<<
 *     elif isinstance(myarray, array.array):
 *         myarraymv = myarray
 */
      __pyx_t_2 = PyDict_New(); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1989, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      if (PyDict_SetItem(__pyx_t_2, __pyx_n_s_dims, __pyx_v_dims) < 0) __PYX_ERR(0, 1989, __pyx_L1_error)

      /* "PyTorch.pyx":1988
 *             return tensor
 *         else:
 *             raise Exception('dims == {dims} not implemented; please raise an issue'.format(             # <<<<<<<<<<<<<<
 *                 dims=dims))
 *     elif isinstance(myarray, array.array):
 */
      __pyx_t_7 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_empty_tuple, __pyx_t_2); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1988, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = PyTuple_New(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1988, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_GIVEREF(__pyx_t_7);
      PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_7);
      __pyx_t_7 = 0;
      __pyx_t_7 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_t_2, NULL); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1988, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_Raise(__pyx_t_7, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __PYX_ERR(0, 1988, __pyx_L1_error)
    }

    /* "PyTorch.pyx":1969
 *     cdef double[:] myarraymv
 *     cdef Storage._DoubleStorage storage
 *     if str(type(myarray)) in ["<type 'numpy.ndarray'>", "<class 'numpy.ndarray'>"]:             # <<<<<<<<<<<<<<
 *         dims = len(myarray.shape)
 *         if dims >= 1:
 */
  }

  /* "PyTorch.pyx":1990
 *             raise Exception('dims == {dims} not implemented; please raise an issue'.format(
 *                 dims=dims))
 *     elif isinstance(myarray, array.array):             # <<<<<<<<<<<<<<
 *         myarraymv = myarray
 *         storage = Storage._DoubleStorage.newWithData(myarraymv)
 */
  __pyx_t_7 = __Pyx_GetModuleGlobalName(__pyx_n_s_array); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1990, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_7, __pyx_n_s_array); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1990, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_4 = PyObject_IsInstance(__pyx_v_myarray, __pyx_t_2); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 1990, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_3 = (__pyx_t_4 != 0);
  if (__pyx_t_3) {

    /* "PyTorch.pyx":1991
 *                 dims=dims))
 *     elif isinstance(myarray, array.array):
 *         myarraymv = myarray             # <<<<<<<<<<<<<<
 *         storage = Storage._DoubleStorage.newWithData(myarraymv)
 *         Storage.THDoubleStorage_retain(storage.native) # since newWithData takes ownership
 */
    __pyx_t_9 = __Pyx_PyObject_to_MemoryviewSlice_ds_double(__pyx_v_myarray);
    if (unlikely(!__pyx_t_9.memview)) __PYX_ERR(0, 1991, __pyx_L1_error)
    __pyx_v_myarraymv = __pyx_t_9;
    __pyx_t_9.memview = NULL;
    __pyx_t_9.data = NULL;

    /* "PyTorch.pyx":1992
 *     elif isinstance(myarray, array.array):
 *         myarraymv = myarray
 *         storage = Storage._DoubleStorage.newWithData(myarraymv)             # <<<<<<<<<<<<<<
 *         Storage.THDoubleStorage_retain(storage.native) # since newWithData takes ownership
 *         tensor = _DoubleTensor.newWithStorage1d(storage, 0, len(myarray), 1)
 */
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7Storage__DoubleStorage), __pyx_n_s_newWithData); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1992, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_1 = __pyx_memoryview_fromslice(__pyx_v_myarraymv, 1, (PyObject *(*)(char *)) __pyx_memview_get_double, (int (*)(char *, PyObject *)) __pyx_memview_set_double, 0);; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1992, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_10 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_7))) {
      __pyx_t_10 = PyMethod_GET_SELF(__pyx_t_7);
      if (likely(__pyx_t_10)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_7);
        __Pyx_INCREF(__pyx_t_10);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_7, function);
      }
    }
    if (!__pyx_t_10) {
      __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_7, __pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1992, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_GOTREF(__pyx_t_2);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_7)) {
        PyObject *__pyx_temp[2] = {__pyx_t_10, __pyx_t_1};
        __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_7, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1992, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_7)) {
        PyObject *__pyx_temp[2] = {__pyx_t_10, __pyx_t_1};
        __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_7, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1992, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      } else
      #endif
      {
        __pyx_t_6 = PyTuple_New(1+1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1992, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __Pyx_GIVEREF(__pyx_t_10); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_10); __pyx_t_10 = NULL;
        __Pyx_GIVEREF(__pyx_t_1);
        PyTuple_SET_ITEM(__pyx_t_6, 0+1, __pyx_t_1);
        __pyx_t_1 = 0;
        __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_7, __pyx_t_6, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1992, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    if (!(likely(((__pyx_t_2) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_2, __pyx_ptype_7Storage__DoubleStorage))))) __PYX_ERR(0, 1992, __pyx_L1_error)
    __pyx_v_storage = ((struct __pyx_obj_7Storage__DoubleStorage *)__pyx_t_2);
    __pyx_t_2 = 0;

    /* "PyTorch.pyx":1993
 *         myarraymv = myarray
 *         storage = Storage._DoubleStorage.newWithData(myarraymv)
 *         Storage.THDoubleStorage_retain(storage.native) # since newWithData takes ownership             # <<<<<<<<<<<<<<
 *         tensor = _DoubleTensor.newWithStorage1d(storage, 0, len(myarray), 1)
 *         return tensor
 */
    THDoubleStorage_retain(__pyx_v_storage->native);

    /* "PyTorch.pyx":1994
 *         storage = Storage._DoubleStorage.newWithData(myarraymv)
 *         Storage.THDoubleStorage_retain(storage.native) # since newWithData takes ownership
 *         tensor = _DoubleTensor.newWithStorage1d(storage, 0, len(myarray), 1)             # <<<<<<<<<<<<<<
 *         return tensor
 *     else:
 */
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7PyTorch__DoubleTensor), __pyx_n_s_newWithStorage1d); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1994, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_5 = PyObject_Length(__pyx_v_myarray); if (unlikely(__pyx_t_5 == -1)) __PYX_ERR(0, 1994, __pyx_L1_error)
    __pyx_t_6 = PyInt_FromSsize_t(__pyx_t_5); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1994, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_1 = NULL;
    __pyx_t_11 = 0;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_7))) {
      __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_7);
      if (likely(__pyx_t_1)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_7);
        __Pyx_INCREF(__pyx_t_1);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_7, function);
        __pyx_t_11 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_7)) {
      PyObject *__pyx_temp[5] = {__pyx_t_1, ((PyObject *)__pyx_v_storage), __pyx_int_0, __pyx_t_6, __pyx_int_1};
      __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_7, __pyx_temp+1-__pyx_t_11, 4+__pyx_t_11); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1994, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_7)) {
      PyObject *__pyx_temp[5] = {__pyx_t_1, ((PyObject *)__pyx_v_storage), __pyx_int_0, __pyx_t_6, __pyx_int_1};
      __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_7, __pyx_temp+1-__pyx_t_11, 4+__pyx_t_11); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1994, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    } else
    #endif
    {
      __pyx_t_10 = PyTuple_New(4+__pyx_t_11); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 1994, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_10);
      if (__pyx_t_1) {
        __Pyx_GIVEREF(__pyx_t_1); PyTuple_SET_ITEM(__pyx_t_10, 0, __pyx_t_1); __pyx_t_1 = NULL;
      }
      __Pyx_INCREF(((PyObject *)__pyx_v_storage));
      __Pyx_GIVEREF(((PyObject *)__pyx_v_storage));
      PyTuple_SET_ITEM(__pyx_t_10, 0+__pyx_t_11, ((PyObject *)__pyx_v_storage));
      __Pyx_INCREF(__pyx_int_0);
      __Pyx_GIVEREF(__pyx_int_0);
      PyTuple_SET_ITEM(__pyx_t_10, 1+__pyx_t_11, __pyx_int_0);
      __Pyx_GIVEREF(__pyx_t_6);
      PyTuple_SET_ITEM(__pyx_t_10, 2+__pyx_t_11, __pyx_t_6);
      __Pyx_INCREF(__pyx_int_1);
      __Pyx_GIVEREF(__pyx_int_1);
      PyTuple_SET_ITEM(__pyx_t_10, 3+__pyx_t_11, __pyx_int_1);
      __pyx_t_6 = 0;
      __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_7, __pyx_t_10, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1994, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    }
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_v_tensor = __pyx_t_2;
    __pyx_t_2 = 0;

    /* "PyTorch.pyx":1995
 *         Storage.THDoubleStorage_retain(storage.native) # since newWithData takes ownership
 *         tensor = _DoubleTensor.newWithStorage1d(storage, 0, len(myarray), 1)
 *         return tensor             # <<<<<<<<<<<<<<
 *     else:
 *         raise Exception("not implemented")
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(__pyx_v_tensor);
    __pyx_r = __pyx_v_tensor;
    goto __pyx_L0;

    /* "PyTorch.pyx":1990
 *             raise Exception('dims == {dims} not implemented; please raise an issue'.format(
 *                 dims=dims))
 *     elif isinstance(myarray, array.array):             # <<<<<<<<<<<<<<
 *         myarraymv = myarray
 *         storage = Storage._DoubleStorage.newWithData(myarraymv)
 */
  }

  /* "PyTorch.pyx":1997
 *         return tensor
 *     else:
 *         raise Exception("not implemented")             # <<<<<<<<<<<<<<
 * 
 * 
 */
  /*else*/ {
    __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_tuple__33, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1997, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(0, 1997, __pyx_L1_error)
  }

  /* "PyTorch.pyx":1966
 * 
 * 
 * def _asDoubleTensor(myarray):             # <<<<<<<<<<<<<<
 *     cdef double[:] myarraymv
 *     cdef Storage._DoubleStorage storage
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __PYX_XDEC_MEMVIEW(&__pyx_t_9, 1);
  __Pyx_XDECREF(__pyx_t_10);
  __Pyx_AddTraceback("PyTorch._asDoubleTensor", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __PYX_XDEC_MEMVIEW(&__pyx_v_myarraymv, 1);
  __Pyx_XDECREF((PyObject *)__pyx_v_storage);
  __Pyx_XDECREF(__pyx_v_dims);
  __Pyx_XDECREF(__pyx_v_totalSize);
  __Pyx_XDECREF(__pyx_v_size);
  __Pyx_XDECREF(__pyx_v_stride);
  __Pyx_XDECREF(__pyx_v_strideSoFar);
  __Pyx_XDECREF(__pyx_v_d);
  __Pyx_XDECREF(__pyx_v_tensor);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2009
 * #        self.thFloatTensor = tensorC
 * 
 *     def __cinit__(self, *args, _allocate=True):             # <<<<<<<<<<<<<<
 * #        cdef _ByteTensor childobject
 *         cdef THByteTensor *newTensorC
 */

/* Python wrapper */
static int __pyx_pw_7PyTorch_11_ByteTensor_1__cinit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static int __pyx_pw_7PyTorch_11_ByteTensor_1__cinit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v__allocate = 0;
  PyObject *__pyx_v_args = 0;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__cinit__ (wrapper)", 0);
  if (PyTuple_GET_SIZE(__pyx_args) > 0) {
    __pyx_v_args = PyTuple_GetSlice(__pyx_args, 0, PyTuple_GET_SIZE(__pyx_args));
    if (unlikely(!__pyx_v_args)) {
      __Pyx_RefNannyFinishContext();
      return -1;
    }
    __Pyx_GOTREF(__pyx_v_args);
  } else {
    __pyx_v_args = __pyx_empty_tuple; __Pyx_INCREF(__pyx_empty_tuple);
  }
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_allocate,0};
    PyObject* values[1] = {0};
    values[0] = ((PyObject *)Py_True);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        default:
        case  0: break;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      if (kw_args == 1) {
        const Py_ssize_t index = 0;
        PyObject* value = PyDict_GetItem(__pyx_kwds, *__pyx_pyargnames[index]);
        if (value) { values[index] = value; kw_args--; }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, 0, "__cinit__") < 0)) __PYX_ERR(0, 2009, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) < 0) {
      goto __pyx_L5_argtuple_error;
    } else {
    }
    __pyx_v__allocate = values[0];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__cinit__", 0, 0, 0, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 2009, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_DECREF(__pyx_v_args); __pyx_v_args = 0;
  __Pyx_AddTraceback("PyTorch._ByteTensor.__cinit__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return -1;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor___cinit__(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self), __pyx_v__allocate, __pyx_v_args);

  /* function exit code */
  __Pyx_XDECREF(__pyx_v_args);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_7PyTorch_11_ByteTensor___cinit__(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, PyObject *__pyx_v__allocate, PyObject *__pyx_v_args) {
  struct THByteTensor *__pyx_v_newTensorC;
  struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_templateObject = 0;
  PyObject *__pyx_v_arg = NULL;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  Py_ssize_t __pyx_t_4;
  int __pyx_t_5;
  int __pyx_t_6;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  long __pyx_t_10;
  long __pyx_t_11;
  long __pyx_t_12;
  long __pyx_t_13;
  __Pyx_RefNannySetupContext("__cinit__", 0);

  /* "PyTorch.pyx":2013
 *         cdef THByteTensor *newTensorC
 *         cdef _ByteTensor templateObject
 *         logger.debug('ByteTensor.__cinit__')             # <<<<<<<<<<<<<<
 * #        cdef THByteStorage *storageC
 * #        cdef long addr
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_logger); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2013, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_debug); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2013, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_tuple__34, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2013, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "PyTorch.pyx":2018
 * #        if len(kwargs) > 0:
 * #            raise Exception('cannot provide arguments to initializer')
 *         if _allocate:             # <<<<<<<<<<<<<<
 *             if len(args) == 1 and isinstance(args[0], _LongStorage):  # it's a size tensor
 *                self.native = THByteTensor_new()
 */
  __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_v__allocate); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 2018, __pyx_L1_error)
  if (__pyx_t_3) {

    /* "PyTorch.pyx":2019
 * #            raise Exception('cannot provide arguments to initializer')
 *         if _allocate:
 *             if len(args) == 1 and isinstance(args[0], _LongStorage):  # it's a size tensor             # <<<<<<<<<<<<<<
 *                self.native = THByteTensor_new()
 *                self.resize(args[0])
 */
    __pyx_t_4 = PyTuple_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 2019, __pyx_L1_error)
    __pyx_t_5 = ((__pyx_t_4 == 1) != 0);
    if (__pyx_t_5) {
    } else {
      __pyx_t_3 = __pyx_t_5;
      goto __pyx_L5_bool_binop_done;
    }
    __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2019, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_LongStorage); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2019, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_5 = PyObject_IsInstance(__pyx_t_1, __pyx_t_2); if (unlikely(__pyx_t_5 == -1)) __PYX_ERR(0, 2019, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_6 = (__pyx_t_5 != 0);
    __pyx_t_3 = __pyx_t_6;
    __pyx_L5_bool_binop_done:;
    if (__pyx_t_3) {

      /* "PyTorch.pyx":2020
 *         if _allocate:
 *             if len(args) == 1 and isinstance(args[0], _LongStorage):  # it's a size tensor
 *                self.native = THByteTensor_new()             # <<<<<<<<<<<<<<
 *                self.resize(args[0])
 *                return
 */
      __pyx_v_self->native = THByteTensor_new();

      /* "PyTorch.pyx":2021
 *             if len(args) == 1 and isinstance(args[0], _LongStorage):  # it's a size tensor
 *                self.native = THByteTensor_new()
 *                self.resize(args[0])             # <<<<<<<<<<<<<<
 *                return
 *             if len(args) == 1 and isinstance(args[0], _ByteTensor):
 */
      __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_resize); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2021, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_7 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 2021, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __pyx_t_8 = NULL;
      if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_1))) {
        __pyx_t_8 = PyMethod_GET_SELF(__pyx_t_1);
        if (likely(__pyx_t_8)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
          __Pyx_INCREF(__pyx_t_8);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_1, function);
        }
      }
      if (!__pyx_t_8) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_t_7); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2021, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        __Pyx_GOTREF(__pyx_t_2);
      } else {
        #if CYTHON_FAST_PYCALL
        if (PyFunction_Check(__pyx_t_1)) {
          PyObject *__pyx_temp[2] = {__pyx_t_8, __pyx_t_7};
          __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_1, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2021, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        } else
        #endif
        #if CYTHON_FAST_PYCCALL
        if (__Pyx_PyFastCFunction_Check(__pyx_t_1)) {
          PyObject *__pyx_temp[2] = {__pyx_t_8, __pyx_t_7};
          __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_1, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2021, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        } else
        #endif
        {
          __pyx_t_9 = PyTuple_New(1+1); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 2021, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_9);
          __Pyx_GIVEREF(__pyx_t_8); PyTuple_SET_ITEM(__pyx_t_9, 0, __pyx_t_8); __pyx_t_8 = NULL;
          __Pyx_GIVEREF(__pyx_t_7);
          PyTuple_SET_ITEM(__pyx_t_9, 0+1, __pyx_t_7);
          __pyx_t_7 = 0;
          __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_9, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2021, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
        }
      }
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

      /* "PyTorch.pyx":2022
 *                self.native = THByteTensor_new()
 *                self.resize(args[0])
 *                return             # <<<<<<<<<<<<<<
 *             if len(args) == 1 and isinstance(args[0], _ByteTensor):
 *                templateObject = args[0]
 */
      __pyx_r = 0;
      goto __pyx_L0;

      /* "PyTorch.pyx":2019
 * #            raise Exception('cannot provide arguments to initializer')
 *         if _allocate:
 *             if len(args) == 1 and isinstance(args[0], _LongStorage):  # it's a size tensor             # <<<<<<<<<<<<<<
 *                self.native = THByteTensor_new()
 *                self.resize(args[0])
 */
    }

    /* "PyTorch.pyx":2023
 *                self.resize(args[0])
 *                return
 *             if len(args) == 1 and isinstance(args[0], _ByteTensor):             # <<<<<<<<<<<<<<
 *                templateObject = args[0]
 *                newTensorC = THByteTensor_newClone(templateObject.native)
 */
    __pyx_t_4 = PyTuple_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 2023, __pyx_L1_error)
    __pyx_t_6 = ((__pyx_t_4 == 1) != 0);
    if (__pyx_t_6) {
    } else {
      __pyx_t_3 = __pyx_t_6;
      goto __pyx_L8_bool_binop_done;
    }
    __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2023, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_6 = __Pyx_TypeCheck(__pyx_t_2, __pyx_ptype_7PyTorch__ByteTensor); 
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_5 = (__pyx_t_6 != 0);
    __pyx_t_3 = __pyx_t_5;
    __pyx_L8_bool_binop_done:;
    if (__pyx_t_3) {

      /* "PyTorch.pyx":2024
 *                return
 *             if len(args) == 1 and isinstance(args[0], _ByteTensor):
 *                templateObject = args[0]             # <<<<<<<<<<<<<<
 *                newTensorC = THByteTensor_newClone(templateObject.native)
 *                self.native = newTensorC
 */
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2024, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      if (!(likely(((__pyx_t_2) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_2, __pyx_ptype_7PyTorch__ByteTensor))))) __PYX_ERR(0, 2024, __pyx_L1_error)
      __pyx_v_templateObject = ((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_t_2);
      __pyx_t_2 = 0;

      /* "PyTorch.pyx":2025
 *             if len(args) == 1 and isinstance(args[0], _ByteTensor):
 *                templateObject = args[0]
 *                newTensorC = THByteTensor_newClone(templateObject.native)             # <<<<<<<<<<<<<<
 *                self.native = newTensorC
 *                return
 */
      __pyx_v_newTensorC = THByteTensor_newClone(__pyx_v_templateObject->native);

      /* "PyTorch.pyx":2026
 *                templateObject = args[0]
 *                newTensorC = THByteTensor_newClone(templateObject.native)
 *                self.native = newTensorC             # <<<<<<<<<<<<<<
 *                return
 *             for arg in args:
 */
      __pyx_v_self->native = __pyx_v_newTensorC;

      /* "PyTorch.pyx":2027
 *                newTensorC = THByteTensor_newClone(templateObject.native)
 *                self.native = newTensorC
 *                return             # <<<<<<<<<<<<<<
 *             for arg in args:
 *                 if not isinstance(arg, int):
 */
      __pyx_r = 0;
      goto __pyx_L0;

      /* "PyTorch.pyx":2023
 *                self.resize(args[0])
 *                return
 *             if len(args) == 1 and isinstance(args[0], _ByteTensor):             # <<<<<<<<<<<<<<
 *                templateObject = args[0]
 *                newTensorC = THByteTensor_newClone(templateObject.native)
 */
    }

    /* "PyTorch.pyx":2028
 *                self.native = newTensorC
 *                return
 *             for arg in args:             # <<<<<<<<<<<<<<
 *                 if not isinstance(arg, int):
 *                     raise Exception('cannot provide arguments to initializer')
 */
    __pyx_t_2 = __pyx_v_args; __Pyx_INCREF(__pyx_t_2); __pyx_t_4 = 0;
    for (;;) {
      if (__pyx_t_4 >= PyTuple_GET_SIZE(__pyx_t_2)) break;
      #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
      __pyx_t_1 = PyTuple_GET_ITEM(__pyx_t_2, __pyx_t_4); __Pyx_INCREF(__pyx_t_1); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 2028, __pyx_L1_error)
      #else
      __pyx_t_1 = PySequence_ITEM(__pyx_t_2, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2028, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      #endif
      __Pyx_XDECREF_SET(__pyx_v_arg, __pyx_t_1);
      __pyx_t_1 = 0;

      /* "PyTorch.pyx":2029
 *                return
 *             for arg in args:
 *                 if not isinstance(arg, int):             # <<<<<<<<<<<<<<
 *                     raise Exception('cannot provide arguments to initializer')
 *             if len(args) == 0:
 */
      __pyx_t_3 = PyInt_Check(__pyx_v_arg); 
      __pyx_t_5 = ((!(__pyx_t_3 != 0)) != 0);
      if (__pyx_t_5) {

        /* "PyTorch.pyx":2030
 *             for arg in args:
 *                 if not isinstance(arg, int):
 *                     raise Exception('cannot provide arguments to initializer')             # <<<<<<<<<<<<<<
 *             if len(args) == 0:
 *                 # print('no args, calling THByteTensor_new()')
 */
        __pyx_t_1 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_tuple__35, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2030, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_Raise(__pyx_t_1, 0, 0, 0);
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        __PYX_ERR(0, 2030, __pyx_L1_error)

        /* "PyTorch.pyx":2029
 *                return
 *             for arg in args:
 *                 if not isinstance(arg, int):             # <<<<<<<<<<<<<<
 *                     raise Exception('cannot provide arguments to initializer')
 *             if len(args) == 0:
 */
      }

      /* "PyTorch.pyx":2028
 *                self.native = newTensorC
 *                return
 *             for arg in args:             # <<<<<<<<<<<<<<
 *                 if not isinstance(arg, int):
 *                     raise Exception('cannot provide arguments to initializer')
 */
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

    /* "PyTorch.pyx":2031
 *                 if not isinstance(arg, int):
 *                     raise Exception('cannot provide arguments to initializer')
 *             if len(args) == 0:             # <<<<<<<<<<<<<<
 *                 # print('no args, calling THByteTensor_new()')
 *                 self.native = THByteTensor_new()
 */
    __pyx_t_4 = PyTuple_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 2031, __pyx_L1_error)
    __pyx_t_5 = ((__pyx_t_4 == 0) != 0);
    if (__pyx_t_5) {

      /* "PyTorch.pyx":2033
 *             if len(args) == 0:
 *                 # print('no args, calling THByteTensor_new()')
 *                 self.native = THByteTensor_new()             # <<<<<<<<<<<<<<
 *             elif len(args) == 1:
 *                 # print('new tensor 1d length', args[0])
 */
      __pyx_v_self->native = THByteTensor_new();

      /* "PyTorch.pyx":2031
 *                 if not isinstance(arg, int):
 *                     raise Exception('cannot provide arguments to initializer')
 *             if len(args) == 0:             # <<<<<<<<<<<<<<
 *                 # print('no args, calling THByteTensor_new()')
 *                 self.native = THByteTensor_new()
 */
      goto __pyx_L13;
    }

    /* "PyTorch.pyx":2034
 *                 # print('no args, calling THByteTensor_new()')
 *                 self.native = THByteTensor_new()
 *             elif len(args) == 1:             # <<<<<<<<<<<<<<
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THByteTensor_newWithSize1d(args[0])
 */
    __pyx_t_4 = PyTuple_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 2034, __pyx_L1_error)
    __pyx_t_5 = ((__pyx_t_4 == 1) != 0);
    if (__pyx_t_5) {

      /* "PyTorch.pyx":2036
 *             elif len(args) == 1:
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THByteTensor_newWithSize1d(args[0])             # <<<<<<<<<<<<<<
 *             elif len(args) == 2:
 *                 # print('args=2')
 */
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2036, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_10 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_10 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2036, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_v_self->native = THByteTensor_newWithSize1d(__pyx_t_10);

      /* "PyTorch.pyx":2034
 *                 # print('no args, calling THByteTensor_new()')
 *                 self.native = THByteTensor_new()
 *             elif len(args) == 1:             # <<<<<<<<<<<<<<
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THByteTensor_newWithSize1d(args[0])
 */
      goto __pyx_L13;
    }

    /* "PyTorch.pyx":2037
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THByteTensor_newWithSize1d(args[0])
 *             elif len(args) == 2:             # <<<<<<<<<<<<<<
 *                 # print('args=2')
 *                 self.native = THByteTensor_newWithSize2d(args[0], args[1])
 */
    __pyx_t_4 = PyTuple_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 2037, __pyx_L1_error)
    __pyx_t_5 = ((__pyx_t_4 == 2) != 0);
    if (__pyx_t_5) {

      /* "PyTorch.pyx":2039
 *             elif len(args) == 2:
 *                 # print('args=2')
 *                 self.native = THByteTensor_newWithSize2d(args[0], args[1])             # <<<<<<<<<<<<<<
 *             elif len(args) == 3:
 *                 # print('new tensor 1d length', args[0])
 */
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2039, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_10 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_10 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2039, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2039, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_11 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_11 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2039, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_v_self->native = THByteTensor_newWithSize2d(__pyx_t_10, __pyx_t_11);

      /* "PyTorch.pyx":2037
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THByteTensor_newWithSize1d(args[0])
 *             elif len(args) == 2:             # <<<<<<<<<<<<<<
 *                 # print('args=2')
 *                 self.native = THByteTensor_newWithSize2d(args[0], args[1])
 */
      goto __pyx_L13;
    }

    /* "PyTorch.pyx":2040
 *                 # print('args=2')
 *                 self.native = THByteTensor_newWithSize2d(args[0], args[1])
 *             elif len(args) == 3:             # <<<<<<<<<<<<<<
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THByteTensor_newWithSize3d(args[0], args[1], args[2])
 */
    __pyx_t_4 = PyTuple_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 2040, __pyx_L1_error)
    __pyx_t_5 = ((__pyx_t_4 == 3) != 0);
    if (__pyx_t_5) {

      /* "PyTorch.pyx":2042
 *             elif len(args) == 3:
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THByteTensor_newWithSize3d(args[0], args[1], args[2])             # <<<<<<<<<<<<<<
 *             elif len(args) == 4:
 *                 # print('new tensor 1d length', args[0])
 */
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2042, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_11 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_11 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2042, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2042, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_10 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_10 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2042, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2042, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_12 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_12 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2042, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_v_self->native = THByteTensor_newWithSize3d(__pyx_t_11, __pyx_t_10, __pyx_t_12);

      /* "PyTorch.pyx":2040
 *                 # print('args=2')
 *                 self.native = THByteTensor_newWithSize2d(args[0], args[1])
 *             elif len(args) == 3:             # <<<<<<<<<<<<<<
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THByteTensor_newWithSize3d(args[0], args[1], args[2])
 */
      goto __pyx_L13;
    }

    /* "PyTorch.pyx":2043
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THByteTensor_newWithSize3d(args[0], args[1], args[2])
 *             elif len(args) == 4:             # <<<<<<<<<<<<<<
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THByteTensor_newWithSize4d(args[0], args[1], args[2], args[3])
 */
    __pyx_t_4 = PyTuple_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 2043, __pyx_L1_error)
    __pyx_t_5 = ((__pyx_t_4 == 4) != 0);
    if (__pyx_t_5) {

      /* "PyTorch.pyx":2045
 *             elif len(args) == 4:
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THByteTensor_newWithSize4d(args[0], args[1], args[2], args[3])             # <<<<<<<<<<<<<<
 *             else:
 *                 logger.error('Raising exception...')
 */
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2045, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_12 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_12 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2045, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2045, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_10 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_10 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2045, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2045, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_11 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_11 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2045, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 3, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2045, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_13 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_13 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2045, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_v_self->native = THByteTensor_newWithSize4d(__pyx_t_12, __pyx_t_10, __pyx_t_11, __pyx_t_13);

      /* "PyTorch.pyx":2043
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THByteTensor_newWithSize3d(args[0], args[1], args[2])
 *             elif len(args) == 4:             # <<<<<<<<<<<<<<
 *                 # print('new tensor 1d length', args[0])
 *                 self.native = THByteTensor_newWithSize4d(args[0], args[1], args[2], args[3])
 */
      goto __pyx_L13;
    }

    /* "PyTorch.pyx":2047
 *                 self.native = THByteTensor_newWithSize4d(args[0], args[1], args[2], args[3])
 *             else:
 *                 logger.error('Raising exception...')             # <<<<<<<<<<<<<<
 *                 raise Exception('Not implemented, len(args)=' + str(len(args)))
 * #        else:
 */
    /*else*/ {
      __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_logger); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2047, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_error); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2047, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_tuple__36, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2047, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

      /* "PyTorch.pyx":2048
 *             else:
 *                 logger.error('Raising exception...')
 *                 raise Exception('Not implemented, len(args)=' + str(len(args)))             # <<<<<<<<<<<<<<
 * #        else:
 * #            if len(args) > 0:
 */
      __pyx_t_4 = PyTuple_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 2048, __pyx_L1_error)
      __pyx_t_2 = PyInt_FromSsize_t(__pyx_t_4); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2048, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2048, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_GIVEREF(__pyx_t_2);
      PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_2);
      __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)(&PyString_Type)), __pyx_t_1, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2048, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_t_1 = PyNumber_Add(__pyx_kp_s_Not_implemented_len_args, __pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2048, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = PyTuple_New(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2048, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_GIVEREF(__pyx_t_1);
      PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_1);
      __pyx_t_1 = 0;
      __pyx_t_1 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_t_2, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2048, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_Raise(__pyx_t_1, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __PYX_ERR(0, 2048, __pyx_L1_error)
    }
    __pyx_L13:;

    /* "PyTorch.pyx":2018
 * #        if len(kwargs) > 0:
 * #            raise Exception('cannot provide arguments to initializer')
 *         if _allocate:             # <<<<<<<<<<<<<<
 *             if len(args) == 1 and isinstance(args[0], _LongStorage):  # it's a size tensor
 *                self.native = THByteTensor_new()
 */
  }

  /* "PyTorch.pyx":2009
 * #        self.thFloatTensor = tensorC
 * 
 *     def __cinit__(self, *args, _allocate=True):             # <<<<<<<<<<<<<<
 * #        cdef _ByteTensor childobject
 *         cdef THByteTensor *newTensorC
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_AddTraceback("PyTorch._ByteTensor.__cinit__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_templateObject);
  __Pyx_XDECREF(__pyx_v_arg);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2067
 * #        self.storage = storage
 * 
 *     def __dealloc__(self):             # <<<<<<<<<<<<<<
 *         cdef int refCount
 * #        cdef int dims
 */

/* Python wrapper */
static void __pyx_pw_7PyTorch_11_ByteTensor_3__dealloc__(PyObject *__pyx_v_self); /*proto*/
static void __pyx_pw_7PyTorch_11_ByteTensor_3__dealloc__(PyObject *__pyx_v_self) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__dealloc__ (wrapper)", 0);
  __pyx_pf_7PyTorch_11_ByteTensor_2__dealloc__(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

static void __pyx_pf_7PyTorch_11_ByteTensor_2__dealloc__(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self) {
  int __pyx_v_refCount;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("__dealloc__", 0);

  /* "PyTorch.pyx":2074
 * #        cdef THFloatStorage *storage
 * #        logger.debug('__dealloc__ native %s', <long>(self.native) != 0)
 *         if <long>(self.native) != 0:             # <<<<<<<<<<<<<<
 *             refCount = THByteTensor_getRefCount(self.native)
 *    #         print('ByteTensor.dealloc old refcount', refCount)
 */
  __pyx_t_1 = ((((long)__pyx_v_self->native) != 0) != 0);
  if (__pyx_t_1) {

    /* "PyTorch.pyx":2075
 * #        logger.debug('__dealloc__ native %s', <long>(self.native) != 0)
 *         if <long>(self.native) != 0:
 *             refCount = THByteTensor_getRefCount(self.native)             # <<<<<<<<<<<<<<
 *    #         print('ByteTensor.dealloc old refcount', refCount)
 *    #        storage = THFloatTensor_storage(self.thFloatTensor)
 */
    __pyx_v_refCount = THByteTensor_getRefCount(__pyx_v_self->native);

    /* "PyTorch.pyx":2086
 *    #        for i in range(dims):
 *    #            # print('   size[', i, ']', THFloatTensor_size(self.thFloatTensor, i))
 *             if refCount < 1:             # <<<<<<<<<<<<<<
 *                 raise Exception('Unallocated an already deallocated tensor... :-O')  # Hmmm, seems this exceptoin wont go anywhere useful... :-P
 *             THByteTensor_free(self.native)
 */
    __pyx_t_1 = ((__pyx_v_refCount < 1) != 0);
    if (__pyx_t_1) {

      /* "PyTorch.pyx":2087
 *    #            # print('   size[', i, ']', THFloatTensor_size(self.thFloatTensor, i))
 *             if refCount < 1:
 *                 raise Exception('Unallocated an already deallocated tensor... :-O')  # Hmmm, seems this exceptoin wont go anywhere useful... :-P             # <<<<<<<<<<<<<<
 *             THByteTensor_free(self.native)
 *         else:
 */
      __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_tuple__37, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2087, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_Raise(__pyx_t_2, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __PYX_ERR(0, 2087, __pyx_L1_error)

      /* "PyTorch.pyx":2086
 *    #        for i in range(dims):
 *    #            # print('   size[', i, ']', THFloatTensor_size(self.thFloatTensor, i))
 *             if refCount < 1:             # <<<<<<<<<<<<<<
 *                 raise Exception('Unallocated an already deallocated tensor... :-O')  # Hmmm, seems this exceptoin wont go anywhere useful... :-P
 *             THByteTensor_free(self.native)
 */
    }

    /* "PyTorch.pyx":2088
 *             if refCount < 1:
 *                 raise Exception('Unallocated an already deallocated tensor... :-O')  # Hmmm, seems this exceptoin wont go anywhere useful... :-P
 *             THByteTensor_free(self.native)             # <<<<<<<<<<<<<<
 *         else:
 *             logger.debug('__dealloc__ tensor never allocated')
 */
    THByteTensor_free(__pyx_v_self->native);

    /* "PyTorch.pyx":2074
 * #        cdef THFloatStorage *storage
 * #        logger.debug('__dealloc__ native %s', <long>(self.native) != 0)
 *         if <long>(self.native) != 0:             # <<<<<<<<<<<<<<
 *             refCount = THByteTensor_getRefCount(self.native)
 *    #         print('ByteTensor.dealloc old refcount', refCount)
 */
    goto __pyx_L3;
  }

  /* "PyTorch.pyx":2090
 *             THByteTensor_free(self.native)
 *         else:
 *             logger.debug('__dealloc__ tensor never allocated')             # <<<<<<<<<<<<<<
 * 
 *     def nElement(_ByteTensor self):
 */
  /*else*/ {
    __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_logger); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2090, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_debug); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2090, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_tuple__38, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2090, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  }
  __pyx_L3:;

  /* "PyTorch.pyx":2067
 * #        self.storage = storage
 * 
 *     def __dealloc__(self):             # <<<<<<<<<<<<<<
 *         cdef int refCount
 * #        cdef int dims
 */

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_WriteUnraisable("PyTorch._ByteTensor.__dealloc__", __pyx_clineno, __pyx_lineno, __pyx_filename, 0, 0);
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
}

/* "PyTorch.pyx":2092
 *             logger.debug('__dealloc__ tensor never allocated')
 * 
 *     def nElement(_ByteTensor self):             # <<<<<<<<<<<<<<
 *         return THByteTensor_nElement(self.native)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_5nElement(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_5nElement(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("nElement (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_4nElement(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_4nElement(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("nElement", 0);

  /* "PyTorch.pyx":2093
 * 
 *     def nElement(_ByteTensor self):
 *         return THByteTensor_nElement(self.native)             # <<<<<<<<<<<<<<
 * 
 *     def asNumpyTensor(_ByteTensor self):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_long(THByteTensor_nElement(__pyx_v_self->native)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2093, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":2092
 *             logger.debug('__dealloc__ tensor never allocated')
 * 
 *     def nElement(_ByteTensor self):             # <<<<<<<<<<<<<<
 *         return THByteTensor_nElement(self.native)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._ByteTensor.nElement", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2095
 *         return THByteTensor_nElement(self.native)
 * 
 *     def asNumpyTensor(_ByteTensor self):             # <<<<<<<<<<<<<<
 *         cdef Storage._ByteStorage storage
 *         cdef unsigned char *data
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_7asNumpyTensor(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_7asNumpyTensor(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("asNumpyTensor (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_6asNumpyTensor(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_6asNumpyTensor(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self) {
  unsigned char *__pyx_v_data;
  struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_contig = 0;
  PyObject *__pyx_v_size = NULL;
  PyObject *__pyx_v_dims = NULL;
  PyObject *__pyx_v_dtype = NULL;
  PyObject *__pyx_v_totalSize = NULL;
  PyObject *__pyx_v_d = NULL;
  PyObject *__pyx_v_myarray = NULL;
  PyObject *__pyx_v_i = NULL;
  PyObject *__pyx_v_shape = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  Py_ssize_t __pyx_t_4;
  int __pyx_t_5;
  int __pyx_t_6;
  PyObject *(*__pyx_t_7)(PyObject *);
  PyObject *__pyx_t_8 = NULL;
  Py_ssize_t __pyx_t_9;
  int __pyx_t_10;
  __Pyx_RefNannySetupContext("asNumpyTensor", 0);

  /* "PyTorch.pyx":2099
 *         cdef unsigned char *data
 *         cdef _ByteTensor contig
 *         size = self.size()             # <<<<<<<<<<<<<<
 *         dims = len(size)
 *         dtype = None
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_size); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2099, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2099, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2099, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_size = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":2100
 *         cdef _ByteTensor contig
 *         size = self.size()
 *         dims = len(size)             # <<<<<<<<<<<<<<
 *         dtype = None
 * 
 */
  __pyx_t_4 = PyObject_Length(__pyx_v_size); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 2100, __pyx_L1_error)
  __pyx_t_1 = PyInt_FromSsize_t(__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2100, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_dims = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":2101
 *         size = self.size()
 *         dims = len(size)
 *         dtype = None             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_INCREF(Py_None);
  __pyx_v_dtype = Py_None;

  /* "PyTorch.pyx":2104
 * 
 * 
 *         dtype=np.uint8             # <<<<<<<<<<<<<<
 *         if dtype is None:
 *           raise Exception("not implemented for Byte")
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_np); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2104, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_uint8); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2104, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF_SET(__pyx_v_dtype, __pyx_t_2);
  __pyx_t_2 = 0;

  /* "PyTorch.pyx":2105
 * 
 *         dtype=np.uint8
 *         if dtype is None:             # <<<<<<<<<<<<<<
 *           raise Exception("not implemented for Byte")
 * #        print('dtype', dtype)
 */
  __pyx_t_5 = (__pyx_v_dtype == Py_None);
  __pyx_t_6 = (__pyx_t_5 != 0);
  if (__pyx_t_6) {

    /* "PyTorch.pyx":2106
 *         dtype=np.uint8
 *         if dtype is None:
 *           raise Exception("not implemented for Byte")             # <<<<<<<<<<<<<<
 * #        print('dtype', dtype)
 *         if dims >= 1:
 */
    __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_tuple__39, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2106, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(0, 2106, __pyx_L1_error)

    /* "PyTorch.pyx":2105
 * 
 *         dtype=np.uint8
 *         if dtype is None:             # <<<<<<<<<<<<<<
 *           raise Exception("not implemented for Byte")
 * #        print('dtype', dtype)
 */
  }

  /* "PyTorch.pyx":2108
 *           raise Exception("not implemented for Byte")
 * #        print('dtype', dtype)
 *         if dims >= 1:             # <<<<<<<<<<<<<<
 *             totalSize = 1
 *             for d in range(dims - 1, -1, -1):
 */
  __pyx_t_2 = PyObject_RichCompare(__pyx_v_dims, __pyx_int_1, Py_GE); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2108, __pyx_L1_error)
  __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely(__pyx_t_6 < 0)) __PYX_ERR(0, 2108, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (__pyx_t_6) {

    /* "PyTorch.pyx":2109
 * #        print('dtype', dtype)
 *         if dims >= 1:
 *             totalSize = 1             # <<<<<<<<<<<<<<
 *             for d in range(dims - 1, -1, -1):
 *                 totalSize *= size[d]
 */
    __Pyx_INCREF(__pyx_int_1);
    __pyx_v_totalSize = __pyx_int_1;

    /* "PyTorch.pyx":2110
 *         if dims >= 1:
 *             totalSize = 1
 *             for d in range(dims - 1, -1, -1):             # <<<<<<<<<<<<<<
 *                 totalSize *= size[d]
 *             myarray = np.zeros(totalSize, dtype=dtype)
 */
    __pyx_t_2 = __Pyx_PyInt_SubtractObjC(__pyx_v_dims, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2110, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_1 = PyTuple_New(3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2110, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_GIVEREF(__pyx_t_2);
    PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_2);
    __Pyx_INCREF(__pyx_int_neg_1);
    __Pyx_GIVEREF(__pyx_int_neg_1);
    PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_int_neg_1);
    __Pyx_INCREF(__pyx_int_neg_1);
    __Pyx_GIVEREF(__pyx_int_neg_1);
    PyTuple_SET_ITEM(__pyx_t_1, 2, __pyx_int_neg_1);
    __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_range, __pyx_t_1, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2110, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    if (likely(PyList_CheckExact(__pyx_t_2)) || PyTuple_CheckExact(__pyx_t_2)) {
      __pyx_t_1 = __pyx_t_2; __Pyx_INCREF(__pyx_t_1); __pyx_t_4 = 0;
      __pyx_t_7 = NULL;
    } else {
      __pyx_t_4 = -1; __pyx_t_1 = PyObject_GetIter(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2110, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_7 = Py_TYPE(__pyx_t_1)->tp_iternext; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 2110, __pyx_L1_error)
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    for (;;) {
      if (likely(!__pyx_t_7)) {
        if (likely(PyList_CheckExact(__pyx_t_1))) {
          if (__pyx_t_4 >= PyList_GET_SIZE(__pyx_t_1)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_2 = PyList_GET_ITEM(__pyx_t_1, __pyx_t_4); __Pyx_INCREF(__pyx_t_2); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 2110, __pyx_L1_error)
          #else
          __pyx_t_2 = PySequence_ITEM(__pyx_t_1, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2110, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          #endif
        } else {
          if (__pyx_t_4 >= PyTuple_GET_SIZE(__pyx_t_1)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_2 = PyTuple_GET_ITEM(__pyx_t_1, __pyx_t_4); __Pyx_INCREF(__pyx_t_2); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 2110, __pyx_L1_error)
          #else
          __pyx_t_2 = PySequence_ITEM(__pyx_t_1, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2110, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          #endif
        }
      } else {
        __pyx_t_2 = __pyx_t_7(__pyx_t_1);
        if (unlikely(!__pyx_t_2)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(exc_type == PyExc_StopIteration || PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 2110, __pyx_L1_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_2);
      }
      __Pyx_XDECREF_SET(__pyx_v_d, __pyx_t_2);
      __pyx_t_2 = 0;

      /* "PyTorch.pyx":2111
 *             totalSize = 1
 *             for d in range(dims - 1, -1, -1):
 *                 totalSize *= size[d]             # <<<<<<<<<<<<<<
 *             myarray = np.zeros(totalSize, dtype=dtype)
 *             contig = self.contiguous()
 */
      __pyx_t_2 = PyObject_GetItem(__pyx_v_size, __pyx_v_d); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2111, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_3 = PyNumber_InPlaceMultiply(__pyx_v_totalSize, __pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2111, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_DECREF_SET(__pyx_v_totalSize, __pyx_t_3);
      __pyx_t_3 = 0;

      /* "PyTorch.pyx":2110
 *         if dims >= 1:
 *             totalSize = 1
 *             for d in range(dims - 1, -1, -1):             # <<<<<<<<<<<<<<
 *                 totalSize *= size[d]
 *             myarray = np.zeros(totalSize, dtype=dtype)
 */
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "PyTorch.pyx":2112
 *             for d in range(dims - 1, -1, -1):
 *                 totalSize *= size[d]
 *             myarray = np.zeros(totalSize, dtype=dtype)             # <<<<<<<<<<<<<<
 *             contig = self.contiguous()
 *             data = contig.data()
 */
    __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_np); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2112, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_zeros); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2112, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2112, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_INCREF(__pyx_v_totalSize);
    __Pyx_GIVEREF(__pyx_v_totalSize);
    PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_v_totalSize);
    __pyx_t_2 = PyDict_New(); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2112, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    if (PyDict_SetItem(__pyx_t_2, __pyx_n_s_dtype, __pyx_v_dtype) < 0) __PYX_ERR(0, 2112, __pyx_L1_error)
    __pyx_t_8 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_1, __pyx_t_2); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2112, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_v_myarray = __pyx_t_8;
    __pyx_t_8 = 0;

    /* "PyTorch.pyx":2113
 *                 totalSize *= size[d]
 *             myarray = np.zeros(totalSize, dtype=dtype)
 *             contig = self.contiguous()             # <<<<<<<<<<<<<<
 *             data = contig.data()
 *             for i in range(totalSize):
 */
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_contiguous); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2113, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_1 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
      __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_2);
      if (likely(__pyx_t_1)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
        __Pyx_INCREF(__pyx_t_1);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_2, function);
      }
    }
    if (__pyx_t_1) {
      __pyx_t_8 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2113, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    } else {
      __pyx_t_8 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2113, __pyx_L1_error)
    }
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    if (!(likely(((__pyx_t_8) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_8, __pyx_ptype_7PyTorch__ByteTensor))))) __PYX_ERR(0, 2113, __pyx_L1_error)
    __pyx_v_contig = ((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_t_8);
    __pyx_t_8 = 0;

    /* "PyTorch.pyx":2114
 *             myarray = np.zeros(totalSize, dtype=dtype)
 *             contig = self.contiguous()
 *             data = contig.data()             # <<<<<<<<<<<<<<
 *             for i in range(totalSize):
 *                 myarray[i] = data[i]
 */
    __pyx_v_data = ((struct __pyx_vtabstruct_7PyTorch__ByteTensor *)__pyx_v_contig->__pyx_vtab)->data(__pyx_v_contig);

    /* "PyTorch.pyx":2115
 *             contig = self.contiguous()
 *             data = contig.data()
 *             for i in range(totalSize):             # <<<<<<<<<<<<<<
 *                 myarray[i] = data[i]
 *             shape = []
 */
    __pyx_t_8 = PyTuple_New(1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2115, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_INCREF(__pyx_v_totalSize);
    __Pyx_GIVEREF(__pyx_v_totalSize);
    PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_v_totalSize);
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_range, __pyx_t_8, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2115, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    if (likely(PyList_CheckExact(__pyx_t_2)) || PyTuple_CheckExact(__pyx_t_2)) {
      __pyx_t_8 = __pyx_t_2; __Pyx_INCREF(__pyx_t_8); __pyx_t_4 = 0;
      __pyx_t_7 = NULL;
    } else {
      __pyx_t_4 = -1; __pyx_t_8 = PyObject_GetIter(__pyx_t_2); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2115, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_7 = Py_TYPE(__pyx_t_8)->tp_iternext; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 2115, __pyx_L1_error)
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    for (;;) {
      if (likely(!__pyx_t_7)) {
        if (likely(PyList_CheckExact(__pyx_t_8))) {
          if (__pyx_t_4 >= PyList_GET_SIZE(__pyx_t_8)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_2 = PyList_GET_ITEM(__pyx_t_8, __pyx_t_4); __Pyx_INCREF(__pyx_t_2); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 2115, __pyx_L1_error)
          #else
          __pyx_t_2 = PySequence_ITEM(__pyx_t_8, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2115, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          #endif
        } else {
          if (__pyx_t_4 >= PyTuple_GET_SIZE(__pyx_t_8)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_2 = PyTuple_GET_ITEM(__pyx_t_8, __pyx_t_4); __Pyx_INCREF(__pyx_t_2); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 2115, __pyx_L1_error)
          #else
          __pyx_t_2 = PySequence_ITEM(__pyx_t_8, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2115, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          #endif
        }
      } else {
        __pyx_t_2 = __pyx_t_7(__pyx_t_8);
        if (unlikely(!__pyx_t_2)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(exc_type == PyExc_StopIteration || PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 2115, __pyx_L1_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_2);
      }
      __Pyx_XDECREF_SET(__pyx_v_i, __pyx_t_2);
      __pyx_t_2 = 0;

      /* "PyTorch.pyx":2116
 *             data = contig.data()
 *             for i in range(totalSize):
 *                 myarray[i] = data[i]             # <<<<<<<<<<<<<<
 *             shape = []
 *             for d in range(dims):
 */
      __pyx_t_9 = __Pyx_PyIndex_AsSsize_t(__pyx_v_i); if (unlikely((__pyx_t_9 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 2116, __pyx_L1_error)
      __pyx_t_2 = __Pyx_PyInt_From_unsigned_char((__pyx_v_data[__pyx_t_9])); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2116, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      if (unlikely(PyObject_SetItem(__pyx_v_myarray, __pyx_v_i, __pyx_t_2) < 0)) __PYX_ERR(0, 2116, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

      /* "PyTorch.pyx":2115
 *             contig = self.contiguous()
 *             data = contig.data()
 *             for i in range(totalSize):             # <<<<<<<<<<<<<<
 *                 myarray[i] = data[i]
 *             shape = []
 */
    }
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;

    /* "PyTorch.pyx":2117
 *             for i in range(totalSize):
 *                 myarray[i] = data[i]
 *             shape = []             # <<<<<<<<<<<<<<
 *             for d in range(dims):
 *                 shape.append(size[d])
 */
    __pyx_t_8 = PyList_New(0); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2117, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_v_shape = ((PyObject*)__pyx_t_8);
    __pyx_t_8 = 0;

    /* "PyTorch.pyx":2118
 *                 myarray[i] = data[i]
 *             shape = []
 *             for d in range(dims):             # <<<<<<<<<<<<<<
 *                 shape.append(size[d])
 *             return myarray.reshape(shape)
 */
    __pyx_t_8 = PyTuple_New(1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2118, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_INCREF(__pyx_v_dims);
    __Pyx_GIVEREF(__pyx_v_dims);
    PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_v_dims);
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_range, __pyx_t_8, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2118, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    if (likely(PyList_CheckExact(__pyx_t_2)) || PyTuple_CheckExact(__pyx_t_2)) {
      __pyx_t_8 = __pyx_t_2; __Pyx_INCREF(__pyx_t_8); __pyx_t_4 = 0;
      __pyx_t_7 = NULL;
    } else {
      __pyx_t_4 = -1; __pyx_t_8 = PyObject_GetIter(__pyx_t_2); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2118, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_7 = Py_TYPE(__pyx_t_8)->tp_iternext; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 2118, __pyx_L1_error)
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    for (;;) {
      if (likely(!__pyx_t_7)) {
        if (likely(PyList_CheckExact(__pyx_t_8))) {
          if (__pyx_t_4 >= PyList_GET_SIZE(__pyx_t_8)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_2 = PyList_GET_ITEM(__pyx_t_8, __pyx_t_4); __Pyx_INCREF(__pyx_t_2); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 2118, __pyx_L1_error)
          #else
          __pyx_t_2 = PySequence_ITEM(__pyx_t_8, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2118, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          #endif
        } else {
          if (__pyx_t_4 >= PyTuple_GET_SIZE(__pyx_t_8)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_2 = PyTuple_GET_ITEM(__pyx_t_8, __pyx_t_4); __Pyx_INCREF(__pyx_t_2); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 2118, __pyx_L1_error)
          #else
          __pyx_t_2 = PySequence_ITEM(__pyx_t_8, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2118, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          #endif
        }
      } else {
        __pyx_t_2 = __pyx_t_7(__pyx_t_8);
        if (unlikely(!__pyx_t_2)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(exc_type == PyExc_StopIteration || PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 2118, __pyx_L1_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_2);
      }
      __Pyx_XDECREF_SET(__pyx_v_d, __pyx_t_2);
      __pyx_t_2 = 0;

      /* "PyTorch.pyx":2119
 *             shape = []
 *             for d in range(dims):
 *                 shape.append(size[d])             # <<<<<<<<<<<<<<
 *             return myarray.reshape(shape)
 *         else:
 */
      __pyx_t_2 = PyObject_GetItem(__pyx_v_size, __pyx_v_d); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2119, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_10 = __Pyx_PyList_Append(__pyx_v_shape, __pyx_t_2); if (unlikely(__pyx_t_10 == -1)) __PYX_ERR(0, 2119, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

      /* "PyTorch.pyx":2118
 *                 myarray[i] = data[i]
 *             shape = []
 *             for d in range(dims):             # <<<<<<<<<<<<<<
 *                 shape.append(size[d])
 *             return myarray.reshape(shape)
 */
    }
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;

    /* "PyTorch.pyx":2120
 *             for d in range(dims):
 *                 shape.append(size[d])
 *             return myarray.reshape(shape)             # <<<<<<<<<<<<<<
 *         else:
 *             raise Exception('Not implemented for dims = {dims}'.format(dims=dims))
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_myarray, __pyx_n_s_reshape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2120, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_1 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
      __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_2);
      if (likely(__pyx_t_1)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
        __Pyx_INCREF(__pyx_t_1);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_2, function);
      }
    }
    if (!__pyx_t_1) {
      __pyx_t_8 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_v_shape); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2120, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[2] = {__pyx_t_1, __pyx_v_shape};
        __pyx_t_8 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2120, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
        __Pyx_GOTREF(__pyx_t_8);
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[2] = {__pyx_t_1, __pyx_v_shape};
        __pyx_t_8 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2120, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
        __Pyx_GOTREF(__pyx_t_8);
      } else
      #endif
      {
        __pyx_t_3 = PyTuple_New(1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2120, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_GIVEREF(__pyx_t_1); PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_1); __pyx_t_1 = NULL;
        __Pyx_INCREF(__pyx_v_shape);
        __Pyx_GIVEREF(__pyx_v_shape);
        PyTuple_SET_ITEM(__pyx_t_3, 0+1, __pyx_v_shape);
        __pyx_t_8 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_3, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2120, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_r = __pyx_t_8;
    __pyx_t_8 = 0;
    goto __pyx_L0;

    /* "PyTorch.pyx":2108
 *           raise Exception("not implemented for Byte")
 * #        print('dtype', dtype)
 *         if dims >= 1:             # <<<<<<<<<<<<<<
 *             totalSize = 1
 *             for d in range(dims - 1, -1, -1):
 */
  }

  /* "PyTorch.pyx":2122
 *             return myarray.reshape(shape)
 *         else:
 *             raise Exception('Not implemented for dims = {dims}'.format(dims=dims))             # <<<<<<<<<<<<<<
 * 
 *     @property
 */
  /*else*/ {
    __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_kp_s_Not_implemented_for_dims_dims, __pyx_n_s_format); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2122, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_2 = PyDict_New(); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2122, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    if (PyDict_SetItem(__pyx_t_2, __pyx_n_s_dims, __pyx_v_dims) < 0) __PYX_ERR(0, 2122, __pyx_L1_error)
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_8, __pyx_empty_tuple, __pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2122, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = PyTuple_New(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2122, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_GIVEREF(__pyx_t_3);
    PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_3);
    __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_t_2, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2122, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(0, 2122, __pyx_L1_error)
  }

  /* "PyTorch.pyx":2095
 *         return THByteTensor_nElement(self.native)
 * 
 *     def asNumpyTensor(_ByteTensor self):             # <<<<<<<<<<<<<<
 *         cdef Storage._ByteStorage storage
 *         cdef unsigned char *data
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("PyTorch._ByteTensor.asNumpyTensor", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_contig);
  __Pyx_XDECREF(__pyx_v_size);
  __Pyx_XDECREF(__pyx_v_dims);
  __Pyx_XDECREF(__pyx_v_dtype);
  __Pyx_XDECREF(__pyx_v_totalSize);
  __Pyx_XDECREF(__pyx_v_d);
  __Pyx_XDECREF(__pyx_v_myarray);
  __Pyx_XDECREF(__pyx_v_i);
  __Pyx_XDECREF(__pyx_v_shape);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2125
 * 
 *     @property
 *     def refCount(_ByteTensor self):             # <<<<<<<<<<<<<<
 *         return THByteTensor_getRefCount(self.native)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_8refCount_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_8refCount_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_8refCount___get__(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_8refCount___get__(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "PyTorch.pyx":2126
 *     @property
 *     def refCount(_ByteTensor self):
 *         return THByteTensor_getRefCount(self.native)             # <<<<<<<<<<<<<<
 * 
 *     cdef unsigned char *data(_ByteTensor self):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_int(THByteTensor_getRefCount(__pyx_v_self->native)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2126, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":2125
 * 
 *     @property
 *     def refCount(_ByteTensor self):             # <<<<<<<<<<<<<<
 *         return THByteTensor_getRefCount(self.native)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._ByteTensor.refCount.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2128
 *         return THByteTensor_getRefCount(self.native)
 * 
 *     cdef unsigned char *data(_ByteTensor self):             # <<<<<<<<<<<<<<
 *         return THByteTensor_data(self.native)
 * 
 */

static unsigned char *__pyx_f_7PyTorch_11_ByteTensor_data(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self) {
  unsigned char *__pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("data", 0);

  /* "PyTorch.pyx":2129
 * 
 *     cdef unsigned char *data(_ByteTensor self):
 *         return THByteTensor_data(self.native)             # <<<<<<<<<<<<<<
 * 
 *     cpdef int dims(self):
 */
  __pyx_r = THByteTensor_data(__pyx_v_self->native);
  goto __pyx_L0;

  /* "PyTorch.pyx":2128
 *         return THByteTensor_getRefCount(self.native)
 * 
 *     cdef unsigned char *data(_ByteTensor self):             # <<<<<<<<<<<<<<
 *         return THByteTensor_data(self.native)
 * 
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2131
 *         return THByteTensor_data(self.native)
 * 
 *     cpdef int dims(self):             # <<<<<<<<<<<<<<
 *         return THByteTensor_nDimension(self.native)
 * 
 */

static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_9dims(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static int __pyx_f_7PyTorch_11_ByteTensor_dims(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, int __pyx_skip_dispatch) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  int __pyx_t_5;
  __Pyx_RefNannySetupContext("dims", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_dims); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2131, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_9dims)) {
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_3 = __pyx_t_1; __pyx_t_4 = NULL;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
        __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
        if (likely(__pyx_t_4)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
          __Pyx_INCREF(__pyx_t_4);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_3, function);
        }
      }
      if (__pyx_t_4) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_4); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2131, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else {
        __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2131, __pyx_L1_error)
      }
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_5 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_5 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 2131, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_r = __pyx_t_5;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "PyTorch.pyx":2132
 * 
 *     cpdef int dims(self):
 *         return THByteTensor_nDimension(self.native)             # <<<<<<<<<<<<<<
 * 
 *     cpdef set1d(self, int x0, unsigned char value):
 */
  __pyx_r = THByteTensor_nDimension(__pyx_v_self->native);
  goto __pyx_L0;

  /* "PyTorch.pyx":2131
 *         return THByteTensor_data(self.native)
 * 
 *     cpdef int dims(self):             # <<<<<<<<<<<<<<
 *         return THByteTensor_nDimension(self.native)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_WriteUnraisable("PyTorch._ByteTensor.dims", __pyx_clineno, __pyx_lineno, __pyx_filename, 0, 0);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_9dims(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_9dims(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("dims (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_8dims(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_8dims(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("dims", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_f_7PyTorch_11_ByteTensor_dims(__pyx_v_self, 1)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2131, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._ByteTensor.dims", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2134
 *         return THByteTensor_nDimension(self.native)
 * 
 *     cpdef set1d(self, int x0, unsigned char value):             # <<<<<<<<<<<<<<
 *         THByteTensor_set1d(self.native, x0, value)
 * 
 */

static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_11set1d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_f_7PyTorch_11_ByteTensor_set1d(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, int __pyx_v_x0, unsigned char __pyx_v_value, int __pyx_skip_dispatch) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  int __pyx_t_7;
  PyObject *__pyx_t_8 = NULL;
  __Pyx_RefNannySetupContext("set1d", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_set1d); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2134, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_11set1d)) {
      __Pyx_XDECREF(__pyx_r);
      __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_x0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2134, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_4 = __Pyx_PyInt_From_unsigned_char(__pyx_v_value); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2134, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_5 = __pyx_t_1; __pyx_t_6 = NULL;
      __pyx_t_7 = 0;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
        __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_5);
        if (likely(__pyx_t_6)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
          __Pyx_INCREF(__pyx_t_6);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_5, function);
          __pyx_t_7 = 1;
        }
      }
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_5)) {
        PyObject *__pyx_temp[3] = {__pyx_t_6, __pyx_t_3, __pyx_t_4};
        __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_7, 2+__pyx_t_7); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2134, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
        PyObject *__pyx_temp[3] = {__pyx_t_6, __pyx_t_3, __pyx_t_4};
        __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_7, 2+__pyx_t_7); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2134, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else
      #endif
      {
        __pyx_t_8 = PyTuple_New(2+__pyx_t_7); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2134, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        if (__pyx_t_6) {
          __Pyx_GIVEREF(__pyx_t_6); PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_t_6); __pyx_t_6 = NULL;
        }
        __Pyx_GIVEREF(__pyx_t_3);
        PyTuple_SET_ITEM(__pyx_t_8, 0+__pyx_t_7, __pyx_t_3);
        __Pyx_GIVEREF(__pyx_t_4);
        PyTuple_SET_ITEM(__pyx_t_8, 1+__pyx_t_7, __pyx_t_4);
        __pyx_t_3 = 0;
        __pyx_t_4 = 0;
        __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_8, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2134, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      }
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __pyx_r = __pyx_t_2;
      __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "PyTorch.pyx":2135
 * 
 *     cpdef set1d(self, int x0, unsigned char value):
 *         THByteTensor_set1d(self.native, x0, value)             # <<<<<<<<<<<<<<
 * 
 *     cpdef set2d(self, int x0, int x1, unsigned char value):
 */
  THByteTensor_set1d(__pyx_v_self->native, __pyx_v_x0, __pyx_v_value);

  /* "PyTorch.pyx":2134
 *         return THByteTensor_nDimension(self.native)
 * 
 *     cpdef set1d(self, int x0, unsigned char value):             # <<<<<<<<<<<<<<
 *         THByteTensor_set1d(self.native, x0, value)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("PyTorch._ByteTensor.set1d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_11set1d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_11set1d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  int __pyx_v_x0;
  unsigned char __pyx_v_value;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("set1d (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_x0,&__pyx_n_s_value,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_x0)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_value)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("set1d", 1, 2, 2, 1); __PYX_ERR(0, 2134, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "set1d") < 0)) __PYX_ERR(0, 2134, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_x0 = __Pyx_PyInt_As_int(values[0]); if (unlikely((__pyx_v_x0 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 2134, __pyx_L3_error)
    __pyx_v_value = __Pyx_PyInt_As_unsigned_char(values[1]); if (unlikely((__pyx_v_value == (unsigned char)-1) && PyErr_Occurred())) __PYX_ERR(0, 2134, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("set1d", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 2134, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._ByteTensor.set1d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_10set1d(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self), __pyx_v_x0, __pyx_v_value);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_10set1d(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, int __pyx_v_x0, unsigned char __pyx_v_value) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("set1d", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_7PyTorch_11_ByteTensor_set1d(__pyx_v_self, __pyx_v_x0, __pyx_v_value, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2134, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._ByteTensor.set1d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2137
 *         THByteTensor_set1d(self.native, x0, value)
 * 
 *     cpdef set2d(self, int x0, int x1, unsigned char value):             # <<<<<<<<<<<<<<
 *         THByteTensor_set2d(self.native, x0, x1, value)
 * 
 */

static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_13set2d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_f_7PyTorch_11_ByteTensor_set2d(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_v_x1, unsigned char __pyx_v_value, int __pyx_skip_dispatch) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  int __pyx_t_8;
  PyObject *__pyx_t_9 = NULL;
  __Pyx_RefNannySetupContext("set2d", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_set2d); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2137, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_13set2d)) {
      __Pyx_XDECREF(__pyx_r);
      __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_x0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2137, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_4 = __Pyx_PyInt_From_int(__pyx_v_x1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2137, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_t_5 = __Pyx_PyInt_From_unsigned_char(__pyx_v_value); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 2137, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_6 = __pyx_t_1; __pyx_t_7 = NULL;
      __pyx_t_8 = 0;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_6))) {
        __pyx_t_7 = PyMethod_GET_SELF(__pyx_t_6);
        if (likely(__pyx_t_7)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
          __Pyx_INCREF(__pyx_t_7);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_6, function);
          __pyx_t_8 = 1;
        }
      }
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_6)) {
        PyObject *__pyx_temp[4] = {__pyx_t_7, __pyx_t_3, __pyx_t_4, __pyx_t_5};
        __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_8, 3+__pyx_t_8); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2137, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_6)) {
        PyObject *__pyx_temp[4] = {__pyx_t_7, __pyx_t_3, __pyx_t_4, __pyx_t_5};
        __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_8, 3+__pyx_t_8); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2137, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      } else
      #endif
      {
        __pyx_t_9 = PyTuple_New(3+__pyx_t_8); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 2137, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_9);
        if (__pyx_t_7) {
          __Pyx_GIVEREF(__pyx_t_7); PyTuple_SET_ITEM(__pyx_t_9, 0, __pyx_t_7); __pyx_t_7 = NULL;
        }
        __Pyx_GIVEREF(__pyx_t_3);
        PyTuple_SET_ITEM(__pyx_t_9, 0+__pyx_t_8, __pyx_t_3);
        __Pyx_GIVEREF(__pyx_t_4);
        PyTuple_SET_ITEM(__pyx_t_9, 1+__pyx_t_8, __pyx_t_4);
        __Pyx_GIVEREF(__pyx_t_5);
        PyTuple_SET_ITEM(__pyx_t_9, 2+__pyx_t_8, __pyx_t_5);
        __pyx_t_3 = 0;
        __pyx_t_4 = 0;
        __pyx_t_5 = 0;
        __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_9, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2137, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      }
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_r = __pyx_t_2;
      __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "PyTorch.pyx":2138
 * 
 *     cpdef set2d(self, int x0, int x1, unsigned char value):
 *         THByteTensor_set2d(self.native, x0, x1, value)             # <<<<<<<<<<<<<<
 * 
 *     cpdef unsigned char get1d(self, int x0):
 */
  THByteTensor_set2d(__pyx_v_self->native, __pyx_v_x0, __pyx_v_x1, __pyx_v_value);

  /* "PyTorch.pyx":2137
 *         THByteTensor_set1d(self.native, x0, value)
 * 
 *     cpdef set2d(self, int x0, int x1, unsigned char value):             # <<<<<<<<<<<<<<
 *         THByteTensor_set2d(self.native, x0, x1, value)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_AddTraceback("PyTorch._ByteTensor.set2d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_13set2d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_13set2d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  int __pyx_v_x0;
  int __pyx_v_x1;
  unsigned char __pyx_v_value;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("set2d (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_x0,&__pyx_n_s_x1,&__pyx_n_s_value,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_x0)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_x1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("set2d", 1, 3, 3, 1); __PYX_ERR(0, 2137, __pyx_L3_error)
        }
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_value)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("set2d", 1, 3, 3, 2); __PYX_ERR(0, 2137, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "set2d") < 0)) __PYX_ERR(0, 2137, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_x0 = __Pyx_PyInt_As_int(values[0]); if (unlikely((__pyx_v_x0 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 2137, __pyx_L3_error)
    __pyx_v_x1 = __Pyx_PyInt_As_int(values[1]); if (unlikely((__pyx_v_x1 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 2137, __pyx_L3_error)
    __pyx_v_value = __Pyx_PyInt_As_unsigned_char(values[2]); if (unlikely((__pyx_v_value == (unsigned char)-1) && PyErr_Occurred())) __PYX_ERR(0, 2137, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("set2d", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 2137, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._ByteTensor.set2d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_12set2d(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self), __pyx_v_x0, __pyx_v_x1, __pyx_v_value);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_12set2d(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_v_x1, unsigned char __pyx_v_value) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("set2d", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_7PyTorch_11_ByteTensor_set2d(__pyx_v_self, __pyx_v_x0, __pyx_v_x1, __pyx_v_value, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2137, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._ByteTensor.set2d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2140
 *         THByteTensor_set2d(self.native, x0, x1, value)
 * 
 *     cpdef unsigned char get1d(self, int x0):             # <<<<<<<<<<<<<<
 *         return THByteTensor_get1d(self.native, x0)
 * 
 */

static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_15get1d(PyObject *__pyx_v_self, PyObject *__pyx_arg_x0); /*proto*/
static unsigned char __pyx_f_7PyTorch_11_ByteTensor_get1d(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_skip_dispatch) {
  unsigned char __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  unsigned char __pyx_t_7;
  __Pyx_RefNannySetupContext("get1d", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_get1d); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2140, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_15get1d)) {
      __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_x0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2140, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_4 = __pyx_t_1; __pyx_t_5 = NULL;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_4))) {
        __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_4);
        if (likely(__pyx_t_5)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
          __Pyx_INCREF(__pyx_t_5);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_4, function);
        }
      }
      if (!__pyx_t_5) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2140, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_GOTREF(__pyx_t_2);
      } else {
        #if CYTHON_FAST_PYCALL
        if (PyFunction_Check(__pyx_t_4)) {
          PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_t_3};
          __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_4, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2140, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        } else
        #endif
        #if CYTHON_FAST_PYCCALL
        if (__Pyx_PyFastCFunction_Check(__pyx_t_4)) {
          PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_t_3};
          __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_4, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2140, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        } else
        #endif
        {
          __pyx_t_6 = PyTuple_New(1+1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2140, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_6);
          __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_5); __pyx_t_5 = NULL;
          __Pyx_GIVEREF(__pyx_t_3);
          PyTuple_SET_ITEM(__pyx_t_6, 0+1, __pyx_t_3);
          __pyx_t_3 = 0;
          __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_4, __pyx_t_6, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2140, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
        }
      }
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_7 = __Pyx_PyInt_As_unsigned_char(__pyx_t_2); if (unlikely((__pyx_t_7 == (unsigned char)-1) && PyErr_Occurred())) __PYX_ERR(0, 2140, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_r = __pyx_t_7;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "PyTorch.pyx":2141
 * 
 *     cpdef unsigned char get1d(self, int x0):
 *         return THByteTensor_get1d(self.native, x0)             # <<<<<<<<<<<<<<
 * 
 *     cpdef unsigned char get2d(self, int x0, int x1):
 */
  __pyx_r = THByteTensor_get1d(__pyx_v_self->native, __pyx_v_x0);
  goto __pyx_L0;

  /* "PyTorch.pyx":2140
 *         THByteTensor_set2d(self.native, x0, x1, value)
 * 
 *     cpdef unsigned char get1d(self, int x0):             # <<<<<<<<<<<<<<
 *         return THByteTensor_get1d(self.native, x0)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_WriteUnraisable("PyTorch._ByteTensor.get1d", __pyx_clineno, __pyx_lineno, __pyx_filename, 0, 0);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_15get1d(PyObject *__pyx_v_self, PyObject *__pyx_arg_x0); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_15get1d(PyObject *__pyx_v_self, PyObject *__pyx_arg_x0) {
  int __pyx_v_x0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("get1d (wrapper)", 0);
  assert(__pyx_arg_x0); {
    __pyx_v_x0 = __Pyx_PyInt_As_int(__pyx_arg_x0); if (unlikely((__pyx_v_x0 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 2140, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._ByteTensor.get1d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_14get1d(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self), ((int)__pyx_v_x0));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_14get1d(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, int __pyx_v_x0) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("get1d", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_unsigned_char(__pyx_f_7PyTorch_11_ByteTensor_get1d(__pyx_v_self, __pyx_v_x0, 1)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2140, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._ByteTensor.get1d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2143
 *         return THByteTensor_get1d(self.native, x0)
 * 
 *     cpdef unsigned char get2d(self, int x0, int x1):             # <<<<<<<<<<<<<<
 *         return THByteTensor_get2d(self.native, x0, x1)
 * 
 */

static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_17get2d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static unsigned char __pyx_f_7PyTorch_11_ByteTensor_get2d(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_v_x1, int __pyx_skip_dispatch) {
  unsigned char __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  int __pyx_t_7;
  PyObject *__pyx_t_8 = NULL;
  unsigned char __pyx_t_9;
  __Pyx_RefNannySetupContext("get2d", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_get2d); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2143, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_17get2d)) {
      __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_x0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2143, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_4 = __Pyx_PyInt_From_int(__pyx_v_x1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2143, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_5 = __pyx_t_1; __pyx_t_6 = NULL;
      __pyx_t_7 = 0;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
        __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_5);
        if (likely(__pyx_t_6)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
          __Pyx_INCREF(__pyx_t_6);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_5, function);
          __pyx_t_7 = 1;
        }
      }
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_5)) {
        PyObject *__pyx_temp[3] = {__pyx_t_6, __pyx_t_3, __pyx_t_4};
        __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_7, 2+__pyx_t_7); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2143, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
        PyObject *__pyx_temp[3] = {__pyx_t_6, __pyx_t_3, __pyx_t_4};
        __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_7, 2+__pyx_t_7); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2143, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else
      #endif
      {
        __pyx_t_8 = PyTuple_New(2+__pyx_t_7); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2143, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        if (__pyx_t_6) {
          __Pyx_GIVEREF(__pyx_t_6); PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_t_6); __pyx_t_6 = NULL;
        }
        __Pyx_GIVEREF(__pyx_t_3);
        PyTuple_SET_ITEM(__pyx_t_8, 0+__pyx_t_7, __pyx_t_3);
        __Pyx_GIVEREF(__pyx_t_4);
        PyTuple_SET_ITEM(__pyx_t_8, 1+__pyx_t_7, __pyx_t_4);
        __pyx_t_3 = 0;
        __pyx_t_4 = 0;
        __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_8, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2143, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      }
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __pyx_t_9 = __Pyx_PyInt_As_unsigned_char(__pyx_t_2); if (unlikely((__pyx_t_9 == (unsigned char)-1) && PyErr_Occurred())) __PYX_ERR(0, 2143, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_r = __pyx_t_9;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "PyTorch.pyx":2144
 * 
 *     cpdef unsigned char get2d(self, int x0, int x1):
 *         return THByteTensor_get2d(self.native, x0, x1)             # <<<<<<<<<<<<<<
 * 
 *     cpdef int isContiguous(_ByteTensor self):
 */
  __pyx_r = THByteTensor_get2d(__pyx_v_self->native, __pyx_v_x0, __pyx_v_x1);
  goto __pyx_L0;

  /* "PyTorch.pyx":2143
 *         return THByteTensor_get1d(self.native, x0)
 * 
 *     cpdef unsigned char get2d(self, int x0, int x1):             # <<<<<<<<<<<<<<
 *         return THByteTensor_get2d(self.native, x0, x1)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_WriteUnraisable("PyTorch._ByteTensor.get2d", __pyx_clineno, __pyx_lineno, __pyx_filename, 0, 0);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_17get2d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_17get2d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  int __pyx_v_x0;
  int __pyx_v_x1;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("get2d (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_x0,&__pyx_n_s_x1,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_x0)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_x1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("get2d", 1, 2, 2, 1); __PYX_ERR(0, 2143, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "get2d") < 0)) __PYX_ERR(0, 2143, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_x0 = __Pyx_PyInt_As_int(values[0]); if (unlikely((__pyx_v_x0 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 2143, __pyx_L3_error)
    __pyx_v_x1 = __Pyx_PyInt_As_int(values[1]); if (unlikely((__pyx_v_x1 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 2143, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("get2d", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 2143, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._ByteTensor.get2d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_16get2d(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self), __pyx_v_x0, __pyx_v_x1);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_16get2d(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_v_x1) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("get2d", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_unsigned_char(__pyx_f_7PyTorch_11_ByteTensor_get2d(__pyx_v_self, __pyx_v_x0, __pyx_v_x1, 1)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2143, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._ByteTensor.get2d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2146
 *         return THByteTensor_get2d(self.native, x0, x1)
 * 
 *     cpdef int isContiguous(_ByteTensor self):             # <<<<<<<<<<<<<<
 *         return THByteTensor_isContiguous(self.native)
 * 
 */

static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_19isContiguous(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static int __pyx_f_7PyTorch_11_ByteTensor_isContiguous(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, int __pyx_skip_dispatch) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  int __pyx_t_5;
  __Pyx_RefNannySetupContext("isContiguous", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_isContiguous); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2146, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_19isContiguous)) {
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_3 = __pyx_t_1; __pyx_t_4 = NULL;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
        __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
        if (likely(__pyx_t_4)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
          __Pyx_INCREF(__pyx_t_4);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_3, function);
        }
      }
      if (__pyx_t_4) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_4); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2146, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else {
        __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2146, __pyx_L1_error)
      }
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_5 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_5 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 2146, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_r = __pyx_t_5;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "PyTorch.pyx":2147
 * 
 *     cpdef int isContiguous(_ByteTensor self):
 *         return THByteTensor_isContiguous(self.native)             # <<<<<<<<<<<<<<
 * 
 *     cpdef unsigned char max(self):
 */
  __pyx_r = THByteTensor_isContiguous(__pyx_v_self->native);
  goto __pyx_L0;

  /* "PyTorch.pyx":2146
 *         return THByteTensor_get2d(self.native, x0, x1)
 * 
 *     cpdef int isContiguous(_ByteTensor self):             # <<<<<<<<<<<<<<
 *         return THByteTensor_isContiguous(self.native)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_WriteUnraisable("PyTorch._ByteTensor.isContiguous", __pyx_clineno, __pyx_lineno, __pyx_filename, 0, 0);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_19isContiguous(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_19isContiguous(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("isContiguous (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_18isContiguous(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_18isContiguous(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("isContiguous", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_f_7PyTorch_11_ByteTensor_isContiguous(__pyx_v_self, 1)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2146, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._ByteTensor.isContiguous", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2149
 *         return THByteTensor_isContiguous(self.native)
 * 
 *     cpdef unsigned char max(self):             # <<<<<<<<<<<<<<
 *         return THByteTensor_maxall(self.native)
 * 
 */

static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_21max(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static unsigned char __pyx_f_7PyTorch_11_ByteTensor_max(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, int __pyx_skip_dispatch) {
  unsigned char __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  unsigned char __pyx_t_5;
  __Pyx_RefNannySetupContext("max", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_max); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2149, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_21max)) {
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_3 = __pyx_t_1; __pyx_t_4 = NULL;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
        __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
        if (likely(__pyx_t_4)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
          __Pyx_INCREF(__pyx_t_4);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_3, function);
        }
      }
      if (__pyx_t_4) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_4); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2149, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else {
        __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2149, __pyx_L1_error)
      }
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_5 = __Pyx_PyInt_As_unsigned_char(__pyx_t_2); if (unlikely((__pyx_t_5 == (unsigned char)-1) && PyErr_Occurred())) __PYX_ERR(0, 2149, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_r = __pyx_t_5;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "PyTorch.pyx":2150
 * 
 *     cpdef unsigned char max(self):
 *         return THByteTensor_maxall(self.native)             # <<<<<<<<<<<<<<
 * 
 *     cpdef unsigned char min(self):
 */
  __pyx_r = THByteTensor_maxall(__pyx_v_self->native);
  goto __pyx_L0;

  /* "PyTorch.pyx":2149
 *         return THByteTensor_isContiguous(self.native)
 * 
 *     cpdef unsigned char max(self):             # <<<<<<<<<<<<<<
 *         return THByteTensor_maxall(self.native)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_WriteUnraisable("PyTorch._ByteTensor.max", __pyx_clineno, __pyx_lineno, __pyx_filename, 0, 0);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_21max(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_21max(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("max (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_20max(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_20max(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("max", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_unsigned_char(__pyx_f_7PyTorch_11_ByteTensor_max(__pyx_v_self, 1)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2149, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._ByteTensor.max", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2152
 *         return THByteTensor_maxall(self.native)
 * 
 *     cpdef unsigned char min(self):             # <<<<<<<<<<<<<<
 *         return THByteTensor_minall(self.native)
 * 
 */

static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_23min(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static unsigned char __pyx_f_7PyTorch_11_ByteTensor_min(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, int __pyx_skip_dispatch) {
  unsigned char __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  unsigned char __pyx_t_5;
  __Pyx_RefNannySetupContext("min", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_min); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2152, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_23min)) {
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_3 = __pyx_t_1; __pyx_t_4 = NULL;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
        __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
        if (likely(__pyx_t_4)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
          __Pyx_INCREF(__pyx_t_4);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_3, function);
        }
      }
      if (__pyx_t_4) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_4); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2152, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else {
        __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2152, __pyx_L1_error)
      }
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_5 = __Pyx_PyInt_As_unsigned_char(__pyx_t_2); if (unlikely((__pyx_t_5 == (unsigned char)-1) && PyErr_Occurred())) __PYX_ERR(0, 2152, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_r = __pyx_t_5;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "PyTorch.pyx":2153
 * 
 *     cpdef unsigned char min(self):
 *         return THByteTensor_minall(self.native)             # <<<<<<<<<<<<<<
 * 
 *     def __repr__(_ByteTensor self):
 */
  __pyx_r = THByteTensor_minall(__pyx_v_self->native);
  goto __pyx_L0;

  /* "PyTorch.pyx":2152
 *         return THByteTensor_maxall(self.native)
 * 
 *     cpdef unsigned char min(self):             # <<<<<<<<<<<<<<
 *         return THByteTensor_minall(self.native)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_WriteUnraisable("PyTorch._ByteTensor.min", __pyx_clineno, __pyx_lineno, __pyx_filename, 0, 0);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_23min(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_23min(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("min (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_22min(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_22min(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("min", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_unsigned_char(__pyx_f_7PyTorch_11_ByteTensor_min(__pyx_v_self, 1)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2152, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._ByteTensor.min", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2155
 *         return THByteTensor_minall(self.native)
 * 
 *     def __repr__(_ByteTensor self):             # <<<<<<<<<<<<<<
 *         return self.as_string(self)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_25__repr__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_25__repr__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__repr__ (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_24__repr__(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_24__repr__(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  __Pyx_RefNannySetupContext("__repr__", 0);

  /* "PyTorch.pyx":2156
 * 
 *     def __repr__(_ByteTensor self):
 *         return self.as_string(self)             # <<<<<<<<<<<<<<
 * 
 *     def as_string(_ByteTensor self, show_size=True):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_as_string); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2156, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (!__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, ((PyObject *)__pyx_v_self)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2156, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
  } else {
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_2)) {
      PyObject *__pyx_temp[2] = {__pyx_t_3, ((PyObject *)__pyx_v_self)};
      __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2156, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_GOTREF(__pyx_t_1);
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
      PyObject *__pyx_temp[2] = {__pyx_t_3, ((PyObject *)__pyx_v_self)};
      __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2156, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_GOTREF(__pyx_t_1);
    } else
    #endif
    {
      __pyx_t_4 = PyTuple_New(1+1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2156, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_GIVEREF(__pyx_t_3); PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_3); __pyx_t_3 = NULL;
      __Pyx_INCREF(((PyObject *)__pyx_v_self));
      __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
      PyTuple_SET_ITEM(__pyx_t_4, 0+1, ((PyObject *)__pyx_v_self));
      __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_4, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2156, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    }
  }
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":2155
 *         return THByteTensor_minall(self.native)
 * 
 *     def __repr__(_ByteTensor self):             # <<<<<<<<<<<<<<
 *         return self.as_string(self)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("PyTorch._ByteTensor.__repr__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2158
 *         return self.as_string(self)
 * 
 *     def as_string(_ByteTensor self, show_size=True):             # <<<<<<<<<<<<<<
 *         # assume 2d matrix for now
 *         cdef int size0
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_27as_string(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_27as_string(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_show_size = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("as_string (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_show_size,0};
    PyObject* values[1] = {0};
    values[0] = ((PyObject *)Py_True);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_show_size);
          if (value) { values[0] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "as_string") < 0)) __PYX_ERR(0, 2158, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_show_size = values[0];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("as_string", 0, 0, 1, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 2158, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._ByteTensor.as_string", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_26as_string(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self), __pyx_v_show_size);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_26as_string(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, PyObject *__pyx_v_show_size) {
  int __pyx_v_size0;
  int __pyx_v_size1;
  int __pyx_v_dims;
  PyObject *__pyx_v_res = NULL;
  int __pyx_v_r;
  PyObject *__pyx_v_thisline = NULL;
  int __pyx_v_c;
  PyObject *__pyx_v_d = NULL;
  int __pyx_v_first;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  int __pyx_t_3;
  int __pyx_t_4;
  int __pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  Py_ssize_t __pyx_t_9;
  PyObject *(*__pyx_t_10)(PyObject *);
  PyObject *__pyx_t_11 = NULL;
  __Pyx_RefNannySetupContext("as_string", 0);

  /* "PyTorch.pyx":2162
 *         cdef int size0
 *         cdef int size1
 *         dims = self.dims()             # <<<<<<<<<<<<<<
 *         if dims == 0:
 *             return '[torch.ByteTensor with no dimension]\n'
 */
  __pyx_v_dims = ((struct __pyx_vtabstruct_7PyTorch__ByteTensor *)__pyx_v_self->__pyx_vtab)->dims(__pyx_v_self, 0);

  /* "PyTorch.pyx":2163
 *         cdef int size1
 *         dims = self.dims()
 *         if dims == 0:             # <<<<<<<<<<<<<<
 *             return '[torch.ByteTensor with no dimension]\n'
 *         elif dims == 2:
 */
  switch (__pyx_v_dims) {
    case 0:

    /* "PyTorch.pyx":2164
 *         dims = self.dims()
 *         if dims == 0:
 *             return '[torch.ByteTensor with no dimension]\n'             # <<<<<<<<<<<<<<
 *         elif dims == 2:
 *             size0 = THByteTensor_size(self.native, 0)
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(__pyx_kp_s_torch_ByteTensor_with_no_dimens);
    __pyx_r = __pyx_kp_s_torch_ByteTensor_with_no_dimens;
    goto __pyx_L0;

    /* "PyTorch.pyx":2163
 *         cdef int size1
 *         dims = self.dims()
 *         if dims == 0:             # <<<<<<<<<<<<<<
 *             return '[torch.ByteTensor with no dimension]\n'
 *         elif dims == 2:
 */
    break;

    /* "PyTorch.pyx":2165
 *         if dims == 0:
 *             return '[torch.ByteTensor with no dimension]\n'
 *         elif dims == 2:             # <<<<<<<<<<<<<<
 *             size0 = THByteTensor_size(self.native, 0)
 *             size1 = THByteTensor_size(self.native, 1)
 */
    case 2:

    /* "PyTorch.pyx":2166
 *             return '[torch.ByteTensor with no dimension]\n'
 *         elif dims == 2:
 *             size0 = THByteTensor_size(self.native, 0)             # <<<<<<<<<<<<<<
 *             size1 = THByteTensor_size(self.native, 1)
 *             res = ''
 */
    __pyx_v_size0 = THByteTensor_size(__pyx_v_self->native, 0);

    /* "PyTorch.pyx":2167
 *         elif dims == 2:
 *             size0 = THByteTensor_size(self.native, 0)
 *             size1 = THByteTensor_size(self.native, 1)             # <<<<<<<<<<<<<<
 *             res = ''
 *             for r in range(size0):
 */
    __pyx_v_size1 = THByteTensor_size(__pyx_v_self->native, 1);

    /* "PyTorch.pyx":2168
 *             size0 = THByteTensor_size(self.native, 0)
 *             size1 = THByteTensor_size(self.native, 1)
 *             res = ''             # <<<<<<<<<<<<<<
 *             for r in range(size0):
 *                 thisline = ''
 */
    __Pyx_INCREF(__pyx_kp_s__7);
    __pyx_v_res = __pyx_kp_s__7;

    /* "PyTorch.pyx":2169
 *             size1 = THByteTensor_size(self.native, 1)
 *             res = ''
 *             for r in range(size0):             # <<<<<<<<<<<<<<
 *                 thisline = ''
 *                 for c in range(size1):
 */
    __pyx_t_1 = __pyx_v_size0;
    for (__pyx_t_2 = 0; __pyx_t_2 < __pyx_t_1; __pyx_t_2+=1) {
      __pyx_v_r = __pyx_t_2;

      /* "PyTorch.pyx":2170
 *             res = ''
 *             for r in range(size0):
 *                 thisline = ''             # <<<<<<<<<<<<<<
 *                 for c in range(size1):
 *                     if c > 0:
 */
      __Pyx_INCREF(__pyx_kp_s__7);
      __Pyx_XDECREF_SET(__pyx_v_thisline, __pyx_kp_s__7);

      /* "PyTorch.pyx":2171
 *             for r in range(size0):
 *                 thisline = ''
 *                 for c in range(size1):             # <<<<<<<<<<<<<<
 *                     if c > 0:
 *                         thisline += ' '
 */
      __pyx_t_3 = __pyx_v_size1;
      for (__pyx_t_4 = 0; __pyx_t_4 < __pyx_t_3; __pyx_t_4+=1) {
        __pyx_v_c = __pyx_t_4;

        /* "PyTorch.pyx":2172
 *                 thisline = ''
 *                 for c in range(size1):
 *                     if c > 0:             # <<<<<<<<<<<<<<
 *                         thisline += ' '
 * 
 */
        __pyx_t_5 = ((__pyx_v_c > 0) != 0);
        if (__pyx_t_5) {

          /* "PyTorch.pyx":2173
 *                 for c in range(size1):
 *                     if c > 0:
 *                         thisline += ' '             # <<<<<<<<<<<<<<
 * 
 *                     thisline += str(self.get2d(r,c),)
 */
          __pyx_t_6 = PyNumber_InPlaceAdd(__pyx_v_thisline, __pyx_kp_s__8); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2173, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_6);
          __Pyx_DECREF_SET(__pyx_v_thisline, __pyx_t_6);
          __pyx_t_6 = 0;

          /* "PyTorch.pyx":2172
 *                 thisline = ''
 *                 for c in range(size1):
 *                     if c > 0:             # <<<<<<<<<<<<<<
 *                         thisline += ' '
 * 
 */
        }

        /* "PyTorch.pyx":2175
 *                         thisline += ' '
 * 
 *                     thisline += str(self.get2d(r,c),)             # <<<<<<<<<<<<<<
 * 
 *                 res += thisline + '\n'
 */
        __pyx_t_6 = __Pyx_PyInt_From_unsigned_char(((struct __pyx_vtabstruct_7PyTorch__ByteTensor *)__pyx_v_self->__pyx_vtab)->get2d(__pyx_v_self, __pyx_v_r, __pyx_v_c, 0)); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2175, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __pyx_t_7 = PyTuple_New(1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 2175, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        __Pyx_GIVEREF(__pyx_t_6);
        PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_6);
        __pyx_t_6 = 0;
        __pyx_t_6 = __Pyx_PyObject_Call(((PyObject *)(&PyString_Type)), __pyx_t_7, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2175, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        __pyx_t_7 = PyNumber_InPlaceAdd(__pyx_v_thisline, __pyx_t_6); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 2175, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_DECREF_SET(__pyx_v_thisline, __pyx_t_7);
        __pyx_t_7 = 0;
      }

      /* "PyTorch.pyx":2177
 *                     thisline += str(self.get2d(r,c),)
 * 
 *                 res += thisline + '\n'             # <<<<<<<<<<<<<<
 *             if show_size:
 *                 res += '[torch.ByteTensor of size ' + ('%.0f' % size0) + 'x' + str(size1) + ']\n'
 */
      __pyx_t_7 = PyNumber_Add(__pyx_v_thisline, __pyx_kp_s__9); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 2177, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __pyx_t_6 = PyNumber_InPlaceAdd(__pyx_v_res, __pyx_t_7); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2177, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_DECREF_SET(__pyx_v_res, __pyx_t_6);
      __pyx_t_6 = 0;
    }

    /* "PyTorch.pyx":2178
 * 
 *                 res += thisline + '\n'
 *             if show_size:             # <<<<<<<<<<<<<<
 *                 res += '[torch.ByteTensor of size ' + ('%.0f' % size0) + 'x' + str(size1) + ']\n'
 *             return res
 */
    __pyx_t_5 = __Pyx_PyObject_IsTrue(__pyx_v_show_size); if (unlikely(__pyx_t_5 < 0)) __PYX_ERR(0, 2178, __pyx_L1_error)
    if (__pyx_t_5) {

      /* "PyTorch.pyx":2179
 *                 res += thisline + '\n'
 *             if show_size:
 *                 res += '[torch.ByteTensor of size ' + ('%.0f' % size0) + 'x' + str(size1) + ']\n'             # <<<<<<<<<<<<<<
 *             return res
 *         elif dims == 1:
 */
      __pyx_t_6 = __Pyx_PyInt_From_int(__pyx_v_size0); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2179, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __pyx_t_7 = __Pyx_PyString_Format(__pyx_kp_s_0f, __pyx_t_6); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 2179, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_6 = PyNumber_Add(__pyx_kp_s_torch_ByteTensor_of_size, __pyx_t_7); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2179, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __pyx_t_7 = PyNumber_Add(__pyx_t_6, __pyx_n_s_x); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 2179, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_6 = __Pyx_PyInt_From_int(__pyx_v_size1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2179, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __pyx_t_8 = PyTuple_New(1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2179, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_GIVEREF(__pyx_t_6);
      PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_t_6);
      __pyx_t_6 = 0;
      __pyx_t_6 = __Pyx_PyObject_Call(((PyObject *)(&PyString_Type)), __pyx_t_8, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2179, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_8 = PyNumber_Add(__pyx_t_7, __pyx_t_6); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2179, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_6 = PyNumber_Add(__pyx_t_8, __pyx_kp_s__10); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2179, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_8 = PyNumber_InPlaceAdd(__pyx_v_res, __pyx_t_6); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2179, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_DECREF_SET(__pyx_v_res, __pyx_t_8);
      __pyx_t_8 = 0;

      /* "PyTorch.pyx":2178
 * 
 *                 res += thisline + '\n'
 *             if show_size:             # <<<<<<<<<<<<<<
 *                 res += '[torch.ByteTensor of size ' + ('%.0f' % size0) + 'x' + str(size1) + ']\n'
 *             return res
 */
    }

    /* "PyTorch.pyx":2180
 *             if show_size:
 *                 res += '[torch.ByteTensor of size ' + ('%.0f' % size0) + 'x' + str(size1) + ']\n'
 *             return res             # <<<<<<<<<<<<<<
 *         elif dims == 1:
 *             size0 = THByteTensor_size(self.native, 0)
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(__pyx_v_res);
    __pyx_r = __pyx_v_res;
    goto __pyx_L0;

    /* "PyTorch.pyx":2165
 *         if dims == 0:
 *             return '[torch.ByteTensor with no dimension]\n'
 *         elif dims == 2:             # <<<<<<<<<<<<<<
 *             size0 = THByteTensor_size(self.native, 0)
 *             size1 = THByteTensor_size(self.native, 1)
 */
    break;

    /* "PyTorch.pyx":2181
 *                 res += '[torch.ByteTensor of size ' + ('%.0f' % size0) + 'x' + str(size1) + ']\n'
 *             return res
 *         elif dims == 1:             # <<<<<<<<<<<<<<
 *             size0 = THByteTensor_size(self.native, 0)
 *             res = ''
 */
    case 1:

    /* "PyTorch.pyx":2182
 *             return res
 *         elif dims == 1:
 *             size0 = THByteTensor_size(self.native, 0)             # <<<<<<<<<<<<<<
 *             res = ''
 *             thisline = ''
 */
    __pyx_v_size0 = THByteTensor_size(__pyx_v_self->native, 0);

    /* "PyTorch.pyx":2183
 *         elif dims == 1:
 *             size0 = THByteTensor_size(self.native, 0)
 *             res = ''             # <<<<<<<<<<<<<<
 *             thisline = ''
 *             for c in range(size0):
 */
    __Pyx_INCREF(__pyx_kp_s__7);
    __pyx_v_res = __pyx_kp_s__7;

    /* "PyTorch.pyx":2184
 *             size0 = THByteTensor_size(self.native, 0)
 *             res = ''
 *             thisline = ''             # <<<<<<<<<<<<<<
 *             for c in range(size0):
 *                 if c > 0:
 */
    __Pyx_INCREF(__pyx_kp_s__7);
    __pyx_v_thisline = __pyx_kp_s__7;

    /* "PyTorch.pyx":2185
 *             res = ''
 *             thisline = ''
 *             for c in range(size0):             # <<<<<<<<<<<<<<
 *                 if c > 0:
 *                     thisline += ' '
 */
    __pyx_t_1 = __pyx_v_size0;
    for (__pyx_t_2 = 0; __pyx_t_2 < __pyx_t_1; __pyx_t_2+=1) {
      __pyx_v_c = __pyx_t_2;

      /* "PyTorch.pyx":2186
 *             thisline = ''
 *             for c in range(size0):
 *                 if c > 0:             # <<<<<<<<<<<<<<
 *                     thisline += ' '
 * 
 */
      __pyx_t_5 = ((__pyx_v_c > 0) != 0);
      if (__pyx_t_5) {

        /* "PyTorch.pyx":2187
 *             for c in range(size0):
 *                 if c > 0:
 *                     thisline += ' '             # <<<<<<<<<<<<<<
 * 
 *                 thisline += str(self.get1d(c))
 */
        __pyx_t_8 = PyNumber_InPlaceAdd(__pyx_v_thisline, __pyx_kp_s__8); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2187, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        __Pyx_DECREF_SET(__pyx_v_thisline, __pyx_t_8);
        __pyx_t_8 = 0;

        /* "PyTorch.pyx":2186
 *             thisline = ''
 *             for c in range(size0):
 *                 if c > 0:             # <<<<<<<<<<<<<<
 *                     thisline += ' '
 * 
 */
      }

      /* "PyTorch.pyx":2189
 *                     thisline += ' '
 * 
 *                 thisline += str(self.get1d(c))             # <<<<<<<<<<<<<<
 * 
 *             res += thisline + '\n'
 */
      __pyx_t_8 = __Pyx_PyInt_From_unsigned_char(((struct __pyx_vtabstruct_7PyTorch__ByteTensor *)__pyx_v_self->__pyx_vtab)->get1d(__pyx_v_self, __pyx_v_c, 0)); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2189, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_6 = PyTuple_New(1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2189, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_GIVEREF(__pyx_t_8);
      PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_8);
      __pyx_t_8 = 0;
      __pyx_t_8 = __Pyx_PyObject_Call(((PyObject *)(&PyString_Type)), __pyx_t_6, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2189, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_6 = PyNumber_InPlaceAdd(__pyx_v_thisline, __pyx_t_8); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2189, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_DECREF_SET(__pyx_v_thisline, __pyx_t_6);
      __pyx_t_6 = 0;
    }

    /* "PyTorch.pyx":2191
 *                 thisline += str(self.get1d(c))
 * 
 *             res += thisline + '\n'             # <<<<<<<<<<<<<<
 *             if show_size:
 *                 res += '[torch.ByteTensor of size ' + str(size0) + ']\n'
 */
    __pyx_t_6 = PyNumber_Add(__pyx_v_thisline, __pyx_kp_s__9); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2191, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_8 = PyNumber_InPlaceAdd(__pyx_v_res, __pyx_t_6); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2191, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_DECREF_SET(__pyx_v_res, __pyx_t_8);
    __pyx_t_8 = 0;

    /* "PyTorch.pyx":2192
 * 
 *             res += thisline + '\n'
 *             if show_size:             # <<<<<<<<<<<<<<
 *                 res += '[torch.ByteTensor of size ' + str(size0) + ']\n'
 *             return res
 */
    __pyx_t_5 = __Pyx_PyObject_IsTrue(__pyx_v_show_size); if (unlikely(__pyx_t_5 < 0)) __PYX_ERR(0, 2192, __pyx_L1_error)
    if (__pyx_t_5) {

      /* "PyTorch.pyx":2193
 *             res += thisline + '\n'
 *             if show_size:
 *                 res += '[torch.ByteTensor of size ' + str(size0) + ']\n'             # <<<<<<<<<<<<<<
 *             return res
 *         elif dims == 3:
 */
      __pyx_t_8 = __Pyx_PyInt_From_int(__pyx_v_size0); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2193, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_6 = PyTuple_New(1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2193, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_GIVEREF(__pyx_t_8);
      PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_8);
      __pyx_t_8 = 0;
      __pyx_t_8 = __Pyx_PyObject_Call(((PyObject *)(&PyString_Type)), __pyx_t_6, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2193, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_6 = PyNumber_Add(__pyx_kp_s_torch_ByteTensor_of_size, __pyx_t_8); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2193, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_8 = PyNumber_Add(__pyx_t_6, __pyx_kp_s__10); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2193, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_6 = PyNumber_InPlaceAdd(__pyx_v_res, __pyx_t_8); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2193, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_DECREF_SET(__pyx_v_res, __pyx_t_6);
      __pyx_t_6 = 0;

      /* "PyTorch.pyx":2192
 * 
 *             res += thisline + '\n'
 *             if show_size:             # <<<<<<<<<<<<<<
 *                 res += '[torch.ByteTensor of size ' + str(size0) + ']\n'
 *             return res
 */
    }

    /* "PyTorch.pyx":2194
 *             if show_size:
 *                 res += '[torch.ByteTensor of size ' + str(size0) + ']\n'
 *             return res             # <<<<<<<<<<<<<<
 *         elif dims == 3:
 *             res = ''
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(__pyx_v_res);
    __pyx_r = __pyx_v_res;
    goto __pyx_L0;

    /* "PyTorch.pyx":2181
 *                 res += '[torch.ByteTensor of size ' + ('%.0f' % size0) + 'x' + str(size1) + ']\n'
 *             return res
 *         elif dims == 1:             # <<<<<<<<<<<<<<
 *             size0 = THByteTensor_size(self.native, 0)
 *             res = ''
 */
    break;

    /* "PyTorch.pyx":2195
 *                 res += '[torch.ByteTensor of size ' + str(size0) + ']\n'
 *             return res
 *         elif dims == 3:             # <<<<<<<<<<<<<<
 *             res = ''
 *             for d in range(self.size()[0]):
 */
    case 3:

    /* "PyTorch.pyx":2196
 *             return res
 *         elif dims == 3:
 *             res = ''             # <<<<<<<<<<<<<<
 *             for d in range(self.size()[0]):
 *                 res += '(' + str(d) + ',.,.) =\n'
 */
    __Pyx_INCREF(__pyx_kp_s__7);
    __pyx_v_res = __pyx_kp_s__7;

    /* "PyTorch.pyx":2197
 *         elif dims == 3:
 *             res = ''
 *             for d in range(self.size()[0]):             # <<<<<<<<<<<<<<
 *                 res += '(' + str(d) + ',.,.) =\n'
 *                 res += self[d].as_string(show_size=False)
 */
    __pyx_t_8 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_size); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2197, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_7 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_8))) {
      __pyx_t_7 = PyMethod_GET_SELF(__pyx_t_8);
      if (likely(__pyx_t_7)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_8);
        __Pyx_INCREF(__pyx_t_7);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_8, function);
      }
    }
    if (__pyx_t_7) {
      __pyx_t_6 = __Pyx_PyObject_CallOneArg(__pyx_t_8, __pyx_t_7); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2197, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    } else {
      __pyx_t_6 = __Pyx_PyObject_CallNoArg(__pyx_t_8); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2197, __pyx_L1_error)
    }
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_6, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2197, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_6 = PyTuple_New(1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2197, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_GIVEREF(__pyx_t_8);
    PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_8);
    __pyx_t_8 = 0;
    __pyx_t_8 = __Pyx_PyObject_Call(__pyx_builtin_range, __pyx_t_6, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2197, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    if (likely(PyList_CheckExact(__pyx_t_8)) || PyTuple_CheckExact(__pyx_t_8)) {
      __pyx_t_6 = __pyx_t_8; __Pyx_INCREF(__pyx_t_6); __pyx_t_9 = 0;
      __pyx_t_10 = NULL;
    } else {
      __pyx_t_9 = -1; __pyx_t_6 = PyObject_GetIter(__pyx_t_8); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2197, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __pyx_t_10 = Py_TYPE(__pyx_t_6)->tp_iternext; if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 2197, __pyx_L1_error)
    }
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    for (;;) {
      if (likely(!__pyx_t_10)) {
        if (likely(PyList_CheckExact(__pyx_t_6))) {
          if (__pyx_t_9 >= PyList_GET_SIZE(__pyx_t_6)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_8 = PyList_GET_ITEM(__pyx_t_6, __pyx_t_9); __Pyx_INCREF(__pyx_t_8); __pyx_t_9++; if (unlikely(0 < 0)) __PYX_ERR(0, 2197, __pyx_L1_error)
          #else
          __pyx_t_8 = PySequence_ITEM(__pyx_t_6, __pyx_t_9); __pyx_t_9++; if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2197, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_8);
          #endif
        } else {
          if (__pyx_t_9 >= PyTuple_GET_SIZE(__pyx_t_6)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_8 = PyTuple_GET_ITEM(__pyx_t_6, __pyx_t_9); __Pyx_INCREF(__pyx_t_8); __pyx_t_9++; if (unlikely(0 < 0)) __PYX_ERR(0, 2197, __pyx_L1_error)
          #else
          __pyx_t_8 = PySequence_ITEM(__pyx_t_6, __pyx_t_9); __pyx_t_9++; if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2197, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_8);
          #endif
        }
      } else {
        __pyx_t_8 = __pyx_t_10(__pyx_t_6);
        if (unlikely(!__pyx_t_8)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(exc_type == PyExc_StopIteration || PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 2197, __pyx_L1_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_8);
      }
      __Pyx_XDECREF_SET(__pyx_v_d, __pyx_t_8);
      __pyx_t_8 = 0;

      /* "PyTorch.pyx":2198
 *             res = ''
 *             for d in range(self.size()[0]):
 *                 res += '(' + str(d) + ',.,.) =\n'             # <<<<<<<<<<<<<<
 *                 res += self[d].as_string(show_size=False)
 *             res += '\ntorch.ByteTensor of size '
 */
      __pyx_t_8 = PyTuple_New(1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2198, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_INCREF(__pyx_v_d);
      __Pyx_GIVEREF(__pyx_v_d);
      PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_v_d);
      __pyx_t_7 = __Pyx_PyObject_Call(((PyObject *)(&PyString_Type)), __pyx_t_8, NULL); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 2198, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_8 = PyNumber_Add(__pyx_kp_s__11, __pyx_t_7); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2198, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __pyx_t_7 = PyNumber_Add(__pyx_t_8, __pyx_kp_s__12); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 2198, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_8 = PyNumber_InPlaceAdd(__pyx_v_res, __pyx_t_7); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2198, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_DECREF_SET(__pyx_v_res, __pyx_t_8);
      __pyx_t_8 = 0;

      /* "PyTorch.pyx":2199
 *             for d in range(self.size()[0]):
 *                 res += '(' + str(d) + ',.,.) =\n'
 *                 res += self[d].as_string(show_size=False)             # <<<<<<<<<<<<<<
 *             res += '\ntorch.ByteTensor of size '
 *             first = True
 */
      __pyx_t_8 = PyObject_GetItem(((PyObject *)__pyx_v_self), __pyx_v_d); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2199, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_t_8, __pyx_n_s_as_string); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 2199, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_8 = PyDict_New(); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2199, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      if (PyDict_SetItem(__pyx_t_8, __pyx_n_s_show_size, Py_False) < 0) __PYX_ERR(0, 2199, __pyx_L1_error)
      __pyx_t_11 = __Pyx_PyObject_Call(__pyx_t_7, __pyx_empty_tuple, __pyx_t_8); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 2199, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_11);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_8 = PyNumber_InPlaceAdd(__pyx_v_res, __pyx_t_11); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2199, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
      __Pyx_DECREF_SET(__pyx_v_res, __pyx_t_8);
      __pyx_t_8 = 0;

      /* "PyTorch.pyx":2197
 *         elif dims == 3:
 *             res = ''
 *             for d in range(self.size()[0]):             # <<<<<<<<<<<<<<
 *                 res += '(' + str(d) + ',.,.) =\n'
 *                 res += self[d].as_string(show_size=False)
 */
    }
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;

    /* "PyTorch.pyx":2200
 *                 res += '(' + str(d) + ',.,.) =\n'
 *                 res += self[d].as_string(show_size=False)
 *             res += '\ntorch.ByteTensor of size '             # <<<<<<<<<<<<<<
 *             first = True
 *             for d in self.size():
 */
    __pyx_t_6 = PyNumber_InPlaceAdd(__pyx_v_res, __pyx_kp_s_torch_ByteTensor_of_size_2); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2200, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF_SET(__pyx_v_res, __pyx_t_6);
    __pyx_t_6 = 0;

    /* "PyTorch.pyx":2201
 *                 res += self[d].as_string(show_size=False)
 *             res += '\ntorch.ByteTensor of size '
 *             first = True             # <<<<<<<<<<<<<<
 *             for d in self.size():
 *                if not first:
 */
    __pyx_v_first = 1;

    /* "PyTorch.pyx":2202
 *             res += '\ntorch.ByteTensor of size '
 *             first = True
 *             for d in self.size():             # <<<<<<<<<<<<<<
 *                if not first:
 *                   res += 'x'
 */
    __pyx_t_8 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_size); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2202, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_11 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_8))) {
      __pyx_t_11 = PyMethod_GET_SELF(__pyx_t_8);
      if (likely(__pyx_t_11)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_8);
        __Pyx_INCREF(__pyx_t_11);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_8, function);
      }
    }
    if (__pyx_t_11) {
      __pyx_t_6 = __Pyx_PyObject_CallOneArg(__pyx_t_8, __pyx_t_11); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2202, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
    } else {
      __pyx_t_6 = __Pyx_PyObject_CallNoArg(__pyx_t_8); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2202, __pyx_L1_error)
    }
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    if (likely(PyList_CheckExact(__pyx_t_6)) || PyTuple_CheckExact(__pyx_t_6)) {
      __pyx_t_8 = __pyx_t_6; __Pyx_INCREF(__pyx_t_8); __pyx_t_9 = 0;
      __pyx_t_10 = NULL;
    } else {
      __pyx_t_9 = -1; __pyx_t_8 = PyObject_GetIter(__pyx_t_6); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2202, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_10 = Py_TYPE(__pyx_t_8)->tp_iternext; if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 2202, __pyx_L1_error)
    }
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    for (;;) {
      if (likely(!__pyx_t_10)) {
        if (likely(PyList_CheckExact(__pyx_t_8))) {
          if (__pyx_t_9 >= PyList_GET_SIZE(__pyx_t_8)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_6 = PyList_GET_ITEM(__pyx_t_8, __pyx_t_9); __Pyx_INCREF(__pyx_t_6); __pyx_t_9++; if (unlikely(0 < 0)) __PYX_ERR(0, 2202, __pyx_L1_error)
          #else
          __pyx_t_6 = PySequence_ITEM(__pyx_t_8, __pyx_t_9); __pyx_t_9++; if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2202, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_6);
          #endif
        } else {
          if (__pyx_t_9 >= PyTuple_GET_SIZE(__pyx_t_8)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_6 = PyTuple_GET_ITEM(__pyx_t_8, __pyx_t_9); __Pyx_INCREF(__pyx_t_6); __pyx_t_9++; if (unlikely(0 < 0)) __PYX_ERR(0, 2202, __pyx_L1_error)
          #else
          __pyx_t_6 = PySequence_ITEM(__pyx_t_8, __pyx_t_9); __pyx_t_9++; if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2202, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_6);
          #endif
        }
      } else {
        __pyx_t_6 = __pyx_t_10(__pyx_t_8);
        if (unlikely(!__pyx_t_6)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(exc_type == PyExc_StopIteration || PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 2202, __pyx_L1_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_6);
      }
      __Pyx_XDECREF_SET(__pyx_v_d, __pyx_t_6);
      __pyx_t_6 = 0;

      /* "PyTorch.pyx":2203
 *             first = True
 *             for d in self.size():
 *                if not first:             # <<<<<<<<<<<<<<
 *                   res += 'x'
 *                res += str(d)
 */
      __pyx_t_5 = ((!(__pyx_v_first != 0)) != 0);
      if (__pyx_t_5) {

        /* "PyTorch.pyx":2204
 *             for d in self.size():
 *                if not first:
 *                   res += 'x'             # <<<<<<<<<<<<<<
 *                res += str(d)
 *                first = False
 */
        __pyx_t_6 = PyNumber_InPlaceAdd(__pyx_v_res, __pyx_n_s_x); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2204, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __Pyx_DECREF_SET(__pyx_v_res, __pyx_t_6);
        __pyx_t_6 = 0;

        /* "PyTorch.pyx":2203
 *             first = True
 *             for d in self.size():
 *                if not first:             # <<<<<<<<<<<<<<
 *                   res += 'x'
 *                res += str(d)
 */
      }

      /* "PyTorch.pyx":2205
 *                if not first:
 *                   res += 'x'
 *                res += str(d)             # <<<<<<<<<<<<<<
 *                first = False
 *             res += ']'
 */
      __pyx_t_6 = PyTuple_New(1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2205, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_INCREF(__pyx_v_d);
      __Pyx_GIVEREF(__pyx_v_d);
      PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_v_d);
      __pyx_t_11 = __Pyx_PyObject_Call(((PyObject *)(&PyString_Type)), __pyx_t_6, NULL); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 2205, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_11);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_6 = PyNumber_InPlaceAdd(__pyx_v_res, __pyx_t_11); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2205, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
      __Pyx_DECREF_SET(__pyx_v_res, __pyx_t_6);
      __pyx_t_6 = 0;

      /* "PyTorch.pyx":2206
 *                   res += 'x'
 *                res += str(d)
 *                first = False             # <<<<<<<<<<<<<<
 *             res += ']'
 *             return res
 */
      __pyx_v_first = 0;

      /* "PyTorch.pyx":2202
 *             res += '\ntorch.ByteTensor of size '
 *             first = True
 *             for d in self.size():             # <<<<<<<<<<<<<<
 *                if not first:
 *                   res += 'x'
 */
    }
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;

    /* "PyTorch.pyx":2207
 *                res += str(d)
 *                first = False
 *             res += ']'             # <<<<<<<<<<<<<<
 *             return res
 *         else:
 */
    __pyx_t_8 = PyNumber_InPlaceAdd(__pyx_v_res, __pyx_kp_s__13); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2207, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF_SET(__pyx_v_res, __pyx_t_8);
    __pyx_t_8 = 0;

    /* "PyTorch.pyx":2208
 *                first = False
 *             res += ']'
 *             return res             # <<<<<<<<<<<<<<
 *         else:
 *             raise Exception("Not implemented: dims > 2")
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(__pyx_v_res);
    __pyx_r = __pyx_v_res;
    goto __pyx_L0;

    /* "PyTorch.pyx":2195
 *                 res += '[torch.ByteTensor of size ' + str(size0) + ']\n'
 *             return res
 *         elif dims == 3:             # <<<<<<<<<<<<<<
 *             res = ''
 *             for d in range(self.size()[0]):
 */
    break;
    default:

    /* "PyTorch.pyx":2210
 *             return res
 *         else:
 *             raise Exception("Not implemented: dims > 2")             # <<<<<<<<<<<<<<
 * 
 *     def __getitem__(_ByteTensor self, int index):
 */
    __pyx_t_8 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_tuple__40, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2210, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_Raise(__pyx_t_8, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __PYX_ERR(0, 2210, __pyx_L1_error)
    break;
  }

  /* "PyTorch.pyx":2158
 *         return self.as_string(self)
 * 
 *     def as_string(_ByteTensor self, show_size=True):             # <<<<<<<<<<<<<<
 *         # assume 2d matrix for now
 *         cdef int size0
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_11);
  __Pyx_AddTraceback("PyTorch._ByteTensor.as_string", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_res);
  __Pyx_XDECREF(__pyx_v_thisline);
  __Pyx_XDECREF(__pyx_v_d);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2212
 *             raise Exception("Not implemented: dims > 2")
 * 
 *     def __getitem__(_ByteTensor self, int index):             # <<<<<<<<<<<<<<
 *         if self.dims() == 1:
 *             return self.get1d(index)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_29__getitem__(PyObject *__pyx_v_self, PyObject *__pyx_arg_index); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_29__getitem__(PyObject *__pyx_v_self, PyObject *__pyx_arg_index) {
  int __pyx_v_index;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__getitem__ (wrapper)", 0);
  assert(__pyx_arg_index); {
    __pyx_v_index = __Pyx_PyInt_As_int(__pyx_arg_index); if (unlikely((__pyx_v_index == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 2212, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._ByteTensor.__getitem__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_28__getitem__(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self), ((int)__pyx_v_index));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_28__getitem__(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, int __pyx_v_index) {
  struct THByteTensor *__pyx_v_res;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  struct __pyx_opt_args_7PyTorch__ByteTensor_fromNative __pyx_t_3;
  __Pyx_RefNannySetupContext("__getitem__", 0);

  /* "PyTorch.pyx":2213
 * 
 *     def __getitem__(_ByteTensor self, int index):
 *         if self.dims() == 1:             # <<<<<<<<<<<<<<
 *             return self.get1d(index)
 *         cdef THByteTensor *res = THByteTensor_newSelect(self.native, 0, index)
 */
  __pyx_t_1 = ((((struct __pyx_vtabstruct_7PyTorch__ByteTensor *)__pyx_v_self->__pyx_vtab)->dims(__pyx_v_self, 0) == 1) != 0);
  if (__pyx_t_1) {

    /* "PyTorch.pyx":2214
 *     def __getitem__(_ByteTensor self, int index):
 *         if self.dims() == 1:
 *             return self.get1d(index)             # <<<<<<<<<<<<<<
 *         cdef THByteTensor *res = THByteTensor_newSelect(self.native, 0, index)
 *         return _ByteTensor_fromNative(res, False)
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_2 = __Pyx_PyInt_From_unsigned_char(((struct __pyx_vtabstruct_7PyTorch__ByteTensor *)__pyx_v_self->__pyx_vtab)->get1d(__pyx_v_self, __pyx_v_index, 0)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2214, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_r = __pyx_t_2;
    __pyx_t_2 = 0;
    goto __pyx_L0;

    /* "PyTorch.pyx":2213
 * 
 *     def __getitem__(_ByteTensor self, int index):
 *         if self.dims() == 1:             # <<<<<<<<<<<<<<
 *             return self.get1d(index)
 *         cdef THByteTensor *res = THByteTensor_newSelect(self.native, 0, index)
 */
  }

  /* "PyTorch.pyx":2215
 *         if self.dims() == 1:
 *             return self.get1d(index)
 *         cdef THByteTensor *res = THByteTensor_newSelect(self.native, 0, index)             # <<<<<<<<<<<<<<
 *         return _ByteTensor_fromNative(res, False)
 * 
 */
  __pyx_v_res = THByteTensor_newSelect(__pyx_v_self->native, 0, __pyx_v_index);

  /* "PyTorch.pyx":2216
 *             return self.get1d(index)
 *         cdef THByteTensor *res = THByteTensor_newSelect(self.native, 0, index)
 *         return _ByteTensor_fromNative(res, False)             # <<<<<<<<<<<<<<
 * 
 *     def __setitem__(_ByteTensor self, int index, unsigned char value):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_3.__pyx_n = 1;
  __pyx_t_3.retain = Py_False;
  __pyx_t_2 = __pyx_f_7PyTorch__ByteTensor_fromNative(__pyx_v_res, &__pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2216, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":2212
 *             raise Exception("Not implemented: dims > 2")
 * 
 *     def __getitem__(_ByteTensor self, int index):             # <<<<<<<<<<<<<<
 *         if self.dims() == 1:
 *             return self.get1d(index)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("PyTorch._ByteTensor.__getitem__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2218
 *         return _ByteTensor_fromNative(res, False)
 * 
 *     def __setitem__(_ByteTensor self, int index, unsigned char value):             # <<<<<<<<<<<<<<
 *         if self.dims() == 1:
 *             self.set1d(index, value)
 */

/* Python wrapper */
static int __pyx_pw_7PyTorch_11_ByteTensor_31__setitem__(PyObject *__pyx_v_self, PyObject *__pyx_arg_index, PyObject *__pyx_arg_value); /*proto*/
static int __pyx_pw_7PyTorch_11_ByteTensor_31__setitem__(PyObject *__pyx_v_self, PyObject *__pyx_arg_index, PyObject *__pyx_arg_value) {
  int __pyx_v_index;
  unsigned char __pyx_v_value;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__setitem__ (wrapper)", 0);
  assert(__pyx_arg_index); {
    __pyx_v_index = __Pyx_PyInt_As_int(__pyx_arg_index); if (unlikely((__pyx_v_index == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 2218, __pyx_L3_error)
  }
  assert(__pyx_arg_value); {
    __pyx_v_value = __Pyx_PyInt_As_unsigned_char(__pyx_arg_value); if (unlikely((__pyx_v_value == (unsigned char)-1) && PyErr_Occurred())) __PYX_ERR(0, 2218, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._ByteTensor.__setitem__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return -1;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_30__setitem__(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self), ((int)__pyx_v_index), ((unsigned char)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_7PyTorch_11_ByteTensor_30__setitem__(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, int __pyx_v_index, unsigned char __pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("__setitem__", 0);

  /* "PyTorch.pyx":2219
 * 
 *     def __setitem__(_ByteTensor self, int index, unsigned char value):
 *         if self.dims() == 1:             # <<<<<<<<<<<<<<
 *             self.set1d(index, value)
 *         else:
 */
  __pyx_t_1 = ((((struct __pyx_vtabstruct_7PyTorch__ByteTensor *)__pyx_v_self->__pyx_vtab)->dims(__pyx_v_self, 0) == 1) != 0);
  if (__pyx_t_1) {

    /* "PyTorch.pyx":2220
 *     def __setitem__(_ByteTensor self, int index, unsigned char value):
 *         if self.dims() == 1:
 *             self.set1d(index, value)             # <<<<<<<<<<<<<<
 *         else:
 *             raise Exception("not implemented")
 */
    __pyx_t_2 = ((struct __pyx_vtabstruct_7PyTorch__ByteTensor *)__pyx_v_self->__pyx_vtab)->set1d(__pyx_v_self, __pyx_v_index, __pyx_v_value, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2220, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

    /* "PyTorch.pyx":2219
 * 
 *     def __setitem__(_ByteTensor self, int index, unsigned char value):
 *         if self.dims() == 1:             # <<<<<<<<<<<<<<
 *             self.set1d(index, value)
 *         else:
 */
    goto __pyx_L3;
  }

  /* "PyTorch.pyx":2222
 *             self.set1d(index, value)
 *         else:
 *             raise Exception("not implemented")             # <<<<<<<<<<<<<<
 * 
 *     def fill(_ByteTensor self, unsigned char value):
 */
  /*else*/ {
    __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_tuple__41, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2222, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(0, 2222, __pyx_L1_error)
  }
  __pyx_L3:;

  /* "PyTorch.pyx":2218
 *         return _ByteTensor_fromNative(res, False)
 * 
 *     def __setitem__(_ByteTensor self, int index, unsigned char value):             # <<<<<<<<<<<<<<
 *         if self.dims() == 1:
 *             self.set1d(index, value)
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("PyTorch._ByteTensor.__setitem__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2224
 *             raise Exception("not implemented")
 * 
 *     def fill(_ByteTensor self, unsigned char value):             # <<<<<<<<<<<<<<
 *         THByteTensor_fill(self.native, value)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_33fill(PyObject *__pyx_v_self, PyObject *__pyx_arg_value); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_33fill(PyObject *__pyx_v_self, PyObject *__pyx_arg_value) {
  unsigned char __pyx_v_value;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("fill (wrapper)", 0);
  assert(__pyx_arg_value); {
    __pyx_v_value = __Pyx_PyInt_As_unsigned_char(__pyx_arg_value); if (unlikely((__pyx_v_value == (unsigned char)-1) && PyErr_Occurred())) __PYX_ERR(0, 2224, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._ByteTensor.fill", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_32fill(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self), ((unsigned char)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_32fill(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, unsigned char __pyx_v_value) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("fill", 0);

  /* "PyTorch.pyx":2225
 * 
 *     def fill(_ByteTensor self, unsigned char value):
 *         THByteTensor_fill(self.native, value)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THByteTensor_fill(__pyx_v_self->native, __pyx_v_value);

  /* "PyTorch.pyx":2226
 *     def fill(_ByteTensor self, unsigned char value):
 *         THByteTensor_fill(self.native, value)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def sum(_ByteTensor self):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":2224
 *             raise Exception("not implemented")
 * 
 *     def fill(_ByteTensor self, unsigned char value):             # <<<<<<<<<<<<<<
 *         THByteTensor_fill(self.native, value)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2228
 *         return self
 * 
 *     def sum(_ByteTensor self):             # <<<<<<<<<<<<<<
 *         cdef unsigned char result = THByteTensor_sumall(self.native)
 *         return result
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_35sum(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_35sum(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("sum (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_34sum(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_34sum(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self) {
  unsigned char __pyx_v_result;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("sum", 0);

  /* "PyTorch.pyx":2229
 * 
 *     def sum(_ByteTensor self):
 *         cdef unsigned char result = THByteTensor_sumall(self.native)             # <<<<<<<<<<<<<<
 *         return result
 * 
 */
  __pyx_v_result = THByteTensor_sumall(__pyx_v_self->native);

  /* "PyTorch.pyx":2230
 *     def sum(_ByteTensor self):
 *         cdef unsigned char result = THByteTensor_sumall(self.native)
 *         return result             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_unsigned_char(__pyx_v_result); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2230, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":2228
 *         return self
 * 
 *     def sum(_ByteTensor self):             # <<<<<<<<<<<<<<
 *         cdef unsigned char result = THByteTensor_sumall(self.native)
 *         return result
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._ByteTensor.sum", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2236
 * 
 * 
 *     def size(_ByteTensor self):             # <<<<<<<<<<<<<<
 *         cdef int dims = self.dims()
 * #        cdef LongStorage size
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_37size(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_37size(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("size (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_36size(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_36size(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self) {
  int __pyx_v_dims;
  PyObject *__pyx_v_size = NULL;
  int __pyx_v_d;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  int __pyx_t_7;
  int __pyx_t_8;
  __Pyx_RefNannySetupContext("size", 0);

  /* "PyTorch.pyx":2237
 * 
 *     def size(_ByteTensor self):
 *         cdef int dims = self.dims()             # <<<<<<<<<<<<<<
 * #        cdef LongStorage size
 *         if dims > 0:
 */
  __pyx_v_dims = ((struct __pyx_vtabstruct_7PyTorch__ByteTensor *)__pyx_v_self->__pyx_vtab)->dims(__pyx_v_self, 0);

  /* "PyTorch.pyx":2239
 *         cdef int dims = self.dims()
 * #        cdef LongStorage size
 *         if dims > 0:             # <<<<<<<<<<<<<<
 *             size = _LongStorage(dims)
 *             for d in range(dims):
 */
  __pyx_t_1 = ((__pyx_v_dims > 0) != 0);
  if (__pyx_t_1) {

    /* "PyTorch.pyx":2240
 * #        cdef LongStorage size
 *         if dims > 0:
 *             size = _LongStorage(dims)             # <<<<<<<<<<<<<<
 *             for d in range(dims):
 *                 size[d] = THByteTensor_size(self.native, d)
 */
    __pyx_t_3 = __Pyx_GetModuleGlobalName(__pyx_n_s_LongStorage); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2240, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = __Pyx_PyInt_From_int(__pyx_v_dims); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2240, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_5 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
      __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_3);
      if (likely(__pyx_t_5)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
        __Pyx_INCREF(__pyx_t_5);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_3, function);
      }
    }
    if (!__pyx_t_5) {
      __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_4); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2240, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_GOTREF(__pyx_t_2);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_3)) {
        PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_t_4};
        __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2240, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
        PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_t_4};
        __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2240, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else
      #endif
      {
        __pyx_t_6 = PyTuple_New(1+1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2240, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_5); __pyx_t_5 = NULL;
        __Pyx_GIVEREF(__pyx_t_4);
        PyTuple_SET_ITEM(__pyx_t_6, 0+1, __pyx_t_4);
        __pyx_t_4 = 0;
        __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_6, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2240, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_v_size = __pyx_t_2;
    __pyx_t_2 = 0;

    /* "PyTorch.pyx":2241
 *         if dims > 0:
 *             size = _LongStorage(dims)
 *             for d in range(dims):             # <<<<<<<<<<<<<<
 *                 size[d] = THByteTensor_size(self.native, d)
 *             return size
 */
    __pyx_t_7 = __pyx_v_dims;
    for (__pyx_t_8 = 0; __pyx_t_8 < __pyx_t_7; __pyx_t_8+=1) {
      __pyx_v_d = __pyx_t_8;

      /* "PyTorch.pyx":2242
 *             size = _LongStorage(dims)
 *             for d in range(dims):
 *                 size[d] = THByteTensor_size(self.native, d)             # <<<<<<<<<<<<<<
 *             return size
 *         else:
 */
      __pyx_t_2 = __Pyx_PyInt_From_long(THByteTensor_size(__pyx_v_self->native, __pyx_v_d)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2242, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      if (unlikely(__Pyx_SetItemInt(__pyx_v_size, __pyx_v_d, __pyx_t_2, int, 1, __Pyx_PyInt_From_int, 0, 1, 1) < 0)) __PYX_ERR(0, 2242, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    }

    /* "PyTorch.pyx":2243
 *             for d in range(dims):
 *                 size[d] = THByteTensor_size(self.native, d)
 *             return size             # <<<<<<<<<<<<<<
 *         else:
 *             return None  # not sure how to handle this yet
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(__pyx_v_size);
    __pyx_r = __pyx_v_size;
    goto __pyx_L0;

    /* "PyTorch.pyx":2239
 *         cdef int dims = self.dims()
 * #        cdef LongStorage size
 *         if dims > 0:             # <<<<<<<<<<<<<<
 *             size = _LongStorage(dims)
 *             for d in range(dims):
 */
  }

  /* "PyTorch.pyx":2245
 *             return size
 *         else:
 *             return None  # not sure how to handle this yet             # <<<<<<<<<<<<<<
 * 
 *     @staticmethod
 */
  /*else*/ {
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(Py_None);
    __pyx_r = Py_None;
    goto __pyx_L0;
  }

  /* "PyTorch.pyx":2236
 * 
 * 
 *     def size(_ByteTensor self):             # <<<<<<<<<<<<<<
 *         cdef int dims = self.dims()
 * #        cdef LongStorage size
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("PyTorch._ByteTensor.size", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_size);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2248
 * 
 *     @staticmethod
 *     def new():             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         return _ByteTensor()
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_39new(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_7PyTorch_11_ByteTensor_39new = {"new", (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_39new, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_39new(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("new (wrapper)", 0);
  if (unlikely(PyTuple_GET_SIZE(__pyx_args) > 0)) {
    __Pyx_RaiseArgtupleInvalid("new", 1, 0, 0, PyTuple_GET_SIZE(__pyx_args)); return NULL;}
  if (unlikely(__pyx_kwds) && unlikely(PyDict_Size(__pyx_kwds) > 0) && unlikely(!__Pyx_CheckKeywordStrings(__pyx_kwds, "new", 0))) return NULL;
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_38new();

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_38new() {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("new", 0);

  /* "PyTorch.pyx":2250
 *     def new():
 * #        # print('allocate tensor')
 *         return _ByteTensor()             # <<<<<<<<<<<<<<
 * #        return _FloatTensor_fromNative(newTensorC, False)
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_7PyTorch__ByteTensor), __pyx_empty_tuple, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2250, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":2248
 * 
 *     @staticmethod
 *     def new():             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         return _ByteTensor()
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._ByteTensor.new", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2253
 * #        return _FloatTensor_fromNative(newTensorC, False)
 * 
 *     def narrow(_ByteTensor self, int dimension, long firstIndex, long size):             # <<<<<<<<<<<<<<
 *         cdef THByteTensor *narrowedC = THByteTensor_newNarrow(self.native, dimension, firstIndex, size)
 *         return _ByteTensor_fromNative(narrowedC, retain=False)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_41narrow(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_41narrow(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  int __pyx_v_dimension;
  long __pyx_v_firstIndex;
  long __pyx_v_size;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("narrow (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_dimension,&__pyx_n_s_firstIndex,&__pyx_n_s_size,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_dimension)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_firstIndex)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("narrow", 1, 3, 3, 1); __PYX_ERR(0, 2253, __pyx_L3_error)
        }
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("narrow", 1, 3, 3, 2); __PYX_ERR(0, 2253, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "narrow") < 0)) __PYX_ERR(0, 2253, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_dimension = __Pyx_PyInt_As_int(values[0]); if (unlikely((__pyx_v_dimension == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 2253, __pyx_L3_error)
    __pyx_v_firstIndex = __Pyx_PyInt_As_long(values[1]); if (unlikely((__pyx_v_firstIndex == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2253, __pyx_L3_error)
    __pyx_v_size = __Pyx_PyInt_As_long(values[2]); if (unlikely((__pyx_v_size == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2253, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("narrow", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 2253, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._ByteTensor.narrow", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_40narrow(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self), __pyx_v_dimension, __pyx_v_firstIndex, __pyx_v_size);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_40narrow(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, int __pyx_v_dimension, long __pyx_v_firstIndex, long __pyx_v_size) {
  struct THByteTensor *__pyx_v_narrowedC;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  struct __pyx_opt_args_7PyTorch__ByteTensor_fromNative __pyx_t_2;
  __Pyx_RefNannySetupContext("narrow", 0);

  /* "PyTorch.pyx":2254
 * 
 *     def narrow(_ByteTensor self, int dimension, long firstIndex, long size):
 *         cdef THByteTensor *narrowedC = THByteTensor_newNarrow(self.native, dimension, firstIndex, size)             # <<<<<<<<<<<<<<
 *         return _ByteTensor_fromNative(narrowedC, retain=False)
 * 
 */
  __pyx_v_narrowedC = THByteTensor_newNarrow(__pyx_v_self->native, __pyx_v_dimension, __pyx_v_firstIndex, __pyx_v_size);

  /* "PyTorch.pyx":2255
 *     def narrow(_ByteTensor self, int dimension, long firstIndex, long size):
 *         cdef THByteTensor *narrowedC = THByteTensor_newNarrow(self.native, dimension, firstIndex, size)
 *         return _ByteTensor_fromNative(narrowedC, retain=False)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2.__pyx_n = 1;
  __pyx_t_2.retain = Py_False;
  __pyx_t_1 = __pyx_f_7PyTorch__ByteTensor_fromNative(__pyx_v_narrowedC, &__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2255, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":2253
 * #        return _FloatTensor_fromNative(newTensorC, False)
 * 
 *     def narrow(_ByteTensor self, int dimension, long firstIndex, long size):             # <<<<<<<<<<<<<<
 *         cdef THByteTensor *narrowedC = THByteTensor_newNarrow(self.native, dimension, firstIndex, size)
 *         return _ByteTensor_fromNative(narrowedC, retain=False)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._ByteTensor.narrow", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2258
 * 
 * 
 *     def contiguous(_ByteTensor self):             # <<<<<<<<<<<<<<
 *         cdef THByteTensor *newTensorC = THByteTensor_newContiguous(self.native)
 *         return _ByteTensor_fromNative(newTensorC, retain=False)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_43contiguous(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_43contiguous(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("contiguous (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_42contiguous(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_42contiguous(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self) {
  struct THByteTensor *__pyx_v_newTensorC;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  struct __pyx_opt_args_7PyTorch__ByteTensor_fromNative __pyx_t_2;
  __Pyx_RefNannySetupContext("contiguous", 0);

  /* "PyTorch.pyx":2259
 * 
 *     def contiguous(_ByteTensor self):
 *         cdef THByteTensor *newTensorC = THByteTensor_newContiguous(self.native)             # <<<<<<<<<<<<<<
 *         return _ByteTensor_fromNative(newTensorC, retain=False)
 * 
 */
  __pyx_v_newTensorC = THByteTensor_newContiguous(__pyx_v_self->native);

  /* "PyTorch.pyx":2260
 *     def contiguous(_ByteTensor self):
 *         cdef THByteTensor *newTensorC = THByteTensor_newContiguous(self.native)
 *         return _ByteTensor_fromNative(newTensorC, retain=False)             # <<<<<<<<<<<<<<
 * 
 *     def resize1d(_ByteTensor self, int size0):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2.__pyx_n = 1;
  __pyx_t_2.retain = Py_False;
  __pyx_t_1 = __pyx_f_7PyTorch__ByteTensor_fromNative(__pyx_v_newTensorC, &__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2260, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":2258
 * 
 * 
 *     def contiguous(_ByteTensor self):             # <<<<<<<<<<<<<<
 *         cdef THByteTensor *newTensorC = THByteTensor_newContiguous(self.native)
 *         return _ByteTensor_fromNative(newTensorC, retain=False)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._ByteTensor.contiguous", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2262
 *         return _ByteTensor_fromNative(newTensorC, retain=False)
 * 
 *     def resize1d(_ByteTensor self, int size0):             # <<<<<<<<<<<<<<
 *         THByteTensor_resize1d(self.native, size0)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_45resize1d(PyObject *__pyx_v_self, PyObject *__pyx_arg_size0); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_45resize1d(PyObject *__pyx_v_self, PyObject *__pyx_arg_size0) {
  int __pyx_v_size0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resize1d (wrapper)", 0);
  assert(__pyx_arg_size0); {
    __pyx_v_size0 = __Pyx_PyInt_As_int(__pyx_arg_size0); if (unlikely((__pyx_v_size0 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 2262, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._ByteTensor.resize1d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_44resize1d(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self), ((int)__pyx_v_size0));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_44resize1d(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, int __pyx_v_size0) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resize1d", 0);

  /* "PyTorch.pyx":2263
 * 
 *     def resize1d(_ByteTensor self, int size0):
 *         THByteTensor_resize1d(self.native, size0)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THByteTensor_resize1d(__pyx_v_self->native, __pyx_v_size0);

  /* "PyTorch.pyx":2264
 *     def resize1d(_ByteTensor self, int size0):
 *         THByteTensor_resize1d(self.native, size0)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def resize2d(_ByteTensor self, int size0, int size1):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":2262
 *         return _ByteTensor_fromNative(newTensorC, retain=False)
 * 
 *     def resize1d(_ByteTensor self, int size0):             # <<<<<<<<<<<<<<
 *         THByteTensor_resize1d(self.native, size0)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2266
 *         return self
 * 
 *     def resize2d(_ByteTensor self, int size0, int size1):             # <<<<<<<<<<<<<<
 *         THByteTensor_resize2d(self.native, size0, size1)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_47resize2d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_47resize2d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  int __pyx_v_size0;
  int __pyx_v_size1;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resize2d (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_size0,&__pyx_n_s_size1,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size0)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("resize2d", 1, 2, 2, 1); __PYX_ERR(0, 2266, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "resize2d") < 0)) __PYX_ERR(0, 2266, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_size0 = __Pyx_PyInt_As_int(values[0]); if (unlikely((__pyx_v_size0 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 2266, __pyx_L3_error)
    __pyx_v_size1 = __Pyx_PyInt_As_int(values[1]); if (unlikely((__pyx_v_size1 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 2266, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("resize2d", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 2266, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._ByteTensor.resize2d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_46resize2d(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self), __pyx_v_size0, __pyx_v_size1);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_46resize2d(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, int __pyx_v_size0, int __pyx_v_size1) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resize2d", 0);

  /* "PyTorch.pyx":2267
 * 
 *     def resize2d(_ByteTensor self, int size0, int size1):
 *         THByteTensor_resize2d(self.native, size0, size1)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THByteTensor_resize2d(__pyx_v_self->native, __pyx_v_size0, __pyx_v_size1);

  /* "PyTorch.pyx":2268
 *     def resize2d(_ByteTensor self, int size0, int size1):
 *         THByteTensor_resize2d(self.native, size0, size1)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def resize3d(_ByteTensor self, int size0, int size1, int size2):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":2266
 *         return self
 * 
 *     def resize2d(_ByteTensor self, int size0, int size1):             # <<<<<<<<<<<<<<
 *         THByteTensor_resize2d(self.native, size0, size1)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2270
 *         return self
 * 
 *     def resize3d(_ByteTensor self, int size0, int size1, int size2):             # <<<<<<<<<<<<<<
 *         THByteTensor_resize3d(self.native, size0, size1, size2)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_49resize3d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_49resize3d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  int __pyx_v_size0;
  int __pyx_v_size1;
  int __pyx_v_size2;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resize3d (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_size0,&__pyx_n_s_size1,&__pyx_n_s_size2,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size0)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("resize3d", 1, 3, 3, 1); __PYX_ERR(0, 2270, __pyx_L3_error)
        }
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("resize3d", 1, 3, 3, 2); __PYX_ERR(0, 2270, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "resize3d") < 0)) __PYX_ERR(0, 2270, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_size0 = __Pyx_PyInt_As_int(values[0]); if (unlikely((__pyx_v_size0 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 2270, __pyx_L3_error)
    __pyx_v_size1 = __Pyx_PyInt_As_int(values[1]); if (unlikely((__pyx_v_size1 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 2270, __pyx_L3_error)
    __pyx_v_size2 = __Pyx_PyInt_As_int(values[2]); if (unlikely((__pyx_v_size2 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 2270, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("resize3d", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 2270, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._ByteTensor.resize3d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_48resize3d(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self), __pyx_v_size0, __pyx_v_size1, __pyx_v_size2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_48resize3d(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, int __pyx_v_size0, int __pyx_v_size1, int __pyx_v_size2) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resize3d", 0);

  /* "PyTorch.pyx":2271
 * 
 *     def resize3d(_ByteTensor self, int size0, int size1, int size2):
 *         THByteTensor_resize3d(self.native, size0, size1, size2)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THByteTensor_resize3d(__pyx_v_self->native, __pyx_v_size0, __pyx_v_size1, __pyx_v_size2);

  /* "PyTorch.pyx":2272
 *     def resize3d(_ByteTensor self, int size0, int size1, int size2):
 *         THByteTensor_resize3d(self.native, size0, size1, size2)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def resize4d(_ByteTensor self, int size0, int size1, int size2, int size3):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":2270
 *         return self
 * 
 *     def resize3d(_ByteTensor self, int size0, int size1, int size2):             # <<<<<<<<<<<<<<
 *         THByteTensor_resize3d(self.native, size0, size1, size2)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2274
 *         return self
 * 
 *     def resize4d(_ByteTensor self, int size0, int size1, int size2, int size3):             # <<<<<<<<<<<<<<
 *         THByteTensor_resize4d(self.native, size0, size1, size2, size3)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_51resize4d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_51resize4d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  int __pyx_v_size0;
  int __pyx_v_size1;
  int __pyx_v_size2;
  int __pyx_v_size3;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resize4d (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_size0,&__pyx_n_s_size1,&__pyx_n_s_size2,&__pyx_n_s_size3,0};
    PyObject* values[4] = {0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size0)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("resize4d", 1, 4, 4, 1); __PYX_ERR(0, 2274, __pyx_L3_error)
        }
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("resize4d", 1, 4, 4, 2); __PYX_ERR(0, 2274, __pyx_L3_error)
        }
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size3)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("resize4d", 1, 4, 4, 3); __PYX_ERR(0, 2274, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "resize4d") < 0)) __PYX_ERR(0, 2274, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 4) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
    }
    __pyx_v_size0 = __Pyx_PyInt_As_int(values[0]); if (unlikely((__pyx_v_size0 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 2274, __pyx_L3_error)
    __pyx_v_size1 = __Pyx_PyInt_As_int(values[1]); if (unlikely((__pyx_v_size1 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 2274, __pyx_L3_error)
    __pyx_v_size2 = __Pyx_PyInt_As_int(values[2]); if (unlikely((__pyx_v_size2 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 2274, __pyx_L3_error)
    __pyx_v_size3 = __Pyx_PyInt_As_int(values[3]); if (unlikely((__pyx_v_size3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 2274, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("resize4d", 1, 4, 4, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 2274, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._ByteTensor.resize4d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_50resize4d(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self), __pyx_v_size0, __pyx_v_size1, __pyx_v_size2, __pyx_v_size3);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_50resize4d(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, int __pyx_v_size0, int __pyx_v_size1, int __pyx_v_size2, int __pyx_v_size3) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resize4d", 0);

  /* "PyTorch.pyx":2275
 * 
 *     def resize4d(_ByteTensor self, int size0, int size1, int size2, int size3):
 *         THByteTensor_resize4d(self.native, size0, size1, size2, size3)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THByteTensor_resize4d(__pyx_v_self->native, __pyx_v_size0, __pyx_v_size1, __pyx_v_size2, __pyx_v_size3);

  /* "PyTorch.pyx":2276
 *     def resize4d(_ByteTensor self, int size0, int size1, int size2, int size3):
 *         THByteTensor_resize4d(self.native, size0, size1, size2, size3)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def resizeAs(_ByteTensor self, _ByteTensor model):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":2274
 *         return self
 * 
 *     def resize4d(_ByteTensor self, int size0, int size1, int size2, int size3):             # <<<<<<<<<<<<<<
 *         THByteTensor_resize4d(self.native, size0, size1, size2, size3)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2278
 *         return self
 * 
 *     def resizeAs(_ByteTensor self, _ByteTensor model):             # <<<<<<<<<<<<<<
 *         THByteTensor_resizeAs(self.native, model.native)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_53resizeAs(PyObject *__pyx_v_self, PyObject *__pyx_v_model); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_53resizeAs(PyObject *__pyx_v_self, PyObject *__pyx_v_model) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resizeAs (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_model), __pyx_ptype_7PyTorch__ByteTensor, 1, "model", 0))) __PYX_ERR(0, 2278, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_52resizeAs(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self), ((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_model));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_52resizeAs(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_model) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resizeAs", 0);

  /* "PyTorch.pyx":2279
 * 
 *     def resizeAs(_ByteTensor self, _ByteTensor model):
 *         THByteTensor_resizeAs(self.native, model.native)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THByteTensor_resizeAs(__pyx_v_self->native, __pyx_v_model->native);

  /* "PyTorch.pyx":2280
 *     def resizeAs(_ByteTensor self, _ByteTensor model):
 *         THByteTensor_resizeAs(self.native, model.native)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def resize(_ByteTensor self, Storage._LongStorage size):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":2278
 *         return self
 * 
 *     def resizeAs(_ByteTensor self, _ByteTensor model):             # <<<<<<<<<<<<<<
 *         THByteTensor_resizeAs(self.native, model.native)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2282
 *         return self
 * 
 *     def resize(_ByteTensor self, Storage._LongStorage size):             # <<<<<<<<<<<<<<
 * #        # print('_FloatTensor.resize size:', size)
 *         if len(size) == 0:
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_55resize(PyObject *__pyx_v_self, PyObject *__pyx_v_size); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_55resize(PyObject *__pyx_v_self, PyObject *__pyx_v_size) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resize (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_size), __pyx_ptype_7Storage__LongStorage, 1, "size", 0))) __PYX_ERR(0, 2282, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_54resize(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self), ((struct __pyx_obj_7Storage__LongStorage *)__pyx_v_size));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_54resize(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, struct __pyx_obj_7Storage__LongStorage *__pyx_v_size) {
  int __pyx_v_dims;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  Py_ssize_t __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  long __pyx_t_4;
  long __pyx_t_5;
  long __pyx_t_6;
  long __pyx_t_7;
  PyObject *__pyx_t_8 = NULL;
  __Pyx_RefNannySetupContext("resize", 0);

  /* "PyTorch.pyx":2284
 *     def resize(_ByteTensor self, Storage._LongStorage size):
 * #        # print('_FloatTensor.resize size:', size)
 *         if len(size) == 0:             # <<<<<<<<<<<<<<
 *             return self
 *         cdef int dims = len(size)
 */
  __pyx_t_1 = PyObject_Length(((PyObject *)__pyx_v_size)); if (unlikely(__pyx_t_1 == -1)) __PYX_ERR(0, 2284, __pyx_L1_error)
  __pyx_t_2 = ((__pyx_t_1 == 0) != 0);
  if (__pyx_t_2) {

    /* "PyTorch.pyx":2285
 * #        # print('_FloatTensor.resize size:', size)
 *         if len(size) == 0:
 *             return self             # <<<<<<<<<<<<<<
 *         cdef int dims = len(size)
 * #        # print('_FloatTensor.resize dims:', dims)
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(((PyObject *)__pyx_v_self));
    __pyx_r = ((PyObject *)__pyx_v_self);
    goto __pyx_L0;

    /* "PyTorch.pyx":2284
 *     def resize(_ByteTensor self, Storage._LongStorage size):
 * #        # print('_FloatTensor.resize size:', size)
 *         if len(size) == 0:             # <<<<<<<<<<<<<<
 *             return self
 *         cdef int dims = len(size)
 */
  }

  /* "PyTorch.pyx":2286
 *         if len(size) == 0:
 *             return self
 *         cdef int dims = len(size)             # <<<<<<<<<<<<<<
 * #        # print('_FloatTensor.resize dims:', dims)
 *         if dims == 1:
 */
  __pyx_t_1 = PyObject_Length(((PyObject *)__pyx_v_size)); if (unlikely(__pyx_t_1 == -1)) __PYX_ERR(0, 2286, __pyx_L1_error)
  __pyx_v_dims = __pyx_t_1;

  /* "PyTorch.pyx":2288
 *         cdef int dims = len(size)
 * #        # print('_FloatTensor.resize dims:', dims)
 *         if dims == 1:             # <<<<<<<<<<<<<<
 *             THByteTensor_resize1d(self.native, size[0])
 *         elif dims == 2:
 */
  switch (__pyx_v_dims) {
    case 1:

    /* "PyTorch.pyx":2289
 * #        # print('_FloatTensor.resize dims:', dims)
 *         if dims == 1:
 *             THByteTensor_resize1d(self.native, size[0])             # <<<<<<<<<<<<<<
 *         elif dims == 2:
 *             THByteTensor_resize2d(self.native, size[0], size[1])
 */
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2289, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_4 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2289, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    THByteTensor_resize1d(__pyx_v_self->native, __pyx_t_4);

    /* "PyTorch.pyx":2288
 *         cdef int dims = len(size)
 * #        # print('_FloatTensor.resize dims:', dims)
 *         if dims == 1:             # <<<<<<<<<<<<<<
 *             THByteTensor_resize1d(self.native, size[0])
 *         elif dims == 2:
 */
    break;

    /* "PyTorch.pyx":2290
 *         if dims == 1:
 *             THByteTensor_resize1d(self.native, size[0])
 *         elif dims == 2:             # <<<<<<<<<<<<<<
 *             THByteTensor_resize2d(self.native, size[0], size[1])
 *         elif dims == 3:
 */
    case 2:

    /* "PyTorch.pyx":2291
 *             THByteTensor_resize1d(self.native, size[0])
 *         elif dims == 2:
 *             THByteTensor_resize2d(self.native, size[0], size[1])             # <<<<<<<<<<<<<<
 *         elif dims == 3:
 *             THByteTensor_resize3d(self.native, size[0], size[1], size[2])
 */
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2291, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_4 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2291, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2291, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_5 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_5 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2291, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    THByteTensor_resize2d(__pyx_v_self->native, __pyx_t_4, __pyx_t_5);

    /* "PyTorch.pyx":2290
 *         if dims == 1:
 *             THByteTensor_resize1d(self.native, size[0])
 *         elif dims == 2:             # <<<<<<<<<<<<<<
 *             THByteTensor_resize2d(self.native, size[0], size[1])
 *         elif dims == 3:
 */
    break;

    /* "PyTorch.pyx":2292
 *         elif dims == 2:
 *             THByteTensor_resize2d(self.native, size[0], size[1])
 *         elif dims == 3:             # <<<<<<<<<<<<<<
 *             THByteTensor_resize3d(self.native, size[0], size[1], size[2])
 *         elif dims == 4:
 */
    case 3:

    /* "PyTorch.pyx":2293
 *             THByteTensor_resize2d(self.native, size[0], size[1])
 *         elif dims == 3:
 *             THByteTensor_resize3d(self.native, size[0], size[1], size[2])             # <<<<<<<<<<<<<<
 *         elif dims == 4:
 *             THByteTensor_resize4d(self.native, size[0], size[1], size[2], size[3])
 */
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2293, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_5 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_5 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2293, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2293, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_4 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2293, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2293, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_6 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_6 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2293, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    THByteTensor_resize3d(__pyx_v_self->native, __pyx_t_5, __pyx_t_4, __pyx_t_6);

    /* "PyTorch.pyx":2292
 *         elif dims == 2:
 *             THByteTensor_resize2d(self.native, size[0], size[1])
 *         elif dims == 3:             # <<<<<<<<<<<<<<
 *             THByteTensor_resize3d(self.native, size[0], size[1], size[2])
 *         elif dims == 4:
 */
    break;

    /* "PyTorch.pyx":2294
 *         elif dims == 3:
 *             THByteTensor_resize3d(self.native, size[0], size[1], size[2])
 *         elif dims == 4:             # <<<<<<<<<<<<<<
 *             THByteTensor_resize4d(self.native, size[0], size[1], size[2], size[3])
 *         else:
 */
    case 4:

    /* "PyTorch.pyx":2295
 *             THByteTensor_resize3d(self.native, size[0], size[1], size[2])
 *         elif dims == 4:
 *             THByteTensor_resize4d(self.native, size[0], size[1], size[2], size[3])             # <<<<<<<<<<<<<<
 *         else:
 *             raise Exception('Not implemented for dims=' + str(dims))
 */
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2295, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_6 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_6 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2295, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2295, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_4 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2295, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2295, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_5 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_5 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2295, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 3, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2295, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_7 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_7 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2295, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    THByteTensor_resize4d(__pyx_v_self->native, __pyx_t_6, __pyx_t_4, __pyx_t_5, __pyx_t_7);

    /* "PyTorch.pyx":2294
 *         elif dims == 3:
 *             THByteTensor_resize3d(self.native, size[0], size[1], size[2])
 *         elif dims == 4:             # <<<<<<<<<<<<<<
 *             THByteTensor_resize4d(self.native, size[0], size[1], size[2], size[3])
 *         else:
 */
    break;
    default:

    /* "PyTorch.pyx":2297
 *             THByteTensor_resize4d(self.native, size[0], size[1], size[2], size[3])
 *         else:
 *             raise Exception('Not implemented for dims=' + str(dims))             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
    __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_dims); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2297, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_8 = PyTuple_New(1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2297, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_GIVEREF(__pyx_t_3);
    PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_t_3);
    __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_PyObject_Call(((PyObject *)(&PyString_Type)), __pyx_t_8, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2297, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_8 = PyNumber_Add(__pyx_kp_s_Not_implemented_for_dims, __pyx_t_3); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2297, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2297, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_GIVEREF(__pyx_t_8);
    PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_8);
    __pyx_t_8 = 0;
    __pyx_t_8 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_t_3, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2297, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_Raise(__pyx_t_8, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __PYX_ERR(0, 2297, __pyx_L1_error)
    break;
  }

  /* "PyTorch.pyx":2298
 *         else:
 *             raise Exception('Not implemented for dims=' + str(dims))
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     @staticmethod
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":2282
 *         return self
 * 
 *     def resize(_ByteTensor self, Storage._LongStorage size):             # <<<<<<<<<<<<<<
 * #        # print('_FloatTensor.resize size:', size)
 *         if len(size) == 0:
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("PyTorch._ByteTensor.resize", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2301
 * 
 *     @staticmethod
 *     def newWithStorage(Storage._ByteStorage storage, offset, Storage._LongStorage size, Storage._LongStorage stride):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THByteTensor *newTensorC = THByteTensor_newWithStorage(storage.native, offset, size.native, stride.native)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_57newWithStorage(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_7PyTorch_11_ByteTensor_57newWithStorage = {"newWithStorage", (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_57newWithStorage, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_57newWithStorage(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  struct __pyx_obj_7Storage__ByteStorage *__pyx_v_storage = 0;
  PyObject *__pyx_v_offset = 0;
  struct __pyx_obj_7Storage__LongStorage *__pyx_v_size = 0;
  struct __pyx_obj_7Storage__LongStorage *__pyx_v_stride = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("newWithStorage (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_storage,&__pyx_n_s_offset,&__pyx_n_s_size,&__pyx_n_s_stride,0};
    PyObject* values[4] = {0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_storage)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_offset)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage", 1, 4, 4, 1); __PYX_ERR(0, 2301, __pyx_L3_error)
        }
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage", 1, 4, 4, 2); __PYX_ERR(0, 2301, __pyx_L3_error)
        }
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage", 1, 4, 4, 3); __PYX_ERR(0, 2301, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "newWithStorage") < 0)) __PYX_ERR(0, 2301, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 4) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
    }
    __pyx_v_storage = ((struct __pyx_obj_7Storage__ByteStorage *)values[0]);
    __pyx_v_offset = values[1];
    __pyx_v_size = ((struct __pyx_obj_7Storage__LongStorage *)values[2]);
    __pyx_v_stride = ((struct __pyx_obj_7Storage__LongStorage *)values[3]);
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("newWithStorage", 1, 4, 4, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 2301, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._ByteTensor.newWithStorage", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_storage), __pyx_ptype_7Storage__ByteStorage, 1, "storage", 0))) __PYX_ERR(0, 2301, __pyx_L1_error)
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_size), __pyx_ptype_7Storage__LongStorage, 1, "size", 0))) __PYX_ERR(0, 2301, __pyx_L1_error)
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_stride), __pyx_ptype_7Storage__LongStorage, 1, "stride", 0))) __PYX_ERR(0, 2301, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_56newWithStorage(__pyx_v_storage, __pyx_v_offset, __pyx_v_size, __pyx_v_stride);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_56newWithStorage(struct __pyx_obj_7Storage__ByteStorage *__pyx_v_storage, PyObject *__pyx_v_offset, struct __pyx_obj_7Storage__LongStorage *__pyx_v_size, struct __pyx_obj_7Storage__LongStorage *__pyx_v_stride) {
  struct THByteTensor *__pyx_v_newTensorC;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  long __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  struct __pyx_opt_args_7PyTorch__ByteTensor_fromNative __pyx_t_3;
  __Pyx_RefNannySetupContext("newWithStorage", 0);

  /* "PyTorch.pyx":2303
 *     def newWithStorage(Storage._ByteStorage storage, offset, Storage._LongStorage size, Storage._LongStorage stride):
 * #        # print('allocate tensor')
 *         cdef THByteTensor *newTensorC = THByteTensor_newWithStorage(storage.native, offset, size.native, stride.native)             # <<<<<<<<<<<<<<
 *         return _ByteTensor_fromNative(newTensorC, False)
 * 
 */
  __pyx_t_1 = __Pyx_PyInt_As_long(__pyx_v_offset); if (unlikely((__pyx_t_1 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2303, __pyx_L1_error)
  __pyx_v_newTensorC = THByteTensor_newWithStorage(__pyx_v_storage->native, __pyx_t_1, __pyx_v_size->native, __pyx_v_stride->native);

  /* "PyTorch.pyx":2304
 * #        # print('allocate tensor')
 *         cdef THByteTensor *newTensorC = THByteTensor_newWithStorage(storage.native, offset, size.native, stride.native)
 *         return _ByteTensor_fromNative(newTensorC, False)             # <<<<<<<<<<<<<<
 * 
 *     @staticmethod
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_3.__pyx_n = 1;
  __pyx_t_3.retain = Py_False;
  __pyx_t_2 = __pyx_f_7PyTorch__ByteTensor_fromNative(__pyx_v_newTensorC, &__pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2304, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":2301
 * 
 *     @staticmethod
 *     def newWithStorage(Storage._ByteStorage storage, offset, Storage._LongStorage size, Storage._LongStorage stride):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THByteTensor *newTensorC = THByteTensor_newWithStorage(storage.native, offset, size.native, stride.native)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("PyTorch._ByteTensor.newWithStorage", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2307
 * 
 *     @staticmethod
 *     def newWithStorage1d(Storage._ByteStorage storage, offset, size0, stride0):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THByteTensor *newTensorC = THByteTensor_newWithStorage1d(storage.native, offset, size0, stride0)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_59newWithStorage1d(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_7PyTorch_11_ByteTensor_59newWithStorage1d = {"newWithStorage1d", (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_59newWithStorage1d, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_59newWithStorage1d(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  struct __pyx_obj_7Storage__ByteStorage *__pyx_v_storage = 0;
  PyObject *__pyx_v_offset = 0;
  PyObject *__pyx_v_size0 = 0;
  PyObject *__pyx_v_stride0 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("newWithStorage1d (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_storage,&__pyx_n_s_offset,&__pyx_n_s_size0,&__pyx_n_s_stride0,0};
    PyObject* values[4] = {0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_storage)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_offset)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage1d", 1, 4, 4, 1); __PYX_ERR(0, 2307, __pyx_L3_error)
        }
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size0)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage1d", 1, 4, 4, 2); __PYX_ERR(0, 2307, __pyx_L3_error)
        }
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride0)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage1d", 1, 4, 4, 3); __PYX_ERR(0, 2307, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "newWithStorage1d") < 0)) __PYX_ERR(0, 2307, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 4) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
    }
    __pyx_v_storage = ((struct __pyx_obj_7Storage__ByteStorage *)values[0]);
    __pyx_v_offset = values[1];
    __pyx_v_size0 = values[2];
    __pyx_v_stride0 = values[3];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("newWithStorage1d", 1, 4, 4, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 2307, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._ByteTensor.newWithStorage1d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_storage), __pyx_ptype_7Storage__ByteStorage, 1, "storage", 0))) __PYX_ERR(0, 2307, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_58newWithStorage1d(__pyx_v_storage, __pyx_v_offset, __pyx_v_size0, __pyx_v_stride0);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_58newWithStorage1d(struct __pyx_obj_7Storage__ByteStorage *__pyx_v_storage, PyObject *__pyx_v_offset, PyObject *__pyx_v_size0, PyObject *__pyx_v_stride0) {
  struct THByteTensor *__pyx_v_newTensorC;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  long __pyx_t_1;
  long __pyx_t_2;
  long __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  struct __pyx_opt_args_7PyTorch__ByteTensor_fromNative __pyx_t_5;
  __Pyx_RefNannySetupContext("newWithStorage1d", 0);

  /* "PyTorch.pyx":2309
 *     def newWithStorage1d(Storage._ByteStorage storage, offset, size0, stride0):
 * #        # print('allocate tensor')
 *         cdef THByteTensor *newTensorC = THByteTensor_newWithStorage1d(storage.native, offset, size0, stride0)             # <<<<<<<<<<<<<<
 *         return _ByteTensor_fromNative(newTensorC, False)
 * 
 */
  __pyx_t_1 = __Pyx_PyInt_As_long(__pyx_v_offset); if (unlikely((__pyx_t_1 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2309, __pyx_L1_error)
  __pyx_t_2 = __Pyx_PyInt_As_long(__pyx_v_size0); if (unlikely((__pyx_t_2 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2309, __pyx_L1_error)
  __pyx_t_3 = __Pyx_PyInt_As_long(__pyx_v_stride0); if (unlikely((__pyx_t_3 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2309, __pyx_L1_error)
  __pyx_v_newTensorC = THByteTensor_newWithStorage1d(__pyx_v_storage->native, __pyx_t_1, __pyx_t_2, __pyx_t_3);

  /* "PyTorch.pyx":2310
 * #        # print('allocate tensor')
 *         cdef THByteTensor *newTensorC = THByteTensor_newWithStorage1d(storage.native, offset, size0, stride0)
 *         return _ByteTensor_fromNative(newTensorC, False)             # <<<<<<<<<<<<<<
 * 
 *     @staticmethod
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_5.__pyx_n = 1;
  __pyx_t_5.retain = Py_False;
  __pyx_t_4 = __pyx_f_7PyTorch__ByteTensor_fromNative(__pyx_v_newTensorC, &__pyx_t_5); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2310, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_r = __pyx_t_4;
  __pyx_t_4 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":2307
 * 
 *     @staticmethod
 *     def newWithStorage1d(Storage._ByteStorage storage, offset, size0, stride0):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THByteTensor *newTensorC = THByteTensor_newWithStorage1d(storage.native, offset, size0, stride0)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("PyTorch._ByteTensor.newWithStorage1d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2313
 * 
 *     @staticmethod
 *     def newWithStorage2d(Storage._ByteStorage storage, offset, size0, stride0, size1, stride1):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THByteTensor *newTensorC = THByteTensor_newWithStorage2d(storage.native, offset, size0, stride0, size1, stride1)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_61newWithStorage2d(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_7PyTorch_11_ByteTensor_61newWithStorage2d = {"newWithStorage2d", (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_61newWithStorage2d, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_61newWithStorage2d(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  struct __pyx_obj_7Storage__ByteStorage *__pyx_v_storage = 0;
  PyObject *__pyx_v_offset = 0;
  PyObject *__pyx_v_size0 = 0;
  PyObject *__pyx_v_stride0 = 0;
  PyObject *__pyx_v_size1 = 0;
  PyObject *__pyx_v_stride1 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("newWithStorage2d (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_storage,&__pyx_n_s_offset,&__pyx_n_s_size0,&__pyx_n_s_stride0,&__pyx_n_s_size1,&__pyx_n_s_stride1,0};
    PyObject* values[6] = {0,0,0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_storage)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_offset)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage2d", 1, 6, 6, 1); __PYX_ERR(0, 2313, __pyx_L3_error)
        }
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size0)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage2d", 1, 6, 6, 2); __PYX_ERR(0, 2313, __pyx_L3_error)
        }
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride0)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage2d", 1, 6, 6, 3); __PYX_ERR(0, 2313, __pyx_L3_error)
        }
        case  4:
        if (likely((values[4] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage2d", 1, 6, 6, 4); __PYX_ERR(0, 2313, __pyx_L3_error)
        }
        case  5:
        if (likely((values[5] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage2d", 1, 6, 6, 5); __PYX_ERR(0, 2313, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "newWithStorage2d") < 0)) __PYX_ERR(0, 2313, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 6) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
      values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
      values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
    }
    __pyx_v_storage = ((struct __pyx_obj_7Storage__ByteStorage *)values[0]);
    __pyx_v_offset = values[1];
    __pyx_v_size0 = values[2];
    __pyx_v_stride0 = values[3];
    __pyx_v_size1 = values[4];
    __pyx_v_stride1 = values[5];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("newWithStorage2d", 1, 6, 6, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 2313, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._ByteTensor.newWithStorage2d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_storage), __pyx_ptype_7Storage__ByteStorage, 1, "storage", 0))) __PYX_ERR(0, 2313, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_60newWithStorage2d(__pyx_v_storage, __pyx_v_offset, __pyx_v_size0, __pyx_v_stride0, __pyx_v_size1, __pyx_v_stride1);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_60newWithStorage2d(struct __pyx_obj_7Storage__ByteStorage *__pyx_v_storage, PyObject *__pyx_v_offset, PyObject *__pyx_v_size0, PyObject *__pyx_v_stride0, PyObject *__pyx_v_size1, PyObject *__pyx_v_stride1) {
  struct THByteTensor *__pyx_v_newTensorC;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  long __pyx_t_1;
  long __pyx_t_2;
  long __pyx_t_3;
  long __pyx_t_4;
  long __pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  struct __pyx_opt_args_7PyTorch__ByteTensor_fromNative __pyx_t_7;
  __Pyx_RefNannySetupContext("newWithStorage2d", 0);

  /* "PyTorch.pyx":2315
 *     def newWithStorage2d(Storage._ByteStorage storage, offset, size0, stride0, size1, stride1):
 * #        # print('allocate tensor')
 *         cdef THByteTensor *newTensorC = THByteTensor_newWithStorage2d(storage.native, offset, size0, stride0, size1, stride1)             # <<<<<<<<<<<<<<
 *         return _ByteTensor_fromNative(newTensorC, False)
 * 
 */
  __pyx_t_1 = __Pyx_PyInt_As_long(__pyx_v_offset); if (unlikely((__pyx_t_1 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2315, __pyx_L1_error)
  __pyx_t_2 = __Pyx_PyInt_As_long(__pyx_v_size0); if (unlikely((__pyx_t_2 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2315, __pyx_L1_error)
  __pyx_t_3 = __Pyx_PyInt_As_long(__pyx_v_stride0); if (unlikely((__pyx_t_3 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2315, __pyx_L1_error)
  __pyx_t_4 = __Pyx_PyInt_As_long(__pyx_v_size1); if (unlikely((__pyx_t_4 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2315, __pyx_L1_error)
  __pyx_t_5 = __Pyx_PyInt_As_long(__pyx_v_stride1); if (unlikely((__pyx_t_5 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2315, __pyx_L1_error)
  __pyx_v_newTensorC = THByteTensor_newWithStorage2d(__pyx_v_storage->native, __pyx_t_1, __pyx_t_2, __pyx_t_3, __pyx_t_4, __pyx_t_5);

  /* "PyTorch.pyx":2316
 * #        # print('allocate tensor')
 *         cdef THByteTensor *newTensorC = THByteTensor_newWithStorage2d(storage.native, offset, size0, stride0, size1, stride1)
 *         return _ByteTensor_fromNative(newTensorC, False)             # <<<<<<<<<<<<<<
 * 
 *     @staticmethod
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_7.__pyx_n = 1;
  __pyx_t_7.retain = Py_False;
  __pyx_t_6 = __pyx_f_7PyTorch__ByteTensor_fromNative(__pyx_v_newTensorC, &__pyx_t_7); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2316, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_r = __pyx_t_6;
  __pyx_t_6 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":2313
 * 
 *     @staticmethod
 *     def newWithStorage2d(Storage._ByteStorage storage, offset, size0, stride0, size1, stride1):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THByteTensor *newTensorC = THByteTensor_newWithStorage2d(storage.native, offset, size0, stride0, size1, stride1)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("PyTorch._ByteTensor.newWithStorage2d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2319
 * 
 *     @staticmethod
 *     def newWithStorage3d(Storage._ByteStorage storage, offset, size0, stride0, size1, stride1, size2, stride2):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THByteTensor *newTensorC = THByteTensor_newWithStorage3d(storage.native, offset, size0, stride0, size1, stride1,
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_63newWithStorage3d(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_7PyTorch_11_ByteTensor_63newWithStorage3d = {"newWithStorage3d", (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_63newWithStorage3d, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_63newWithStorage3d(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  struct __pyx_obj_7Storage__ByteStorage *__pyx_v_storage = 0;
  PyObject *__pyx_v_offset = 0;
  PyObject *__pyx_v_size0 = 0;
  PyObject *__pyx_v_stride0 = 0;
  PyObject *__pyx_v_size1 = 0;
  PyObject *__pyx_v_stride1 = 0;
  PyObject *__pyx_v_size2 = 0;
  PyObject *__pyx_v_stride2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("newWithStorage3d (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_storage,&__pyx_n_s_offset,&__pyx_n_s_size0,&__pyx_n_s_stride0,&__pyx_n_s_size1,&__pyx_n_s_stride1,&__pyx_n_s_size2,&__pyx_n_s_stride2,0};
    PyObject* values[8] = {0,0,0,0,0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  8: values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_storage)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_offset)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage3d", 1, 8, 8, 1); __PYX_ERR(0, 2319, __pyx_L3_error)
        }
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size0)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage3d", 1, 8, 8, 2); __PYX_ERR(0, 2319, __pyx_L3_error)
        }
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride0)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage3d", 1, 8, 8, 3); __PYX_ERR(0, 2319, __pyx_L3_error)
        }
        case  4:
        if (likely((values[4] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage3d", 1, 8, 8, 4); __PYX_ERR(0, 2319, __pyx_L3_error)
        }
        case  5:
        if (likely((values[5] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage3d", 1, 8, 8, 5); __PYX_ERR(0, 2319, __pyx_L3_error)
        }
        case  6:
        if (likely((values[6] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage3d", 1, 8, 8, 6); __PYX_ERR(0, 2319, __pyx_L3_error)
        }
        case  7:
        if (likely((values[7] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage3d", 1, 8, 8, 7); __PYX_ERR(0, 2319, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "newWithStorage3d") < 0)) __PYX_ERR(0, 2319, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 8) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
      values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
      values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
      values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
      values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
    }
    __pyx_v_storage = ((struct __pyx_obj_7Storage__ByteStorage *)values[0]);
    __pyx_v_offset = values[1];
    __pyx_v_size0 = values[2];
    __pyx_v_stride0 = values[3];
    __pyx_v_size1 = values[4];
    __pyx_v_stride1 = values[5];
    __pyx_v_size2 = values[6];
    __pyx_v_stride2 = values[7];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("newWithStorage3d", 1, 8, 8, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 2319, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._ByteTensor.newWithStorage3d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_storage), __pyx_ptype_7Storage__ByteStorage, 1, "storage", 0))) __PYX_ERR(0, 2319, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_62newWithStorage3d(__pyx_v_storage, __pyx_v_offset, __pyx_v_size0, __pyx_v_stride0, __pyx_v_size1, __pyx_v_stride1, __pyx_v_size2, __pyx_v_stride2);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_62newWithStorage3d(struct __pyx_obj_7Storage__ByteStorage *__pyx_v_storage, PyObject *__pyx_v_offset, PyObject *__pyx_v_size0, PyObject *__pyx_v_stride0, PyObject *__pyx_v_size1, PyObject *__pyx_v_stride1, PyObject *__pyx_v_size2, PyObject *__pyx_v_stride2) {
  struct THByteTensor *__pyx_v_newTensorC;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  long __pyx_t_1;
  long __pyx_t_2;
  long __pyx_t_3;
  long __pyx_t_4;
  long __pyx_t_5;
  long __pyx_t_6;
  long __pyx_t_7;
  PyObject *__pyx_t_8 = NULL;
  struct __pyx_opt_args_7PyTorch__ByteTensor_fromNative __pyx_t_9;
  __Pyx_RefNannySetupContext("newWithStorage3d", 0);

  /* "PyTorch.pyx":2321
 *     def newWithStorage3d(Storage._ByteStorage storage, offset, size0, stride0, size1, stride1, size2, stride2):
 * #        # print('allocate tensor')
 *         cdef THByteTensor *newTensorC = THByteTensor_newWithStorage3d(storage.native, offset, size0, stride0, size1, stride1,             # <<<<<<<<<<<<<<
 *             size2, stride2)
 *         return _ByteTensor_fromNative(newTensorC, False)
 */
  __pyx_t_1 = __Pyx_PyInt_As_long(__pyx_v_offset); if (unlikely((__pyx_t_1 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2321, __pyx_L1_error)
  __pyx_t_2 = __Pyx_PyInt_As_long(__pyx_v_size0); if (unlikely((__pyx_t_2 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2321, __pyx_L1_error)
  __pyx_t_3 = __Pyx_PyInt_As_long(__pyx_v_stride0); if (unlikely((__pyx_t_3 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2321, __pyx_L1_error)
  __pyx_t_4 = __Pyx_PyInt_As_long(__pyx_v_size1); if (unlikely((__pyx_t_4 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2321, __pyx_L1_error)
  __pyx_t_5 = __Pyx_PyInt_As_long(__pyx_v_stride1); if (unlikely((__pyx_t_5 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2321, __pyx_L1_error)

  /* "PyTorch.pyx":2322
 * #        # print('allocate tensor')
 *         cdef THByteTensor *newTensorC = THByteTensor_newWithStorage3d(storage.native, offset, size0, stride0, size1, stride1,
 *             size2, stride2)             # <<<<<<<<<<<<<<
 *         return _ByteTensor_fromNative(newTensorC, False)
 * 
 */
  __pyx_t_6 = __Pyx_PyInt_As_long(__pyx_v_size2); if (unlikely((__pyx_t_6 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2322, __pyx_L1_error)
  __pyx_t_7 = __Pyx_PyInt_As_long(__pyx_v_stride2); if (unlikely((__pyx_t_7 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2322, __pyx_L1_error)

  /* "PyTorch.pyx":2321
 *     def newWithStorage3d(Storage._ByteStorage storage, offset, size0, stride0, size1, stride1, size2, stride2):
 * #        # print('allocate tensor')
 *         cdef THByteTensor *newTensorC = THByteTensor_newWithStorage3d(storage.native, offset, size0, stride0, size1, stride1,             # <<<<<<<<<<<<<<
 *             size2, stride2)
 *         return _ByteTensor_fromNative(newTensorC, False)
 */
  __pyx_v_newTensorC = THByteTensor_newWithStorage3d(__pyx_v_storage->native, __pyx_t_1, __pyx_t_2, __pyx_t_3, __pyx_t_4, __pyx_t_5, __pyx_t_6, __pyx_t_7);

  /* "PyTorch.pyx":2323
 *         cdef THByteTensor *newTensorC = THByteTensor_newWithStorage3d(storage.native, offset, size0, stride0, size1, stride1,
 *             size2, stride2)
 *         return _ByteTensor_fromNative(newTensorC, False)             # <<<<<<<<<<<<<<
 * 
 *     @staticmethod
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_9.__pyx_n = 1;
  __pyx_t_9.retain = Py_False;
  __pyx_t_8 = __pyx_f_7PyTorch__ByteTensor_fromNative(__pyx_v_newTensorC, &__pyx_t_9); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2323, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __pyx_r = __pyx_t_8;
  __pyx_t_8 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":2319
 * 
 *     @staticmethod
 *     def newWithStorage3d(Storage._ByteStorage storage, offset, size0, stride0, size1, stride1, size2, stride2):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THByteTensor *newTensorC = THByteTensor_newWithStorage3d(storage.native, offset, size0, stride0, size1, stride1,
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("PyTorch._ByteTensor.newWithStorage3d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2326
 * 
 *     @staticmethod
 *     def newWithStorage4d(Storage._ByteStorage storage, offset, size0, stride0, size1, stride1, size2, stride2,             # <<<<<<<<<<<<<<
 *             size3, stride3):
 * #        # print('allocate tensor')
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_65newWithStorage4d(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_7PyTorch_11_ByteTensor_65newWithStorage4d = {"newWithStorage4d", (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_65newWithStorage4d, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_65newWithStorage4d(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  struct __pyx_obj_7Storage__ByteStorage *__pyx_v_storage = 0;
  PyObject *__pyx_v_offset = 0;
  PyObject *__pyx_v_size0 = 0;
  PyObject *__pyx_v_stride0 = 0;
  PyObject *__pyx_v_size1 = 0;
  PyObject *__pyx_v_stride1 = 0;
  PyObject *__pyx_v_size2 = 0;
  PyObject *__pyx_v_stride2 = 0;
  PyObject *__pyx_v_size3 = 0;
  PyObject *__pyx_v_stride3 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("newWithStorage4d (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_storage,&__pyx_n_s_offset,&__pyx_n_s_size0,&__pyx_n_s_stride0,&__pyx_n_s_size1,&__pyx_n_s_stride1,&__pyx_n_s_size2,&__pyx_n_s_stride2,&__pyx_n_s_size3,&__pyx_n_s_stride3,0};
    PyObject* values[10] = {0,0,0,0,0,0,0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case 10: values[9] = PyTuple_GET_ITEM(__pyx_args, 9);
        case  9: values[8] = PyTuple_GET_ITEM(__pyx_args, 8);
        case  8: values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_storage)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_offset)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage4d", 1, 10, 10, 1); __PYX_ERR(0, 2326, __pyx_L3_error)
        }
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size0)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage4d", 1, 10, 10, 2); __PYX_ERR(0, 2326, __pyx_L3_error)
        }
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride0)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage4d", 1, 10, 10, 3); __PYX_ERR(0, 2326, __pyx_L3_error)
        }
        case  4:
        if (likely((values[4] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage4d", 1, 10, 10, 4); __PYX_ERR(0, 2326, __pyx_L3_error)
        }
        case  5:
        if (likely((values[5] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage4d", 1, 10, 10, 5); __PYX_ERR(0, 2326, __pyx_L3_error)
        }
        case  6:
        if (likely((values[6] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage4d", 1, 10, 10, 6); __PYX_ERR(0, 2326, __pyx_L3_error)
        }
        case  7:
        if (likely((values[7] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage4d", 1, 10, 10, 7); __PYX_ERR(0, 2326, __pyx_L3_error)
        }
        case  8:
        if (likely((values[8] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size3)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage4d", 1, 10, 10, 8); __PYX_ERR(0, 2326, __pyx_L3_error)
        }
        case  9:
        if (likely((values[9] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_stride3)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("newWithStorage4d", 1, 10, 10, 9); __PYX_ERR(0, 2326, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "newWithStorage4d") < 0)) __PYX_ERR(0, 2326, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 10) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
      values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
      values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
      values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
      values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
      values[8] = PyTuple_GET_ITEM(__pyx_args, 8);
      values[9] = PyTuple_GET_ITEM(__pyx_args, 9);
    }
    __pyx_v_storage = ((struct __pyx_obj_7Storage__ByteStorage *)values[0]);
    __pyx_v_offset = values[1];
    __pyx_v_size0 = values[2];
    __pyx_v_stride0 = values[3];
    __pyx_v_size1 = values[4];
    __pyx_v_stride1 = values[5];
    __pyx_v_size2 = values[6];
    __pyx_v_stride2 = values[7];
    __pyx_v_size3 = values[8];
    __pyx_v_stride3 = values[9];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("newWithStorage4d", 1, 10, 10, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 2326, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._ByteTensor.newWithStorage4d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_storage), __pyx_ptype_7Storage__ByteStorage, 1, "storage", 0))) __PYX_ERR(0, 2326, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_64newWithStorage4d(__pyx_v_storage, __pyx_v_offset, __pyx_v_size0, __pyx_v_stride0, __pyx_v_size1, __pyx_v_stride1, __pyx_v_size2, __pyx_v_stride2, __pyx_v_size3, __pyx_v_stride3);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_64newWithStorage4d(struct __pyx_obj_7Storage__ByteStorage *__pyx_v_storage, PyObject *__pyx_v_offset, PyObject *__pyx_v_size0, PyObject *__pyx_v_stride0, PyObject *__pyx_v_size1, PyObject *__pyx_v_stride1, PyObject *__pyx_v_size2, PyObject *__pyx_v_stride2, PyObject *__pyx_v_size3, PyObject *__pyx_v_stride3) {
  struct THByteTensor *__pyx_v_newTensorC;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  long __pyx_t_1;
  long __pyx_t_2;
  long __pyx_t_3;
  long __pyx_t_4;
  long __pyx_t_5;
  long __pyx_t_6;
  long __pyx_t_7;
  long __pyx_t_8;
  long __pyx_t_9;
  PyObject *__pyx_t_10 = NULL;
  struct __pyx_opt_args_7PyTorch__ByteTensor_fromNative __pyx_t_11;
  __Pyx_RefNannySetupContext("newWithStorage4d", 0);

  /* "PyTorch.pyx":2329
 *             size3, stride3):
 * #        # print('allocate tensor')
 *         cdef THByteTensor *newTensorC = THByteTensor_newWithStorage4d(storage.native, offset, size0, stride0, size1, stride1,             # <<<<<<<<<<<<<<
 *             size2, stride2, size3, stride3)
 *         return _ByteTensor_fromNative(newTensorC, False)
 */
  __pyx_t_1 = __Pyx_PyInt_As_long(__pyx_v_offset); if (unlikely((__pyx_t_1 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2329, __pyx_L1_error)
  __pyx_t_2 = __Pyx_PyInt_As_long(__pyx_v_size0); if (unlikely((__pyx_t_2 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2329, __pyx_L1_error)
  __pyx_t_3 = __Pyx_PyInt_As_long(__pyx_v_stride0); if (unlikely((__pyx_t_3 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2329, __pyx_L1_error)
  __pyx_t_4 = __Pyx_PyInt_As_long(__pyx_v_size1); if (unlikely((__pyx_t_4 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2329, __pyx_L1_error)
  __pyx_t_5 = __Pyx_PyInt_As_long(__pyx_v_stride1); if (unlikely((__pyx_t_5 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2329, __pyx_L1_error)

  /* "PyTorch.pyx":2330
 * #        # print('allocate tensor')
 *         cdef THByteTensor *newTensorC = THByteTensor_newWithStorage4d(storage.native, offset, size0, stride0, size1, stride1,
 *             size2, stride2, size3, stride3)             # <<<<<<<<<<<<<<
 *         return _ByteTensor_fromNative(newTensorC, False)
 * 
 */
  __pyx_t_6 = __Pyx_PyInt_As_long(__pyx_v_size2); if (unlikely((__pyx_t_6 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2330, __pyx_L1_error)
  __pyx_t_7 = __Pyx_PyInt_As_long(__pyx_v_stride2); if (unlikely((__pyx_t_7 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2330, __pyx_L1_error)
  __pyx_t_8 = __Pyx_PyInt_As_long(__pyx_v_size3); if (unlikely((__pyx_t_8 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2330, __pyx_L1_error)
  __pyx_t_9 = __Pyx_PyInt_As_long(__pyx_v_stride3); if (unlikely((__pyx_t_9 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2330, __pyx_L1_error)

  /* "PyTorch.pyx":2329
 *             size3, stride3):
 * #        # print('allocate tensor')
 *         cdef THByteTensor *newTensorC = THByteTensor_newWithStorage4d(storage.native, offset, size0, stride0, size1, stride1,             # <<<<<<<<<<<<<<
 *             size2, stride2, size3, stride3)
 *         return _ByteTensor_fromNative(newTensorC, False)
 */
  __pyx_v_newTensorC = THByteTensor_newWithStorage4d(__pyx_v_storage->native, __pyx_t_1, __pyx_t_2, __pyx_t_3, __pyx_t_4, __pyx_t_5, __pyx_t_6, __pyx_t_7, __pyx_t_8, __pyx_t_9);

  /* "PyTorch.pyx":2331
 *         cdef THByteTensor *newTensorC = THByteTensor_newWithStorage4d(storage.native, offset, size0, stride0, size1, stride1,
 *             size2, stride2, size3, stride3)
 *         return _ByteTensor_fromNative(newTensorC, False)             # <<<<<<<<<<<<<<
 * 
 *     def clone(_ByteTensor self):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_11.__pyx_n = 1;
  __pyx_t_11.retain = Py_False;
  __pyx_t_10 = __pyx_f_7PyTorch__ByteTensor_fromNative(__pyx_v_newTensorC, &__pyx_t_11); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 2331, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __pyx_r = __pyx_t_10;
  __pyx_t_10 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":2326
 * 
 *     @staticmethod
 *     def newWithStorage4d(Storage._ByteStorage storage, offset, size0, stride0, size1, stride1, size2, stride2,             # <<<<<<<<<<<<<<
 *             size3, stride3):
 * #        # print('allocate tensor')
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_10);
  __Pyx_AddTraceback("PyTorch._ByteTensor.newWithStorage4d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2333
 *         return _ByteTensor_fromNative(newTensorC, False)
 * 
 *     def clone(_ByteTensor self):             # <<<<<<<<<<<<<<
 *         cdef THByteTensor *newTensorC = THByteTensor_newClone(self.native)
 *         return _ByteTensor_fromNative(newTensorC, False)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_67clone(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_67clone(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("clone (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_66clone(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_66clone(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self) {
  struct THByteTensor *__pyx_v_newTensorC;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  struct __pyx_opt_args_7PyTorch__ByteTensor_fromNative __pyx_t_2;
  __Pyx_RefNannySetupContext("clone", 0);

  /* "PyTorch.pyx":2334
 * 
 *     def clone(_ByteTensor self):
 *         cdef THByteTensor *newTensorC = THByteTensor_newClone(self.native)             # <<<<<<<<<<<<<<
 *         return _ByteTensor_fromNative(newTensorC, False)
 * 
 */
  __pyx_v_newTensorC = THByteTensor_newClone(__pyx_v_self->native);

  /* "PyTorch.pyx":2335
 *     def clone(_ByteTensor self):
 *         cdef THByteTensor *newTensorC = THByteTensor_newClone(self.native)
 *         return _ByteTensor_fromNative(newTensorC, False)             # <<<<<<<<<<<<<<
 * 
 *     def storage(_ByteTensor self):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2.__pyx_n = 1;
  __pyx_t_2.retain = Py_False;
  __pyx_t_1 = __pyx_f_7PyTorch__ByteTensor_fromNative(__pyx_v_newTensorC, &__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2335, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":2333
 *         return _ByteTensor_fromNative(newTensorC, False)
 * 
 *     def clone(_ByteTensor self):             # <<<<<<<<<<<<<<
 *         cdef THByteTensor *newTensorC = THByteTensor_newClone(self.native)
 *         return _ByteTensor_fromNative(newTensorC, False)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._ByteTensor.clone", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2337
 *         return _ByteTensor_fromNative(newTensorC, False)
 * 
 *     def storage(_ByteTensor self):             # <<<<<<<<<<<<<<
 *         cdef Storage.THByteStorage *storageC = THByteTensor_storage(self.native)
 *         if storageC == NULL:
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_69storage(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_69storage(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("storage (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_68storage(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_68storage(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self) {
  struct THByteStorage *__pyx_v_storageC;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("storage", 0);

  /* "PyTorch.pyx":2338
 * 
 *     def storage(_ByteTensor self):
 *         cdef Storage.THByteStorage *storageC = THByteTensor_storage(self.native)             # <<<<<<<<<<<<<<
 *         if storageC == NULL:
 *             return None
 */
  __pyx_v_storageC = THByteTensor_storage(__pyx_v_self->native);

  /* "PyTorch.pyx":2339
 *     def storage(_ByteTensor self):
 *         cdef Storage.THByteStorage *storageC = THByteTensor_storage(self.native)
 *         if storageC == NULL:             # <<<<<<<<<<<<<<
 *             return None
 *         return Storage._ByteStorage_fromNative(storageC)
 */
  __pyx_t_1 = ((__pyx_v_storageC == NULL) != 0);
  if (__pyx_t_1) {

    /* "PyTorch.pyx":2340
 *         cdef Storage.THByteStorage *storageC = THByteTensor_storage(self.native)
 *         if storageC == NULL:
 *             return None             # <<<<<<<<<<<<<<
 *         return Storage._ByteStorage_fromNative(storageC)
 * 
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(Py_None);
    __pyx_r = Py_None;
    goto __pyx_L0;

    /* "PyTorch.pyx":2339
 *     def storage(_ByteTensor self):
 *         cdef Storage.THByteStorage *storageC = THByteTensor_storage(self.native)
 *         if storageC == NULL:             # <<<<<<<<<<<<<<
 *             return None
 *         return Storage._ByteStorage_fromNative(storageC)
 */
  }

  /* "PyTorch.pyx":2341
 *         if storageC == NULL:
 *             return None
 *         return Storage._ByteStorage_fromNative(storageC)             # <<<<<<<<<<<<<<
 * 
 *     def __add__(_ByteTensor self, second):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2 = __pyx_f_7Storage__ByteStorage_fromNative(__pyx_v_storageC, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2341, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":2337
 *         return _ByteTensor_fromNative(newTensorC, False)
 * 
 *     def storage(_ByteTensor self):             # <<<<<<<<<<<<<<
 *         cdef Storage.THByteStorage *storageC = THByteTensor_storage(self.native)
 *         if storageC == NULL:
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("PyTorch._ByteTensor.storage", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2343
 *         return Storage._ByteStorage_fromNative(storageC)
 * 
 *     def __add__(_ByteTensor self, second):             # <<<<<<<<<<<<<<
 *         # assume 2d matrix for now?
 *         cdef _ByteTensor res = _ByteTensor.new()
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_71__add__(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_71__add__(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__add__ (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_self), __pyx_ptype_7PyTorch__ByteTensor, 1, "self", 0))) __PYX_ERR(0, 2343, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_70__add__(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self), ((PyObject *)__pyx_v_second));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_70__add__(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, PyObject *__pyx_v_second) {
  struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_res = 0;
  struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_secondTensor = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  int __pyx_t_5;
  unsigned char __pyx_t_6;
  __Pyx_RefNannySetupContext("__add__", 0);

  /* "PyTorch.pyx":2345
 *     def __add__(_ByteTensor self, second):
 *         # assume 2d matrix for now?
 *         cdef _ByteTensor res = _ByteTensor.new()             # <<<<<<<<<<<<<<
 *         cdef _ByteTensor secondTensor
 *         if isinstance(second, numbers.Number):
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7PyTorch__ByteTensor), __pyx_n_s_new); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2345, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2345, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2345, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_7PyTorch__ByteTensor))))) __PYX_ERR(0, 2345, __pyx_L1_error)
  __pyx_v_res = ((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":2347
 *         cdef _ByteTensor res = _ByteTensor.new()
 *         cdef _ByteTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THByteTensor_add(res.native, self.native, second)
 *         else:
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_numbers); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2347, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_Number); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2347, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_4 = PyObject_IsInstance(__pyx_v_second, __pyx_t_2); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 2347, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = (__pyx_t_4 != 0);
  if (__pyx_t_5) {

    /* "PyTorch.pyx":2348
 *         cdef _ByteTensor secondTensor
 *         if isinstance(second, numbers.Number):
 *             THByteTensor_add(res.native, self.native, second)             # <<<<<<<<<<<<<<
 *         else:
 *             secondTensor = second
 */
    __pyx_t_6 = __Pyx_PyInt_As_unsigned_char(__pyx_v_second); if (unlikely((__pyx_t_6 == (unsigned char)-1) && PyErr_Occurred())) __PYX_ERR(0, 2348, __pyx_L1_error)
    THByteTensor_add(__pyx_v_res->native, __pyx_v_self->native, __pyx_t_6);

    /* "PyTorch.pyx":2347
 *         cdef _ByteTensor res = _ByteTensor.new()
 *         cdef _ByteTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THByteTensor_add(res.native, self.native, second)
 *         else:
 */
    goto __pyx_L3;
  }

  /* "PyTorch.pyx":2350
 *             THByteTensor_add(res.native, self.native, second)
 *         else:
 *             secondTensor = second             # <<<<<<<<<<<<<<
 *             THByteTensor_cadd(res.native, self.native, 1, secondTensor.native)
 *         return res
 */
  /*else*/ {
    if (!(likely(((__pyx_v_second) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_second, __pyx_ptype_7PyTorch__ByteTensor))))) __PYX_ERR(0, 2350, __pyx_L1_error)
    __pyx_t_2 = __pyx_v_second;
    __Pyx_INCREF(__pyx_t_2);
    __pyx_v_secondTensor = ((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_t_2);
    __pyx_t_2 = 0;

    /* "PyTorch.pyx":2351
 *         else:
 *             secondTensor = second
 *             THByteTensor_cadd(res.native, self.native, 1, secondTensor.native)             # <<<<<<<<<<<<<<
 *         return res
 * 
 */
    THByteTensor_cadd(__pyx_v_res->native, __pyx_v_self->native, 1, __pyx_v_secondTensor->native);
  }
  __pyx_L3:;

  /* "PyTorch.pyx":2352
 *             secondTensor = second
 *             THByteTensor_cadd(res.native, self.native, 1, secondTensor.native)
 *         return res             # <<<<<<<<<<<<<<
 * 
 *     def cmul(_ByteTensor self, second):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = ((PyObject *)__pyx_v_res);
  goto __pyx_L0;

  /* "PyTorch.pyx":2343
 *         return Storage._ByteStorage_fromNative(storageC)
 * 
 *     def __add__(_ByteTensor self, second):             # <<<<<<<<<<<<<<
 *         # assume 2d matrix for now?
 *         cdef _ByteTensor res = _ByteTensor.new()
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("PyTorch._ByteTensor.__add__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XDECREF((PyObject *)__pyx_v_secondTensor);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2354
 *         return res
 * 
 *     def cmul(_ByteTensor self, second):             # <<<<<<<<<<<<<<
 * #        cdef _ByteTensor res = _ByteTensor.new()
 *         cdef _ByteTensor secondTensor
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_73cmul(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_73cmul(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cmul (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_72cmul(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self), ((PyObject *)__pyx_v_second));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_72cmul(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, PyObject *__pyx_v_second) {
  struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_secondTensor = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("cmul", 0);

  /* "PyTorch.pyx":2357
 * #        cdef _ByteTensor res = _ByteTensor.new()
 *         cdef _ByteTensor secondTensor
 *         secondTensor = second             # <<<<<<<<<<<<<<
 *         THByteTensor_cmul(self.native, self.native, secondTensor.native)
 *         return self
 */
  if (!(likely(((__pyx_v_second) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_second, __pyx_ptype_7PyTorch__ByteTensor))))) __PYX_ERR(0, 2357, __pyx_L1_error)
  __pyx_t_1 = __pyx_v_second;
  __Pyx_INCREF(__pyx_t_1);
  __pyx_v_secondTensor = ((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":2358
 *         cdef _ByteTensor secondTensor
 *         secondTensor = second
 *         THByteTensor_cmul(self.native, self.native, secondTensor.native)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THByteTensor_cmul(__pyx_v_self->native, __pyx_v_self->native, __pyx_v_secondTensor->native);

  /* "PyTorch.pyx":2359
 *         secondTensor = second
 *         THByteTensor_cmul(self.native, self.native, secondTensor.native)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def __sub__(_ByteTensor self, second):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":2354
 *         return res
 * 
 *     def cmul(_ByteTensor self, second):             # <<<<<<<<<<<<<<
 * #        cdef _ByteTensor res = _ByteTensor.new()
 *         cdef _ByteTensor secondTensor
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._ByteTensor.cmul", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_secondTensor);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2361
 *         return self
 * 
 *     def __sub__(_ByteTensor self, second):             # <<<<<<<<<<<<<<
 *         # assume 2d matrix for now?
 *         cdef _ByteTensor res = _ByteTensor.new()
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_75__sub__(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_75__sub__(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__sub__ (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_self), __pyx_ptype_7PyTorch__ByteTensor, 1, "self", 0))) __PYX_ERR(0, 2361, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_74__sub__(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self), ((PyObject *)__pyx_v_second));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_74__sub__(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, PyObject *__pyx_v_second) {
  struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_res = 0;
  struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_secondTensor = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  int __pyx_t_5;
  unsigned char __pyx_t_6;
  __Pyx_RefNannySetupContext("__sub__", 0);

  /* "PyTorch.pyx":2363
 *     def __sub__(_ByteTensor self, second):
 *         # assume 2d matrix for now?
 *         cdef _ByteTensor res = _ByteTensor.new()             # <<<<<<<<<<<<<<
 *         cdef _ByteTensor secondTensor
 *         if isinstance(second, numbers.Number):
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7PyTorch__ByteTensor), __pyx_n_s_new); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2363, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2363, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2363, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_7PyTorch__ByteTensor))))) __PYX_ERR(0, 2363, __pyx_L1_error)
  __pyx_v_res = ((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":2365
 *         cdef _ByteTensor res = _ByteTensor.new()
 *         cdef _ByteTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THByteTensor_add(res.native, self.native, -second)
 *         else:
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_numbers); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2365, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_Number); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2365, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_4 = PyObject_IsInstance(__pyx_v_second, __pyx_t_2); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 2365, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = (__pyx_t_4 != 0);
  if (__pyx_t_5) {

    /* "PyTorch.pyx":2366
 *         cdef _ByteTensor secondTensor
 *         if isinstance(second, numbers.Number):
 *             THByteTensor_add(res.native, self.native, -second)             # <<<<<<<<<<<<<<
 *         else:
 *             secondTensor = second
 */
    __pyx_t_2 = PyNumber_Negative(__pyx_v_second); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2366, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_6 = __Pyx_PyInt_As_unsigned_char(__pyx_t_2); if (unlikely((__pyx_t_6 == (unsigned char)-1) && PyErr_Occurred())) __PYX_ERR(0, 2366, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    THByteTensor_add(__pyx_v_res->native, __pyx_v_self->native, __pyx_t_6);

    /* "PyTorch.pyx":2365
 *         cdef _ByteTensor res = _ByteTensor.new()
 *         cdef _ByteTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THByteTensor_add(res.native, self.native, -second)
 *         else:
 */
    goto __pyx_L3;
  }

  /* "PyTorch.pyx":2368
 *             THByteTensor_add(res.native, self.native, -second)
 *         else:
 *             secondTensor = second             # <<<<<<<<<<<<<<
 *             THByteTensor_cadd(res.native, self.native, -1, secondTensor.native)
 *         return res
 */
  /*else*/ {
    if (!(likely(((__pyx_v_second) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_second, __pyx_ptype_7PyTorch__ByteTensor))))) __PYX_ERR(0, 2368, __pyx_L1_error)
    __pyx_t_2 = __pyx_v_second;
    __Pyx_INCREF(__pyx_t_2);
    __pyx_v_secondTensor = ((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_t_2);
    __pyx_t_2 = 0;

    /* "PyTorch.pyx":2369
 *         else:
 *             secondTensor = second
 *             THByteTensor_cadd(res.native, self.native, -1, secondTensor.native)             # <<<<<<<<<<<<<<
 *         return res
 * 
 */
    THByteTensor_cadd(__pyx_v_res->native, __pyx_v_self->native, -1, __pyx_v_secondTensor->native);
  }
  __pyx_L3:;

  /* "PyTorch.pyx":2370
 *             secondTensor = second
 *             THByteTensor_cadd(res.native, self.native, -1, secondTensor.native)
 *         return res             # <<<<<<<<<<<<<<
 * 
 *     def eq(_ByteTensor self, _ByteTensor second):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = ((PyObject *)__pyx_v_res);
  goto __pyx_L0;

  /* "PyTorch.pyx":2361
 *         return self
 * 
 *     def __sub__(_ByteTensor self, second):             # <<<<<<<<<<<<<<
 *         # assume 2d matrix for now?
 *         cdef _ByteTensor res = _ByteTensor.new()
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("PyTorch._ByteTensor.__sub__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XDECREF((PyObject *)__pyx_v_secondTensor);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2372
 *         return res
 * 
 *     def eq(_ByteTensor self, _ByteTensor second):             # <<<<<<<<<<<<<<
 *         cdef _ByteTensor res = _ByteTensor.new()
 *         THByteTensor_eqTensor(res.native, self.native, second.native);
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_77eq(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_77eq(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("eq (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_second), __pyx_ptype_7PyTorch__ByteTensor, 1, "second", 0))) __PYX_ERR(0, 2372, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_76eq(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self), ((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_second));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_76eq(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_second) {
  struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_res = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("eq", 0);

  /* "PyTorch.pyx":2373
 * 
 *     def eq(_ByteTensor self, _ByteTensor second):
 *         cdef _ByteTensor res = _ByteTensor.new()             # <<<<<<<<<<<<<<
 *         THByteTensor_eqTensor(res.native, self.native, second.native);
 *         return res
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7PyTorch__ByteTensor), __pyx_n_s_new); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2373, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2373, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2373, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_7PyTorch__ByteTensor))))) __PYX_ERR(0, 2373, __pyx_L1_error)
  __pyx_v_res = ((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":2374
 *     def eq(_ByteTensor self, _ByteTensor second):
 *         cdef _ByteTensor res = _ByteTensor.new()
 *         THByteTensor_eqTensor(res.native, self.native, second.native);             # <<<<<<<<<<<<<<
 *         return res
 * 
 */
  THByteTensor_eqTensor(__pyx_v_res->native, __pyx_v_self->native, __pyx_v_second->native);

  /* "PyTorch.pyx":2375
 *         cdef _ByteTensor res = _ByteTensor.new()
 *         THByteTensor_eqTensor(res.native, self.native, second.native);
 *         return res             # <<<<<<<<<<<<<<
 * 
 *     def icmin(_ByteTensor self, second):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = ((PyObject *)__pyx_v_res);
  goto __pyx_L0;

  /* "PyTorch.pyx":2372
 *         return res
 * 
 *     def eq(_ByteTensor self, _ByteTensor second):             # <<<<<<<<<<<<<<
 *         cdef _ByteTensor res = _ByteTensor.new()
 *         THByteTensor_eqTensor(res.native, self.native, second.native);
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("PyTorch._ByteTensor.eq", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2377
 *         return res
 * 
 *     def icmin(_ByteTensor self, second):             # <<<<<<<<<<<<<<
 *       THByteTensor_cminValue(self.native, self.native, second)
 *       return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_79icmin(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_79icmin(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("icmin (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_78icmin(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self), ((PyObject *)__pyx_v_second));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_78icmin(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  unsigned char __pyx_t_1;
  __Pyx_RefNannySetupContext("icmin", 0);

  /* "PyTorch.pyx":2378
 * 
 *     def icmin(_ByteTensor self, second):
 *       THByteTensor_cminValue(self.native, self.native, second)             # <<<<<<<<<<<<<<
 *       return self
 * 
 */
  __pyx_t_1 = __Pyx_PyInt_As_unsigned_char(__pyx_v_second); if (unlikely((__pyx_t_1 == (unsigned char)-1) && PyErr_Occurred())) __PYX_ERR(0, 2378, __pyx_L1_error)
  THByteTensor_cminValue(__pyx_v_self->native, __pyx_v_self->native, __pyx_t_1);

  /* "PyTorch.pyx":2379
 *     def icmin(_ByteTensor self, second):
 *       THByteTensor_cminValue(self.native, self.native, second)
 *       return self             # <<<<<<<<<<<<<<
 * 
 *     def icmax(_ByteTensor self, second):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":2377
 *         return res
 * 
 *     def icmin(_ByteTensor self, second):             # <<<<<<<<<<<<<<
 *       THByteTensor_cminValue(self.native, self.native, second)
 *       return self
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("PyTorch._ByteTensor.icmin", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2381
 *       return self
 * 
 *     def icmax(_ByteTensor self, second):             # <<<<<<<<<<<<<<
 *       THByteTensor_cmaxValue(self.native, self.native, second)
 *       return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_81icmax(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_81icmax(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("icmax (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_80icmax(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self), ((PyObject *)__pyx_v_second));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_80icmax(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  unsigned char __pyx_t_1;
  __Pyx_RefNannySetupContext("icmax", 0);

  /* "PyTorch.pyx":2382
 * 
 *     def icmax(_ByteTensor self, second):
 *       THByteTensor_cmaxValue(self.native, self.native, second)             # <<<<<<<<<<<<<<
 *       return self
 * 
 */
  __pyx_t_1 = __Pyx_PyInt_As_unsigned_char(__pyx_v_second); if (unlikely((__pyx_t_1 == (unsigned char)-1) && PyErr_Occurred())) __PYX_ERR(0, 2382, __pyx_L1_error)
  THByteTensor_cmaxValue(__pyx_v_self->native, __pyx_v_self->native, __pyx_t_1);

  /* "PyTorch.pyx":2383
 *     def icmax(_ByteTensor self, second):
 *       THByteTensor_cmaxValue(self.native, self.native, second)
 *       return self             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":2381
 *       return self
 * 
 *     def icmax(_ByteTensor self, second):             # <<<<<<<<<<<<<<
 *       THByteTensor_cmaxValue(self.native, self.native, second)
 *       return self
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("PyTorch._ByteTensor.icmax", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2386
 * 
 * 
 *     def __floordiv__(_ByteTensor self, second):             # <<<<<<<<<<<<<<
 *         cdef _ByteTensor res = _ByteTensor.new()
 *         cdef _ByteTensor secondTensor
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_83__floordiv__(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_83__floordiv__(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__floordiv__ (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_self), __pyx_ptype_7PyTorch__ByteTensor, 1, "self", 0))) __PYX_ERR(0, 2386, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_82__floordiv__(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self), ((PyObject *)__pyx_v_second));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_82__floordiv__(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, PyObject *__pyx_v_second) {
  struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_res = 0;
  struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_secondTensor = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  int __pyx_t_5;
  unsigned char __pyx_t_6;
  __Pyx_RefNannySetupContext("__floordiv__", 0);

  /* "PyTorch.pyx":2387
 * 
 *     def __floordiv__(_ByteTensor self, second):
 *         cdef _ByteTensor res = _ByteTensor.new()             # <<<<<<<<<<<<<<
 *         cdef _ByteTensor secondTensor
 *         if isinstance(second, numbers.Number):
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7PyTorch__ByteTensor), __pyx_n_s_new); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2387, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2387, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2387, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_7PyTorch__ByteTensor))))) __PYX_ERR(0, 2387, __pyx_L1_error)
  __pyx_v_res = ((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":2389
 *         cdef _ByteTensor res = _ByteTensor.new()
 *         cdef _ByteTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THByteTensor_div(res.native, self.native, second)
 *         else:
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_numbers); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2389, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_Number); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2389, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_4 = PyObject_IsInstance(__pyx_v_second, __pyx_t_2); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 2389, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = (__pyx_t_4 != 0);
  if (__pyx_t_5) {

    /* "PyTorch.pyx":2390
 *         cdef _ByteTensor secondTensor
 *         if isinstance(second, numbers.Number):
 *             THByteTensor_div(res.native, self.native, second)             # <<<<<<<<<<<<<<
 *         else:
 *             secondTensor = second
 */
    __pyx_t_6 = __Pyx_PyInt_As_unsigned_char(__pyx_v_second); if (unlikely((__pyx_t_6 == (unsigned char)-1) && PyErr_Occurred())) __PYX_ERR(0, 2390, __pyx_L1_error)
    THByteTensor_div(__pyx_v_res->native, __pyx_v_self->native, __pyx_t_6);

    /* "PyTorch.pyx":2389
 *         cdef _ByteTensor res = _ByteTensor.new()
 *         cdef _ByteTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THByteTensor_div(res.native, self.native, second)
 *         else:
 */
    goto __pyx_L3;
  }

  /* "PyTorch.pyx":2392
 *             THByteTensor_div(res.native, self.native, second)
 *         else:
 *             secondTensor = second             # <<<<<<<<<<<<<<
 *             THByteTensor_cdiv(res.native, self.native, secondTensor.native)
 *         return res
 */
  /*else*/ {
    if (!(likely(((__pyx_v_second) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_second, __pyx_ptype_7PyTorch__ByteTensor))))) __PYX_ERR(0, 2392, __pyx_L1_error)
    __pyx_t_2 = __pyx_v_second;
    __Pyx_INCREF(__pyx_t_2);
    __pyx_v_secondTensor = ((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_t_2);
    __pyx_t_2 = 0;

    /* "PyTorch.pyx":2393
 *         else:
 *             secondTensor = second
 *             THByteTensor_cdiv(res.native, self.native, secondTensor.native)             # <<<<<<<<<<<<<<
 *         return res
 * 
 */
    THByteTensor_cdiv(__pyx_v_res->native, __pyx_v_self->native, __pyx_v_secondTensor->native);
  }
  __pyx_L3:;

  /* "PyTorch.pyx":2394
 *             secondTensor = second
 *             THByteTensor_cdiv(res.native, self.native, secondTensor.native)
 *         return res             # <<<<<<<<<<<<<<
 * 
 *     def __ifloordiv__(_ByteTensor self, second):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = ((PyObject *)__pyx_v_res);
  goto __pyx_L0;

  /* "PyTorch.pyx":2386
 * 
 * 
 *     def __floordiv__(_ByteTensor self, second):             # <<<<<<<<<<<<<<
 *         cdef _ByteTensor res = _ByteTensor.new()
 *         cdef _ByteTensor secondTensor
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("PyTorch._ByteTensor.__floordiv__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XDECREF((PyObject *)__pyx_v_secondTensor);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2396
 *         return res
 * 
 *     def __ifloordiv__(_ByteTensor self, second):             # <<<<<<<<<<<<<<
 *         cdef _ByteTensor secondTensor
 *         if isinstance(second, numbers.Number):
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_85__ifloordiv__(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_85__ifloordiv__(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__ifloordiv__ (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_84__ifloordiv__(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self), ((PyObject *)__pyx_v_second));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_84__ifloordiv__(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, PyObject *__pyx_v_second) {
  struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_secondTensor = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  int __pyx_t_4;
  unsigned char __pyx_t_5;
  __Pyx_RefNannySetupContext("__ifloordiv__", 0);

  /* "PyTorch.pyx":2398
 *     def __ifloordiv__(_ByteTensor self, second):
 *         cdef _ByteTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THByteTensor_div(self.native, self.native, second)
 *         else:
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_numbers); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2398, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_Number); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2398, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = PyObject_IsInstance(__pyx_v_second, __pyx_t_2); if (unlikely(__pyx_t_3 == -1)) __PYX_ERR(0, 2398, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_4 = (__pyx_t_3 != 0);
  if (__pyx_t_4) {

    /* "PyTorch.pyx":2399
 *         cdef _ByteTensor secondTensor
 *         if isinstance(second, numbers.Number):
 *             THByteTensor_div(self.native, self.native, second)             # <<<<<<<<<<<<<<
 *         else:
 *             secondTensor = second
 */
    __pyx_t_5 = __Pyx_PyInt_As_unsigned_char(__pyx_v_second); if (unlikely((__pyx_t_5 == (unsigned char)-1) && PyErr_Occurred())) __PYX_ERR(0, 2399, __pyx_L1_error)
    THByteTensor_div(__pyx_v_self->native, __pyx_v_self->native, __pyx_t_5);

    /* "PyTorch.pyx":2398
 *     def __ifloordiv__(_ByteTensor self, second):
 *         cdef _ByteTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THByteTensor_div(self.native, self.native, second)
 *         else:
 */
    goto __pyx_L3;
  }

  /* "PyTorch.pyx":2401
 *             THByteTensor_div(self.native, self.native, second)
 *         else:
 *             secondTensor = second             # <<<<<<<<<<<<<<
 *             THByteTensor_cdiv(self.native, self.native, secondTensor.native)
 *         return self
 */
  /*else*/ {
    if (!(likely(((__pyx_v_second) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_second, __pyx_ptype_7PyTorch__ByteTensor))))) __PYX_ERR(0, 2401, __pyx_L1_error)
    __pyx_t_2 = __pyx_v_second;
    __Pyx_INCREF(__pyx_t_2);
    __pyx_v_secondTensor = ((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_t_2);
    __pyx_t_2 = 0;

    /* "PyTorch.pyx":2402
 *         else:
 *             secondTensor = second
 *             THByteTensor_cdiv(self.native, self.native, secondTensor.native)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
    THByteTensor_cdiv(__pyx_v_self->native, __pyx_v_self->native, __pyx_v_secondTensor->native);
  }
  __pyx_L3:;

  /* "PyTorch.pyx":2403
 *             secondTensor = second
 *             THByteTensor_cdiv(self.native, self.native, secondTensor.native)
 *         return self             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":2396
 *         return res
 * 
 *     def __ifloordiv__(_ByteTensor self, second):             # <<<<<<<<<<<<<<
 *         cdef _ByteTensor secondTensor
 *         if isinstance(second, numbers.Number):
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("PyTorch._ByteTensor.__ifloordiv__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_secondTensor);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2406
 * 
 * 
 *     def __iadd__(_ByteTensor self, second):             # <<<<<<<<<<<<<<
 *         cdef _ByteTensor secondTensor
 *         if isinstance(second, numbers.Number):
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_87__iadd__(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_87__iadd__(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__iadd__ (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_86__iadd__(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self), ((PyObject *)__pyx_v_second));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_86__iadd__(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, PyObject *__pyx_v_second) {
  struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_secondTensor = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  int __pyx_t_4;
  unsigned char __pyx_t_5;
  __Pyx_RefNannySetupContext("__iadd__", 0);

  /* "PyTorch.pyx":2408
 *     def __iadd__(_ByteTensor self, second):
 *         cdef _ByteTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THByteTensor_add(self.native, self.native, second)
 *         else:
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_numbers); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2408, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_Number); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2408, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = PyObject_IsInstance(__pyx_v_second, __pyx_t_2); if (unlikely(__pyx_t_3 == -1)) __PYX_ERR(0, 2408, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_4 = (__pyx_t_3 != 0);
  if (__pyx_t_4) {

    /* "PyTorch.pyx":2409
 *         cdef _ByteTensor secondTensor
 *         if isinstance(second, numbers.Number):
 *             THByteTensor_add(self.native, self.native, second)             # <<<<<<<<<<<<<<
 *         else:
 *             secondTensor = second
 */
    __pyx_t_5 = __Pyx_PyInt_As_unsigned_char(__pyx_v_second); if (unlikely((__pyx_t_5 == (unsigned char)-1) && PyErr_Occurred())) __PYX_ERR(0, 2409, __pyx_L1_error)
    THByteTensor_add(__pyx_v_self->native, __pyx_v_self->native, __pyx_t_5);

    /* "PyTorch.pyx":2408
 *     def __iadd__(_ByteTensor self, second):
 *         cdef _ByteTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THByteTensor_add(self.native, self.native, second)
 *         else:
 */
    goto __pyx_L3;
  }

  /* "PyTorch.pyx":2411
 *             THByteTensor_add(self.native, self.native, second)
 *         else:
 *             secondTensor = second             # <<<<<<<<<<<<<<
 *             THByteTensor_cadd(self.native, self.native, 1, secondTensor.native)
 *         return self
 */
  /*else*/ {
    if (!(likely(((__pyx_v_second) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_second, __pyx_ptype_7PyTorch__ByteTensor))))) __PYX_ERR(0, 2411, __pyx_L1_error)
    __pyx_t_2 = __pyx_v_second;
    __Pyx_INCREF(__pyx_t_2);
    __pyx_v_secondTensor = ((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_t_2);
    __pyx_t_2 = 0;

    /* "PyTorch.pyx":2412
 *         else:
 *             secondTensor = second
 *             THByteTensor_cadd(self.native, self.native, 1, secondTensor.native)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
    THByteTensor_cadd(__pyx_v_self->native, __pyx_v_self->native, 1, __pyx_v_secondTensor->native);
  }
  __pyx_L3:;

  /* "PyTorch.pyx":2413
 *             secondTensor = second
 *             THByteTensor_cadd(self.native, self.native, 1, secondTensor.native)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def __isub__(_ByteTensor self, second):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":2406
 * 
 * 
 *     def __iadd__(_ByteTensor self, second):             # <<<<<<<<<<<<<<
 *         cdef _ByteTensor secondTensor
 *         if isinstance(second, numbers.Number):
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("PyTorch._ByteTensor.__iadd__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_secondTensor);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2415
 *         return self
 * 
 *     def __isub__(_ByteTensor self, second):             # <<<<<<<<<<<<<<
 *         cdef _ByteTensor secondTensor
 *         if isinstance(second, numbers.Number):
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_89__isub__(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_89__isub__(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__isub__ (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_88__isub__(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self), ((PyObject *)__pyx_v_second));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_88__isub__(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, PyObject *__pyx_v_second) {
  struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_secondTensor = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  int __pyx_t_4;
  unsigned char __pyx_t_5;
  __Pyx_RefNannySetupContext("__isub__", 0);

  /* "PyTorch.pyx":2417
 *     def __isub__(_ByteTensor self, second):
 *         cdef _ByteTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THByteTensor_add(self.native, self.native, -second)
 *         else:
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_numbers); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2417, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_Number); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2417, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = PyObject_IsInstance(__pyx_v_second, __pyx_t_2); if (unlikely(__pyx_t_3 == -1)) __PYX_ERR(0, 2417, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_4 = (__pyx_t_3 != 0);
  if (__pyx_t_4) {

    /* "PyTorch.pyx":2418
 *         cdef _ByteTensor secondTensor
 *         if isinstance(second, numbers.Number):
 *             THByteTensor_add(self.native, self.native, -second)             # <<<<<<<<<<<<<<
 *         else:
 *             secondTensor = second
 */
    __pyx_t_2 = PyNumber_Negative(__pyx_v_second); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2418, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_5 = __Pyx_PyInt_As_unsigned_char(__pyx_t_2); if (unlikely((__pyx_t_5 == (unsigned char)-1) && PyErr_Occurred())) __PYX_ERR(0, 2418, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    THByteTensor_add(__pyx_v_self->native, __pyx_v_self->native, __pyx_t_5);

    /* "PyTorch.pyx":2417
 *     def __isub__(_ByteTensor self, second):
 *         cdef _ByteTensor secondTensor
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THByteTensor_add(self.native, self.native, -second)
 *         else:
 */
    goto __pyx_L3;
  }

  /* "PyTorch.pyx":2420
 *             THByteTensor_add(self.native, self.native, -second)
 *         else:
 *             secondTensor = second             # <<<<<<<<<<<<<<
 *             THByteTensor_cadd(self.native, self.native, -1, secondTensor.native)
 *         return self
 */
  /*else*/ {
    if (!(likely(((__pyx_v_second) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_second, __pyx_ptype_7PyTorch__ByteTensor))))) __PYX_ERR(0, 2420, __pyx_L1_error)
    __pyx_t_2 = __pyx_v_second;
    __Pyx_INCREF(__pyx_t_2);
    __pyx_v_secondTensor = ((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_t_2);
    __pyx_t_2 = 0;

    /* "PyTorch.pyx":2421
 *         else:
 *             secondTensor = second
 *             THByteTensor_cadd(self.native, self.native, -1, secondTensor.native)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
    THByteTensor_cadd(__pyx_v_self->native, __pyx_v_self->native, -1, __pyx_v_secondTensor->native);
  }
  __pyx_L3:;

  /* "PyTorch.pyx":2422
 *             secondTensor = second
 *             THByteTensor_cadd(self.native, self.native, -1, secondTensor.native)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def __imul__(_ByteTensor self, unsigned char value):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":2415
 *         return self
 * 
 *     def __isub__(_ByteTensor self, second):             # <<<<<<<<<<<<<<
 *         cdef _ByteTensor secondTensor
 *         if isinstance(second, numbers.Number):
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("PyTorch._ByteTensor.__isub__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_secondTensor);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2424
 *         return self
 * 
 *     def __imul__(_ByteTensor self, unsigned char value):             # <<<<<<<<<<<<<<
 *         THByteTensor_mul(self.native, self.native, value)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_91__imul__(PyObject *__pyx_v_self, PyObject *__pyx_arg_value); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_91__imul__(PyObject *__pyx_v_self, PyObject *__pyx_arg_value) {
  unsigned char __pyx_v_value;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__imul__ (wrapper)", 0);
  assert(__pyx_arg_value); {
    __pyx_v_value = __Pyx_PyInt_As_unsigned_char(__pyx_arg_value); if (unlikely((__pyx_v_value == (unsigned char)-1) && PyErr_Occurred())) __PYX_ERR(0, 2424, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._ByteTensor.__imul__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_90__imul__(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self), ((unsigned char)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_90__imul__(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, unsigned char __pyx_v_value) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__imul__", 0);

  /* "PyTorch.pyx":2425
 * 
 *     def __imul__(_ByteTensor self, unsigned char value):
 *         THByteTensor_mul(self.native, self.native, value)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THByteTensor_mul(__pyx_v_self->native, __pyx_v_self->native, __pyx_v_value);

  /* "PyTorch.pyx":2426
 *     def __imul__(_ByteTensor self, unsigned char value):
 *         THByteTensor_mul(self.native, self.native, value)
 *         return self             # <<<<<<<<<<<<<<
 * 
 * #    def __mul__(_ByteTensor self, _ByteTensor M2):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":2424
 *         return self
 * 
 *     def __imul__(_ByteTensor self, unsigned char value):             # <<<<<<<<<<<<<<
 *         THByteTensor_mul(self.native, self.native, value)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2429
 * 
 * #    def __mul__(_ByteTensor self, _ByteTensor M2):
 *     def __mul__(_ByteTensor self, second):             # <<<<<<<<<<<<<<
 *         cdef _ByteTensor M2
 *         cdef _ByteTensor T
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_93__mul__(PyObject *__pyx_v_self, PyObject *__pyx_v_second); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_93__mul__(PyObject *__pyx_v_self, PyObject *__pyx_v_second) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__mul__ (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_self), __pyx_ptype_7PyTorch__ByteTensor, 1, "self", 0))) __PYX_ERR(0, 2429, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_92__mul__(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self), ((PyObject *)__pyx_v_second));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_92__mul__(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, PyObject *__pyx_v_second) {
  struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_res = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  int __pyx_t_5;
  unsigned char __pyx_t_6;
  __Pyx_RefNannySetupContext("__mul__", 0);

  /* "PyTorch.pyx":2436
 *         cdef int resCols
 * 
 *         res = _ByteTensor.new()             # <<<<<<<<<<<<<<
 *         if isinstance(second, numbers.Number):
 *             THByteTensor_mul(res.native, self.native, second)
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7PyTorch__ByteTensor), __pyx_n_s_new); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2436, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2436, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2436, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_7PyTorch__ByteTensor))))) __PYX_ERR(0, 2436, __pyx_L1_error)
  __pyx_v_res = ((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":2437
 * 
 *         res = _ByteTensor.new()
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THByteTensor_mul(res.native, self.native, second)
 *             return res
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_numbers); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2437, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_Number); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2437, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_4 = PyObject_IsInstance(__pyx_v_second, __pyx_t_2); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 2437, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = (__pyx_t_4 != 0);
  if (__pyx_t_5) {

    /* "PyTorch.pyx":2438
 *         res = _ByteTensor.new()
 *         if isinstance(second, numbers.Number):
 *             THByteTensor_mul(res.native, self.native, second)             # <<<<<<<<<<<<<<
 *             return res
 *         else:
 */
    __pyx_t_6 = __Pyx_PyInt_As_unsigned_char(__pyx_v_second); if (unlikely((__pyx_t_6 == (unsigned char)-1) && PyErr_Occurred())) __PYX_ERR(0, 2438, __pyx_L1_error)
    THByteTensor_mul(__pyx_v_res->native, __pyx_v_self->native, __pyx_t_6);

    /* "PyTorch.pyx":2439
 *         if isinstance(second, numbers.Number):
 *             THByteTensor_mul(res.native, self.native, second)
 *             return res             # <<<<<<<<<<<<<<
 *         else:
 * 
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(((PyObject *)__pyx_v_res));
    __pyx_r = ((PyObject *)__pyx_v_res);
    goto __pyx_L0;

    /* "PyTorch.pyx":2437
 * 
 *         res = _ByteTensor.new()
 *         if isinstance(second, numbers.Number):             # <<<<<<<<<<<<<<
 *             THByteTensor_mul(res.native, self.native, second)
 *             return res
 */
  }

  /* "PyTorch.pyx":2442
 *         else:
 * 
 *             raise Exception('Invalid arg type for second: ' + str(type(second)))             # <<<<<<<<<<<<<<
 * 
 * 
 */
  /*else*/ {
    __pyx_t_2 = PyTuple_New(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2442, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_INCREF(((PyObject *)Py_TYPE(__pyx_v_second)));
    __Pyx_GIVEREF(((PyObject *)Py_TYPE(__pyx_v_second)));
    PyTuple_SET_ITEM(__pyx_t_2, 0, ((PyObject *)Py_TYPE(__pyx_v_second)));
    __pyx_t_1 = __Pyx_PyObject_Call(((PyObject *)(&PyString_Type)), __pyx_t_2, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2442, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = PyNumber_Add(__pyx_kp_s_Invalid_arg_type_for_second, __pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2442, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2442, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_GIVEREF(__pyx_t_2);
    PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_2);
    __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_t_1, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2442, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(0, 2442, __pyx_L1_error)
  }

  /* "PyTorch.pyx":2429
 * 
 * #    def __mul__(_ByteTensor self, _ByteTensor M2):
 *     def __mul__(_ByteTensor self, second):             # <<<<<<<<<<<<<<
 *         cdef _ByteTensor M2
 *         cdef _ByteTensor T
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("PyTorch._ByteTensor.__mul__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2447
 *     # ========== random ===============================
 * 
 *     def bernoulli(_ByteTensor self, float p=0.5):             # <<<<<<<<<<<<<<
 *         THByteTensor_bernoulli(self.native, globalState.generator, p)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_95bernoulli(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_95bernoulli(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  float __pyx_v_p;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("bernoulli (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_p,0};
    PyObject* values[1] = {0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_p);
          if (value) { values[0] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "bernoulli") < 0)) __PYX_ERR(0, 2447, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    if (values[0]) {
      __pyx_v_p = __pyx_PyFloat_AsFloat(values[0]); if (unlikely((__pyx_v_p == (float)-1) && PyErr_Occurred())) __PYX_ERR(0, 2447, __pyx_L3_error)
    } else {
      __pyx_v_p = ((float)0.5);
    }
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("bernoulli", 0, 0, 1, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 2447, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._ByteTensor.bernoulli", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_94bernoulli(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self), __pyx_v_p);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_94bernoulli(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, float __pyx_v_p) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("bernoulli", 0);

  /* "PyTorch.pyx":2448
 * 
 *     def bernoulli(_ByteTensor self, float p=0.5):
 *         THByteTensor_bernoulli(self.native, globalState.generator, p)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THByteTensor_bernoulli(__pyx_v_self->native, __pyx_v_7PyTorch_globalState->generator, __pyx_v_p);

  /* "PyTorch.pyx":2449
 *     def bernoulli(_ByteTensor self, float p=0.5):
 *         THByteTensor_bernoulli(self.native, globalState.generator, p)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def geometric(_ByteTensor self, float p=0.5):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":2447
 *     # ========== random ===============================
 * 
 *     def bernoulli(_ByteTensor self, float p=0.5):             # <<<<<<<<<<<<<<
 *         THByteTensor_bernoulli(self.native, globalState.generator, p)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2451
 *         return self
 * 
 *     def geometric(_ByteTensor self, float p=0.5):             # <<<<<<<<<<<<<<
 *         THByteTensor_geometric(self.native, globalState.generator, p)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_97geometric(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11_ByteTensor_97geometric(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  float __pyx_v_p;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("geometric (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_p,0};
    PyObject* values[1] = {0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_p);
          if (value) { values[0] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "geometric") < 0)) __PYX_ERR(0, 2451, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    if (values[0]) {
      __pyx_v_p = __pyx_PyFloat_AsFloat(values[0]); if (unlikely((__pyx_v_p == (float)-1) && PyErr_Occurred())) __PYX_ERR(0, 2451, __pyx_L3_error)
    } else {
      __pyx_v_p = ((float)0.5);
    }
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("geometric", 0, 0, 1, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 2451, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyTorch._ByteTensor.geometric", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_7PyTorch_11_ByteTensor_96geometric(((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_self), __pyx_v_p);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11_ByteTensor_96geometric(struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_self, float __pyx_v_p) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("geometric", 0);

  /* "PyTorch.pyx":2452
 * 
 *     def geometric(_ByteTensor self, float p=0.5):
 *         THByteTensor_geometric(self.native, globalState.generator, p)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THByteTensor_geometric(__pyx_v_self->native, __pyx_v_7PyTorch_globalState->generator, __pyx_v_p);

  /* "PyTorch.pyx":2453
 *     def geometric(_ByteTensor self, float p=0.5):
 *         THByteTensor_geometric(self.native, globalState.generator, p)
 *         return self             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyTorch.pyx":2451
 *         return self
 * 
 *     def geometric(_ByteTensor self, float p=0.5):             # <<<<<<<<<<<<<<
 *         THByteTensor_geometric(self.native, globalState.generator, p)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2458
 * 
 * #    @staticmethod
 * cdef _ByteTensor_fromNative(THByteTensor *tensorC, retain=True):             # <<<<<<<<<<<<<<
 *     if retain:
 *         THByteTensor_retain(tensorC)
 */

static PyObject *__pyx_f_7PyTorch__ByteTensor_fromNative(struct THByteTensor *__pyx_v_tensorC, struct __pyx_opt_args_7PyTorch__ByteTensor_fromNative *__pyx_optional_args) {
  PyObject *__pyx_v_retain = ((PyObject *)Py_True);
  struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_tensor = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("_ByteTensor_fromNative", 0);
  if (__pyx_optional_args) {
    if (__pyx_optional_args->__pyx_n > 0) {
      __pyx_v_retain = __pyx_optional_args->retain;
    }
  }

  /* "PyTorch.pyx":2459
 * #    @staticmethod
 * cdef _ByteTensor_fromNative(THByteTensor *tensorC, retain=True):
 *     if retain:             # <<<<<<<<<<<<<<
 *         THByteTensor_retain(tensorC)
 *     tensor = _ByteTensor(_allocate=False)
 */
  __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_v_retain); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(0, 2459, __pyx_L1_error)
  if (__pyx_t_1) {

    /* "PyTorch.pyx":2460
 * cdef _ByteTensor_fromNative(THByteTensor *tensorC, retain=True):
 *     if retain:
 *         THByteTensor_retain(tensorC)             # <<<<<<<<<<<<<<
 *     tensor = _ByteTensor(_allocate=False)
 *     tensor.native = tensorC
 */
    THByteTensor_retain(__pyx_v_tensorC);

    /* "PyTorch.pyx":2459
 * #    @staticmethod
 * cdef _ByteTensor_fromNative(THByteTensor *tensorC, retain=True):
 *     if retain:             # <<<<<<<<<<<<<<
 *         THByteTensor_retain(tensorC)
 *     tensor = _ByteTensor(_allocate=False)
 */
  }

  /* "PyTorch.pyx":2461
 *     if retain:
 *         THByteTensor_retain(tensorC)
 *     tensor = _ByteTensor(_allocate=False)             # <<<<<<<<<<<<<<
 *     tensor.native = tensorC
 *     return tensor
 */
  __pyx_t_2 = PyDict_New(); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2461, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_t_2, __pyx_n_s_allocate, Py_False) < 0) __PYX_ERR(0, 2461, __pyx_L1_error)
  __pyx_t_3 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_7PyTorch__ByteTensor), __pyx_empty_tuple, __pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2461, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_tensor = ((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_t_3);
  __pyx_t_3 = 0;

  /* "PyTorch.pyx":2462
 *         THByteTensor_retain(tensorC)
 *     tensor = _ByteTensor(_allocate=False)
 *     tensor.native = tensorC             # <<<<<<<<<<<<<<
 *     return tensor
 * 
 */
  __pyx_v_tensor->native = __pyx_v_tensorC;

  /* "PyTorch.pyx":2463
 *     tensor = _ByteTensor(_allocate=False)
 *     tensor.native = tensorC
 *     return tensor             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_tensor));
  __pyx_r = ((PyObject *)__pyx_v_tensor);
  goto __pyx_L0;

  /* "PyTorch.pyx":2458
 * 
 * #    @staticmethod
 * cdef _ByteTensor_fromNative(THByteTensor *tensorC, retain=True):             # <<<<<<<<<<<<<<
 *     if retain:
 *         THByteTensor_retain(tensorC)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("PyTorch._ByteTensor_fromNative", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_tensor);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2466
 * 
 * 
 * def _asByteTensor(myarray):             # <<<<<<<<<<<<<<
 *     cdef unsigned char[:] myarraymv
 *     cdef Storage._ByteStorage storage
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_9_asByteTensor(PyObject *__pyx_self, PyObject *__pyx_v_myarray); /*proto*/
static PyMethodDef __pyx_mdef_7PyTorch_9_asByteTensor = {"_asByteTensor", (PyCFunction)__pyx_pw_7PyTorch_9_asByteTensor, METH_O, 0};
static PyObject *__pyx_pw_7PyTorch_9_asByteTensor(PyObject *__pyx_self, PyObject *__pyx_v_myarray) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_asByteTensor (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_8_asByteTensor(__pyx_self, ((PyObject *)__pyx_v_myarray));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_8_asByteTensor(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_myarray) {
  __Pyx_memviewslice __pyx_v_myarraymv = { 0, 0, { 0 }, { 0 }, { 0 } };
  struct __pyx_obj_7Storage__ByteStorage *__pyx_v_storage = 0;
  PyObject *__pyx_v_dims = NULL;
  PyObject *__pyx_v_totalSize = NULL;
  PyObject *__pyx_v_size = NULL;
  PyObject *__pyx_v_stride = NULL;
  PyObject *__pyx_v_strideSoFar = NULL;
  PyObject *__pyx_v_d = NULL;
  PyObject *__pyx_v_tensor = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  int __pyx_t_4;
  Py_ssize_t __pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *(*__pyx_t_8)(PyObject *);
  __Pyx_memviewslice __pyx_t_9 = { 0, 0, { 0 }, { 0 }, { 0 } };
  PyObject *__pyx_t_10 = NULL;
  int __pyx_t_11;
  __Pyx_RefNannySetupContext("_asByteTensor", 0);

  /* "PyTorch.pyx":2469
 *     cdef unsigned char[:] myarraymv
 *     cdef Storage._ByteStorage storage
 *     if str(type(myarray)) in ["<type 'numpy.ndarray'>", "<class 'numpy.ndarray'>"]:             # <<<<<<<<<<<<<<
 *         dims = len(myarray.shape)
 *         if dims >= 1:
 */
  __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2469, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_INCREF(((PyObject *)Py_TYPE(__pyx_v_myarray)));
  __Pyx_GIVEREF(((PyObject *)Py_TYPE(__pyx_v_myarray)));
  PyTuple_SET_ITEM(__pyx_t_1, 0, ((PyObject *)Py_TYPE(__pyx_v_myarray)));
  __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)(&PyString_Type)), __pyx_t_1, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2469, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_4 = (__Pyx_PyString_Equals(__pyx_t_2, __pyx_kp_s_type_numpy_ndarray, Py_EQ)); if (unlikely(__pyx_t_4 < 0)) __PYX_ERR(0, 2469, __pyx_L1_error)
  if (!__pyx_t_4) {
  } else {
    __pyx_t_3 = __pyx_t_4;
    goto __pyx_L4_bool_binop_done;
  }
  __pyx_t_4 = (__Pyx_PyString_Equals(__pyx_t_2, __pyx_kp_s_class_numpy_ndarray, Py_EQ)); if (unlikely(__pyx_t_4 < 0)) __PYX_ERR(0, 2469, __pyx_L1_error)
  __pyx_t_3 = __pyx_t_4;
  __pyx_L4_bool_binop_done:;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_4 = (__pyx_t_3 != 0);
  if (__pyx_t_4) {

    /* "PyTorch.pyx":2470
 *     cdef Storage._ByteStorage storage
 *     if str(type(myarray)) in ["<type 'numpy.ndarray'>", "<class 'numpy.ndarray'>"]:
 *         dims = len(myarray.shape)             # <<<<<<<<<<<<<<
 *         if dims >= 1:
 *             totalSize = 1
 */
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_myarray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2470, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_5 = PyObject_Length(__pyx_t_2); if (unlikely(__pyx_t_5 == -1)) __PYX_ERR(0, 2470, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = PyInt_FromSsize_t(__pyx_t_5); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2470, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_v_dims = __pyx_t_2;
    __pyx_t_2 = 0;

    /* "PyTorch.pyx":2471
 *     if str(type(myarray)) in ["<type 'numpy.ndarray'>", "<class 'numpy.ndarray'>"]:
 *         dims = len(myarray.shape)
 *         if dims >= 1:             # <<<<<<<<<<<<<<
 *             totalSize = 1
 *             size = Storage._LongStorage.newWithSize(dims)
 */
    __pyx_t_2 = PyObject_RichCompare(__pyx_v_dims, __pyx_int_1, Py_GE); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2471, __pyx_L1_error)
    __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely(__pyx_t_4 < 0)) __PYX_ERR(0, 2471, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    if (__pyx_t_4) {

      /* "PyTorch.pyx":2472
 *         dims = len(myarray.shape)
 *         if dims >= 1:
 *             totalSize = 1             # <<<<<<<<<<<<<<
 *             size = Storage._LongStorage.newWithSize(dims)
 *             stride = Storage._LongStorage.newWithSize(dims)
 */
      __Pyx_INCREF(__pyx_int_1);
      __pyx_v_totalSize = __pyx_int_1;

      /* "PyTorch.pyx":2473
 *         if dims >= 1:
 *             totalSize = 1
 *             size = Storage._LongStorage.newWithSize(dims)             # <<<<<<<<<<<<<<
 *             stride = Storage._LongStorage.newWithSize(dims)
 *             strideSoFar = 1
 */
      __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7Storage__LongStorage), __pyx_n_s_newWithSize); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2473, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_6 = NULL;
      if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_1))) {
        __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_1);
        if (likely(__pyx_t_6)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
          __Pyx_INCREF(__pyx_t_6);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_1, function);
        }
      }
      if (!__pyx_t_6) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_v_dims); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2473, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
      } else {
        #if CYTHON_FAST_PYCALL
        if (PyFunction_Check(__pyx_t_1)) {
          PyObject *__pyx_temp[2] = {__pyx_t_6, __pyx_v_dims};
          __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_1, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2473, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
          __Pyx_GOTREF(__pyx_t_2);
        } else
        #endif
        #if CYTHON_FAST_PYCCALL
        if (__Pyx_PyFastCFunction_Check(__pyx_t_1)) {
          PyObject *__pyx_temp[2] = {__pyx_t_6, __pyx_v_dims};
          __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_1, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2473, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
          __Pyx_GOTREF(__pyx_t_2);
        } else
        #endif
        {
          __pyx_t_7 = PyTuple_New(1+1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 2473, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_7);
          __Pyx_GIVEREF(__pyx_t_6); PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_6); __pyx_t_6 = NULL;
          __Pyx_INCREF(__pyx_v_dims);
          __Pyx_GIVEREF(__pyx_v_dims);
          PyTuple_SET_ITEM(__pyx_t_7, 0+1, __pyx_v_dims);
          __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_7, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2473, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        }
      }
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_v_size = __pyx_t_2;
      __pyx_t_2 = 0;

      /* "PyTorch.pyx":2474
 *             totalSize = 1
 *             size = Storage._LongStorage.newWithSize(dims)
 *             stride = Storage._LongStorage.newWithSize(dims)             # <<<<<<<<<<<<<<
 *             strideSoFar = 1
 *             for d in range(dims - 1, -1, -1):
 */
      __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7Storage__LongStorage), __pyx_n_s_newWithSize); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2474, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_7 = NULL;
      if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_1))) {
        __pyx_t_7 = PyMethod_GET_SELF(__pyx_t_1);
        if (likely(__pyx_t_7)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
          __Pyx_INCREF(__pyx_t_7);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_1, function);
        }
      }
      if (!__pyx_t_7) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_v_dims); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2474, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
      } else {
        #if CYTHON_FAST_PYCALL
        if (PyFunction_Check(__pyx_t_1)) {
          PyObject *__pyx_temp[2] = {__pyx_t_7, __pyx_v_dims};
          __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_1, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2474, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
          __Pyx_GOTREF(__pyx_t_2);
        } else
        #endif
        #if CYTHON_FAST_PYCCALL
        if (__Pyx_PyFastCFunction_Check(__pyx_t_1)) {
          PyObject *__pyx_temp[2] = {__pyx_t_7, __pyx_v_dims};
          __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_1, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2474, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
          __Pyx_GOTREF(__pyx_t_2);
        } else
        #endif
        {
          __pyx_t_6 = PyTuple_New(1+1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2474, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_6);
          __Pyx_GIVEREF(__pyx_t_7); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_7); __pyx_t_7 = NULL;
          __Pyx_INCREF(__pyx_v_dims);
          __Pyx_GIVEREF(__pyx_v_dims);
          PyTuple_SET_ITEM(__pyx_t_6, 0+1, __pyx_v_dims);
          __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_6, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2474, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
        }
      }
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_v_stride = __pyx_t_2;
      __pyx_t_2 = 0;

      /* "PyTorch.pyx":2475
 *             size = Storage._LongStorage.newWithSize(dims)
 *             stride = Storage._LongStorage.newWithSize(dims)
 *             strideSoFar = 1             # <<<<<<<<<<<<<<
 *             for d in range(dims - 1, -1, -1):
 *                 totalSize *= myarray.shape[d]
 */
      __Pyx_INCREF(__pyx_int_1);
      __pyx_v_strideSoFar = __pyx_int_1;

      /* "PyTorch.pyx":2476
 *             stride = Storage._LongStorage.newWithSize(dims)
 *             strideSoFar = 1
 *             for d in range(dims - 1, -1, -1):             # <<<<<<<<<<<<<<
 *                 totalSize *= myarray.shape[d]
 *                 size[d] = myarray.shape[d]
 */
      __pyx_t_2 = __Pyx_PyInt_SubtractObjC(__pyx_v_dims, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2476, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_1 = PyTuple_New(3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2476, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_GIVEREF(__pyx_t_2);
      PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_2);
      __Pyx_INCREF(__pyx_int_neg_1);
      __Pyx_GIVEREF(__pyx_int_neg_1);
      PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_int_neg_1);
      __Pyx_INCREF(__pyx_int_neg_1);
      __Pyx_GIVEREF(__pyx_int_neg_1);
      PyTuple_SET_ITEM(__pyx_t_1, 2, __pyx_int_neg_1);
      __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_range, __pyx_t_1, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2476, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      if (likely(PyList_CheckExact(__pyx_t_2)) || PyTuple_CheckExact(__pyx_t_2)) {
        __pyx_t_1 = __pyx_t_2; __Pyx_INCREF(__pyx_t_1); __pyx_t_5 = 0;
        __pyx_t_8 = NULL;
      } else {
        __pyx_t_5 = -1; __pyx_t_1 = PyObject_GetIter(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2476, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __pyx_t_8 = Py_TYPE(__pyx_t_1)->tp_iternext; if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2476, __pyx_L1_error)
      }
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      for (;;) {
        if (likely(!__pyx_t_8)) {
          if (likely(PyList_CheckExact(__pyx_t_1))) {
            if (__pyx_t_5 >= PyList_GET_SIZE(__pyx_t_1)) break;
            #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
            __pyx_t_2 = PyList_GET_ITEM(__pyx_t_1, __pyx_t_5); __Pyx_INCREF(__pyx_t_2); __pyx_t_5++; if (unlikely(0 < 0)) __PYX_ERR(0, 2476, __pyx_L1_error)
            #else
            __pyx_t_2 = PySequence_ITEM(__pyx_t_1, __pyx_t_5); __pyx_t_5++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2476, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_2);
            #endif
          } else {
            if (__pyx_t_5 >= PyTuple_GET_SIZE(__pyx_t_1)) break;
            #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
            __pyx_t_2 = PyTuple_GET_ITEM(__pyx_t_1, __pyx_t_5); __Pyx_INCREF(__pyx_t_2); __pyx_t_5++; if (unlikely(0 < 0)) __PYX_ERR(0, 2476, __pyx_L1_error)
            #else
            __pyx_t_2 = PySequence_ITEM(__pyx_t_1, __pyx_t_5); __pyx_t_5++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2476, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_2);
            #endif
          }
        } else {
          __pyx_t_2 = __pyx_t_8(__pyx_t_1);
          if (unlikely(!__pyx_t_2)) {
            PyObject* exc_type = PyErr_Occurred();
            if (exc_type) {
              if (likely(exc_type == PyExc_StopIteration || PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
              else __PYX_ERR(0, 2476, __pyx_L1_error)
            }
            break;
          }
          __Pyx_GOTREF(__pyx_t_2);
        }
        __Pyx_XDECREF_SET(__pyx_v_d, __pyx_t_2);
        __pyx_t_2 = 0;

        /* "PyTorch.pyx":2477
 *             strideSoFar = 1
 *             for d in range(dims - 1, -1, -1):
 *                 totalSize *= myarray.shape[d]             # <<<<<<<<<<<<<<
 *                 size[d] = myarray.shape[d]
 *                 stride[d] = strideSoFar
 */
        __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_myarray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2477, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __pyx_t_6 = PyObject_GetItem(__pyx_t_2, __pyx_v_d); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2477, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        __pyx_t_2 = PyNumber_InPlaceMultiply(__pyx_v_totalSize, __pyx_t_6); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2477, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_DECREF_SET(__pyx_v_totalSize, __pyx_t_2);
        __pyx_t_2 = 0;

        /* "PyTorch.pyx":2478
 *             for d in range(dims - 1, -1, -1):
 *                 totalSize *= myarray.shape[d]
 *                 size[d] = myarray.shape[d]             # <<<<<<<<<<<<<<
 *                 stride[d] = strideSoFar
 *                 strideSoFar *= size[d]
 */
        __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_myarray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2478, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __pyx_t_6 = PyObject_GetItem(__pyx_t_2, __pyx_v_d); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2478, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        if (unlikely(PyObject_SetItem(__pyx_v_size, __pyx_v_d, __pyx_t_6) < 0)) __PYX_ERR(0, 2478, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;

        /* "PyTorch.pyx":2479
 *                 totalSize *= myarray.shape[d]
 *                 size[d] = myarray.shape[d]
 *                 stride[d] = strideSoFar             # <<<<<<<<<<<<<<
 *                 strideSoFar *= size[d]
 *             myarraymv = myarray.reshape(totalSize)
 */
        if (unlikely(PyObject_SetItem(__pyx_v_stride, __pyx_v_d, __pyx_v_strideSoFar) < 0)) __PYX_ERR(0, 2479, __pyx_L1_error)

        /* "PyTorch.pyx":2480
 *                 size[d] = myarray.shape[d]
 *                 stride[d] = strideSoFar
 *                 strideSoFar *= size[d]             # <<<<<<<<<<<<<<
 *             myarraymv = myarray.reshape(totalSize)
 *             storage = Storage._ByteStorage.newWithData(myarraymv)
 */
        __pyx_t_6 = PyObject_GetItem(__pyx_v_size, __pyx_v_d); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2480, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __pyx_t_2 = PyNumber_InPlaceMultiply(__pyx_v_strideSoFar, __pyx_t_6); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2480, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_DECREF_SET(__pyx_v_strideSoFar, __pyx_t_2);
        __pyx_t_2 = 0;

        /* "PyTorch.pyx":2476
 *             stride = Storage._LongStorage.newWithSize(dims)
 *             strideSoFar = 1
 *             for d in range(dims - 1, -1, -1):             # <<<<<<<<<<<<<<
 *                 totalSize *= myarray.shape[d]
 *                 size[d] = myarray.shape[d]
 */
      }
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

      /* "PyTorch.pyx":2481
 *                 stride[d] = strideSoFar
 *                 strideSoFar *= size[d]
 *             myarraymv = myarray.reshape(totalSize)             # <<<<<<<<<<<<<<
 *             storage = Storage._ByteStorage.newWithData(myarraymv)
 *             Storage.THByteStorage_retain(storage.native) # since newWithData takes ownership
 */
      __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_myarray, __pyx_n_s_reshape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2481, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_6 = NULL;
      if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
        __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_2);
        if (likely(__pyx_t_6)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
          __Pyx_INCREF(__pyx_t_6);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_2, function);
        }
      }
      if (!__pyx_t_6) {
        __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_v_totalSize); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2481, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
      } else {
        #if CYTHON_FAST_PYCALL
        if (PyFunction_Check(__pyx_t_2)) {
          PyObject *__pyx_temp[2] = {__pyx_t_6, __pyx_v_totalSize};
          __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2481, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
          __Pyx_GOTREF(__pyx_t_1);
        } else
        #endif
        #if CYTHON_FAST_PYCCALL
        if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
          PyObject *__pyx_temp[2] = {__pyx_t_6, __pyx_v_totalSize};
          __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2481, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
          __Pyx_GOTREF(__pyx_t_1);
        } else
        #endif
        {
          __pyx_t_7 = PyTuple_New(1+1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 2481, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_7);
          __Pyx_GIVEREF(__pyx_t_6); PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_6); __pyx_t_6 = NULL;
          __Pyx_INCREF(__pyx_v_totalSize);
          __Pyx_GIVEREF(__pyx_v_totalSize);
          PyTuple_SET_ITEM(__pyx_t_7, 0+1, __pyx_v_totalSize);
          __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_7, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2481, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_1);
          __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        }
      }
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_9 = __Pyx_PyObject_to_MemoryviewSlice_ds_unsigned_char(__pyx_t_1);
      if (unlikely(!__pyx_t_9.memview)) __PYX_ERR(0, 2481, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_v_myarraymv = __pyx_t_9;
      __pyx_t_9.memview = NULL;
      __pyx_t_9.data = NULL;

      /* "PyTorch.pyx":2482
 *                 strideSoFar *= size[d]
 *             myarraymv = myarray.reshape(totalSize)
 *             storage = Storage._ByteStorage.newWithData(myarraymv)             # <<<<<<<<<<<<<<
 *             Storage.THByteStorage_retain(storage.native) # since newWithData takes ownership
 * 
 */
      __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7Storage__ByteStorage), __pyx_n_s_newWithData); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2482, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_7 = __pyx_memoryview_fromslice(__pyx_v_myarraymv, 1, (PyObject *(*)(char *)) __pyx_memview_get_unsigned_char, (int (*)(char *, PyObject *)) __pyx_memview_set_unsigned_char, 0);; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 2482, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __pyx_t_6 = NULL;
      if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
        __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_2);
        if (likely(__pyx_t_6)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
          __Pyx_INCREF(__pyx_t_6);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_2, function);
        }
      }
      if (!__pyx_t_6) {
        __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_7); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2482, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        __Pyx_GOTREF(__pyx_t_1);
      } else {
        #if CYTHON_FAST_PYCALL
        if (PyFunction_Check(__pyx_t_2)) {
          PyObject *__pyx_temp[2] = {__pyx_t_6, __pyx_t_7};
          __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2482, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
          __Pyx_GOTREF(__pyx_t_1);
          __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        } else
        #endif
        #if CYTHON_FAST_PYCCALL
        if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
          PyObject *__pyx_temp[2] = {__pyx_t_6, __pyx_t_7};
          __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2482, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
          __Pyx_GOTREF(__pyx_t_1);
          __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        } else
        #endif
        {
          __pyx_t_10 = PyTuple_New(1+1); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 2482, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_10);
          __Pyx_GIVEREF(__pyx_t_6); PyTuple_SET_ITEM(__pyx_t_10, 0, __pyx_t_6); __pyx_t_6 = NULL;
          __Pyx_GIVEREF(__pyx_t_7);
          PyTuple_SET_ITEM(__pyx_t_10, 0+1, __pyx_t_7);
          __pyx_t_7 = 0;
          __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_10, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2482, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_1);
          __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
        }
      }
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_7Storage__ByteStorage))))) __PYX_ERR(0, 2482, __pyx_L1_error)
      __pyx_v_storage = ((struct __pyx_obj_7Storage__ByteStorage *)__pyx_t_1);
      __pyx_t_1 = 0;

      /* "PyTorch.pyx":2483
 *             myarraymv = myarray.reshape(totalSize)
 *             storage = Storage._ByteStorage.newWithData(myarraymv)
 *             Storage.THByteStorage_retain(storage.native) # since newWithData takes ownership             # <<<<<<<<<<<<<<
 * 
 *             tensor = _ByteTensor.newWithStorage(storage, 0, size, stride)
 */
      THByteStorage_retain(__pyx_v_storage->native);

      /* "PyTorch.pyx":2485
 *             Storage.THByteStorage_retain(storage.native) # since newWithData takes ownership
 * 
 *             tensor = _ByteTensor.newWithStorage(storage, 0, size, stride)             # <<<<<<<<<<<<<<
 *             return tensor
 *         else:
 */
      __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7PyTorch__ByteTensor), __pyx_n_s_newWithStorage); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2485, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_10 = NULL;
      __pyx_t_11 = 0;
      if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
        __pyx_t_10 = PyMethod_GET_SELF(__pyx_t_2);
        if (likely(__pyx_t_10)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
          __Pyx_INCREF(__pyx_t_10);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_2, function);
          __pyx_t_11 = 1;
        }
      }
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[5] = {__pyx_t_10, ((PyObject *)__pyx_v_storage), __pyx_int_0, __pyx_v_size, __pyx_v_stride};
        __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_11, 4+__pyx_t_11); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2485, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
        __Pyx_GOTREF(__pyx_t_1);
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[5] = {__pyx_t_10, ((PyObject *)__pyx_v_storage), __pyx_int_0, __pyx_v_size, __pyx_v_stride};
        __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_11, 4+__pyx_t_11); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2485, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
        __Pyx_GOTREF(__pyx_t_1);
      } else
      #endif
      {
        __pyx_t_7 = PyTuple_New(4+__pyx_t_11); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 2485, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        if (__pyx_t_10) {
          __Pyx_GIVEREF(__pyx_t_10); PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_10); __pyx_t_10 = NULL;
        }
        __Pyx_INCREF(((PyObject *)__pyx_v_storage));
        __Pyx_GIVEREF(((PyObject *)__pyx_v_storage));
        PyTuple_SET_ITEM(__pyx_t_7, 0+__pyx_t_11, ((PyObject *)__pyx_v_storage));
        __Pyx_INCREF(__pyx_int_0);
        __Pyx_GIVEREF(__pyx_int_0);
        PyTuple_SET_ITEM(__pyx_t_7, 1+__pyx_t_11, __pyx_int_0);
        __Pyx_INCREF(__pyx_v_size);
        __Pyx_GIVEREF(__pyx_v_size);
        PyTuple_SET_ITEM(__pyx_t_7, 2+__pyx_t_11, __pyx_v_size);
        __Pyx_INCREF(__pyx_v_stride);
        __Pyx_GIVEREF(__pyx_v_stride);
        PyTuple_SET_ITEM(__pyx_t_7, 3+__pyx_t_11, __pyx_v_stride);
        __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_7, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2485, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      }
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_v_tensor = __pyx_t_1;
      __pyx_t_1 = 0;

      /* "PyTorch.pyx":2486
 * 
 *             tensor = _ByteTensor.newWithStorage(storage, 0, size, stride)
 *             return tensor             # <<<<<<<<<<<<<<
 *         else:
 *             raise Exception('dims == {dims} not implemented; please raise an issue'.format(
 */
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_v_tensor);
      __pyx_r = __pyx_v_tensor;
      goto __pyx_L0;

      /* "PyTorch.pyx":2471
 *     if str(type(myarray)) in ["<type 'numpy.ndarray'>", "<class 'numpy.ndarray'>"]:
 *         dims = len(myarray.shape)
 *         if dims >= 1:             # <<<<<<<<<<<<<<
 *             totalSize = 1
 *             size = Storage._LongStorage.newWithSize(dims)
 */
    }

    /* "PyTorch.pyx":2488
 *             return tensor
 *         else:
 *             raise Exception('dims == {dims} not implemented; please raise an issue'.format(             # <<<<<<<<<<<<<<
 *                 dims=dims))
 *     elif isinstance(myarray, array.array):
 */
    /*else*/ {
      __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_kp_s_dims_dims_not_implemented_please, __pyx_n_s_format); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2488, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);

      /* "PyTorch.pyx":2489
 *         else:
 *             raise Exception('dims == {dims} not implemented; please raise an issue'.format(
 *                 dims=dims))             # <<<<<<<<<<<<<<
 *     elif isinstance(myarray, array.array):
 *         myarraymv = myarray
 */
      __pyx_t_2 = PyDict_New(); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2489, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      if (PyDict_SetItem(__pyx_t_2, __pyx_n_s_dims, __pyx_v_dims) < 0) __PYX_ERR(0, 2489, __pyx_L1_error)

      /* "PyTorch.pyx":2488
 *             return tensor
 *         else:
 *             raise Exception('dims == {dims} not implemented; please raise an issue'.format(             # <<<<<<<<<<<<<<
 *                 dims=dims))
 *     elif isinstance(myarray, array.array):
 */
      __pyx_t_7 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_empty_tuple, __pyx_t_2); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 2488, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = PyTuple_New(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2488, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_GIVEREF(__pyx_t_7);
      PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_7);
      __pyx_t_7 = 0;
      __pyx_t_7 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_t_2, NULL); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 2488, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_Raise(__pyx_t_7, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __PYX_ERR(0, 2488, __pyx_L1_error)
    }

    /* "PyTorch.pyx":2469
 *     cdef unsigned char[:] myarraymv
 *     cdef Storage._ByteStorage storage
 *     if str(type(myarray)) in ["<type 'numpy.ndarray'>", "<class 'numpy.ndarray'>"]:             # <<<<<<<<<<<<<<
 *         dims = len(myarray.shape)
 *         if dims >= 1:
 */
  }

  /* "PyTorch.pyx":2490
 *             raise Exception('dims == {dims} not implemented; please raise an issue'.format(
 *                 dims=dims))
 *     elif isinstance(myarray, array.array):             # <<<<<<<<<<<<<<
 *         myarraymv = myarray
 *         storage = Storage._ByteStorage.newWithData(myarraymv)
 */
  __pyx_t_7 = __Pyx_GetModuleGlobalName(__pyx_n_s_array); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 2490, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_7, __pyx_n_s_array); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2490, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_4 = PyObject_IsInstance(__pyx_v_myarray, __pyx_t_2); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(0, 2490, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_3 = (__pyx_t_4 != 0);
  if (__pyx_t_3) {

    /* "PyTorch.pyx":2491
 *                 dims=dims))
 *     elif isinstance(myarray, array.array):
 *         myarraymv = myarray             # <<<<<<<<<<<<<<
 *         storage = Storage._ByteStorage.newWithData(myarraymv)
 *         Storage.THByteStorage_retain(storage.native) # since newWithData takes ownership
 */
    __pyx_t_9 = __Pyx_PyObject_to_MemoryviewSlice_ds_unsigned_char(__pyx_v_myarray);
    if (unlikely(!__pyx_t_9.memview)) __PYX_ERR(0, 2491, __pyx_L1_error)
    __pyx_v_myarraymv = __pyx_t_9;
    __pyx_t_9.memview = NULL;
    __pyx_t_9.data = NULL;

    /* "PyTorch.pyx":2492
 *     elif isinstance(myarray, array.array):
 *         myarraymv = myarray
 *         storage = Storage._ByteStorage.newWithData(myarraymv)             # <<<<<<<<<<<<<<
 *         Storage.THByteStorage_retain(storage.native) # since newWithData takes ownership
 *         tensor = _ByteTensor.newWithStorage1d(storage, 0, len(myarray), 1)
 */
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7Storage__ByteStorage), __pyx_n_s_newWithData); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 2492, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_1 = __pyx_memoryview_fromslice(__pyx_v_myarraymv, 1, (PyObject *(*)(char *)) __pyx_memview_get_unsigned_char, (int (*)(char *, PyObject *)) __pyx_memview_set_unsigned_char, 0);; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2492, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_10 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_7))) {
      __pyx_t_10 = PyMethod_GET_SELF(__pyx_t_7);
      if (likely(__pyx_t_10)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_7);
        __Pyx_INCREF(__pyx_t_10);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_7, function);
      }
    }
    if (!__pyx_t_10) {
      __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_7, __pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2492, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_GOTREF(__pyx_t_2);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_7)) {
        PyObject *__pyx_temp[2] = {__pyx_t_10, __pyx_t_1};
        __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_7, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2492, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_7)) {
        PyObject *__pyx_temp[2] = {__pyx_t_10, __pyx_t_1};
        __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_7, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2492, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      } else
      #endif
      {
        __pyx_t_6 = PyTuple_New(1+1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2492, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __Pyx_GIVEREF(__pyx_t_10); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_10); __pyx_t_10 = NULL;
        __Pyx_GIVEREF(__pyx_t_1);
        PyTuple_SET_ITEM(__pyx_t_6, 0+1, __pyx_t_1);
        __pyx_t_1 = 0;
        __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_7, __pyx_t_6, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2492, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    if (!(likely(((__pyx_t_2) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_2, __pyx_ptype_7Storage__ByteStorage))))) __PYX_ERR(0, 2492, __pyx_L1_error)
    __pyx_v_storage = ((struct __pyx_obj_7Storage__ByteStorage *)__pyx_t_2);
    __pyx_t_2 = 0;

    /* "PyTorch.pyx":2493
 *         myarraymv = myarray
 *         storage = Storage._ByteStorage.newWithData(myarraymv)
 *         Storage.THByteStorage_retain(storage.native) # since newWithData takes ownership             # <<<<<<<<<<<<<<
 *         tensor = _ByteTensor.newWithStorage1d(storage, 0, len(myarray), 1)
 *         return tensor
 */
    THByteStorage_retain(__pyx_v_storage->native);

    /* "PyTorch.pyx":2494
 *         storage = Storage._ByteStorage.newWithData(myarraymv)
 *         Storage.THByteStorage_retain(storage.native) # since newWithData takes ownership
 *         tensor = _ByteTensor.newWithStorage1d(storage, 0, len(myarray), 1)             # <<<<<<<<<<<<<<
 *         return tensor
 *     else:
 */
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_7PyTorch__ByteTensor), __pyx_n_s_newWithStorage1d); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 2494, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_5 = PyObject_Length(__pyx_v_myarray); if (unlikely(__pyx_t_5 == -1)) __PYX_ERR(0, 2494, __pyx_L1_error)
    __pyx_t_6 = PyInt_FromSsize_t(__pyx_t_5); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2494, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_1 = NULL;
    __pyx_t_11 = 0;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_7))) {
      __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_7);
      if (likely(__pyx_t_1)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_7);
        __Pyx_INCREF(__pyx_t_1);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_7, function);
        __pyx_t_11 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_7)) {
      PyObject *__pyx_temp[5] = {__pyx_t_1, ((PyObject *)__pyx_v_storage), __pyx_int_0, __pyx_t_6, __pyx_int_1};
      __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_7, __pyx_temp+1-__pyx_t_11, 4+__pyx_t_11); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2494, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_7)) {
      PyObject *__pyx_temp[5] = {__pyx_t_1, ((PyObject *)__pyx_v_storage), __pyx_int_0, __pyx_t_6, __pyx_int_1};
      __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_7, __pyx_temp+1-__pyx_t_11, 4+__pyx_t_11); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2494, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    } else
    #endif
    {
      __pyx_t_10 = PyTuple_New(4+__pyx_t_11); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 2494, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_10);
      if (__pyx_t_1) {
        __Pyx_GIVEREF(__pyx_t_1); PyTuple_SET_ITEM(__pyx_t_10, 0, __pyx_t_1); __pyx_t_1 = NULL;
      }
      __Pyx_INCREF(((PyObject *)__pyx_v_storage));
      __Pyx_GIVEREF(((PyObject *)__pyx_v_storage));
      PyTuple_SET_ITEM(__pyx_t_10, 0+__pyx_t_11, ((PyObject *)__pyx_v_storage));
      __Pyx_INCREF(__pyx_int_0);
      __Pyx_GIVEREF(__pyx_int_0);
      PyTuple_SET_ITEM(__pyx_t_10, 1+__pyx_t_11, __pyx_int_0);
      __Pyx_GIVEREF(__pyx_t_6);
      PyTuple_SET_ITEM(__pyx_t_10, 2+__pyx_t_11, __pyx_t_6);
      __Pyx_INCREF(__pyx_int_1);
      __Pyx_GIVEREF(__pyx_int_1);
      PyTuple_SET_ITEM(__pyx_t_10, 3+__pyx_t_11, __pyx_int_1);
      __pyx_t_6 = 0;
      __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_7, __pyx_t_10, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2494, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    }
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_v_tensor = __pyx_t_2;
    __pyx_t_2 = 0;

    /* "PyTorch.pyx":2495
 *         Storage.THByteStorage_retain(storage.native) # since newWithData takes ownership
 *         tensor = _ByteTensor.newWithStorage1d(storage, 0, len(myarray), 1)
 *         return tensor             # <<<<<<<<<<<<<<
 *     else:
 *         raise Exception("not implemented")
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(__pyx_v_tensor);
    __pyx_r = __pyx_v_tensor;
    goto __pyx_L0;

    /* "PyTorch.pyx":2490
 *             raise Exception('dims == {dims} not implemented; please raise an issue'.format(
 *                 dims=dims))
 *     elif isinstance(myarray, array.array):             # <<<<<<<<<<<<<<
 *         myarraymv = myarray
 *         storage = Storage._ByteStorage.newWithData(myarraymv)
 */
  }

  /* "PyTorch.pyx":2497
 *         return tensor
 *     else:
 *         raise Exception("not implemented")             # <<<<<<<<<<<<<<
 * 
 * 
 */
  /*else*/ {
    __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_tuple__42, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2497, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(0, 2497, __pyx_L1_error)
  }

  /* "PyTorch.pyx":2466
 * 
 * 
 * def _asByteTensor(myarray):             # <<<<<<<<<<<<<<
 *     cdef unsigned char[:] myarraymv
 *     cdef Storage._ByteStorage storage
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __PYX_XDEC_MEMVIEW(&__pyx_t_9, 1);
  __Pyx_XDECREF(__pyx_t_10);
  __Pyx_AddTraceback("PyTorch._asByteTensor", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __PYX_XDEC_MEMVIEW(&__pyx_v_myarraymv, 1);
  __Pyx_XDECREF((PyObject *)__pyx_v_storage);
  __Pyx_XDECREF(__pyx_v_dims);
  __Pyx_XDECREF(__pyx_v_totalSize);
  __Pyx_XDECREF(__pyx_v_size);
  __Pyx_XDECREF(__pyx_v_stride);
  __Pyx_XDECREF(__pyx_v_strideSoFar);
  __Pyx_XDECREF(__pyx_v_d);
  __Pyx_XDECREF(__pyx_v_tensor);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2503
 * 
 * cdef class GlobalState(object):
 *     def __cinit__(GlobalState self):             # <<<<<<<<<<<<<<
 *         pass
 * 
 */

/* Python wrapper */
static int __pyx_pw_7PyTorch_11GlobalState_1__cinit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static int __pyx_pw_7PyTorch_11GlobalState_1__cinit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__cinit__ (wrapper)", 0);
  if (unlikely(PyTuple_GET_SIZE(__pyx_args) > 0)) {
    __Pyx_RaiseArgtupleInvalid("__cinit__", 1, 0, 0, PyTuple_GET_SIZE(__pyx_args)); return -1;}
  if (unlikely(__pyx_kwds) && unlikely(PyDict_Size(__pyx_kwds) > 0) && unlikely(!__Pyx_CheckKeywordStrings(__pyx_kwds, "__cinit__", 0))) return -1;
  __pyx_r = __pyx_pf_7PyTorch_11GlobalState___cinit__(((struct __pyx_obj_7PyTorch_GlobalState *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_7PyTorch_11GlobalState___cinit__(CYTHON_UNUSED struct __pyx_obj_7PyTorch_GlobalState *__pyx_v_self) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__cinit__", 0);

  /* function exit code */
  __pyx_r = 0;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2506
 *         pass
 * 
 *     def __dealloc__(self):             # <<<<<<<<<<<<<<
 *         pass
 * 
 */

/* Python wrapper */
static void __pyx_pw_7PyTorch_11GlobalState_3__dealloc__(PyObject *__pyx_v_self); /*proto*/
static void __pyx_pw_7PyTorch_11GlobalState_3__dealloc__(PyObject *__pyx_v_self) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__dealloc__ (wrapper)", 0);
  __pyx_pf_7PyTorch_11GlobalState_2__dealloc__(((struct __pyx_obj_7PyTorch_GlobalState *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

static void __pyx_pf_7PyTorch_11GlobalState_2__dealloc__(CYTHON_UNUSED struct __pyx_obj_7PyTorch_GlobalState *__pyx_v_self) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__dealloc__", 0);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

/* "PyTorch.pyx":2509
 *         pass
 * 
 *     def getLua(self):             # <<<<<<<<<<<<<<
 *         return LuaState_fromNative(self.L)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11GlobalState_5getLua(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_11GlobalState_5getLua(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("getLua (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_11GlobalState_4getLua(((struct __pyx_obj_7PyTorch_GlobalState *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_11GlobalState_4getLua(struct __pyx_obj_7PyTorch_GlobalState *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("getLua", 0);

  /* "PyTorch.pyx":2510
 * 
 *     def getLua(self):
 *         return LuaState_fromNative(self.L)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_3lua_LuaState_fromNative(__pyx_v_self->L); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2510, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":2509
 *         pass
 * 
 *     def getLua(self):             # <<<<<<<<<<<<<<
 *         return LuaState_fromNative(self.L)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch.GlobalState.getLua", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2520
 * 
 * 
 * def _popFloatTensor():             # <<<<<<<<<<<<<<
 *     global globalState
 *     cdef THFloatTensor *tensorC = popFloatTensor(globalState.L)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_11_popFloatTensor(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyMethodDef __pyx_mdef_7PyTorch_11_popFloatTensor = {"_popFloatTensor", (PyCFunction)__pyx_pw_7PyTorch_11_popFloatTensor, METH_NOARGS, 0};
static PyObject *__pyx_pw_7PyTorch_11_popFloatTensor(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_popFloatTensor (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_10_popFloatTensor(__pyx_self);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_10_popFloatTensor(CYTHON_UNUSED PyObject *__pyx_self) {
  struct THFloatTensor *__pyx_v_tensorC;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("_popFloatTensor", 0);

  /* "PyTorch.pyx":2522
 * def _popFloatTensor():
 *     global globalState
 *     cdef THFloatTensor *tensorC = popFloatTensor(globalState.L)             # <<<<<<<<<<<<<<
 *     return _FloatTensor_fromNative(tensorC)
 * 
 */
  __pyx_v_tensorC = popFloatTensor(__pyx_v_7PyTorch_globalState->L);

  /* "PyTorch.pyx":2523
 *     global globalState
 *     cdef THFloatTensor *tensorC = popFloatTensor(globalState.L)
 *     return _FloatTensor_fromNative(tensorC)             # <<<<<<<<<<<<<<
 * 
 * def _pushFloatTensor(_FloatTensor tensor):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_7PyTorch__FloatTensor_fromNative(__pyx_v_tensorC, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2523, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":2520
 * 
 * 
 * def _popFloatTensor():             # <<<<<<<<<<<<<<
 *     global globalState
 *     cdef THFloatTensor *tensorC = popFloatTensor(globalState.L)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._popFloatTensor", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2525
 *     return _FloatTensor_fromNative(tensorC)
 * 
 * def _pushFloatTensor(_FloatTensor tensor):             # <<<<<<<<<<<<<<
 *     global globalState
 *     pushFloatTensor(globalState.L, tensor.native)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_13_pushFloatTensor(PyObject *__pyx_self, PyObject *__pyx_v_tensor); /*proto*/
static PyMethodDef __pyx_mdef_7PyTorch_13_pushFloatTensor = {"_pushFloatTensor", (PyCFunction)__pyx_pw_7PyTorch_13_pushFloatTensor, METH_O, 0};
static PyObject *__pyx_pw_7PyTorch_13_pushFloatTensor(PyObject *__pyx_self, PyObject *__pyx_v_tensor) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_pushFloatTensor (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_tensor), __pyx_ptype_7PyTorch__FloatTensor, 1, "tensor", 0))) __PYX_ERR(0, 2525, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_12_pushFloatTensor(__pyx_self, ((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_tensor));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_12_pushFloatTensor(CYTHON_UNUSED PyObject *__pyx_self, struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_tensor) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_pushFloatTensor", 0);

  /* "PyTorch.pyx":2527
 * def _pushFloatTensor(_FloatTensor tensor):
 *     global globalState
 *     pushFloatTensor(globalState.L, tensor.native)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  pushFloatTensor(__pyx_v_7PyTorch_globalState->L, __pyx_v_tensor->native);

  /* "PyTorch.pyx":2525
 *     return _FloatTensor_fromNative(tensorC)
 * 
 * def _pushFloatTensor(_FloatTensor tensor):             # <<<<<<<<<<<<<<
 *     global globalState
 *     pushFloatTensor(globalState.L, tensor.native)
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2533
 * 
 * 
 * def _popDoubleTensor():             # <<<<<<<<<<<<<<
 *     global globalState
 *     cdef THDoubleTensor *tensorC = popDoubleTensor(globalState.L)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_15_popDoubleTensor(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyMethodDef __pyx_mdef_7PyTorch_15_popDoubleTensor = {"_popDoubleTensor", (PyCFunction)__pyx_pw_7PyTorch_15_popDoubleTensor, METH_NOARGS, 0};
static PyObject *__pyx_pw_7PyTorch_15_popDoubleTensor(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_popDoubleTensor (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_14_popDoubleTensor(__pyx_self);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_14_popDoubleTensor(CYTHON_UNUSED PyObject *__pyx_self) {
  struct THDoubleTensor *__pyx_v_tensorC;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("_popDoubleTensor", 0);

  /* "PyTorch.pyx":2535
 * def _popDoubleTensor():
 *     global globalState
 *     cdef THDoubleTensor *tensorC = popDoubleTensor(globalState.L)             # <<<<<<<<<<<<<<
 *     return _DoubleTensor_fromNative(tensorC)
 * 
 */
  __pyx_v_tensorC = popDoubleTensor(__pyx_v_7PyTorch_globalState->L);

  /* "PyTorch.pyx":2536
 *     global globalState
 *     cdef THDoubleTensor *tensorC = popDoubleTensor(globalState.L)
 *     return _DoubleTensor_fromNative(tensorC)             # <<<<<<<<<<<<<<
 * 
 * def _pushDoubleTensor(_DoubleTensor tensor):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_7PyTorch__DoubleTensor_fromNative(__pyx_v_tensorC, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2536, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":2533
 * 
 * 
 * def _popDoubleTensor():             # <<<<<<<<<<<<<<
 *     global globalState
 *     cdef THDoubleTensor *tensorC = popDoubleTensor(globalState.L)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._popDoubleTensor", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2538
 *     return _DoubleTensor_fromNative(tensorC)
 * 
 * def _pushDoubleTensor(_DoubleTensor tensor):             # <<<<<<<<<<<<<<
 *     global globalState
 *     pushDoubleTensor(globalState.L, tensor.native)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_17_pushDoubleTensor(PyObject *__pyx_self, PyObject *__pyx_v_tensor); /*proto*/
static PyMethodDef __pyx_mdef_7PyTorch_17_pushDoubleTensor = {"_pushDoubleTensor", (PyCFunction)__pyx_pw_7PyTorch_17_pushDoubleTensor, METH_O, 0};
static PyObject *__pyx_pw_7PyTorch_17_pushDoubleTensor(PyObject *__pyx_self, PyObject *__pyx_v_tensor) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_pushDoubleTensor (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_tensor), __pyx_ptype_7PyTorch__DoubleTensor, 1, "tensor", 0))) __PYX_ERR(0, 2538, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_16_pushDoubleTensor(__pyx_self, ((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_tensor));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_16_pushDoubleTensor(CYTHON_UNUSED PyObject *__pyx_self, struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_tensor) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_pushDoubleTensor", 0);

  /* "PyTorch.pyx":2540
 * def _pushDoubleTensor(_DoubleTensor tensor):
 *     global globalState
 *     pushDoubleTensor(globalState.L, tensor.native)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  pushDoubleTensor(__pyx_v_7PyTorch_globalState->L, __pyx_v_tensor->native);

  /* "PyTorch.pyx":2538
 *     return _DoubleTensor_fromNative(tensorC)
 * 
 * def _pushDoubleTensor(_DoubleTensor tensor):             # <<<<<<<<<<<<<<
 *     global globalState
 *     pushDoubleTensor(globalState.L, tensor.native)
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2546
 * 
 * 
 * def _popByteTensor():             # <<<<<<<<<<<<<<
 *     global globalState
 *     cdef THByteTensor *tensorC = popByteTensor(globalState.L)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_19_popByteTensor(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyMethodDef __pyx_mdef_7PyTorch_19_popByteTensor = {"_popByteTensor", (PyCFunction)__pyx_pw_7PyTorch_19_popByteTensor, METH_NOARGS, 0};
static PyObject *__pyx_pw_7PyTorch_19_popByteTensor(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_popByteTensor (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_18_popByteTensor(__pyx_self);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_18_popByteTensor(CYTHON_UNUSED PyObject *__pyx_self) {
  struct THByteTensor *__pyx_v_tensorC;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("_popByteTensor", 0);

  /* "PyTorch.pyx":2548
 * def _popByteTensor():
 *     global globalState
 *     cdef THByteTensor *tensorC = popByteTensor(globalState.L)             # <<<<<<<<<<<<<<
 *     return _ByteTensor_fromNative(tensorC)
 * 
 */
  __pyx_v_tensorC = popByteTensor(__pyx_v_7PyTorch_globalState->L);

  /* "PyTorch.pyx":2549
 *     global globalState
 *     cdef THByteTensor *tensorC = popByteTensor(globalState.L)
 *     return _ByteTensor_fromNative(tensorC)             # <<<<<<<<<<<<<<
 * 
 * def _pushByteTensor(_ByteTensor tensor):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_7PyTorch__ByteTensor_fromNative(__pyx_v_tensorC, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2549, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "PyTorch.pyx":2546
 * 
 * 
 * def _popByteTensor():             # <<<<<<<<<<<<<<
 *     global globalState
 *     cdef THByteTensor *tensorC = popByteTensor(globalState.L)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch._popByteTensor", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2551
 *     return _ByteTensor_fromNative(tensorC)
 * 
 * def _pushByteTensor(_ByteTensor tensor):             # <<<<<<<<<<<<<<
 *     global globalState
 *     pushByteTensor(globalState.L, tensor.native)
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_21_pushByteTensor(PyObject *__pyx_self, PyObject *__pyx_v_tensor); /*proto*/
static PyMethodDef __pyx_mdef_7PyTorch_21_pushByteTensor = {"_pushByteTensor", (PyCFunction)__pyx_pw_7PyTorch_21_pushByteTensor, METH_O, 0};
static PyObject *__pyx_pw_7PyTorch_21_pushByteTensor(PyObject *__pyx_self, PyObject *__pyx_v_tensor) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_pushByteTensor (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_tensor), __pyx_ptype_7PyTorch__ByteTensor, 1, "tensor", 0))) __PYX_ERR(0, 2551, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_20_pushByteTensor(__pyx_self, ((struct __pyx_obj_7PyTorch__ByteTensor *)__pyx_v_tensor));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_20_pushByteTensor(CYTHON_UNUSED PyObject *__pyx_self, struct __pyx_obj_7PyTorch__ByteTensor *__pyx_v_tensor) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_pushByteTensor", 0);

  /* "PyTorch.pyx":2553
 * def _pushByteTensor(_ByteTensor tensor):
 *     global globalState
 *     pushByteTensor(globalState.L, tensor.native)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  pushByteTensor(__pyx_v_7PyTorch_globalState->L, __pyx_v_tensor->native);

  /* "PyTorch.pyx":2551
 *     return _ByteTensor_fromNative(tensorC)
 * 
 * def _pushByteTensor(_ByteTensor tensor):             # <<<<<<<<<<<<<<
 *     global globalState
 *     pushByteTensor(globalState.L, tensor.native)
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2566
 * 
 * 
 * cpdef int getFloatPrediction(_FloatTensor output):             # <<<<<<<<<<<<<<
 *     cdef int prediction = 0
 *     cdef float maxSoFar = output[0]
 */

static PyObject *__pyx_pw_7PyTorch_23getFloatPrediction(PyObject *__pyx_self, PyObject *__pyx_v_output); /*proto*/
static int __pyx_f_7PyTorch_getFloatPrediction(struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_output, CYTHON_UNUSED int __pyx_skip_dispatch) {
  int __pyx_v_prediction;
  float __pyx_v_maxSoFar;
  float __pyx_v_thisValue;
  int __pyx_v_i;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  float __pyx_t_2;
  long __pyx_t_3;
  int __pyx_t_4;
  int __pyx_t_5;
  __Pyx_RefNannySetupContext("getFloatPrediction", 0);

  /* "PyTorch.pyx":2567
 * 
 * cpdef int getFloatPrediction(_FloatTensor output):
 *     cdef int prediction = 0             # <<<<<<<<<<<<<<
 *     cdef float maxSoFar = output[0]
 *     cdef float thisValue = 0
 */
  __pyx_v_prediction = 0;

  /* "PyTorch.pyx":2568
 * cpdef int getFloatPrediction(_FloatTensor output):
 *     cdef int prediction = 0
 *     cdef float maxSoFar = output[0]             # <<<<<<<<<<<<<<
 *     cdef float thisValue = 0
 *     cdef int i = 0
 */
  __pyx_t_1 = __Pyx_GetItemInt(((PyObject *)__pyx_v_output), 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2568, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __pyx_PyFloat_AsFloat(__pyx_t_1); if (unlikely((__pyx_t_2 == (float)-1) && PyErr_Occurred())) __PYX_ERR(0, 2568, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_maxSoFar = __pyx_t_2;

  /* "PyTorch.pyx":2569
 *     cdef int prediction = 0
 *     cdef float maxSoFar = output[0]
 *     cdef float thisValue = 0             # <<<<<<<<<<<<<<
 *     cdef int i = 0
 *     for i in range(THFloatTensor_size(output.native, 0)):
 */
  __pyx_v_thisValue = 0.0;

  /* "PyTorch.pyx":2570
 *     cdef float maxSoFar = output[0]
 *     cdef float thisValue = 0
 *     cdef int i = 0             # <<<<<<<<<<<<<<
 *     for i in range(THFloatTensor_size(output.native, 0)):
 *         thisValue = THFloatTensor_get1d(output.native, i)
 */
  __pyx_v_i = 0;

  /* "PyTorch.pyx":2571
 *     cdef float thisValue = 0
 *     cdef int i = 0
 *     for i in range(THFloatTensor_size(output.native, 0)):             # <<<<<<<<<<<<<<
 *         thisValue = THFloatTensor_get1d(output.native, i)
 *         if thisValue > maxSoFar:
 */
  __pyx_t_3 = THFloatTensor_size(__pyx_v_output->native, 0);
  for (__pyx_t_4 = 0; __pyx_t_4 < __pyx_t_3; __pyx_t_4+=1) {
    __pyx_v_i = __pyx_t_4;

    /* "PyTorch.pyx":2572
 *     cdef int i = 0
 *     for i in range(THFloatTensor_size(output.native, 0)):
 *         thisValue = THFloatTensor_get1d(output.native, i)             # <<<<<<<<<<<<<<
 *         if thisValue > maxSoFar:
 *             maxSoFar = thisValue
 */
    __pyx_v_thisValue = THFloatTensor_get1d(__pyx_v_output->native, __pyx_v_i);

    /* "PyTorch.pyx":2573
 *     for i in range(THFloatTensor_size(output.native, 0)):
 *         thisValue = THFloatTensor_get1d(output.native, i)
 *         if thisValue > maxSoFar:             # <<<<<<<<<<<<<<
 *             maxSoFar = thisValue
 *             prediction = i
 */
    __pyx_t_5 = ((__pyx_v_thisValue > __pyx_v_maxSoFar) != 0);
    if (__pyx_t_5) {

      /* "PyTorch.pyx":2574
 *         thisValue = THFloatTensor_get1d(output.native, i)
 *         if thisValue > maxSoFar:
 *             maxSoFar = thisValue             # <<<<<<<<<<<<<<
 *             prediction = i
 *     return prediction + 1
 */
      __pyx_v_maxSoFar = __pyx_v_thisValue;

      /* "PyTorch.pyx":2575
 *         if thisValue > maxSoFar:
 *             maxSoFar = thisValue
 *             prediction = i             # <<<<<<<<<<<<<<
 *     return prediction + 1
 * 
 */
      __pyx_v_prediction = __pyx_v_i;

      /* "PyTorch.pyx":2573
 *     for i in range(THFloatTensor_size(output.native, 0)):
 *         thisValue = THFloatTensor_get1d(output.native, i)
 *         if thisValue > maxSoFar:             # <<<<<<<<<<<<<<
 *             maxSoFar = thisValue
 *             prediction = i
 */
    }
  }

  /* "PyTorch.pyx":2576
 *             maxSoFar = thisValue
 *             prediction = i
 *     return prediction + 1             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_r = (__pyx_v_prediction + 1);
  goto __pyx_L0;

  /* "PyTorch.pyx":2566
 * 
 * 
 * cpdef int getFloatPrediction(_FloatTensor output):             # <<<<<<<<<<<<<<
 *     cdef int prediction = 0
 *     cdef float maxSoFar = output[0]
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_WriteUnraisable("PyTorch.getFloatPrediction", __pyx_clineno, __pyx_lineno, __pyx_filename, 0, 0);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_23getFloatPrediction(PyObject *__pyx_self, PyObject *__pyx_v_output); /*proto*/
static PyObject *__pyx_pw_7PyTorch_23getFloatPrediction(PyObject *__pyx_self, PyObject *__pyx_v_output) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("getFloatPrediction (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_output), __pyx_ptype_7PyTorch__FloatTensor, 1, "output", 0))) __PYX_ERR(0, 2566, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_22getFloatPrediction(__pyx_self, ((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_output));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_22getFloatPrediction(CYTHON_UNUSED PyObject *__pyx_self, struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_output) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("getFloatPrediction", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_f_7PyTorch_getFloatPrediction(__pyx_v_output, 0)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2566, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch.getFloatPrediction", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2582
 * 
 * 
 * cpdef int getDoublePrediction(_DoubleTensor output):             # <<<<<<<<<<<<<<
 *     cdef int prediction = 0
 *     cdef double maxSoFar = output[0]
 */

static PyObject *__pyx_pw_7PyTorch_25getDoublePrediction(PyObject *__pyx_self, PyObject *__pyx_v_output); /*proto*/
static int __pyx_f_7PyTorch_getDoublePrediction(struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_output, CYTHON_UNUSED int __pyx_skip_dispatch) {
  int __pyx_v_prediction;
  double __pyx_v_maxSoFar;
  double __pyx_v_thisValue;
  int __pyx_v_i;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  double __pyx_t_2;
  long __pyx_t_3;
  int __pyx_t_4;
  int __pyx_t_5;
  __Pyx_RefNannySetupContext("getDoublePrediction", 0);

  /* "PyTorch.pyx":2583
 * 
 * cpdef int getDoublePrediction(_DoubleTensor output):
 *     cdef int prediction = 0             # <<<<<<<<<<<<<<
 *     cdef double maxSoFar = output[0]
 *     cdef double thisValue = 0
 */
  __pyx_v_prediction = 0;

  /* "PyTorch.pyx":2584
 * cpdef int getDoublePrediction(_DoubleTensor output):
 *     cdef int prediction = 0
 *     cdef double maxSoFar = output[0]             # <<<<<<<<<<<<<<
 *     cdef double thisValue = 0
 *     cdef int i = 0
 */
  __pyx_t_1 = __Pyx_GetItemInt(((PyObject *)__pyx_v_output), 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2584, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __pyx_PyFloat_AsDouble(__pyx_t_1); if (unlikely((__pyx_t_2 == (double)-1) && PyErr_Occurred())) __PYX_ERR(0, 2584, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_maxSoFar = __pyx_t_2;

  /* "PyTorch.pyx":2585
 *     cdef int prediction = 0
 *     cdef double maxSoFar = output[0]
 *     cdef double thisValue = 0             # <<<<<<<<<<<<<<
 *     cdef int i = 0
 *     for i in range(THDoubleTensor_size(output.native, 0)):
 */
  __pyx_v_thisValue = 0.0;

  /* "PyTorch.pyx":2586
 *     cdef double maxSoFar = output[0]
 *     cdef double thisValue = 0
 *     cdef int i = 0             # <<<<<<<<<<<<<<
 *     for i in range(THDoubleTensor_size(output.native, 0)):
 *         thisValue = THDoubleTensor_get1d(output.native, i)
 */
  __pyx_v_i = 0;

  /* "PyTorch.pyx":2587
 *     cdef double thisValue = 0
 *     cdef int i = 0
 *     for i in range(THDoubleTensor_size(output.native, 0)):             # <<<<<<<<<<<<<<
 *         thisValue = THDoubleTensor_get1d(output.native, i)
 *         if thisValue > maxSoFar:
 */
  __pyx_t_3 = THDoubleTensor_size(__pyx_v_output->native, 0);
  for (__pyx_t_4 = 0; __pyx_t_4 < __pyx_t_3; __pyx_t_4+=1) {
    __pyx_v_i = __pyx_t_4;

    /* "PyTorch.pyx":2588
 *     cdef int i = 0
 *     for i in range(THDoubleTensor_size(output.native, 0)):
 *         thisValue = THDoubleTensor_get1d(output.native, i)             # <<<<<<<<<<<<<<
 *         if thisValue > maxSoFar:
 *             maxSoFar = thisValue
 */
    __pyx_v_thisValue = THDoubleTensor_get1d(__pyx_v_output->native, __pyx_v_i);

    /* "PyTorch.pyx":2589
 *     for i in range(THDoubleTensor_size(output.native, 0)):
 *         thisValue = THDoubleTensor_get1d(output.native, i)
 *         if thisValue > maxSoFar:             # <<<<<<<<<<<<<<
 *             maxSoFar = thisValue
 *             prediction = i
 */
    __pyx_t_5 = ((__pyx_v_thisValue > __pyx_v_maxSoFar) != 0);
    if (__pyx_t_5) {

      /* "PyTorch.pyx":2590
 *         thisValue = THDoubleTensor_get1d(output.native, i)
 *         if thisValue > maxSoFar:
 *             maxSoFar = thisValue             # <<<<<<<<<<<<<<
 *             prediction = i
 *     return prediction + 1
 */
      __pyx_v_maxSoFar = __pyx_v_thisValue;

      /* "PyTorch.pyx":2591
 *         if thisValue > maxSoFar:
 *             maxSoFar = thisValue
 *             prediction = i             # <<<<<<<<<<<<<<
 *     return prediction + 1
 * 
 */
      __pyx_v_prediction = __pyx_v_i;

      /* "PyTorch.pyx":2589
 *     for i in range(THDoubleTensor_size(output.native, 0)):
 *         thisValue = THDoubleTensor_get1d(output.native, i)
 *         if thisValue > maxSoFar:             # <<<<<<<<<<<<<<
 *             maxSoFar = thisValue
 *             prediction = i
 */
    }
  }

  /* "PyTorch.pyx":2592
 *             maxSoFar = thisValue
 *             prediction = i
 *     return prediction + 1             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_r = (__pyx_v_prediction + 1);
  goto __pyx_L0;

  /* "PyTorch.pyx":2582
 * 
 * 
 * cpdef int getDoublePrediction(_DoubleTensor output):             # <<<<<<<<<<<<<<
 *     cdef int prediction = 0
 *     cdef double maxSoFar = output[0]
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_WriteUnraisable("PyTorch.getDoublePrediction", __pyx_clineno, __pyx_lineno, __pyx_filename, 0, 0);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_25getDoublePrediction(PyObject *__pyx_self, PyObject *__pyx_v_output); /*proto*/
static PyObject *__pyx_pw_7PyTorch_25getDoublePrediction(PyObject *__pyx_self, PyObject *__pyx_v_output) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("getDoublePrediction (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_output), __pyx_ptype_7PyTorch__DoubleTensor, 1, "output", 0))) __PYX_ERR(0, 2582, __pyx_L1_error)
  __pyx_r = __pyx_pf_7PyTorch_24getDoublePrediction(__pyx_self, ((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_output));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_24getDoublePrediction(CYTHON_UNUSED PyObject *__pyx_self, struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_output) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("getDoublePrediction", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_f_7PyTorch_getDoublePrediction(__pyx_v_output, 0)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2582, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch.getDoublePrediction", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2602
 * cdef GlobalState globalState
 * 
 * def getGlobalState():             # <<<<<<<<<<<<<<
 *     global globalState
 *     return globalState
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_27getGlobalState(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyMethodDef __pyx_mdef_7PyTorch_27getGlobalState = {"getGlobalState", (PyCFunction)__pyx_pw_7PyTorch_27getGlobalState, METH_NOARGS, 0};
static PyObject *__pyx_pw_7PyTorch_27getGlobalState(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("getGlobalState (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_26getGlobalState(__pyx_self);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_26getGlobalState(CYTHON_UNUSED PyObject *__pyx_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("getGlobalState", 0);

  /* "PyTorch.pyx":2604
 * def getGlobalState():
 *     global globalState
 *     return globalState             # <<<<<<<<<<<<<<
 * 
 * def require(libName):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_7PyTorch_globalState));
  __pyx_r = ((PyObject *)__pyx_v_7PyTorch_globalState);
  goto __pyx_L0;

  /* "PyTorch.pyx":2602
 * cdef GlobalState globalState
 * 
 * def getGlobalState():             # <<<<<<<<<<<<<<
 *     global globalState
 *     return globalState
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2606
 *     return globalState
 * 
 * def require(libName):             # <<<<<<<<<<<<<<
 *     global globalState
 *     cdef lua_State *L
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_29require(PyObject *__pyx_self, PyObject *__pyx_v_libName); /*proto*/
static PyMethodDef __pyx_mdef_7PyTorch_29require = {"require", (PyCFunction)__pyx_pw_7PyTorch_29require, METH_O, 0};
static PyObject *__pyx_pw_7PyTorch_29require(PyObject *__pyx_self, PyObject *__pyx_v_libName) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("require (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_28require(__pyx_self, ((PyObject *)__pyx_v_libName));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_28require(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_libName) {
  struct lua_State *__pyx_v_L;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  struct lua_State *__pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  char const *__pyx_t_4;
  __Pyx_RefNannySetupContext("require", 0);

  /* "PyTorch.pyx":2609
 *     global globalState
 *     cdef lua_State *L
 *     L = globalState.L             # <<<<<<<<<<<<<<
 *     luaRequire(L, libName.encode('utf-8'))
 * 
 */
  __pyx_t_1 = __pyx_v_7PyTorch_globalState->L;
  __pyx_v_L = __pyx_t_1;

  /* "PyTorch.pyx":2610
 *     cdef lua_State *L
 *     L = globalState.L
 *     luaRequire(L, libName.encode('utf-8'))             # <<<<<<<<<<<<<<
 * 
 * def getGlobal(name):
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_libName, __pyx_n_s_encode); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2610, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_tuple__43, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2610, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_4 = __Pyx_PyObject_AsString(__pyx_t_3); if (unlikely((!__pyx_t_4) && PyErr_Occurred())) __PYX_ERR(0, 2610, __pyx_L1_error)
  luaRequire(__pyx_v_L, __pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "PyTorch.pyx":2606
 *     return globalState
 * 
 * def require(libName):             # <<<<<<<<<<<<<<
 *     global globalState
 *     cdef lua_State *L
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("PyTorch.require", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2612
 *     luaRequire(L, libName.encode('utf-8'))
 * 
 * def getGlobal(name):             # <<<<<<<<<<<<<<
 *     global globalState
 *     cdef lua_State *L
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_31getGlobal(PyObject *__pyx_self, PyObject *__pyx_v_name); /*proto*/
static PyMethodDef __pyx_mdef_7PyTorch_31getGlobal = {"getGlobal", (PyCFunction)__pyx_pw_7PyTorch_31getGlobal, METH_O, 0};
static PyObject *__pyx_pw_7PyTorch_31getGlobal(PyObject *__pyx_self, PyObject *__pyx_v_name) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("getGlobal (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_30getGlobal(__pyx_self, ((PyObject *)__pyx_v_name));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_30getGlobal(CYTHON_UNUSED PyObject *__pyx_self, CYTHON_UNUSED PyObject *__pyx_v_name) {
  CYTHON_UNUSED struct lua_State *__pyx_v_L;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  struct lua_State *__pyx_t_1;
  __Pyx_RefNannySetupContext("getGlobal", 0);

  /* "PyTorch.pyx":2615
 *     global globalState
 *     cdef lua_State *L
 *     L = globalState.L             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_1 = __pyx_v_7PyTorch_globalState->L;
  __pyx_v_L = __pyx_t_1;

  /* "PyTorch.pyx":2612
 *     luaRequire(L, libName.encode('utf-8'))
 * 
 * def getGlobal(name):             # <<<<<<<<<<<<<<
 *     global globalState
 *     cdef lua_State *L
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2618
 * 
 * 
 * def init():             # <<<<<<<<<<<<<<
 *     global globalState
 *     # print('initializing PyTorch...')
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_33init(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyMethodDef __pyx_mdef_7PyTorch_33init = {"init", (PyCFunction)__pyx_pw_7PyTorch_33init, METH_NOARGS, 0};
static PyObject *__pyx_pw_7PyTorch_33init(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("init (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_32init(__pyx_self);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_32init(CYTHON_UNUSED PyObject *__pyx_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("init", 0);

  /* "PyTorch.pyx":2621
 *     global globalState
 *     # print('initializing PyTorch...')
 *     globalState = GlobalState()             # <<<<<<<<<<<<<<
 *     globalState.L = luaInit()
 *     globalState.generator = <THGenerator *>(getGlobal2(globalState.L, 'torch', '_gen'))
 */
  __pyx_t_1 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_7PyTorch_GlobalState), __pyx_empty_tuple, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2621, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_XGOTREF(((PyObject *)__pyx_v_7PyTorch_globalState));
  __Pyx_DECREF_SET(__pyx_v_7PyTorch_globalState, ((struct __pyx_obj_7PyTorch_GlobalState *)__pyx_t_1));
  __Pyx_GIVEREF(__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyTorch.pyx":2622
 *     # print('initializing PyTorch...')
 *     globalState = GlobalState()
 *     globalState.L = luaInit()             # <<<<<<<<<<<<<<
 *     globalState.generator = <THGenerator *>(getGlobal2(globalState.L, 'torch', '_gen'))
 *     # print('generator null:', globalState.generator == NULL)
 */
  __pyx_v_7PyTorch_globalState->L = luaInit();

  /* "PyTorch.pyx":2623
 *     globalState = GlobalState()
 *     globalState.L = luaInit()
 *     globalState.generator = <THGenerator *>(getGlobal2(globalState.L, 'torch', '_gen'))             # <<<<<<<<<<<<<<
 *     # print('generator null:', globalState.generator == NULL)
 *     # print(' ... PyTorch initialized')
 */
  __pyx_v_7PyTorch_globalState->generator = ((struct THGenerator *)getGlobal2(__pyx_v_7PyTorch_globalState->L, ((char const *)"torch"), ((char const *)"_gen")));

  /* "PyTorch.pyx":2618
 * 
 * 
 * def init():             # <<<<<<<<<<<<<<
 *     global globalState
 *     # print('initializing PyTorch...')
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyTorch.init", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyTorch.pyx":2633
 * # ==== Nn ==================================
 * cdef class Nn(object):  # just used to provide the `nn.` syntax
 *     def collectgarbage(self):             # <<<<<<<<<<<<<<
 *         collectGarbage(globalState.L)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_7PyTorch_2Nn_1collectgarbage(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_7PyTorch_2Nn_1collectgarbage(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("collectgarbage (wrapper)", 0);
  __pyx_r = __pyx_pf_7PyTorch_2Nn_collectgarbage(((struct __pyx_obj_7PyTorch_Nn *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_7PyTorch_2Nn_collectgarbage(CYTHON_UNUSED struct __pyx_obj_7PyTorch_Nn *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("collectgarbage", 0);

  /* "PyTorch.pyx":2634
 * cdef class Nn(object):  # just used to provide the `nn.` syntax
 *     def collectgarbage(self):
 *         collectGarbage(globalState.L)             # <<<<<<<<<<<<<<
 * 
 * #    def Linear(self, inputSize, outputSize):
 */
  collectGarbage(__pyx_v_7PyTorch_globalState->L);

  /* "PyTorch.pyx":2633
 * # ==== Nn ==================================
 * cdef class Nn(object):  # just used to provide the `nn.` syntax
 *     def collectgarbage(self):             # <<<<<<<<<<<<<<
 *         collectGarbage(globalState.L)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cpython/array.pxd":91
 *             __data_union data
 * 
 *         def __getbuffer__(self, Py_buffer* info, int flags):             # <<<<<<<<<<<<<<
 *             # This implementation of getbuffer is geared towards Cython
 *             # requirements, and does not yet fullfill the PEP.
 */

/* Python wrapper */
static CYTHON_UNUSED int __pyx_pw_7cpython_5array_5array_1__getbuffer__(PyObject *__pyx_v_self, Py_buffer *__pyx_v_info, int __pyx_v_flags); /*proto*/
static CYTHON_UNUSED int __pyx_pw_7cpython_5array_5array_1__getbuffer__(PyObject *__pyx_v_self, Py_buffer *__pyx_v_info, int __pyx_v_flags) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__getbuffer__ (wrapper)", 0);
  __pyx_r = __pyx_pf_7cpython_5array_5array___getbuffer__(((arrayobject *)__pyx_v_self), ((Py_buffer *)__pyx_v_info), ((int)__pyx_v_flags));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_7cpython_5array_5array___getbuffer__(arrayobject *__pyx_v_self, Py_buffer *__pyx_v_info, CYTHON_UNUSED int __pyx_v_flags) {
  PyObject *__pyx_v_item_count = NULL;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  char *__pyx_t_2;
  int __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  Py_ssize_t __pyx_t_5;
  int __pyx_t_6;
  __Pyx_RefNannySetupContext("__getbuffer__", 0);
  if (__pyx_v_info != NULL) {
    __pyx_v_info->obj = Py_None; __Pyx_INCREF(Py_None);
    __Pyx_GIVEREF(__pyx_v_info->obj);
  }

  /* "cpython/array.pxd":96
 *             # In particular strided access is always provided regardless
 *             # of flags
 *             item_count = Py_SIZE(self)             # <<<<<<<<<<<<<<
 * 
 *             info.suboffsets = NULL
 */
  __pyx_t_1 = PyInt_FromSsize_t(Py_SIZE(((PyObject *)__pyx_v_self))); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 96, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_item_count = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "cpython/array.pxd":98
 *             item_count = Py_SIZE(self)
 * 
 *             info.suboffsets = NULL             # <<<<<<<<<<<<<<
 *             info.buf = self.data.as_chars
 *             info.readonly = 0
 */
  __pyx_v_info->suboffsets = NULL;

  /* "cpython/array.pxd":99
 * 
 *             info.suboffsets = NULL
 *             info.buf = self.data.as_chars             # <<<<<<<<<<<<<<
 *             info.readonly = 0
 *             info.ndim = 1
 */
  __pyx_t_2 = __pyx_v_self->data.as_chars;
  __pyx_v_info->buf = __pyx_t_2;

  /* "cpython/array.pxd":100
 *             info.suboffsets = NULL
 *             info.buf = self.data.as_chars
 *             info.readonly = 0             # <<<<<<<<<<<<<<
 *             info.ndim = 1
 *             info.itemsize = self.ob_descr.itemsize   # e.g. sizeof(float)
 */
  __pyx_v_info->readonly = 0;

  /* "cpython/array.pxd":101
 *             info.buf = self.data.as_chars
 *             info.readonly = 0
 *             info.ndim = 1             # <<<<<<<<<<<<<<
 *             info.itemsize = self.ob_descr.itemsize   # e.g. sizeof(float)
 *             info.len = info.itemsize * item_count
 */
  __pyx_v_info->ndim = 1;

  /* "cpython/array.pxd":102
 *             info.readonly = 0
 *             info.ndim = 1
 *             info.itemsize = self.ob_descr.itemsize   # e.g. sizeof(float)             # <<<<<<<<<<<<<<
 *             info.len = info.itemsize * item_count
 * 
 */
  __pyx_t_3 = __pyx_v_self->ob_descr->itemsize;
  __pyx_v_info->itemsize = __pyx_t_3;

  /* "cpython/array.pxd":103
 *             info.ndim = 1
 *             info.itemsize = self.ob_descr.itemsize   # e.g. sizeof(float)
 *             info.len = info.itemsize * item_count             # <<<<<<<<<<<<<<
 * 
 *             info.shape = <Py_ssize_t*> PyObject_Malloc(sizeof(Py_ssize_t) + 2)
 */
  __pyx_t_1 = PyInt_FromSsize_t(__pyx_v_info->itemsize); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 103, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = PyNumber_Multiply(__pyx_t_1, __pyx_v_item_count); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 103, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_5 = __Pyx_PyIndex_AsSsize_t(__pyx_t_4); if (unlikely((__pyx_t_5 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(1, 103, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_v_info->len = __pyx_t_5;

  /* "cpython/array.pxd":105
 *             info.len = info.itemsize * item_count
 * 
 *             info.shape = <Py_ssize_t*> PyObject_Malloc(sizeof(Py_ssize_t) + 2)             # <<<<<<<<<<<<<<
 *             if not info.shape:
 *                 raise MemoryError()
 */
  __pyx_v_info->shape = ((Py_ssize_t *)PyObject_Malloc(((sizeof(Py_ssize_t)) + 2)));

  /* "cpython/array.pxd":106
 * 
 *             info.shape = <Py_ssize_t*> PyObject_Malloc(sizeof(Py_ssize_t) + 2)
 *             if not info.shape:             # <<<<<<<<<<<<<<
 *                 raise MemoryError()
 *             info.shape[0] = item_count      # constant regardless of resizing
 */
  __pyx_t_6 = ((!(__pyx_v_info->shape != 0)) != 0);
  if (__pyx_t_6) {

    /* "cpython/array.pxd":107
 *             info.shape = <Py_ssize_t*> PyObject_Malloc(sizeof(Py_ssize_t) + 2)
 *             if not info.shape:
 *                 raise MemoryError()             # <<<<<<<<<<<<<<
 *             info.shape[0] = item_count      # constant regardless of resizing
 *             info.strides = &info.itemsize
 */
    PyErr_NoMemory(); __PYX_ERR(1, 107, __pyx_L1_error)

    /* "cpython/array.pxd":106
 * 
 *             info.shape = <Py_ssize_t*> PyObject_Malloc(sizeof(Py_ssize_t) + 2)
 *             if not info.shape:             # <<<<<<<<<<<<<<
 *                 raise MemoryError()
 *             info.shape[0] = item_count      # constant regardless of resizing
 */
  }

  /* "cpython/array.pxd":108
 *             if not info.shape:
 *                 raise MemoryError()
 *             info.shape[0] = item_count      # constant regardless of resizing             # <<<<<<<<<<<<<<
 *             info.strides = &info.itemsize
 * 
 */
  __pyx_t_5 = __Pyx_PyIndex_AsSsize_t(__pyx_v_item_count); if (unlikely((__pyx_t_5 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(1, 108, __pyx_L1_error)
  (__pyx_v_info->shape[0]) = __pyx_t_5;

  /* "cpython/array.pxd":109
 *                 raise MemoryError()
 *             info.shape[0] = item_count      # constant regardless of resizing
 *             info.strides = &info.itemsize             # <<<<<<<<<<<<<<
 * 
 *             info.format = <char*> (info.shape + 1)
 */
  __pyx_v_info->strides = (&__pyx_v_info->itemsize);

  /* "cpython/array.pxd":111
 *             info.strides = &info.itemsize
 * 
 *             info.format = <char*> (info.shape + 1)             # <<<<<<<<<<<<<<
 *             info.format[0] = self.ob_descr.typecode
 *             info.format[1] = 0
 */
  __pyx_v_info->format = ((char *)(__pyx_v_info->shape + 1));

  /* "cpython/array.pxd":112
 * 
 *             info.format = <char*> (info.shape + 1)
 *             info.format[0] = self.ob_descr.typecode             # <<<<<<<<<<<<<<
 *             info.format[1] = 0
 *             info.obj = self
 */
  __pyx_t_3 = __pyx_v_self->ob_descr->typecode;
  (__pyx_v_info->format[0]) = __pyx_t_3;

  /* "cpython/array.pxd":113
 *             info.format = <char*> (info.shape + 1)
 *             info.format[0] = self.ob_descr.typecode
 *             info.format[1] = 0             # <<<<<<<<<<<<<<
 *             info.obj = self
 * 
 */
  (__pyx_v_info->format[1]) = 0;

  /* "cpython/array.pxd":114
 *             info.format[0] = self.ob_descr.typecode
 *             info.format[1] = 0
 *             info.obj = self             # <<<<<<<<<<<<<<
 * 
 *         def __releasebuffer__(self, Py_buffer* info):
 */
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
  __Pyx_GOTREF(__pyx_v_info->obj);
  __Pyx_DECREF(__pyx_v_info->obj);
  __pyx_v_info->obj = ((PyObject *)__pyx_v_self);

  /* "cpython/array.pxd":91
 *             __data_union data
 * 
 *         def __getbuffer__(self, Py_buffer* info, int flags):             # <<<<<<<<<<<<<<
 *             # This implementation of getbuffer is geared towards Cython
 *             # requirements, and does not yet fullfill the PEP.
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("cpython.array.array.__getbuffer__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  if (__pyx_v_info != NULL && __pyx_v_info->obj != NULL) {
    __Pyx_GOTREF(__pyx_v_info->obj);
    __Pyx_DECREF(__pyx_v_info->obj); __pyx_v_info->obj = NULL;
  }
  goto __pyx_L2;
  __pyx_L0:;
  if (__pyx_v_info != NULL && __pyx_v_info->obj == Py_None) {
    __Pyx_GOTREF(Py_None);
    __Pyx_DECREF(Py_None); __pyx_v_info->obj = NULL;
  }
  __pyx_L2:;
  __Pyx_XDECREF(__pyx_v_item_count);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cpython/array.pxd":116
 *             info.obj = self
 * 
 *         def __releasebuffer__(self, Py_buffer* info):             # <<<<<<<<<<<<<<
 *             PyObject_Free(info.shape)
 * 
 */

/* Python wrapper */
static CYTHON_UNUSED void __pyx_pw_7cpython_5array_5array_3__releasebuffer__(PyObject *__pyx_v_self, Py_buffer *__pyx_v_info); /*proto*/
static CYTHON_UNUSED void __pyx_pw_7cpython_5array_5array_3__releasebuffer__(PyObject *__pyx_v_self, Py_buffer *__pyx_v_info) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__releasebuffer__ (wrapper)", 0);
  __pyx_pf_7cpython_5array_5array_2__releasebuffer__(((arrayobject *)__pyx_v_self), ((Py_buffer *)__pyx_v_info));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

static void __pyx_pf_7cpython_5array_5array_2__releasebuffer__(CYTHON_UNUSED arrayobject *__pyx_v_self, Py_buffer *__pyx_v_info) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__releasebuffer__", 0);

  /* "cpython/array.pxd":117
 * 
 *         def __releasebuffer__(self, Py_buffer* info):
 *             PyObject_Free(info.shape)             # <<<<<<<<<<<<<<
 * 
 *     array newarrayobject(PyTypeObject* type, Py_ssize_t size, arraydescr *descr)
 */
  PyObject_Free(__pyx_v_info->shape);

  /* "cpython/array.pxd":116
 *             info.obj = self
 * 
 *         def __releasebuffer__(self, Py_buffer* info):             # <<<<<<<<<<<<<<
 *             PyObject_Free(info.shape)
 * 
 */

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

/* "cpython/array.pxd":128
 * 
 * 
 * cdef inline array clone(array template, Py_ssize_t length, bint zero):             # <<<<<<<<<<<<<<
 *     """ fast creation of a new array, given a template array.
 *     type will be same as template.
 */

static CYTHON_INLINE arrayobject *__pyx_f_7cpython_5array_clone(arrayobject *__pyx_v_template, Py_ssize_t __pyx_v_length, int __pyx_v_zero) {
  arrayobject *__pyx_v_op = NULL;
  arrayobject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  int __pyx_t_3;
  int __pyx_t_4;
  __Pyx_RefNannySetupContext("clone", 0);

  /* "cpython/array.pxd":132
 *     type will be same as template.
 *     if zero is true, new array will be initialized with zeroes."""
 *     op = newarrayobject(Py_TYPE(template), length, template.ob_descr)             # <<<<<<<<<<<<<<
 *     if zero and op is not None:
 *         memset(op.data.as_chars, 0, length * op.ob_descr.itemsize)
 */
  __pyx_t_1 = ((PyObject *)newarrayobject(Py_TYPE(((PyObject *)__pyx_v_template)), __pyx_v_length, __pyx_v_template->ob_descr)); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 132, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_op = ((arrayobject *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "cpython/array.pxd":133
 *     if zero is true, new array will be initialized with zeroes."""
 *     op = newarrayobject(Py_TYPE(template), length, template.ob_descr)
 *     if zero and op is not None:             # <<<<<<<<<<<<<<
 *         memset(op.data.as_chars, 0, length * op.ob_descr.itemsize)
 *     return op
 */
  __pyx_t_3 = (__pyx_v_zero != 0);
  if (__pyx_t_3) {
  } else {
    __pyx_t_2 = __pyx_t_3;
    goto __pyx_L4_bool_binop_done;
  }
  __pyx_t_3 = (((PyObject *)__pyx_v_op) != Py_None);
  __pyx_t_4 = (__pyx_t_3 != 0);
  __pyx_t_2 = __pyx_t_4;
  __pyx_L4_bool_binop_done:;
  if (__pyx_t_2) {

    /* "cpython/array.pxd":134
 *     op = newarrayobject(Py_TYPE(template), length, template.ob_descr)
 *     if zero and op is not None:
 *         memset(op.data.as_chars, 0, length * op.ob_descr.itemsize)             # <<<<<<<<<<<<<<
 *     return op
 * 
 */
    memset(__pyx_v_op->data.as_chars, 0, (__pyx_v_length * __pyx_v_op->ob_descr->itemsize));

    /* "cpython/array.pxd":133
 *     if zero is true, new array will be initialized with zeroes."""
 *     op = newarrayobject(Py_TYPE(template), length, template.ob_descr)
 *     if zero and op is not None:             # <<<<<<<<<<<<<<
 *         memset(op.data.as_chars, 0, length * op.ob_descr.itemsize)
 *     return op
 */
  }

  /* "cpython/array.pxd":135
 *     if zero and op is not None:
 *         memset(op.data.as_chars, 0, length * op.ob_descr.itemsize)
 *     return op             # <<<<<<<<<<<<<<
 * 
 * cdef inline array copy(array self):
 */
  __Pyx_XDECREF(((PyObject *)__pyx_r));
  __Pyx_INCREF(((PyObject *)__pyx_v_op));
  __pyx_r = __pyx_v_op;
  goto __pyx_L0;

  /* "cpython/array.pxd":128
 * 
 * 
 * cdef inline array clone(array template, Py_ssize_t length, bint zero):             # <<<<<<<<<<<<<<
 *     """ fast creation of a new array, given a template array.
 *     type will be same as template.
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("cpython.array.clone", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_op);
  __Pyx_XGIVEREF((PyObject *)__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cpython/array.pxd":137
 *     return op
 * 
 * cdef inline array copy(array self):             # <<<<<<<<<<<<<<
 *     """ make a copy of an array. """
 *     op = newarrayobject(Py_TYPE(self), Py_SIZE(self), self.ob_descr)
 */

static CYTHON_INLINE arrayobject *__pyx_f_7cpython_5array_copy(arrayobject *__pyx_v_self) {
  arrayobject *__pyx_v_op = NULL;
  arrayobject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("copy", 0);

  /* "cpython/array.pxd":139
 * cdef inline array copy(array self):
 *     """ make a copy of an array. """
 *     op = newarrayobject(Py_TYPE(self), Py_SIZE(self), self.ob_descr)             # <<<<<<<<<<<<<<
 *     memcpy(op.data.as_chars, self.data.as_chars, Py_SIZE(op) * op.ob_descr.itemsize)
 *     return op
 */
  __pyx_t_1 = ((PyObject *)newarrayobject(Py_TYPE(((PyObject *)__pyx_v_self)), Py_SIZE(((PyObject *)__pyx_v_self)), __pyx_v_self->ob_descr)); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 139, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_op = ((arrayobject *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "cpython/array.pxd":140
 *     """ make a copy of an array. """
 *     op = newarrayobject(Py_TYPE(self), Py_SIZE(self), self.ob_descr)
 *     memcpy(op.data.as_chars, self.data.as_chars, Py_SIZE(op) * op.ob_descr.itemsize)             # <<<<<<<<<<<<<<
 *     return op
 * 
 */
  memcpy(__pyx_v_op->data.as_chars, __pyx_v_self->data.as_chars, (Py_SIZE(((PyObject *)__pyx_v_op)) * __pyx_v_op->ob_descr->itemsize));

  /* "cpython/array.pxd":141
 *     op = newarrayobject(Py_TYPE(self), Py_SIZE(self), self.ob_descr)
 *     memcpy(op.data.as_chars, self.data.as_chars, Py_SIZE(op) * op.ob_descr.itemsize)
 *     return op             # <<<<<<<<<<<<<<
 * 
 * cdef inline int extend_buffer(array self, char* stuff, Py_ssize_t n) except -1:
 */
  __Pyx_XDECREF(((PyObject *)__pyx_r));
  __Pyx_INCREF(((PyObject *)__pyx_v_op));
  __pyx_r = __pyx_v_op;
  goto __pyx_L0;

  /* "cpython/array.pxd":137
 *     return op
 * 
 * cdef inline array copy(array self):             # <<<<<<<<<<<<<<
 *     """ make a copy of an array. """
 *     op = newarrayobject(Py_TYPE(self), Py_SIZE(self), self.ob_descr)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("cpython.array.copy", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_op);
  __Pyx_XGIVEREF((PyObject *)__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cpython/array.pxd":143
 *     return op
 * 
 * cdef inline int extend_buffer(array self, char* stuff, Py_ssize_t n) except -1:             # <<<<<<<<<<<<<<
 *     """ efficent appending of new stuff of same type
 *     (e.g. of same array type)
 */

static CYTHON_INLINE int __pyx_f_7cpython_5array_extend_buffer(arrayobject *__pyx_v_self, char *__pyx_v_stuff, Py_ssize_t __pyx_v_n) {
  Py_ssize_t __pyx_v_itemsize;
  Py_ssize_t __pyx_v_origsize;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  __Pyx_RefNannySetupContext("extend_buffer", 0);

  /* "cpython/array.pxd":147
 *     (e.g. of same array type)
 *     n: number of elements (not number of bytes!) """
 *     cdef Py_ssize_t itemsize = self.ob_descr.itemsize             # <<<<<<<<<<<<<<
 *     cdef Py_ssize_t origsize = Py_SIZE(self)
 *     resize_smart(self, origsize + n)
 */
  __pyx_t_1 = __pyx_v_self->ob_descr->itemsize;
  __pyx_v_itemsize = __pyx_t_1;

  /* "cpython/array.pxd":148
 *     n: number of elements (not number of bytes!) """
 *     cdef Py_ssize_t itemsize = self.ob_descr.itemsize
 *     cdef Py_ssize_t origsize = Py_SIZE(self)             # <<<<<<<<<<<<<<
 *     resize_smart(self, origsize + n)
 *     memcpy(self.data.as_chars + origsize * itemsize, stuff, n * itemsize)
 */
  __pyx_v_origsize = Py_SIZE(((PyObject *)__pyx_v_self));

  /* "cpython/array.pxd":149
 *     cdef Py_ssize_t itemsize = self.ob_descr.itemsize
 *     cdef Py_ssize_t origsize = Py_SIZE(self)
 *     resize_smart(self, origsize + n)             # <<<<<<<<<<<<<<
 *     memcpy(self.data.as_chars + origsize * itemsize, stuff, n * itemsize)
 *     return 0
 */
  __pyx_t_1 = resize_smart(__pyx_v_self, (__pyx_v_origsize + __pyx_v_n)); if (unlikely(__pyx_t_1 == -1)) __PYX_ERR(1, 149, __pyx_L1_error)

  /* "cpython/array.pxd":150
 *     cdef Py_ssize_t origsize = Py_SIZE(self)
 *     resize_smart(self, origsize + n)
 *     memcpy(self.data.as_chars + origsize * itemsize, stuff, n * itemsize)             # <<<<<<<<<<<<<<
 *     return 0
 * 
 */
  memcpy((__pyx_v_self->data.as_chars + (__pyx_v_origsize * __pyx_v_itemsize)), __pyx_v_stuff, (__pyx_v_n * __pyx_v_itemsize));

  /* "cpython/array.pxd":151
 *     resize_smart(self, origsize + n)
 *     memcpy(self.data.as_chars + origsize * itemsize, stuff, n * itemsize)
 *     return 0             # <<<<<<<<<<<<<<
 * 
 * cdef inline int extend(array self, array other) except -1:
 */
  __pyx_r = 0;
  goto __pyx_L0;

  /* "cpython/array.pxd":143
 *     return op
 * 
 * cdef inline int extend_buffer(array self, char* stuff, Py_ssize_t n) except -1:             # <<<<<<<<<<<<<<
 *     """ efficent appending of new stuff of same type
 *     (e.g. of same array type)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("cpython.array.extend_buffer", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cpython/array.pxd":153
 *     return 0
 * 
 * cdef inline int extend(array self, array other) except -1:             # <<<<<<<<<<<<<<
 *     """ extend array with data from another array; types must match. """
 *     if self.ob_descr.typecode != other.ob_descr.typecode:
 */

static CYTHON_INLINE int __pyx_f_7cpython_5array_extend(arrayobject *__pyx_v_self, arrayobject *__pyx_v_other) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  __Pyx_RefNannySetupContext("extend", 0);

  /* "cpython/array.pxd":155
 * cdef inline int extend(array self, array other) except -1:
 *     """ extend array with data from another array; types must match. """
 *     if self.ob_descr.typecode != other.ob_descr.typecode:             # <<<<<<<<<<<<<<
 *         PyErr_BadArgument()
 *     return extend_buffer(self, other.data.as_chars, Py_SIZE(other))
 */
  __pyx_t_1 = ((__pyx_v_self->ob_descr->typecode != __pyx_v_other->ob_descr->typecode) != 0);
  if (__pyx_t_1) {

    /* "cpython/array.pxd":156
 *     """ extend array with data from another array; types must match. """
 *     if self.ob_descr.typecode != other.ob_descr.typecode:
 *         PyErr_BadArgument()             # <<<<<<<<<<<<<<
 *     return extend_buffer(self, other.data.as_chars, Py_SIZE(other))
 * 
 */
    __pyx_t_2 = PyErr_BadArgument(); if (unlikely(__pyx_t_2 == 0)) __PYX_ERR(1, 156, __pyx_L1_error)

    /* "cpython/array.pxd":155
 * cdef inline int extend(array self, array other) except -1:
 *     """ extend array with data from another array; types must match. """
 *     if self.ob_descr.typecode != other.ob_descr.typecode:             # <<<<<<<<<<<<<<
 *         PyErr_BadArgument()
 *     return extend_buffer(self, other.data.as_chars, Py_SIZE(other))
 */
  }

  /* "cpython/array.pxd":157
 *     if self.ob_descr.typecode != other.ob_descr.typecode:
 *         PyErr_BadArgument()
 *     return extend_buffer(self, other.data.as_chars, Py_SIZE(other))             # <<<<<<<<<<<<<<
 * 
 * cdef inline void zero(array self):
 */
  __pyx_t_2 = __pyx_f_7cpython_5array_extend_buffer(__pyx_v_self, __pyx_v_other->data.as_chars, Py_SIZE(((PyObject *)__pyx_v_other))); if (unlikely(__pyx_t_2 == -1)) __PYX_ERR(1, 157, __pyx_L1_error)
  __pyx_r = __pyx_t_2;
  goto __pyx_L0;

  /* "cpython/array.pxd":153
 *     return 0
 * 
 * cdef inline int extend(array self, array other) except -1:             # <<<<<<<<<<<<<<
 *     """ extend array with data from another array; types must match. """
 *     if self.ob_descr.typecode != other.ob_descr.typecode:
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("cpython.array.extend", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cpython/array.pxd":159
 *     return extend_buffer(self, other.data.as_chars, Py_SIZE(other))
 * 
 * cdef inline void zero(array self):             # <<<<<<<<<<<<<<
 *     """ set all elements of array to zero. """
 *     memset(self.data.as_chars, 0, Py_SIZE(self) * self.ob_descr.itemsize)
 */

static CYTHON_INLINE void __pyx_f_7cpython_5array_zero(arrayobject *__pyx_v_self) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("zero", 0);

  /* "cpython/array.pxd":161
 * cdef inline void zero(array self):
 *     """ set all elements of array to zero. """
 *     memset(self.data.as_chars, 0, Py_SIZE(self) * self.ob_descr.itemsize)             # <<<<<<<<<<<<<<
 */
  memset(__pyx_v_self->data.as_chars, 0, (Py_SIZE(((PyObject *)__pyx_v_self)) * __pyx_v_self->ob_descr->itemsize));

  /* "cpython/array.pxd":159
 *     return extend_buffer(self, other.data.as_chars, Py_SIZE(other))
 * 
 * cdef inline void zero(array self):             # <<<<<<<<<<<<<<
 *     """ set all elements of array to zero. """
 *     memset(self.data.as_chars, 0, Py_SIZE(self) * self.ob_descr.itemsize)
 */

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

/* "View.MemoryView":120
 *         cdef bint dtype_is_object
 * 
 *     def __cinit__(array self, tuple shape, Py_ssize_t itemsize, format not None,             # <<<<<<<<<<<<<<
 *                   mode="c", bint allocate_buffer=True):
 * 
 */

/* Python wrapper */
static int __pyx_array___cinit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static int __pyx_array___cinit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_shape = 0;
  Py_ssize_t __pyx_v_itemsize;
  PyObject *__pyx_v_format = 0;
  PyObject *__pyx_v_mode = 0;
  int __pyx_v_allocate_buffer;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__cinit__ (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_shape,&__pyx_n_s_itemsize,&__pyx_n_s_format,&__pyx_n_s_mode,&__pyx_n_s_allocate_buffer,0};
    PyObject* values[5] = {0,0,0,0,0};
    values[3] = ((PyObject *)__pyx_n_s_c);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_shape)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_itemsize)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("__cinit__", 0, 3, 5, 1); __PYX_ERR(2, 120, __pyx_L3_error)
        }
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_format)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("__cinit__", 0, 3, 5, 2); __PYX_ERR(2, 120, __pyx_L3_error)
        }
        case  3:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_mode);
          if (value) { values[3] = value; kw_args--; }
        }
        case  4:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_allocate_buffer);
          if (value) { values[4] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "__cinit__") < 0)) __PYX_ERR(2, 120, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_shape = ((PyObject*)values[0]);
    __pyx_v_itemsize = __Pyx_PyIndex_AsSsize_t(values[1]); if (unlikely((__pyx_v_itemsize == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(2, 120, __pyx_L3_error)
    __pyx_v_format = values[2];
    __pyx_v_mode = values[3];
    if (values[4]) {
      __pyx_v_allocate_buffer = __Pyx_PyObject_IsTrue(values[4]); if (unlikely((__pyx_v_allocate_buffer == (int)-1) && PyErr_Occurred())) __PYX_ERR(2, 121, __pyx_L3_error)
    } else {

      /* "View.MemoryView":121
 * 
 *     def __cinit__(array self, tuple shape, Py_ssize_t itemsize, format not None,
 *                   mode="c", bint allocate_buffer=True):             # <<<<<<<<<<<<<<
 * 
 *         cdef int idx
 */
      __pyx_v_allocate_buffer = ((int)1);
    }
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__cinit__", 0, 3, 5, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(2, 120, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("View.MemoryView.array.__cinit__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return -1;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_shape), (&PyTuple_Type), 1, "shape", 1))) __PYX_ERR(2, 120, __pyx_L1_error)
  if (unlikely(((PyObject *)__pyx_v_format) == Py_None)) {
    PyErr_Format(PyExc_TypeError, "Argument '%.200s' must not be None", "format"); __PYX_ERR(2, 120, __pyx_L1_error)
  }
  __pyx_r = __pyx_array___pyx_pf_15View_dot_MemoryView_5array___cinit__(((struct __pyx_array_obj *)__pyx_v_self), __pyx_v_shape, __pyx_v_itemsize, __pyx_v_format, __pyx_v_mode, __pyx_v_allocate_buffer);

  /* "View.MemoryView":120
 *         cdef bint dtype_is_object
 * 
 *     def __cinit__(array self, tuple shape, Py_ssize_t itemsize, format not None,             # <<<<<<<<<<<<<<
 *                   mode="c", bint allocate_buffer=True):
 * 
 */

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_array___pyx_pf_15View_dot_MemoryView_5array___cinit__(struct __pyx_array_obj *__pyx_v_self, PyObject *__pyx_v_shape, Py_ssize_t __pyx_v_itemsize, PyObject *__pyx_v_format, PyObject *__pyx_v_mode, int __pyx_v_allocate_buffer) {
  int __pyx_v_idx;
  Py_ssize_t __pyx_v_i;
  Py_ssize_t __pyx_v_dim;
  PyObject **__pyx_v_p;
  char __pyx_v_order;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  Py_ssize_t __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  char *__pyx_t_6;
  int __pyx_t_7;
  Py_ssize_t __pyx_t_8;
  PyObject *__pyx_t_9 = NULL;
  PyObject *__pyx_t_10 = NULL;
  __Pyx_RefNannySetupContext("__cinit__", 0);
  __Pyx_INCREF(__pyx_v_format);

  /* "View.MemoryView":127
 *         cdef PyObject **p
 * 
 *         self.ndim = <int> len(shape)             # <<<<<<<<<<<<<<
 *         self.itemsize = itemsize
 * 
 */
  if (unlikely(__pyx_v_shape == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "object of type 'NoneType' has no len()");
    __PYX_ERR(2, 127, __pyx_L1_error)
  }
  __pyx_t_1 = PyTuple_GET_SIZE(__pyx_v_shape); if (unlikely(__pyx_t_1 == -1)) __PYX_ERR(2, 127, __pyx_L1_error)
  __pyx_v_self->ndim = ((int)__pyx_t_1);

  /* "View.MemoryView":128
 * 
 *         self.ndim = <int> len(shape)
 *         self.itemsize = itemsize             # <<<<<<<<<<<<<<
 * 
 *         if not self.ndim:
 */
  __pyx_v_self->itemsize = __pyx_v_itemsize;

  /* "View.MemoryView":130
 *         self.itemsize = itemsize
 * 
 *         if not self.ndim:             # <<<<<<<<<<<<<<
 *             raise ValueError("Empty shape tuple for cython.array")
 * 
 */
  __pyx_t_2 = ((!(__pyx_v_self->ndim != 0)) != 0);
  if (__pyx_t_2) {

    /* "View.MemoryView":131
 * 
 *         if not self.ndim:
 *             raise ValueError("Empty shape tuple for cython.array")             # <<<<<<<<<<<<<<
 * 
 *         if itemsize <= 0:
 */
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__44, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 131, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(2, 131, __pyx_L1_error)

    /* "View.MemoryView":130
 *         self.itemsize = itemsize
 * 
 *         if not self.ndim:             # <<<<<<<<<<<<<<
 *             raise ValueError("Empty shape tuple for cython.array")
 * 
 */
  }

  /* "View.MemoryView":133
 *             raise ValueError("Empty shape tuple for cython.array")
 * 
 *         if itemsize <= 0:             # <<<<<<<<<<<<<<
 *             raise ValueError("itemsize <= 0 for cython.array")
 * 
 */
  __pyx_t_2 = ((__pyx_v_itemsize <= 0) != 0);
  if (__pyx_t_2) {

    /* "View.MemoryView":134
 * 
 *         if itemsize <= 0:
 *             raise ValueError("itemsize <= 0 for cython.array")             # <<<<<<<<<<<<<<
 * 
 *         if not isinstance(format, bytes):
 */
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__45, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 134, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(2, 134, __pyx_L1_error)

    /* "View.MemoryView":133
 *             raise ValueError("Empty shape tuple for cython.array")
 * 
 *         if itemsize <= 0:             # <<<<<<<<<<<<<<
 *             raise ValueError("itemsize <= 0 for cython.array")
 * 
 */
  }

  /* "View.MemoryView":136
 *             raise ValueError("itemsize <= 0 for cython.array")
 * 
 *         if not isinstance(format, bytes):             # <<<<<<<<<<<<<<
 *             format = format.encode('ASCII')
 *         self._format = format  # keep a reference to the byte string
 */
  __pyx_t_2 = PyBytes_Check(__pyx_v_format); 
  __pyx_t_4 = ((!(__pyx_t_2 != 0)) != 0);
  if (__pyx_t_4) {

    /* "View.MemoryView":137
 * 
 *         if not isinstance(format, bytes):
 *             format = format.encode('ASCII')             # <<<<<<<<<<<<<<
 *         self._format = format  # keep a reference to the byte string
 *         self.format = self._format
 */
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_format, __pyx_n_s_encode); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 137, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_5 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_tuple__46, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 137, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_DECREF_SET(__pyx_v_format, __pyx_t_5);
    __pyx_t_5 = 0;

    /* "View.MemoryView":136
 *             raise ValueError("itemsize <= 0 for cython.array")
 * 
 *         if not isinstance(format, bytes):             # <<<<<<<<<<<<<<
 *             format = format.encode('ASCII')
 *         self._format = format  # keep a reference to the byte string
 */
  }

  /* "View.MemoryView":138
 *         if not isinstance(format, bytes):
 *             format = format.encode('ASCII')
 *         self._format = format  # keep a reference to the byte string             # <<<<<<<<<<<<<<
 *         self.format = self._format
 * 
 */
  if (!(likely(PyBytes_CheckExact(__pyx_v_format))||((__pyx_v_format) == Py_None)||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "bytes", Py_TYPE(__pyx_v_format)->tp_name), 0))) __PYX_ERR(2, 138, __pyx_L1_error)
  __pyx_t_5 = __pyx_v_format;
  __Pyx_INCREF(__pyx_t_5);
  __Pyx_GIVEREF(__pyx_t_5);
  __Pyx_GOTREF(__pyx_v_self->_format);
  __Pyx_DECREF(__pyx_v_self->_format);
  __pyx_v_self->_format = ((PyObject*)__pyx_t_5);
  __pyx_t_5 = 0;

  /* "View.MemoryView":139
 *             format = format.encode('ASCII')
 *         self._format = format  # keep a reference to the byte string
 *         self.format = self._format             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_6 = __Pyx_PyObject_AsString(__pyx_v_self->_format); if (unlikely((!__pyx_t_6) && PyErr_Occurred())) __PYX_ERR(2, 139, __pyx_L1_error)
  __pyx_v_self->format = __pyx_t_6;

  /* "View.MemoryView":142
 * 
 * 
 *         self._shape = <Py_ssize_t *> PyObject_Malloc(sizeof(Py_ssize_t)*self.ndim*2)             # <<<<<<<<<<<<<<
 *         self._strides = self._shape + self.ndim
 * 
 */
  __pyx_v_self->_shape = ((Py_ssize_t *)PyObject_Malloc((((sizeof(Py_ssize_t)) * __pyx_v_self->ndim) * 2)));

  /* "View.MemoryView":143
 * 
 *         self._shape = <Py_ssize_t *> PyObject_Malloc(sizeof(Py_ssize_t)*self.ndim*2)
 *         self._strides = self._shape + self.ndim             # <<<<<<<<<<<<<<
 * 
 *         if not self._shape:
 */
  __pyx_v_self->_strides = (__pyx_v_self->_shape + __pyx_v_self->ndim);

  /* "View.MemoryView":145
 *         self._strides = self._shape + self.ndim
 * 
 *         if not self._shape:             # <<<<<<<<<<<<<<
 *             raise MemoryError("unable to allocate shape and strides.")
 * 
 */
  __pyx_t_4 = ((!(__pyx_v_self->_shape != 0)) != 0);
  if (__pyx_t_4) {

    /* "View.MemoryView":146
 * 
 *         if not self._shape:
 *             raise MemoryError("unable to allocate shape and strides.")             # <<<<<<<<<<<<<<
 * 
 * 
 */
    __pyx_t_5 = __Pyx_PyObject_Call(__pyx_builtin_MemoryError, __pyx_tuple__47, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 146, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_Raise(__pyx_t_5, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __PYX_ERR(2, 146, __pyx_L1_error)

    /* "View.MemoryView":145
 *         self._strides = self._shape + self.ndim
 * 
 *         if not self._shape:             # <<<<<<<<<<<<<<
 *             raise MemoryError("unable to allocate shape and strides.")
 * 
 */
  }

  /* "View.MemoryView":149
 * 
 * 
 *         for idx, dim in enumerate(shape):             # <<<<<<<<<<<<<<
 *             if dim <= 0:
 *                 raise ValueError("Invalid shape in axis %d: %d." % (idx, dim))
 */
  __pyx_t_7 = 0;
  __pyx_t_5 = __pyx_v_shape; __Pyx_INCREF(__pyx_t_5); __pyx_t_1 = 0;
  for (;;) {
    if (__pyx_t_1 >= PyTuple_GET_SIZE(__pyx_t_5)) break;
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    __pyx_t_3 = PyTuple_GET_ITEM(__pyx_t_5, __pyx_t_1); __Pyx_INCREF(__pyx_t_3); __pyx_t_1++; if (unlikely(0 < 0)) __PYX_ERR(2, 149, __pyx_L1_error)
    #else
    __pyx_t_3 = PySequence_ITEM(__pyx_t_5, __pyx_t_1); __pyx_t_1++; if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 149, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    #endif
    __pyx_t_8 = __Pyx_PyIndex_AsSsize_t(__pyx_t_3); if (unlikely((__pyx_t_8 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(2, 149, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_v_dim = __pyx_t_8;
    __pyx_v_idx = __pyx_t_7;
    __pyx_t_7 = (__pyx_t_7 + 1);

    /* "View.MemoryView":150
 * 
 *         for idx, dim in enumerate(shape):
 *             if dim <= 0:             # <<<<<<<<<<<<<<
 *                 raise ValueError("Invalid shape in axis %d: %d." % (idx, dim))
 *             self._shape[idx] = dim
 */
    __pyx_t_4 = ((__pyx_v_dim <= 0) != 0);
    if (__pyx_t_4) {

      /* "View.MemoryView":151
 *         for idx, dim in enumerate(shape):
 *             if dim <= 0:
 *                 raise ValueError("Invalid shape in axis %d: %d." % (idx, dim))             # <<<<<<<<<<<<<<
 *             self._shape[idx] = dim
 * 
 */
      __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_idx); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 151, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_9 = PyInt_FromSsize_t(__pyx_v_dim); if (unlikely(!__pyx_t_9)) __PYX_ERR(2, 151, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __pyx_t_10 = PyTuple_New(2); if (unlikely(!__pyx_t_10)) __PYX_ERR(2, 151, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_10);
      __Pyx_GIVEREF(__pyx_t_3);
      PyTuple_SET_ITEM(__pyx_t_10, 0, __pyx_t_3);
      __Pyx_GIVEREF(__pyx_t_9);
      PyTuple_SET_ITEM(__pyx_t_10, 1, __pyx_t_9);
      __pyx_t_3 = 0;
      __pyx_t_9 = 0;
      __pyx_t_9 = __Pyx_PyString_Format(__pyx_kp_s_Invalid_shape_in_axis_d_d, __pyx_t_10); if (unlikely(!__pyx_t_9)) __PYX_ERR(2, 151, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
      __pyx_t_10 = PyTuple_New(1); if (unlikely(!__pyx_t_10)) __PYX_ERR(2, 151, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_10);
      __Pyx_GIVEREF(__pyx_t_9);
      PyTuple_SET_ITEM(__pyx_t_10, 0, __pyx_t_9);
      __pyx_t_9 = 0;
      __pyx_t_9 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_t_10, NULL); if (unlikely(!__pyx_t_9)) __PYX_ERR(2, 151, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
      __Pyx_Raise(__pyx_t_9, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      __PYX_ERR(2, 151, __pyx_L1_error)

      /* "View.MemoryView":150
 * 
 *         for idx, dim in enumerate(shape):
 *             if dim <= 0:             # <<<<<<<<<<<<<<
 *                 raise ValueError("Invalid shape in axis %d: %d." % (idx, dim))
 *             self._shape[idx] = dim
 */
    }

    /* "View.MemoryView":152
 *             if dim <= 0:
 *                 raise ValueError("Invalid shape in axis %d: %d." % (idx, dim))
 *             self._shape[idx] = dim             # <<<<<<<<<<<<<<
 * 
 *         cdef char order
 */
    (__pyx_v_self->_shape[__pyx_v_idx]) = __pyx_v_dim;

    /* "View.MemoryView":149
 * 
 * 
 *         for idx, dim in enumerate(shape):             # <<<<<<<<<<<<<<
 *             if dim <= 0:
 *                 raise ValueError("Invalid shape in axis %d: %d." % (idx, dim))
 */
  }
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

  /* "View.MemoryView":155
 * 
 *         cdef char order
 *         if mode == 'fortran':             # <<<<<<<<<<<<<<
 *             order = b'F'
 *             self.mode = u'fortran'
 */
  __pyx_t_4 = (__Pyx_PyString_Equals(__pyx_v_mode, __pyx_n_s_fortran, Py_EQ)); if (unlikely(__pyx_t_4 < 0)) __PYX_ERR(2, 155, __pyx_L1_error)
  if (__pyx_t_4) {

    /* "View.MemoryView":156
 *         cdef char order
 *         if mode == 'fortran':
 *             order = b'F'             # <<<<<<<<<<<<<<
 *             self.mode = u'fortran'
 *         elif mode == 'c':
 */
    __pyx_v_order = 'F';

    /* "View.MemoryView":157
 *         if mode == 'fortran':
 *             order = b'F'
 *             self.mode = u'fortran'             # <<<<<<<<<<<<<<
 *         elif mode == 'c':
 *             order = b'C'
 */
    __Pyx_INCREF(__pyx_n_u_fortran);
    __Pyx_GIVEREF(__pyx_n_u_fortran);
    __Pyx_GOTREF(__pyx_v_self->mode);
    __Pyx_DECREF(__pyx_v_self->mode);
    __pyx_v_self->mode = __pyx_n_u_fortran;

    /* "View.MemoryView":155
 * 
 *         cdef char order
 *         if mode == 'fortran':             # <<<<<<<<<<<<<<
 *             order = b'F'
 *             self.mode = u'fortran'
 */
    goto __pyx_L10;
  }

  /* "View.MemoryView":158
 *             order = b'F'
 *             self.mode = u'fortran'
 *         elif mode == 'c':             # <<<<<<<<<<<<<<
 *             order = b'C'
 *             self.mode = u'c'
 */
  __pyx_t_4 = (__Pyx_PyString_Equals(__pyx_v_mode, __pyx_n_s_c, Py_EQ)); if (unlikely(__pyx_t_4 < 0)) __PYX_ERR(2, 158, __pyx_L1_error)
  if (__pyx_t_4) {

    /* "View.MemoryView":159
 *             self.mode = u'fortran'
 *         elif mode == 'c':
 *             order = b'C'             # <<<<<<<<<<<<<<
 *             self.mode = u'c'
 *         else:
 */
    __pyx_v_order = 'C';

    /* "View.MemoryView":160
 *         elif mode == 'c':
 *             order = b'C'
 *             self.mode = u'c'             # <<<<<<<<<<<<<<
 *         else:
 *             raise ValueError("Invalid mode, expected 'c' or 'fortran', got %s" % mode)
 */
    __Pyx_INCREF(__pyx_n_u_c);
    __Pyx_GIVEREF(__pyx_n_u_c);
    __Pyx_GOTREF(__pyx_v_self->mode);
    __Pyx_DECREF(__pyx_v_self->mode);
    __pyx_v_self->mode = __pyx_n_u_c;

    /* "View.MemoryView":158
 *             order = b'F'
 *             self.mode = u'fortran'
 *         elif mode == 'c':             # <<<<<<<<<<<<<<
 *             order = b'C'
 *             self.mode = u'c'
 */
    goto __pyx_L10;
  }

  /* "View.MemoryView":162
 *             self.mode = u'c'
 *         else:
 *             raise ValueError("Invalid mode, expected 'c' or 'fortran', got %s" % mode)             # <<<<<<<<<<<<<<
 * 
 *         self.len = fill_contig_strides_array(self._shape, self._strides,
 */
  /*else*/ {
    __pyx_t_5 = __Pyx_PyString_Format(__pyx_kp_s_Invalid_mode_expected_c_or_fortr, __pyx_v_mode); if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 162, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_9 = PyTuple_New(1); if (unlikely(!__pyx_t_9)) __PYX_ERR(2, 162, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_9);
    __Pyx_GIVEREF(__pyx_t_5);
    PyTuple_SET_ITEM(__pyx_t_9, 0, __pyx_t_5);
    __pyx_t_5 = 0;
    __pyx_t_5 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_t_9, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 162, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
    __Pyx_Raise(__pyx_t_5, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __PYX_ERR(2, 162, __pyx_L1_error)
  }
  __pyx_L10:;

  /* "View.MemoryView":164
 *             raise ValueError("Invalid mode, expected 'c' or 'fortran', got %s" % mode)
 * 
 *         self.len = fill_contig_strides_array(self._shape, self._strides,             # <<<<<<<<<<<<<<
 *                                              itemsize, self.ndim, order)
 * 
 */
  __pyx_v_self->len = __pyx_fill_contig_strides_array(__pyx_v_self->_shape, __pyx_v_self->_strides, __pyx_v_itemsize, __pyx_v_self->ndim, __pyx_v_order);

  /* "View.MemoryView":167
 *                                              itemsize, self.ndim, order)
 * 
 *         self.free_data = allocate_buffer             # <<<<<<<<<<<<<<
 *         self.dtype_is_object = format == b'O'
 *         if allocate_buffer:
 */
  __pyx_v_self->free_data = __pyx_v_allocate_buffer;

  /* "View.MemoryView":168
 * 
 *         self.free_data = allocate_buffer
 *         self.dtype_is_object = format == b'O'             # <<<<<<<<<<<<<<
 *         if allocate_buffer:
 * 
 */
  __pyx_t_5 = PyObject_RichCompare(__pyx_v_format, __pyx_n_b_O, Py_EQ); __Pyx_XGOTREF(__pyx_t_5); if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 168, __pyx_L1_error)
  __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_t_5); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(2, 168, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_v_self->dtype_is_object = __pyx_t_4;

  /* "View.MemoryView":169
 *         self.free_data = allocate_buffer
 *         self.dtype_is_object = format == b'O'
 *         if allocate_buffer:             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_4 = (__pyx_v_allocate_buffer != 0);
  if (__pyx_t_4) {

    /* "View.MemoryView":172
 * 
 * 
 *             self.data = <char *>malloc(self.len)             # <<<<<<<<<<<<<<
 *             if not self.data:
 *                 raise MemoryError("unable to allocate array data.")
 */
    __pyx_v_self->data = ((char *)malloc(__pyx_v_self->len));

    /* "View.MemoryView":173
 * 
 *             self.data = <char *>malloc(self.len)
 *             if not self.data:             # <<<<<<<<<<<<<<
 *                 raise MemoryError("unable to allocate array data.")
 * 
 */
    __pyx_t_4 = ((!(__pyx_v_self->data != 0)) != 0);
    if (__pyx_t_4) {

      /* "View.MemoryView":174
 *             self.data = <char *>malloc(self.len)
 *             if not self.data:
 *                 raise MemoryError("unable to allocate array data.")             # <<<<<<<<<<<<<<
 * 
 *             if self.dtype_is_object:
 */
      __pyx_t_5 = __Pyx_PyObject_Call(__pyx_builtin_MemoryError, __pyx_tuple__48, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 174, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_Raise(__pyx_t_5, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __PYX_ERR(2, 174, __pyx_L1_error)

      /* "View.MemoryView":173
 * 
 *             self.data = <char *>malloc(self.len)
 *             if not self.data:             # <<<<<<<<<<<<<<
 *                 raise MemoryError("unable to allocate array data.")
 * 
 */
    }

    /* "View.MemoryView":176
 *                 raise MemoryError("unable to allocate array data.")
 * 
 *             if self.dtype_is_object:             # <<<<<<<<<<<<<<
 *                 p = <PyObject **> self.data
 *                 for i in range(self.len / itemsize):
 */
    __pyx_t_4 = (__pyx_v_self->dtype_is_object != 0);
    if (__pyx_t_4) {

      /* "View.MemoryView":177
 * 
 *             if self.dtype_is_object:
 *                 p = <PyObject **> self.data             # <<<<<<<<<<<<<<
 *                 for i in range(self.len / itemsize):
 *                     p[i] = Py_None
 */
      __pyx_v_p = ((PyObject **)__pyx_v_self->data);

      /* "View.MemoryView":178
 *             if self.dtype_is_object:
 *                 p = <PyObject **> self.data
 *                 for i in range(self.len / itemsize):             # <<<<<<<<<<<<<<
 *                     p[i] = Py_None
 *                     Py_INCREF(Py_None)
 */
      if (unlikely(__pyx_v_itemsize == 0)) {
        PyErr_SetString(PyExc_ZeroDivisionError, "integer division or modulo by zero");
        __PYX_ERR(2, 178, __pyx_L1_error)
      }
      else if (sizeof(Py_ssize_t) == sizeof(long) && (!(((Py_ssize_t)-1) > 0)) && unlikely(__pyx_v_itemsize == (Py_ssize_t)-1)  && unlikely(UNARY_NEG_WOULD_OVERFLOW(__pyx_v_self->len))) {
        PyErr_SetString(PyExc_OverflowError, "value too large to perform division");
        __PYX_ERR(2, 178, __pyx_L1_error)
      }
      __pyx_t_1 = __Pyx_div_Py_ssize_t(__pyx_v_self->len, __pyx_v_itemsize);
      for (__pyx_t_8 = 0; __pyx_t_8 < __pyx_t_1; __pyx_t_8+=1) {
        __pyx_v_i = __pyx_t_8;

        /* "View.MemoryView":179
 *                 p = <PyObject **> self.data
 *                 for i in range(self.len / itemsize):
 *                     p[i] = Py_None             # <<<<<<<<<<<<<<
 *                     Py_INCREF(Py_None)
 * 
 */
        (__pyx_v_p[__pyx_v_i]) = Py_None;

        /* "View.MemoryView":180
 *                 for i in range(self.len / itemsize):
 *                     p[i] = Py_None
 *                     Py_INCREF(Py_None)             # <<<<<<<<<<<<<<
 * 
 *     @cname('getbuffer')
 */
        Py_INCREF(Py_None);
      }

      /* "View.MemoryView":176
 *                 raise MemoryError("unable to allocate array data.")
 * 
 *             if self.dtype_is_object:             # <<<<<<<<<<<<<<
 *                 p = <PyObject **> self.data
 *                 for i in range(self.len / itemsize):
 */
    }

    /* "View.MemoryView":169
 *         self.free_data = allocate_buffer
 *         self.dtype_is_object = format == b'O'
 *         if allocate_buffer:             # <<<<<<<<<<<<<<
 * 
 * 
 */
  }

  /* "View.MemoryView":120
 *         cdef bint dtype_is_object
 * 
 *     def __cinit__(array self, tuple shape, Py_ssize_t itemsize, format not None,             # <<<<<<<<<<<<<<
 *                   mode="c", bint allocate_buffer=True):
 * 
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_XDECREF(__pyx_t_10);
  __Pyx_AddTraceback("View.MemoryView.array.__cinit__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_format);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":183
 * 
 *     @cname('getbuffer')
 *     def __getbuffer__(self, Py_buffer *info, int flags):             # <<<<<<<<<<<<<<
 *         cdef int bufmode = -1
 *         if self.mode == u"c":
 */

/* Python wrapper */
static CYTHON_UNUSED int __pyx_array_getbuffer(PyObject *__pyx_v_self, Py_buffer *__pyx_v_info, int __pyx_v_flags); /*proto*/
static CYTHON_UNUSED int __pyx_array_getbuffer(PyObject *__pyx_v_self, Py_buffer *__pyx_v_info, int __pyx_v_flags) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__getbuffer__ (wrapper)", 0);
  __pyx_r = __pyx_array___pyx_pf_15View_dot_MemoryView_5array_2__getbuffer__(((struct __pyx_array_obj *)__pyx_v_self), ((Py_buffer *)__pyx_v_info), ((int)__pyx_v_flags));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_array___pyx_pf_15View_dot_MemoryView_5array_2__getbuffer__(struct __pyx_array_obj *__pyx_v_self, Py_buffer *__pyx_v_info, int __pyx_v_flags) {
  int __pyx_v_bufmode;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  char *__pyx_t_4;
  Py_ssize_t __pyx_t_5;
  int __pyx_t_6;
  Py_ssize_t *__pyx_t_7;
  __Pyx_RefNannySetupContext("__getbuffer__", 0);
  if (__pyx_v_info != NULL) {
    __pyx_v_info->obj = Py_None; __Pyx_INCREF(Py_None);
    __Pyx_GIVEREF(__pyx_v_info->obj);
  }

  /* "View.MemoryView":184
 *     @cname('getbuffer')
 *     def __getbuffer__(self, Py_buffer *info, int flags):
 *         cdef int bufmode = -1             # <<<<<<<<<<<<<<
 *         if self.mode == u"c":
 *             bufmode = PyBUF_C_CONTIGUOUS | PyBUF_ANY_CONTIGUOUS
 */
  __pyx_v_bufmode = -1;

  /* "View.MemoryView":185
 *     def __getbuffer__(self, Py_buffer *info, int flags):
 *         cdef int bufmode = -1
 *         if self.mode == u"c":             # <<<<<<<<<<<<<<
 *             bufmode = PyBUF_C_CONTIGUOUS | PyBUF_ANY_CONTIGUOUS
 *         elif self.mode == u"fortran":
 */
  __pyx_t_1 = (__Pyx_PyUnicode_Equals(__pyx_v_self->mode, __pyx_n_u_c, Py_EQ)); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(2, 185, __pyx_L1_error)
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "View.MemoryView":186
 *         cdef int bufmode = -1
 *         if self.mode == u"c":
 *             bufmode = PyBUF_C_CONTIGUOUS | PyBUF_ANY_CONTIGUOUS             # <<<<<<<<<<<<<<
 *         elif self.mode == u"fortran":
 *             bufmode = PyBUF_F_CONTIGUOUS | PyBUF_ANY_CONTIGUOUS
 */
    __pyx_v_bufmode = (PyBUF_C_CONTIGUOUS | PyBUF_ANY_CONTIGUOUS);

    /* "View.MemoryView":185
 *     def __getbuffer__(self, Py_buffer *info, int flags):
 *         cdef int bufmode = -1
 *         if self.mode == u"c":             # <<<<<<<<<<<<<<
 *             bufmode = PyBUF_C_CONTIGUOUS | PyBUF_ANY_CONTIGUOUS
 *         elif self.mode == u"fortran":
 */
    goto __pyx_L3;
  }

  /* "View.MemoryView":187
 *         if self.mode == u"c":
 *             bufmode = PyBUF_C_CONTIGUOUS | PyBUF_ANY_CONTIGUOUS
 *         elif self.mode == u"fortran":             # <<<<<<<<<<<<<<
 *             bufmode = PyBUF_F_CONTIGUOUS | PyBUF_ANY_CONTIGUOUS
 *         if not (flags & bufmode):
 */
  __pyx_t_2 = (__Pyx_PyUnicode_Equals(__pyx_v_self->mode, __pyx_n_u_fortran, Py_EQ)); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(2, 187, __pyx_L1_error)
  __pyx_t_1 = (__pyx_t_2 != 0);
  if (__pyx_t_1) {

    /* "View.MemoryView":188
 *             bufmode = PyBUF_C_CONTIGUOUS | PyBUF_ANY_CONTIGUOUS
 *         elif self.mode == u"fortran":
 *             bufmode = PyBUF_F_CONTIGUOUS | PyBUF_ANY_CONTIGUOUS             # <<<<<<<<<<<<<<
 *         if not (flags & bufmode):
 *             raise ValueError("Can only create a buffer that is contiguous in memory.")
 */
    __pyx_v_bufmode = (PyBUF_F_CONTIGUOUS | PyBUF_ANY_CONTIGUOUS);

    /* "View.MemoryView":187
 *         if self.mode == u"c":
 *             bufmode = PyBUF_C_CONTIGUOUS | PyBUF_ANY_CONTIGUOUS
 *         elif self.mode == u"fortran":             # <<<<<<<<<<<<<<
 *             bufmode = PyBUF_F_CONTIGUOUS | PyBUF_ANY_CONTIGUOUS
 *         if not (flags & bufmode):
 */
  }
  __pyx_L3:;

  /* "View.MemoryView":189
 *         elif self.mode == u"fortran":
 *             bufmode = PyBUF_F_CONTIGUOUS | PyBUF_ANY_CONTIGUOUS
 *         if not (flags & bufmode):             # <<<<<<<<<<<<<<
 *             raise ValueError("Can only create a buffer that is contiguous in memory.")
 *         info.buf = self.data
 */
  __pyx_t_1 = ((!((__pyx_v_flags & __pyx_v_bufmode) != 0)) != 0);
  if (__pyx_t_1) {

    /* "View.MemoryView":190
 *             bufmode = PyBUF_F_CONTIGUOUS | PyBUF_ANY_CONTIGUOUS
 *         if not (flags & bufmode):
 *             raise ValueError("Can only create a buffer that is contiguous in memory.")             # <<<<<<<<<<<<<<
 *         info.buf = self.data
 *         info.len = self.len
 */
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__49, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 190, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(2, 190, __pyx_L1_error)

    /* "View.MemoryView":189
 *         elif self.mode == u"fortran":
 *             bufmode = PyBUF_F_CONTIGUOUS | PyBUF_ANY_CONTIGUOUS
 *         if not (flags & bufmode):             # <<<<<<<<<<<<<<
 *             raise ValueError("Can only create a buffer that is contiguous in memory.")
 *         info.buf = self.data
 */
  }

  /* "View.MemoryView":191
 *         if not (flags & bufmode):
 *             raise ValueError("Can only create a buffer that is contiguous in memory.")
 *         info.buf = self.data             # <<<<<<<<<<<<<<
 *         info.len = self.len
 *         info.ndim = self.ndim
 */
  __pyx_t_4 = __pyx_v_self->data;
  __pyx_v_info->buf = __pyx_t_4;

  /* "View.MemoryView":192
 *             raise ValueError("Can only create a buffer that is contiguous in memory.")
 *         info.buf = self.data
 *         info.len = self.len             # <<<<<<<<<<<<<<
 *         info.ndim = self.ndim
 *         info.shape = self._shape
 */
  __pyx_t_5 = __pyx_v_self->len;
  __pyx_v_info->len = __pyx_t_5;

  /* "View.MemoryView":193
 *         info.buf = self.data
 *         info.len = self.len
 *         info.ndim = self.ndim             # <<<<<<<<<<<<<<
 *         info.shape = self._shape
 *         info.strides = self._strides
 */
  __pyx_t_6 = __pyx_v_self->ndim;
  __pyx_v_info->ndim = __pyx_t_6;

  /* "View.MemoryView":194
 *         info.len = self.len
 *         info.ndim = self.ndim
 *         info.shape = self._shape             # <<<<<<<<<<<<<<
 *         info.strides = self._strides
 *         info.suboffsets = NULL
 */
  __pyx_t_7 = __pyx_v_self->_shape;
  __pyx_v_info->shape = __pyx_t_7;

  /* "View.MemoryView":195
 *         info.ndim = self.ndim
 *         info.shape = self._shape
 *         info.strides = self._strides             # <<<<<<<<<<<<<<
 *         info.suboffsets = NULL
 *         info.itemsize = self.itemsize
 */
  __pyx_t_7 = __pyx_v_self->_strides;
  __pyx_v_info->strides = __pyx_t_7;

  /* "View.MemoryView":196
 *         info.shape = self._shape
 *         info.strides = self._strides
 *         info.suboffsets = NULL             # <<<<<<<<<<<<<<
 *         info.itemsize = self.itemsize
 *         info.readonly = 0
 */
  __pyx_v_info->suboffsets = NULL;

  /* "View.MemoryView":197
 *         info.strides = self._strides
 *         info.suboffsets = NULL
 *         info.itemsize = self.itemsize             # <<<<<<<<<<<<<<
 *         info.readonly = 0
 * 
 */
  __pyx_t_5 = __pyx_v_self->itemsize;
  __pyx_v_info->itemsize = __pyx_t_5;

  /* "View.MemoryView":198
 *         info.suboffsets = NULL
 *         info.itemsize = self.itemsize
 *         info.readonly = 0             # <<<<<<<<<<<<<<
 * 
 *         if flags & PyBUF_FORMAT:
 */
  __pyx_v_info->readonly = 0;

  /* "View.MemoryView":200
 *         info.readonly = 0
 * 
 *         if flags & PyBUF_FORMAT:             # <<<<<<<<<<<<<<
 *             info.format = self.format
 *         else:
 */
  __pyx_t_1 = ((__pyx_v_flags & PyBUF_FORMAT) != 0);
  if (__pyx_t_1) {

    /* "View.MemoryView":201
 * 
 *         if flags & PyBUF_FORMAT:
 *             info.format = self.format             # <<<<<<<<<<<<<<
 *         else:
 *             info.format = NULL
 */
    __pyx_t_4 = __pyx_v_self->format;
    __pyx_v_info->format = __pyx_t_4;

    /* "View.MemoryView":200
 *         info.readonly = 0
 * 
 *         if flags & PyBUF_FORMAT:             # <<<<<<<<<<<<<<
 *             info.format = self.format
 *         else:
 */
    goto __pyx_L5;
  }

  /* "View.MemoryView":203
 *             info.format = self.format
 *         else:
 *             info.format = NULL             # <<<<<<<<<<<<<<
 * 
 *         info.obj = self
 */
  /*else*/ {
    __pyx_v_info->format = NULL;
  }
  __pyx_L5:;

  /* "View.MemoryView":205
 *             info.format = NULL
 * 
 *         info.obj = self             # <<<<<<<<<<<<<<
 * 
 *     __pyx_getbuffer = capsule(<void *> &__pyx_array_getbuffer, "getbuffer(obj, view, flags)")
 */
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
  __Pyx_GOTREF(__pyx_v_info->obj);
  __Pyx_DECREF(__pyx_v_info->obj);
  __pyx_v_info->obj = ((PyObject *)__pyx_v_self);

  /* "View.MemoryView":183
 * 
 *     @cname('getbuffer')
 *     def __getbuffer__(self, Py_buffer *info, int flags):             # <<<<<<<<<<<<<<
 *         cdef int bufmode = -1
 *         if self.mode == u"c":
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("View.MemoryView.array.__getbuffer__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  if (__pyx_v_info != NULL && __pyx_v_info->obj != NULL) {
    __Pyx_GOTREF(__pyx_v_info->obj);
    __Pyx_DECREF(__pyx_v_info->obj); __pyx_v_info->obj = NULL;
  }
  goto __pyx_L2;
  __pyx_L0:;
  if (__pyx_v_info != NULL && __pyx_v_info->obj == Py_None) {
    __Pyx_GOTREF(Py_None);
    __Pyx_DECREF(Py_None); __pyx_v_info->obj = NULL;
  }
  __pyx_L2:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":209
 *     __pyx_getbuffer = capsule(<void *> &__pyx_array_getbuffer, "getbuffer(obj, view, flags)")
 * 
 *     def __dealloc__(array self):             # <<<<<<<<<<<<<<
 *         if self.callback_free_data != NULL:
 *             self.callback_free_data(self.data)
 */

/* Python wrapper */
static void __pyx_array___dealloc__(PyObject *__pyx_v_self); /*proto*/
static void __pyx_array___dealloc__(PyObject *__pyx_v_self) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__dealloc__ (wrapper)", 0);
  __pyx_array___pyx_pf_15View_dot_MemoryView_5array_4__dealloc__(((struct __pyx_array_obj *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

static void __pyx_array___pyx_pf_15View_dot_MemoryView_5array_4__dealloc__(struct __pyx_array_obj *__pyx_v_self) {
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  __Pyx_RefNannySetupContext("__dealloc__", 0);

  /* "View.MemoryView":210
 * 
 *     def __dealloc__(array self):
 *         if self.callback_free_data != NULL:             # <<<<<<<<<<<<<<
 *             self.callback_free_data(self.data)
 *         elif self.free_data:
 */
  __pyx_t_1 = ((__pyx_v_self->callback_free_data != NULL) != 0);
  if (__pyx_t_1) {

    /* "View.MemoryView":211
 *     def __dealloc__(array self):
 *         if self.callback_free_data != NULL:
 *             self.callback_free_data(self.data)             # <<<<<<<<<<<<<<
 *         elif self.free_data:
 *             if self.dtype_is_object:
 */
    __pyx_v_self->callback_free_data(__pyx_v_self->data);

    /* "View.MemoryView":210
 * 
 *     def __dealloc__(array self):
 *         if self.callback_free_data != NULL:             # <<<<<<<<<<<<<<
 *             self.callback_free_data(self.data)
 *         elif self.free_data:
 */
    goto __pyx_L3;
  }

  /* "View.MemoryView":212
 *         if self.callback_free_data != NULL:
 *             self.callback_free_data(self.data)
 *         elif self.free_data:             # <<<<<<<<<<<<<<
 *             if self.dtype_is_object:
 *                 refcount_objects_in_slice(self.data, self._shape,
 */
  __pyx_t_1 = (__pyx_v_self->free_data != 0);
  if (__pyx_t_1) {

    /* "View.MemoryView":213
 *             self.callback_free_data(self.data)
 *         elif self.free_data:
 *             if self.dtype_is_object:             # <<<<<<<<<<<<<<
 *                 refcount_objects_in_slice(self.data, self._shape,
 *                                           self._strides, self.ndim, False)
 */
    __pyx_t_1 = (__pyx_v_self->dtype_is_object != 0);
    if (__pyx_t_1) {

      /* "View.MemoryView":214
 *         elif self.free_data:
 *             if self.dtype_is_object:
 *                 refcount_objects_in_slice(self.data, self._shape,             # <<<<<<<<<<<<<<
 *                                           self._strides, self.ndim, False)
 *             free(self.data)
 */
      __pyx_memoryview_refcount_objects_in_slice(__pyx_v_self->data, __pyx_v_self->_shape, __pyx_v_self->_strides, __pyx_v_self->ndim, 0);

      /* "View.MemoryView":213
 *             self.callback_free_data(self.data)
 *         elif self.free_data:
 *             if self.dtype_is_object:             # <<<<<<<<<<<<<<
 *                 refcount_objects_in_slice(self.data, self._shape,
 *                                           self._strides, self.ndim, False)
 */
    }

    /* "View.MemoryView":216
 *                 refcount_objects_in_slice(self.data, self._shape,
 *                                           self._strides, self.ndim, False)
 *             free(self.data)             # <<<<<<<<<<<<<<
 *         PyObject_Free(self._shape)
 * 
 */
    free(__pyx_v_self->data);

    /* "View.MemoryView":212
 *         if self.callback_free_data != NULL:
 *             self.callback_free_data(self.data)
 *         elif self.free_data:             # <<<<<<<<<<<<<<
 *             if self.dtype_is_object:
 *                 refcount_objects_in_slice(self.data, self._shape,
 */
  }
  __pyx_L3:;

  /* "View.MemoryView":217
 *                                           self._strides, self.ndim, False)
 *             free(self.data)
 *         PyObject_Free(self._shape)             # <<<<<<<<<<<<<<
 * 
 *     @property
 */
  PyObject_Free(__pyx_v_self->_shape);

  /* "View.MemoryView":209
 *     __pyx_getbuffer = capsule(<void *> &__pyx_array_getbuffer, "getbuffer(obj, view, flags)")
 * 
 *     def __dealloc__(array self):             # <<<<<<<<<<<<<<
 *         if self.callback_free_data != NULL:
 *             self.callback_free_data(self.data)
 */

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

/* "View.MemoryView":220
 * 
 *     @property
 *     def memview(self):             # <<<<<<<<<<<<<<
 *         return self.get_memview()
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_15View_dot_MemoryView_5array_7memview_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_15View_dot_MemoryView_5array_7memview_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_15View_dot_MemoryView_5array_7memview___get__(((struct __pyx_array_obj *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_15View_dot_MemoryView_5array_7memview___get__(struct __pyx_array_obj *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "View.MemoryView":221
 *     @property
 *     def memview(self):
 *         return self.get_memview()             # <<<<<<<<<<<<<<
 * 
 *     @cname('get_memview')
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = ((struct __pyx_vtabstruct_array *)__pyx_v_self->__pyx_vtab)->get_memview(__pyx_v_self); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 221, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "View.MemoryView":220
 * 
 *     @property
 *     def memview(self):             # <<<<<<<<<<<<<<
 *         return self.get_memview()
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("View.MemoryView.array.memview.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":224
 * 
 *     @cname('get_memview')
 *     cdef get_memview(self):             # <<<<<<<<<<<<<<
 *         flags =  PyBUF_ANY_CONTIGUOUS|PyBUF_FORMAT|PyBUF_WRITABLE
 *         return  memoryview(self, flags, self.dtype_is_object)
 */

static PyObject *__pyx_array_get_memview(struct __pyx_array_obj *__pyx_v_self) {
  int __pyx_v_flags;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("get_memview", 0);

  /* "View.MemoryView":225
 *     @cname('get_memview')
 *     cdef get_memview(self):
 *         flags =  PyBUF_ANY_CONTIGUOUS|PyBUF_FORMAT|PyBUF_WRITABLE             # <<<<<<<<<<<<<<
 *         return  memoryview(self, flags, self.dtype_is_object)
 * 
 */
  __pyx_v_flags = ((PyBUF_ANY_CONTIGUOUS | PyBUF_FORMAT) | PyBUF_WRITABLE);

  /* "View.MemoryView":226
 *     cdef get_memview(self):
 *         flags =  PyBUF_ANY_CONTIGUOUS|PyBUF_FORMAT|PyBUF_WRITABLE
 *         return  memoryview(self, flags, self.dtype_is_object)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_flags); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 226, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyBool_FromLong(__pyx_v_self->dtype_is_object); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 226, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = PyTuple_New(3); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 226, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
  PyTuple_SET_ITEM(__pyx_t_3, 0, ((PyObject *)__pyx_v_self));
  __Pyx_GIVEREF(__pyx_t_1);
  PyTuple_SET_ITEM(__pyx_t_3, 1, __pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_2);
  PyTuple_SET_ITEM(__pyx_t_3, 2, __pyx_t_2);
  __pyx_t_1 = 0;
  __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)__pyx_memoryview_type), __pyx_t_3, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 226, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "View.MemoryView":224
 * 
 *     @cname('get_memview')
 *     cdef get_memview(self):             # <<<<<<<<<<<<<<
 *         flags =  PyBUF_ANY_CONTIGUOUS|PyBUF_FORMAT|PyBUF_WRITABLE
 *         return  memoryview(self, flags, self.dtype_is_object)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("View.MemoryView.array.get_memview", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":229
 * 
 * 
 *     def __getattr__(self, attr):             # <<<<<<<<<<<<<<
 *         return getattr(self.memview, attr)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_array___getattr__(PyObject *__pyx_v_self, PyObject *__pyx_v_attr); /*proto*/
static PyObject *__pyx_array___getattr__(PyObject *__pyx_v_self, PyObject *__pyx_v_attr) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__getattr__ (wrapper)", 0);
  __pyx_r = __pyx_array___pyx_pf_15View_dot_MemoryView_5array_6__getattr__(((struct __pyx_array_obj *)__pyx_v_self), ((PyObject *)__pyx_v_attr));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_array___pyx_pf_15View_dot_MemoryView_5array_6__getattr__(struct __pyx_array_obj *__pyx_v_self, PyObject *__pyx_v_attr) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("__getattr__", 0);

  /* "View.MemoryView":230
 * 
 *     def __getattr__(self, attr):
 *         return getattr(self.memview, attr)             # <<<<<<<<<<<<<<
 * 
 *     def __getitem__(self, item):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_memview); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 230, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetAttr(__pyx_t_1, __pyx_v_attr); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 230, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "View.MemoryView":229
 * 
 * 
 *     def __getattr__(self, attr):             # <<<<<<<<<<<<<<
 *         return getattr(self.memview, attr)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("View.MemoryView.array.__getattr__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":232
 *         return getattr(self.memview, attr)
 * 
 *     def __getitem__(self, item):             # <<<<<<<<<<<<<<
 *         return self.memview[item]
 * 
 */

/* Python wrapper */
static PyObject *__pyx_array___getitem__(PyObject *__pyx_v_self, PyObject *__pyx_v_item); /*proto*/
static PyObject *__pyx_array___getitem__(PyObject *__pyx_v_self, PyObject *__pyx_v_item) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__getitem__ (wrapper)", 0);
  __pyx_r = __pyx_array___pyx_pf_15View_dot_MemoryView_5array_8__getitem__(((struct __pyx_array_obj *)__pyx_v_self), ((PyObject *)__pyx_v_item));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_array___pyx_pf_15View_dot_MemoryView_5array_8__getitem__(struct __pyx_array_obj *__pyx_v_self, PyObject *__pyx_v_item) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("__getitem__", 0);

  /* "View.MemoryView":233
 * 
 *     def __getitem__(self, item):
 *         return self.memview[item]             # <<<<<<<<<<<<<<
 * 
 *     def __setitem__(self, item, value):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_memview); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 233, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = PyObject_GetItem(__pyx_t_1, __pyx_v_item); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 233, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "View.MemoryView":232
 *         return getattr(self.memview, attr)
 * 
 *     def __getitem__(self, item):             # <<<<<<<<<<<<<<
 *         return self.memview[item]
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("View.MemoryView.array.__getitem__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":235
 *         return self.memview[item]
 * 
 *     def __setitem__(self, item, value):             # <<<<<<<<<<<<<<
 *         self.memview[item] = value
 * 
 */

/* Python wrapper */
static int __pyx_array___setitem__(PyObject *__pyx_v_self, PyObject *__pyx_v_item, PyObject *__pyx_v_value); /*proto*/
static int __pyx_array___setitem__(PyObject *__pyx_v_self, PyObject *__pyx_v_item, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__setitem__ (wrapper)", 0);
  __pyx_r = __pyx_array___pyx_pf_15View_dot_MemoryView_5array_10__setitem__(((struct __pyx_array_obj *)__pyx_v_self), ((PyObject *)__pyx_v_item), ((PyObject *)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_array___pyx_pf_15View_dot_MemoryView_5array_10__setitem__(struct __pyx_array_obj *__pyx_v_self, PyObject *__pyx_v_item, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("__setitem__", 0);

  /* "View.MemoryView":236
 * 
 *     def __setitem__(self, item, value):
 *         self.memview[item] = value             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_memview); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 236, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (unlikely(PyObject_SetItem(__pyx_t_1, __pyx_v_item, __pyx_v_value) < 0)) __PYX_ERR(2, 236, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "View.MemoryView":235
 *         return self.memview[item]
 * 
 *     def __setitem__(self, item, value):             # <<<<<<<<<<<<<<
 *         self.memview[item] = value
 * 
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("View.MemoryView.array.__setitem__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":240
 * 
 * @cname("__pyx_array_new")
 * cdef array array_cwrapper(tuple shape, Py_ssize_t itemsize, char *format,             # <<<<<<<<<<<<<<
 *                           char *mode, char *buf):
 *     cdef array result
 */

static struct __pyx_array_obj *__pyx_array_new(PyObject *__pyx_v_shape, Py_ssize_t __pyx_v_itemsize, char *__pyx_v_format, char *__pyx_v_mode, char *__pyx_v_buf) {
  struct __pyx_array_obj *__pyx_v_result = 0;
  struct __pyx_array_obj *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  __Pyx_RefNannySetupContext("array_cwrapper", 0);

  /* "View.MemoryView":244
 *     cdef array result
 * 
 *     if buf == NULL:             # <<<<<<<<<<<<<<
 *         result = array(shape, itemsize, format, mode.decode('ASCII'))
 *     else:
 */
  __pyx_t_1 = ((__pyx_v_buf == NULL) != 0);
  if (__pyx_t_1) {

    /* "View.MemoryView":245
 * 
 *     if buf == NULL:
 *         result = array(shape, itemsize, format, mode.decode('ASCII'))             # <<<<<<<<<<<<<<
 *     else:
 *         result = array(shape, itemsize, format, mode.decode('ASCII'),
 */
    __pyx_t_2 = PyInt_FromSsize_t(__pyx_v_itemsize); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 245, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_PyBytes_FromString(__pyx_v_format); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 245, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = __Pyx_decode_c_string(__pyx_v_mode, 0, strlen(__pyx_v_mode), NULL, NULL, PyUnicode_DecodeASCII); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 245, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_5 = PyTuple_New(4); if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 245, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_INCREF(__pyx_v_shape);
    __Pyx_GIVEREF(__pyx_v_shape);
    PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_v_shape);
    __Pyx_GIVEREF(__pyx_t_2);
    PyTuple_SET_ITEM(__pyx_t_5, 1, __pyx_t_2);
    __Pyx_GIVEREF(__pyx_t_3);
    PyTuple_SET_ITEM(__pyx_t_5, 2, __pyx_t_3);
    __Pyx_GIVEREF(__pyx_t_4);
    PyTuple_SET_ITEM(__pyx_t_5, 3, __pyx_t_4);
    __pyx_t_2 = 0;
    __pyx_t_3 = 0;
    __pyx_t_4 = 0;
    __pyx_t_4 = __Pyx_PyObject_Call(((PyObject *)__pyx_array_type), __pyx_t_5, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 245, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_v_result = ((struct __pyx_array_obj *)__pyx_t_4);
    __pyx_t_4 = 0;

    /* "View.MemoryView":244
 *     cdef array result
 * 
 *     if buf == NULL:             # <<<<<<<<<<<<<<
 *         result = array(shape, itemsize, format, mode.decode('ASCII'))
 *     else:
 */
    goto __pyx_L3;
  }

  /* "View.MemoryView":247
 *         result = array(shape, itemsize, format, mode.decode('ASCII'))
 *     else:
 *         result = array(shape, itemsize, format, mode.decode('ASCII'),             # <<<<<<<<<<<<<<
 *                        allocate_buffer=False)
 *         result.data = buf
 */
  /*else*/ {
    __pyx_t_4 = PyInt_FromSsize_t(__pyx_v_itemsize); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 247, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_5 = __Pyx_PyBytes_FromString(__pyx_v_format); if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 247, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_3 = __Pyx_decode_c_string(__pyx_v_mode, 0, strlen(__pyx_v_mode), NULL, NULL, PyUnicode_DecodeASCII); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 247, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_2 = PyTuple_New(4); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 247, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_INCREF(__pyx_v_shape);
    __Pyx_GIVEREF(__pyx_v_shape);
    PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_v_shape);
    __Pyx_GIVEREF(__pyx_t_4);
    PyTuple_SET_ITEM(__pyx_t_2, 1, __pyx_t_4);
    __Pyx_GIVEREF(__pyx_t_5);
    PyTuple_SET_ITEM(__pyx_t_2, 2, __pyx_t_5);
    __Pyx_GIVEREF(__pyx_t_3);
    PyTuple_SET_ITEM(__pyx_t_2, 3, __pyx_t_3);
    __pyx_t_4 = 0;
    __pyx_t_5 = 0;
    __pyx_t_3 = 0;

    /* "View.MemoryView":248
 *     else:
 *         result = array(shape, itemsize, format, mode.decode('ASCII'),
 *                        allocate_buffer=False)             # <<<<<<<<<<<<<<
 *         result.data = buf
 * 
 */
    __pyx_t_3 = PyDict_New(); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 248, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_allocate_buffer, Py_False) < 0) __PYX_ERR(2, 248, __pyx_L1_error)

    /* "View.MemoryView":247
 *         result = array(shape, itemsize, format, mode.decode('ASCII'))
 *     else:
 *         result = array(shape, itemsize, format, mode.decode('ASCII'),             # <<<<<<<<<<<<<<
 *                        allocate_buffer=False)
 *         result.data = buf
 */
    __pyx_t_5 = __Pyx_PyObject_Call(((PyObject *)__pyx_array_type), __pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 247, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_v_result = ((struct __pyx_array_obj *)__pyx_t_5);
    __pyx_t_5 = 0;

    /* "View.MemoryView":249
 *         result = array(shape, itemsize, format, mode.decode('ASCII'),
 *                        allocate_buffer=False)
 *         result.data = buf             # <<<<<<<<<<<<<<
 * 
 *     return result
 */
    __pyx_v_result->data = __pyx_v_buf;
  }
  __pyx_L3:;

  /* "View.MemoryView":251
 *         result.data = buf
 * 
 *     return result             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(((PyObject *)__pyx_r));
  __Pyx_INCREF(((PyObject *)__pyx_v_result));
  __pyx_r = __pyx_v_result;
  goto __pyx_L0;

  /* "View.MemoryView":240
 * 
 * @cname("__pyx_array_new")
 * cdef array array_cwrapper(tuple shape, Py_ssize_t itemsize, char *format,             # <<<<<<<<<<<<<<
 *                           char *mode, char *buf):
 *     cdef array result
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("View.MemoryView.array_cwrapper", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_result);
  __Pyx_XGIVEREF((PyObject *)__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":277
 * cdef class Enum(object):
 *     cdef object name
 *     def __init__(self, name):             # <<<<<<<<<<<<<<
 *         self.name = name
 *     def __repr__(self):
 */

/* Python wrapper */
static int __pyx_MemviewEnum___init__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static int __pyx_MemviewEnum___init__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_name = 0;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__init__ (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_name,0};
    PyObject* values[1] = {0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_name)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "__init__") < 0)) __PYX_ERR(2, 277, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 1) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
    }
    __pyx_v_name = values[0];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__init__", 1, 1, 1, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(2, 277, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("View.MemoryView.Enum.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return -1;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_MemviewEnum___pyx_pf_15View_dot_MemoryView_4Enum___init__(((struct __pyx_MemviewEnum_obj *)__pyx_v_self), __pyx_v_name);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_MemviewEnum___pyx_pf_15View_dot_MemoryView_4Enum___init__(struct __pyx_MemviewEnum_obj *__pyx_v_self, PyObject *__pyx_v_name) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__init__", 0);

  /* "View.MemoryView":278
 *     cdef object name
 *     def __init__(self, name):
 *         self.name = name             # <<<<<<<<<<<<<<
 *     def __repr__(self):
 *         return self.name
 */
  __Pyx_INCREF(__pyx_v_name);
  __Pyx_GIVEREF(__pyx_v_name);
  __Pyx_GOTREF(__pyx_v_self->name);
  __Pyx_DECREF(__pyx_v_self->name);
  __pyx_v_self->name = __pyx_v_name;

  /* "View.MemoryView":277
 * cdef class Enum(object):
 *     cdef object name
 *     def __init__(self, name):             # <<<<<<<<<<<<<<
 *         self.name = name
 *     def __repr__(self):
 */

  /* function exit code */
  __pyx_r = 0;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":279
 *     def __init__(self, name):
 *         self.name = name
 *     def __repr__(self):             # <<<<<<<<<<<<<<
 *         return self.name
 * 
 */

/* Python wrapper */
static PyObject *__pyx_MemviewEnum___repr__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_MemviewEnum___repr__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__repr__ (wrapper)", 0);
  __pyx_r = __pyx_MemviewEnum___pyx_pf_15View_dot_MemoryView_4Enum_2__repr__(((struct __pyx_MemviewEnum_obj *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_MemviewEnum___pyx_pf_15View_dot_MemoryView_4Enum_2__repr__(struct __pyx_MemviewEnum_obj *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__repr__", 0);

  /* "View.MemoryView":280
 *         self.name = name
 *     def __repr__(self):
 *         return self.name             # <<<<<<<<<<<<<<
 * 
 * cdef generic = Enum("<strided and direct or indirect>")
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_self->name);
  __pyx_r = __pyx_v_self->name;
  goto __pyx_L0;

  /* "View.MemoryView":279
 *     def __init__(self, name):
 *         self.name = name
 *     def __repr__(self):             # <<<<<<<<<<<<<<
 *         return self.name
 * 
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":294
 * 
 * @cname('__pyx_align_pointer')
 * cdef void *align_pointer(void *memory, size_t alignment) nogil:             # <<<<<<<<<<<<<<
 *     "Align pointer memory on a given boundary"
 *     cdef Py_intptr_t aligned_p = <Py_intptr_t> memory
 */

static void *__pyx_align_pointer(void *__pyx_v_memory, size_t __pyx_v_alignment) {
  Py_intptr_t __pyx_v_aligned_p;
  size_t __pyx_v_offset;
  void *__pyx_r;
  int __pyx_t_1;

  /* "View.MemoryView":296
 * cdef void *align_pointer(void *memory, size_t alignment) nogil:
 *     "Align pointer memory on a given boundary"
 *     cdef Py_intptr_t aligned_p = <Py_intptr_t> memory             # <<<<<<<<<<<<<<
 *     cdef size_t offset
 * 
 */
  __pyx_v_aligned_p = ((Py_intptr_t)__pyx_v_memory);

  /* "View.MemoryView":300
 * 
 *     with cython.cdivision(True):
 *         offset = aligned_p % alignment             # <<<<<<<<<<<<<<
 * 
 *     if offset > 0:
 */
  __pyx_v_offset = (__pyx_v_aligned_p % __pyx_v_alignment);

  /* "View.MemoryView":302
 *         offset = aligned_p % alignment
 * 
 *     if offset > 0:             # <<<<<<<<<<<<<<
 *         aligned_p += alignment - offset
 * 
 */
  __pyx_t_1 = ((__pyx_v_offset > 0) != 0);
  if (__pyx_t_1) {

    /* "View.MemoryView":303
 * 
 *     if offset > 0:
 *         aligned_p += alignment - offset             # <<<<<<<<<<<<<<
 * 
 *     return <void *> aligned_p
 */
    __pyx_v_aligned_p = (__pyx_v_aligned_p + (__pyx_v_alignment - __pyx_v_offset));

    /* "View.MemoryView":302
 *         offset = aligned_p % alignment
 * 
 *     if offset > 0:             # <<<<<<<<<<<<<<
 *         aligned_p += alignment - offset
 * 
 */
  }

  /* "View.MemoryView":305
 *         aligned_p += alignment - offset
 * 
 *     return <void *> aligned_p             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_r = ((void *)__pyx_v_aligned_p);
  goto __pyx_L0;

  /* "View.MemoryView":294
 * 
 * @cname('__pyx_align_pointer')
 * cdef void *align_pointer(void *memory, size_t alignment) nogil:             # <<<<<<<<<<<<<<
 *     "Align pointer memory on a given boundary"
 *     cdef Py_intptr_t aligned_p = <Py_intptr_t> memory
 */

  /* function exit code */
  __pyx_L0:;
  return __pyx_r;
}

/* "View.MemoryView":341
 *     cdef __Pyx_TypeInfo *typeinfo
 * 
 *     def __cinit__(memoryview self, object obj, int flags, bint dtype_is_object=False):             # <<<<<<<<<<<<<<
 *         self.obj = obj
 *         self.flags = flags
 */

/* Python wrapper */
static int __pyx_memoryview___cinit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static int __pyx_memoryview___cinit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_obj = 0;
  int __pyx_v_flags;
  int __pyx_v_dtype_is_object;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__cinit__ (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_obj,&__pyx_n_s_flags,&__pyx_n_s_dtype_is_object,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_obj)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_flags)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("__cinit__", 0, 2, 3, 1); __PYX_ERR(2, 341, __pyx_L3_error)
        }
        case  2:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_dtype_is_object);
          if (value) { values[2] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "__cinit__") < 0)) __PYX_ERR(2, 341, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_obj = values[0];
    __pyx_v_flags = __Pyx_PyInt_As_int(values[1]); if (unlikely((__pyx_v_flags == (int)-1) && PyErr_Occurred())) __PYX_ERR(2, 341, __pyx_L3_error)
    if (values[2]) {
      __pyx_v_dtype_is_object = __Pyx_PyObject_IsTrue(values[2]); if (unlikely((__pyx_v_dtype_is_object == (int)-1) && PyErr_Occurred())) __PYX_ERR(2, 341, __pyx_L3_error)
    } else {
      __pyx_v_dtype_is_object = ((int)0);
    }
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__cinit__", 0, 2, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(2, 341, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("View.MemoryView.memoryview.__cinit__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return -1;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview___cinit__(((struct __pyx_memoryview_obj *)__pyx_v_self), __pyx_v_obj, __pyx_v_flags, __pyx_v_dtype_is_object);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview___cinit__(struct __pyx_memoryview_obj *__pyx_v_self, PyObject *__pyx_v_obj, int __pyx_v_flags, int __pyx_v_dtype_is_object) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  int __pyx_t_3;
  int __pyx_t_4;
  __Pyx_RefNannySetupContext("__cinit__", 0);

  /* "View.MemoryView":342
 * 
 *     def __cinit__(memoryview self, object obj, int flags, bint dtype_is_object=False):
 *         self.obj = obj             # <<<<<<<<<<<<<<
 *         self.flags = flags
 *         if type(self) is memoryview or obj is not None:
 */
  __Pyx_INCREF(__pyx_v_obj);
  __Pyx_GIVEREF(__pyx_v_obj);
  __Pyx_GOTREF(__pyx_v_self->obj);
  __Pyx_DECREF(__pyx_v_self->obj);
  __pyx_v_self->obj = __pyx_v_obj;

  /* "View.MemoryView":343
 *     def __cinit__(memoryview self, object obj, int flags, bint dtype_is_object=False):
 *         self.obj = obj
 *         self.flags = flags             # <<<<<<<<<<<<<<
 *         if type(self) is memoryview or obj is not None:
 *             __Pyx_GetBuffer(obj, &self.view, flags)
 */
  __pyx_v_self->flags = __pyx_v_flags;

  /* "View.MemoryView":344
 *         self.obj = obj
 *         self.flags = flags
 *         if type(self) is memoryview or obj is not None:             # <<<<<<<<<<<<<<
 *             __Pyx_GetBuffer(obj, &self.view, flags)
 *             if <PyObject *> self.view.obj == NULL:
 */
  __pyx_t_2 = (((PyObject *)Py_TYPE(((PyObject *)__pyx_v_self))) == ((PyObject *)__pyx_memoryview_type));
  __pyx_t_3 = (__pyx_t_2 != 0);
  if (!__pyx_t_3) {
  } else {
    __pyx_t_1 = __pyx_t_3;
    goto __pyx_L4_bool_binop_done;
  }
  __pyx_t_3 = (__pyx_v_obj != Py_None);
  __pyx_t_2 = (__pyx_t_3 != 0);
  __pyx_t_1 = __pyx_t_2;
  __pyx_L4_bool_binop_done:;
  if (__pyx_t_1) {

    /* "View.MemoryView":345
 *         self.flags = flags
 *         if type(self) is memoryview or obj is not None:
 *             __Pyx_GetBuffer(obj, &self.view, flags)             # <<<<<<<<<<<<<<
 *             if <PyObject *> self.view.obj == NULL:
 *                 (<__pyx_buffer *> &self.view).obj = Py_None
 */
    __pyx_t_4 = __Pyx_GetBuffer(__pyx_v_obj, (&__pyx_v_self->view), __pyx_v_flags); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(2, 345, __pyx_L1_error)

    /* "View.MemoryView":346
 *         if type(self) is memoryview or obj is not None:
 *             __Pyx_GetBuffer(obj, &self.view, flags)
 *             if <PyObject *> self.view.obj == NULL:             # <<<<<<<<<<<<<<
 *                 (<__pyx_buffer *> &self.view).obj = Py_None
 *                 Py_INCREF(Py_None)
 */
    __pyx_t_1 = ((((PyObject *)__pyx_v_self->view.obj) == NULL) != 0);
    if (__pyx_t_1) {

      /* "View.MemoryView":347
 *             __Pyx_GetBuffer(obj, &self.view, flags)
 *             if <PyObject *> self.view.obj == NULL:
 *                 (<__pyx_buffer *> &self.view).obj = Py_None             # <<<<<<<<<<<<<<
 *                 Py_INCREF(Py_None)
 * 
 */
      ((Py_buffer *)(&__pyx_v_self->view))->obj = Py_None;

      /* "View.MemoryView":348
 *             if <PyObject *> self.view.obj == NULL:
 *                 (<__pyx_buffer *> &self.view).obj = Py_None
 *                 Py_INCREF(Py_None)             # <<<<<<<<<<<<<<
 * 
 *         global __pyx_memoryview_thread_locks_used
 */
      Py_INCREF(Py_None);

      /* "View.MemoryView":346
 *         if type(self) is memoryview or obj is not None:
 *             __Pyx_GetBuffer(obj, &self.view, flags)
 *             if <PyObject *> self.view.obj == NULL:             # <<<<<<<<<<<<<<
 *                 (<__pyx_buffer *> &self.view).obj = Py_None
 *                 Py_INCREF(Py_None)
 */
    }

    /* "View.MemoryView":344
 *         self.obj = obj
 *         self.flags = flags
 *         if type(self) is memoryview or obj is not None:             # <<<<<<<<<<<<<<
 *             __Pyx_GetBuffer(obj, &self.view, flags)
 *             if <PyObject *> self.view.obj == NULL:
 */
  }

  /* "View.MemoryView":351
 * 
 *         global __pyx_memoryview_thread_locks_used
 *         if __pyx_memoryview_thread_locks_used < THREAD_LOCKS_PREALLOCATED:             # <<<<<<<<<<<<<<
 *             self.lock = __pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used]
 *             __pyx_memoryview_thread_locks_used += 1
 */
  __pyx_t_1 = ((__pyx_memoryview_thread_locks_used < 8) != 0);
  if (__pyx_t_1) {

    /* "View.MemoryView":352
 *         global __pyx_memoryview_thread_locks_used
 *         if __pyx_memoryview_thread_locks_used < THREAD_LOCKS_PREALLOCATED:
 *             self.lock = __pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used]             # <<<<<<<<<<<<<<
 *             __pyx_memoryview_thread_locks_used += 1
 *         if self.lock is NULL:
 */
    __pyx_v_self->lock = (__pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used]);

    /* "View.MemoryView":353
 *         if __pyx_memoryview_thread_locks_used < THREAD_LOCKS_PREALLOCATED:
 *             self.lock = __pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used]
 *             __pyx_memoryview_thread_locks_used += 1             # <<<<<<<<<<<<<<
 *         if self.lock is NULL:
 *             self.lock = PyThread_allocate_lock()
 */
    __pyx_memoryview_thread_locks_used = (__pyx_memoryview_thread_locks_used + 1);

    /* "View.MemoryView":351
 * 
 *         global __pyx_memoryview_thread_locks_used
 *         if __pyx_memoryview_thread_locks_used < THREAD_LOCKS_PREALLOCATED:             # <<<<<<<<<<<<<<
 *             self.lock = __pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used]
 *             __pyx_memoryview_thread_locks_used += 1
 */
  }

  /* "View.MemoryView":354
 *             self.lock = __pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used]
 *             __pyx_memoryview_thread_locks_used += 1
 *         if self.lock is NULL:             # <<<<<<<<<<<<<<
 *             self.lock = PyThread_allocate_lock()
 *             if self.lock is NULL:
 */
  __pyx_t_1 = ((__pyx_v_self->lock == NULL) != 0);
  if (__pyx_t_1) {

    /* "View.MemoryView":355
 *             __pyx_memoryview_thread_locks_used += 1
 *         if self.lock is NULL:
 *             self.lock = PyThread_allocate_lock()             # <<<<<<<<<<<<<<
 *             if self.lock is NULL:
 *                 raise MemoryError
 */
    __pyx_v_self->lock = PyThread_allocate_lock();

    /* "View.MemoryView":356
 *         if self.lock is NULL:
 *             self.lock = PyThread_allocate_lock()
 *             if self.lock is NULL:             # <<<<<<<<<<<<<<
 *                 raise MemoryError
 * 
 */
    __pyx_t_1 = ((__pyx_v_self->lock == NULL) != 0);
    if (__pyx_t_1) {

      /* "View.MemoryView":357
 *             self.lock = PyThread_allocate_lock()
 *             if self.lock is NULL:
 *                 raise MemoryError             # <<<<<<<<<<<<<<
 * 
 *         if flags & PyBUF_FORMAT:
 */
      PyErr_NoMemory(); __PYX_ERR(2, 357, __pyx_L1_error)

      /* "View.MemoryView":356
 *         if self.lock is NULL:
 *             self.lock = PyThread_allocate_lock()
 *             if self.lock is NULL:             # <<<<<<<<<<<<<<
 *                 raise MemoryError
 * 
 */
    }

    /* "View.MemoryView":354
 *             self.lock = __pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used]
 *             __pyx_memoryview_thread_locks_used += 1
 *         if self.lock is NULL:             # <<<<<<<<<<<<<<
 *             self.lock = PyThread_allocate_lock()
 *             if self.lock is NULL:
 */
  }

  /* "View.MemoryView":359
 *                 raise MemoryError
 * 
 *         if flags & PyBUF_FORMAT:             # <<<<<<<<<<<<<<
 *             self.dtype_is_object = (self.view.format[0] == b'O' and self.view.format[1] == b'\0')
 *         else:
 */
  __pyx_t_1 = ((__pyx_v_flags & PyBUF_FORMAT) != 0);
  if (__pyx_t_1) {

    /* "View.MemoryView":360
 * 
 *         if flags & PyBUF_FORMAT:
 *             self.dtype_is_object = (self.view.format[0] == b'O' and self.view.format[1] == b'\0')             # <<<<<<<<<<<<<<
 *         else:
 *             self.dtype_is_object = dtype_is_object
 */
    __pyx_t_2 = (((__pyx_v_self->view.format[0]) == 'O') != 0);
    if (__pyx_t_2) {
    } else {
      __pyx_t_1 = __pyx_t_2;
      goto __pyx_L11_bool_binop_done;
    }
    __pyx_t_2 = (((__pyx_v_self->view.format[1]) == '\x00') != 0);
    __pyx_t_1 = __pyx_t_2;
    __pyx_L11_bool_binop_done:;
    __pyx_v_self->dtype_is_object = __pyx_t_1;

    /* "View.MemoryView":359
 *                 raise MemoryError
 * 
 *         if flags & PyBUF_FORMAT:             # <<<<<<<<<<<<<<
 *             self.dtype_is_object = (self.view.format[0] == b'O' and self.view.format[1] == b'\0')
 *         else:
 */
    goto __pyx_L10;
  }

  /* "View.MemoryView":362
 *             self.dtype_is_object = (self.view.format[0] == b'O' and self.view.format[1] == b'\0')
 *         else:
 *             self.dtype_is_object = dtype_is_object             # <<<<<<<<<<<<<<
 * 
 *         self.acquisition_count_aligned_p = <__pyx_atomic_int *> align_pointer(
 */
  /*else*/ {
    __pyx_v_self->dtype_is_object = __pyx_v_dtype_is_object;
  }
  __pyx_L10:;

  /* "View.MemoryView":364
 *             self.dtype_is_object = dtype_is_object
 * 
 *         self.acquisition_count_aligned_p = <__pyx_atomic_int *> align_pointer(             # <<<<<<<<<<<<<<
 *                   <void *> &self.acquisition_count[0], sizeof(__pyx_atomic_int))
 *         self.typeinfo = NULL
 */
  __pyx_v_self->acquisition_count_aligned_p = ((__pyx_atomic_int *)__pyx_align_pointer(((void *)(&(__pyx_v_self->acquisition_count[0]))), (sizeof(__pyx_atomic_int))));

  /* "View.MemoryView":366
 *         self.acquisition_count_aligned_p = <__pyx_atomic_int *> align_pointer(
 *                   <void *> &self.acquisition_count[0], sizeof(__pyx_atomic_int))
 *         self.typeinfo = NULL             # <<<<<<<<<<<<<<
 * 
 *     def __dealloc__(memoryview self):
 */
  __pyx_v_self->typeinfo = NULL;

  /* "View.MemoryView":341
 *     cdef __Pyx_TypeInfo *typeinfo
 * 
 *     def __cinit__(memoryview self, object obj, int flags, bint dtype_is_object=False):             # <<<<<<<<<<<<<<
 *         self.obj = obj
 *         self.flags = flags
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_AddTraceback("View.MemoryView.memoryview.__cinit__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":368
 *         self.typeinfo = NULL
 * 
 *     def __dealloc__(memoryview self):             # <<<<<<<<<<<<<<
 *         if self.obj is not None:
 *             __Pyx_ReleaseBuffer(&self.view)
 */

/* Python wrapper */
static void __pyx_memoryview___dealloc__(PyObject *__pyx_v_self); /*proto*/
static void __pyx_memoryview___dealloc__(PyObject *__pyx_v_self) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__dealloc__ (wrapper)", 0);
  __pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_2__dealloc__(((struct __pyx_memoryview_obj *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

static void __pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_2__dealloc__(struct __pyx_memoryview_obj *__pyx_v_self) {
  int __pyx_v_i;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  int __pyx_t_3;
  int __pyx_t_4;
  PyThread_type_lock __pyx_t_5;
  PyThread_type_lock __pyx_t_6;
  __Pyx_RefNannySetupContext("__dealloc__", 0);

  /* "View.MemoryView":369
 * 
 *     def __dealloc__(memoryview self):
 *         if self.obj is not None:             # <<<<<<<<<<<<<<
 *             __Pyx_ReleaseBuffer(&self.view)
 * 
 */
  __pyx_t_1 = (__pyx_v_self->obj != Py_None);
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "View.MemoryView":370
 *     def __dealloc__(memoryview self):
 *         if self.obj is not None:
 *             __Pyx_ReleaseBuffer(&self.view)             # <<<<<<<<<<<<<<
 * 
 *         cdef int i
 */
    __Pyx_ReleaseBuffer((&__pyx_v_self->view));

    /* "View.MemoryView":369
 * 
 *     def __dealloc__(memoryview self):
 *         if self.obj is not None:             # <<<<<<<<<<<<<<
 *             __Pyx_ReleaseBuffer(&self.view)
 * 
 */
  }

  /* "View.MemoryView":374
 *         cdef int i
 *         global __pyx_memoryview_thread_locks_used
 *         if self.lock != NULL:             # <<<<<<<<<<<<<<
 *             for i in range(__pyx_memoryview_thread_locks_used):
 *                 if __pyx_memoryview_thread_locks[i] is self.lock:
 */
  __pyx_t_2 = ((__pyx_v_self->lock != NULL) != 0);
  if (__pyx_t_2) {

    /* "View.MemoryView":375
 *         global __pyx_memoryview_thread_locks_used
 *         if self.lock != NULL:
 *             for i in range(__pyx_memoryview_thread_locks_used):             # <<<<<<<<<<<<<<
 *                 if __pyx_memoryview_thread_locks[i] is self.lock:
 *                     __pyx_memoryview_thread_locks_used -= 1
 */
    __pyx_t_3 = __pyx_memoryview_thread_locks_used;
    for (__pyx_t_4 = 0; __pyx_t_4 < __pyx_t_3; __pyx_t_4+=1) {
      __pyx_v_i = __pyx_t_4;

      /* "View.MemoryView":376
 *         if self.lock != NULL:
 *             for i in range(__pyx_memoryview_thread_locks_used):
 *                 if __pyx_memoryview_thread_locks[i] is self.lock:             # <<<<<<<<<<<<<<
 *                     __pyx_memoryview_thread_locks_used -= 1
 *                     if i != __pyx_memoryview_thread_locks_used:
 */
      __pyx_t_2 = (((__pyx_memoryview_thread_locks[__pyx_v_i]) == __pyx_v_self->lock) != 0);
      if (__pyx_t_2) {

        /* "View.MemoryView":377
 *             for i in range(__pyx_memoryview_thread_locks_used):
 *                 if __pyx_memoryview_thread_locks[i] is self.lock:
 *                     __pyx_memoryview_thread_locks_used -= 1             # <<<<<<<<<<<<<<
 *                     if i != __pyx_memoryview_thread_locks_used:
 *                         __pyx_memoryview_thread_locks[i], __pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used] = (
 */
        __pyx_memoryview_thread_locks_used = (__pyx_memoryview_thread_locks_used - 1);

        /* "View.MemoryView":378
 *                 if __pyx_memoryview_thread_locks[i] is self.lock:
 *                     __pyx_memoryview_thread_locks_used -= 1
 *                     if i != __pyx_memoryview_thread_locks_used:             # <<<<<<<<<<<<<<
 *                         __pyx_memoryview_thread_locks[i], __pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used] = (
 *                             __pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used], __pyx_memoryview_thread_locks[i])
 */
        __pyx_t_2 = ((__pyx_v_i != __pyx_memoryview_thread_locks_used) != 0);
        if (__pyx_t_2) {

          /* "View.MemoryView":380
 *                     if i != __pyx_memoryview_thread_locks_used:
 *                         __pyx_memoryview_thread_locks[i], __pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used] = (
 *                             __pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used], __pyx_memoryview_thread_locks[i])             # <<<<<<<<<<<<<<
 *                     break
 *             else:
 */
          __pyx_t_5 = (__pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used]);
          __pyx_t_6 = (__pyx_memoryview_thread_locks[__pyx_v_i]);

          /* "View.MemoryView":379
 *                     __pyx_memoryview_thread_locks_used -= 1
 *                     if i != __pyx_memoryview_thread_locks_used:
 *                         __pyx_memoryview_thread_locks[i], __pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used] = (             # <<<<<<<<<<<<<<
 *                             __pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used], __pyx_memoryview_thread_locks[i])
 *                     break
 */
          (__pyx_memoryview_thread_locks[__pyx_v_i]) = __pyx_t_5;
          (__pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used]) = __pyx_t_6;

          /* "View.MemoryView":378
 *                 if __pyx_memoryview_thread_locks[i] is self.lock:
 *                     __pyx_memoryview_thread_locks_used -= 1
 *                     if i != __pyx_memoryview_thread_locks_used:             # <<<<<<<<<<<<<<
 *                         __pyx_memoryview_thread_locks[i], __pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used] = (
 *                             __pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used], __pyx_memoryview_thread_locks[i])
 */
        }

        /* "View.MemoryView":381
 *                         __pyx_memoryview_thread_locks[i], __pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used] = (
 *                             __pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used], __pyx_memoryview_thread_locks[i])
 *                     break             # <<<<<<<<<<<<<<
 *             else:
 *                 PyThread_free_lock(self.lock)
 */
        goto __pyx_L6_break;

        /* "View.MemoryView":376
 *         if self.lock != NULL:
 *             for i in range(__pyx_memoryview_thread_locks_used):
 *                 if __pyx_memoryview_thread_locks[i] is self.lock:             # <<<<<<<<<<<<<<
 *                     __pyx_memoryview_thread_locks_used -= 1
 *                     if i != __pyx_memoryview_thread_locks_used:
 */
      }
    }
    /*else*/ {

      /* "View.MemoryView":383
 *                     break
 *             else:
 *                 PyThread_free_lock(self.lock)             # <<<<<<<<<<<<<<
 * 
 *     cdef char *get_item_pointer(memoryview self, object index) except NULL:
 */
      PyThread_free_lock(__pyx_v_self->lock);
    }
    __pyx_L6_break:;

    /* "View.MemoryView":374
 *         cdef int i
 *         global __pyx_memoryview_thread_locks_used
 *         if self.lock != NULL:             # <<<<<<<<<<<<<<
 *             for i in range(__pyx_memoryview_thread_locks_used):
 *                 if __pyx_memoryview_thread_locks[i] is self.lock:
 */
  }

  /* "View.MemoryView":368
 *         self.typeinfo = NULL
 * 
 *     def __dealloc__(memoryview self):             # <<<<<<<<<<<<<<
 *         if self.obj is not None:
 *             __Pyx_ReleaseBuffer(&self.view)
 */

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

/* "View.MemoryView":385
 *                 PyThread_free_lock(self.lock)
 * 
 *     cdef char *get_item_pointer(memoryview self, object index) except NULL:             # <<<<<<<<<<<<<<
 *         cdef Py_ssize_t dim
 *         cdef char *itemp = <char *> self.view.buf
 */

static char *__pyx_memoryview_get_item_pointer(struct __pyx_memoryview_obj *__pyx_v_self, PyObject *__pyx_v_index) {
  Py_ssize_t __pyx_v_dim;
  char *__pyx_v_itemp;
  PyObject *__pyx_v_idx = NULL;
  char *__pyx_r;
  __Pyx_RefNannyDeclarations
  Py_ssize_t __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  Py_ssize_t __pyx_t_3;
  PyObject *(*__pyx_t_4)(PyObject *);
  PyObject *__pyx_t_5 = NULL;
  Py_ssize_t __pyx_t_6;
  char *__pyx_t_7;
  __Pyx_RefNannySetupContext("get_item_pointer", 0);

  /* "View.MemoryView":387
 *     cdef char *get_item_pointer(memoryview self, object index) except NULL:
 *         cdef Py_ssize_t dim
 *         cdef char *itemp = <char *> self.view.buf             # <<<<<<<<<<<<<<
 * 
 *         for dim, idx in enumerate(index):
 */
  __pyx_v_itemp = ((char *)__pyx_v_self->view.buf);

  /* "View.MemoryView":389
 *         cdef char *itemp = <char *> self.view.buf
 * 
 *         for dim, idx in enumerate(index):             # <<<<<<<<<<<<<<
 *             itemp = pybuffer_index(&self.view, itemp, idx, dim)
 * 
 */
  __pyx_t_1 = 0;
  if (likely(PyList_CheckExact(__pyx_v_index)) || PyTuple_CheckExact(__pyx_v_index)) {
    __pyx_t_2 = __pyx_v_index; __Pyx_INCREF(__pyx_t_2); __pyx_t_3 = 0;
    __pyx_t_4 = NULL;
  } else {
    __pyx_t_3 = -1; __pyx_t_2 = PyObject_GetIter(__pyx_v_index); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 389, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_4 = Py_TYPE(__pyx_t_2)->tp_iternext; if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 389, __pyx_L1_error)
  }
  for (;;) {
    if (likely(!__pyx_t_4)) {
      if (likely(PyList_CheckExact(__pyx_t_2))) {
        if (__pyx_t_3 >= PyList_GET_SIZE(__pyx_t_2)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_5 = PyList_GET_ITEM(__pyx_t_2, __pyx_t_3); __Pyx_INCREF(__pyx_t_5); __pyx_t_3++; if (unlikely(0 < 0)) __PYX_ERR(2, 389, __pyx_L1_error)
        #else
        __pyx_t_5 = PySequence_ITEM(__pyx_t_2, __pyx_t_3); __pyx_t_3++; if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 389, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
        #endif
      } else {
        if (__pyx_t_3 >= PyTuple_GET_SIZE(__pyx_t_2)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_5 = PyTuple_GET_ITEM(__pyx_t_2, __pyx_t_3); __Pyx_INCREF(__pyx_t_5); __pyx_t_3++; if (unlikely(0 < 0)) __PYX_ERR(2, 389, __pyx_L1_error)
        #else
        __pyx_t_5 = PySequence_ITEM(__pyx_t_2, __pyx_t_3); __pyx_t_3++; if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 389, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
        #endif
      }
    } else {
      __pyx_t_5 = __pyx_t_4(__pyx_t_2);
      if (unlikely(!__pyx_t_5)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(exc_type == PyExc_StopIteration || PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(2, 389, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_5);
    }
    __Pyx_XDECREF_SET(__pyx_v_idx, __pyx_t_5);
    __pyx_t_5 = 0;
    __pyx_v_dim = __pyx_t_1;
    __pyx_t_1 = (__pyx_t_1 + 1);

    /* "View.MemoryView":390
 * 
 *         for dim, idx in enumerate(index):
 *             itemp = pybuffer_index(&self.view, itemp, idx, dim)             # <<<<<<<<<<<<<<
 * 
 *         return itemp
 */
    __pyx_t_6 = __Pyx_PyIndex_AsSsize_t(__pyx_v_idx); if (unlikely((__pyx_t_6 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(2, 390, __pyx_L1_error)
    __pyx_t_7 = __pyx_pybuffer_index((&__pyx_v_self->view), __pyx_v_itemp, __pyx_t_6, __pyx_v_dim); if (unlikely(__pyx_t_7 == NULL)) __PYX_ERR(2, 390, __pyx_L1_error)
    __pyx_v_itemp = __pyx_t_7;

    /* "View.MemoryView":389
 *         cdef char *itemp = <char *> self.view.buf
 * 
 *         for dim, idx in enumerate(index):             # <<<<<<<<<<<<<<
 *             itemp = pybuffer_index(&self.view, itemp, idx, dim)
 * 
 */
  }
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "View.MemoryView":392
 *             itemp = pybuffer_index(&self.view, itemp, idx, dim)
 * 
 *         return itemp             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_r = __pyx_v_itemp;
  goto __pyx_L0;

  /* "View.MemoryView":385
 *                 PyThread_free_lock(self.lock)
 * 
 *     cdef char *get_item_pointer(memoryview self, object index) except NULL:             # <<<<<<<<<<<<<<
 *         cdef Py_ssize_t dim
 *         cdef char *itemp = <char *> self.view.buf
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("View.MemoryView.memoryview.get_item_pointer", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_idx);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":395
 * 
 * 
 *     def __getitem__(memoryview self, object index):             # <<<<<<<<<<<<<<
 *         if index is Ellipsis:
 *             return self
 */

/* Python wrapper */
static PyObject *__pyx_memoryview___getitem__(PyObject *__pyx_v_self, PyObject *__pyx_v_index); /*proto*/
static PyObject *__pyx_memoryview___getitem__(PyObject *__pyx_v_self, PyObject *__pyx_v_index) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__getitem__ (wrapper)", 0);
  __pyx_r = __pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_4__getitem__(((struct __pyx_memoryview_obj *)__pyx_v_self), ((PyObject *)__pyx_v_index));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_4__getitem__(struct __pyx_memoryview_obj *__pyx_v_self, PyObject *__pyx_v_index) {
  PyObject *__pyx_v_have_slices = NULL;
  PyObject *__pyx_v_indices = NULL;
  char *__pyx_v_itemp;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  char *__pyx_t_6;
  __Pyx_RefNannySetupContext("__getitem__", 0);

  /* "View.MemoryView":396
 * 
 *     def __getitem__(memoryview self, object index):
 *         if index is Ellipsis:             # <<<<<<<<<<<<<<
 *             return self
 * 
 */
  __pyx_t_1 = (__pyx_v_index == __pyx_builtin_Ellipsis);
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "View.MemoryView":397
 *     def __getitem__(memoryview self, object index):
 *         if index is Ellipsis:
 *             return self             # <<<<<<<<<<<<<<
 * 
 *         have_slices, indices = _unellipsify(index, self.view.ndim)
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(((PyObject *)__pyx_v_self));
    __pyx_r = ((PyObject *)__pyx_v_self);
    goto __pyx_L0;

    /* "View.MemoryView":396
 * 
 *     def __getitem__(memoryview self, object index):
 *         if index is Ellipsis:             # <<<<<<<<<<<<<<
 *             return self
 * 
 */
  }

  /* "View.MemoryView":399
 *             return self
 * 
 *         have_slices, indices = _unellipsify(index, self.view.ndim)             # <<<<<<<<<<<<<<
 * 
 *         cdef char *itemp
 */
  __pyx_t_3 = _unellipsify(__pyx_v_index, __pyx_v_self->view.ndim); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 399, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (likely(__pyx_t_3 != Py_None)) {
    PyObject* sequence = __pyx_t_3;
    #if !CYTHON_COMPILING_IN_PYPY
    Py_ssize_t size = Py_SIZE(sequence);
    #else
    Py_ssize_t size = PySequence_Size(sequence);
    #endif
    if (unlikely(size != 2)) {
      if (size > 2) __Pyx_RaiseTooManyValuesError(2);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(2, 399, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    __pyx_t_4 = PyTuple_GET_ITEM(sequence, 0); 
    __pyx_t_5 = PyTuple_GET_ITEM(sequence, 1); 
    __Pyx_INCREF(__pyx_t_4);
    __Pyx_INCREF(__pyx_t_5);
    #else
    __pyx_t_4 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 399, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_5 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 399, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    #endif
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __Pyx_RaiseNoneNotIterableError(); __PYX_ERR(2, 399, __pyx_L1_error)
  }
  __pyx_v_have_slices = __pyx_t_4;
  __pyx_t_4 = 0;
  __pyx_v_indices = __pyx_t_5;
  __pyx_t_5 = 0;

  /* "View.MemoryView":402
 * 
 *         cdef char *itemp
 *         if have_slices:             # <<<<<<<<<<<<<<
 *             return memview_slice(self, indices)
 *         else:
 */
  __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_v_have_slices); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(2, 402, __pyx_L1_error)
  if (__pyx_t_2) {

    /* "View.MemoryView":403
 *         cdef char *itemp
 *         if have_slices:
 *             return memview_slice(self, indices)             # <<<<<<<<<<<<<<
 *         else:
 *             itemp = self.get_item_pointer(indices)
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_3 = ((PyObject *)__pyx_memview_slice(__pyx_v_self, __pyx_v_indices)); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 403, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_r = __pyx_t_3;
    __pyx_t_3 = 0;
    goto __pyx_L0;

    /* "View.MemoryView":402
 * 
 *         cdef char *itemp
 *         if have_slices:             # <<<<<<<<<<<<<<
 *             return memview_slice(self, indices)
 *         else:
 */
  }

  /* "View.MemoryView":405
 *             return memview_slice(self, indices)
 *         else:
 *             itemp = self.get_item_pointer(indices)             # <<<<<<<<<<<<<<
 *             return self.convert_item_to_object(itemp)
 * 
 */
  /*else*/ {
    __pyx_t_6 = ((struct __pyx_vtabstruct_memoryview *)__pyx_v_self->__pyx_vtab)->get_item_pointer(__pyx_v_self, __pyx_v_indices); if (unlikely(__pyx_t_6 == NULL)) __PYX_ERR(2, 405, __pyx_L1_error)
    __pyx_v_itemp = __pyx_t_6;

    /* "View.MemoryView":406
 *         else:
 *             itemp = self.get_item_pointer(indices)
 *             return self.convert_item_to_object(itemp)             # <<<<<<<<<<<<<<
 * 
 *     def __setitem__(memoryview self, object index, object value):
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_3 = ((struct __pyx_vtabstruct_memoryview *)__pyx_v_self->__pyx_vtab)->convert_item_to_object(__pyx_v_self, __pyx_v_itemp); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 406, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_r = __pyx_t_3;
    __pyx_t_3 = 0;
    goto __pyx_L0;
  }

  /* "View.MemoryView":395
 * 
 * 
 *     def __getitem__(memoryview self, object index):             # <<<<<<<<<<<<<<
 *         if index is Ellipsis:
 *             return self
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("View.MemoryView.memoryview.__getitem__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_have_slices);
  __Pyx_XDECREF(__pyx_v_indices);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":408
 *             return self.convert_item_to_object(itemp)
 * 
 *     def __setitem__(memoryview self, object index, object value):             # <<<<<<<<<<<<<<
 *         have_slices, index = _unellipsify(index, self.view.ndim)
 * 
 */

/* Python wrapper */
static int __pyx_memoryview___setitem__(PyObject *__pyx_v_self, PyObject *__pyx_v_index, PyObject *__pyx_v_value); /*proto*/
static int __pyx_memoryview___setitem__(PyObject *__pyx_v_self, PyObject *__pyx_v_index, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__setitem__ (wrapper)", 0);
  __pyx_r = __pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_6__setitem__(((struct __pyx_memoryview_obj *)__pyx_v_self), ((PyObject *)__pyx_v_index), ((PyObject *)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_6__setitem__(struct __pyx_memoryview_obj *__pyx_v_self, PyObject *__pyx_v_index, PyObject *__pyx_v_value) {
  PyObject *__pyx_v_have_slices = NULL;
  PyObject *__pyx_v_obj = NULL;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  __Pyx_RefNannySetupContext("__setitem__", 0);
  __Pyx_INCREF(__pyx_v_index);

  /* "View.MemoryView":409
 * 
 *     def __setitem__(memoryview self, object index, object value):
 *         have_slices, index = _unellipsify(index, self.view.ndim)             # <<<<<<<<<<<<<<
 * 
 *         if have_slices:
 */
  __pyx_t_1 = _unellipsify(__pyx_v_index, __pyx_v_self->view.ndim); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 409, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (likely(__pyx_t_1 != Py_None)) {
    PyObject* sequence = __pyx_t_1;
    #if !CYTHON_COMPILING_IN_PYPY
    Py_ssize_t size = Py_SIZE(sequence);
    #else
    Py_ssize_t size = PySequence_Size(sequence);
    #endif
    if (unlikely(size != 2)) {
      if (size > 2) __Pyx_RaiseTooManyValuesError(2);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(2, 409, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    __pyx_t_2 = PyTuple_GET_ITEM(sequence, 0); 
    __pyx_t_3 = PyTuple_GET_ITEM(sequence, 1); 
    __Pyx_INCREF(__pyx_t_2);
    __Pyx_INCREF(__pyx_t_3);
    #else
    __pyx_t_2 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 409, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 409, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    #endif
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  } else {
    __Pyx_RaiseNoneNotIterableError(); __PYX_ERR(2, 409, __pyx_L1_error)
  }
  __pyx_v_have_slices = __pyx_t_2;
  __pyx_t_2 = 0;
  __Pyx_DECREF_SET(__pyx_v_index, __pyx_t_3);
  __pyx_t_3 = 0;

  /* "View.MemoryView":411
 *         have_slices, index = _unellipsify(index, self.view.ndim)
 * 
 *         if have_slices:             # <<<<<<<<<<<<<<
 *             obj = self.is_slice(value)
 *             if obj:
 */
  __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_v_have_slices); if (unlikely(__pyx_t_4 < 0)) __PYX_ERR(2, 411, __pyx_L1_error)
  if (__pyx_t_4) {

    /* "View.MemoryView":412
 * 
 *         if have_slices:
 *             obj = self.is_slice(value)             # <<<<<<<<<<<<<<
 *             if obj:
 *                 self.setitem_slice_assignment(self[index], obj)
 */
    __pyx_t_1 = ((struct __pyx_vtabstruct_memoryview *)__pyx_v_self->__pyx_vtab)->is_slice(__pyx_v_self, __pyx_v_value); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 412, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_v_obj = __pyx_t_1;
    __pyx_t_1 = 0;

    /* "View.MemoryView":413
 *         if have_slices:
 *             obj = self.is_slice(value)
 *             if obj:             # <<<<<<<<<<<<<<
 *                 self.setitem_slice_assignment(self[index], obj)
 *             else:
 */
    __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_v_obj); if (unlikely(__pyx_t_4 < 0)) __PYX_ERR(2, 413, __pyx_L1_error)
    if (__pyx_t_4) {

      /* "View.MemoryView":414
 *             obj = self.is_slice(value)
 *             if obj:
 *                 self.setitem_slice_assignment(self[index], obj)             # <<<<<<<<<<<<<<
 *             else:
 *                 self.setitem_slice_assign_scalar(self[index], value)
 */
      __pyx_t_1 = PyObject_GetItem(((PyObject *)__pyx_v_self), __pyx_v_index); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 414, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_3 = ((struct __pyx_vtabstruct_memoryview *)__pyx_v_self->__pyx_vtab)->setitem_slice_assignment(__pyx_v_self, __pyx_t_1, __pyx_v_obj); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 414, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

      /* "View.MemoryView":413
 *         if have_slices:
 *             obj = self.is_slice(value)
 *             if obj:             # <<<<<<<<<<<<<<
 *                 self.setitem_slice_assignment(self[index], obj)
 *             else:
 */
      goto __pyx_L4;
    }

    /* "View.MemoryView":416
 *                 self.setitem_slice_assignment(self[index], obj)
 *             else:
 *                 self.setitem_slice_assign_scalar(self[index], value)             # <<<<<<<<<<<<<<
 *         else:
 *             self.setitem_indexed(index, value)
 */
    /*else*/ {
      __pyx_t_3 = PyObject_GetItem(((PyObject *)__pyx_v_self), __pyx_v_index); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 416, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      if (!(likely(((__pyx_t_3) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_3, __pyx_memoryview_type))))) __PYX_ERR(2, 416, __pyx_L1_error)
      __pyx_t_1 = ((struct __pyx_vtabstruct_memoryview *)__pyx_v_self->__pyx_vtab)->setitem_slice_assign_scalar(__pyx_v_self, ((struct __pyx_memoryview_obj *)__pyx_t_3), __pyx_v_value); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 416, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    }
    __pyx_L4:;

    /* "View.MemoryView":411
 *         have_slices, index = _unellipsify(index, self.view.ndim)
 * 
 *         if have_slices:             # <<<<<<<<<<<<<<
 *             obj = self.is_slice(value)
 *             if obj:
 */
    goto __pyx_L3;
  }

  /* "View.MemoryView":418
 *                 self.setitem_slice_assign_scalar(self[index], value)
 *         else:
 *             self.setitem_indexed(index, value)             # <<<<<<<<<<<<<<
 * 
 *     cdef is_slice(self, obj):
 */
  /*else*/ {
    __pyx_t_1 = ((struct __pyx_vtabstruct_memoryview *)__pyx_v_self->__pyx_vtab)->setitem_indexed(__pyx_v_self, __pyx_v_index, __pyx_v_value); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 418, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }
  __pyx_L3:;

  /* "View.MemoryView":408
 *             return self.convert_item_to_object(itemp)
 * 
 *     def __setitem__(memoryview self, object index, object value):             # <<<<<<<<<<<<<<
 *         have_slices, index = _unellipsify(index, self.view.ndim)
 * 
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("View.MemoryView.memoryview.__setitem__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_have_slices);
  __Pyx_XDECREF(__pyx_v_obj);
  __Pyx_XDECREF(__pyx_v_index);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":420
 *             self.setitem_indexed(index, value)
 * 
 *     cdef is_slice(self, obj):             # <<<<<<<<<<<<<<
 *         if not isinstance(obj, memoryview):
 *             try:
 */

static PyObject *__pyx_memoryview_is_slice(struct __pyx_memoryview_obj *__pyx_v_self, PyObject *__pyx_v_obj) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  int __pyx_t_9;
  __Pyx_RefNannySetupContext("is_slice", 0);
  __Pyx_INCREF(__pyx_v_obj);

  /* "View.MemoryView":421
 * 
 *     cdef is_slice(self, obj):
 *         if not isinstance(obj, memoryview):             # <<<<<<<<<<<<<<
 *             try:
 *                 obj = memoryview(obj, self.flags|PyBUF_ANY_CONTIGUOUS,
 */
  __pyx_t_1 = __Pyx_TypeCheck(__pyx_v_obj, __pyx_memoryview_type); 
  __pyx_t_2 = ((!(__pyx_t_1 != 0)) != 0);
  if (__pyx_t_2) {

    /* "View.MemoryView":422
 *     cdef is_slice(self, obj):
 *         if not isinstance(obj, memoryview):
 *             try:             # <<<<<<<<<<<<<<
 *                 obj = memoryview(obj, self.flags|PyBUF_ANY_CONTIGUOUS,
 *                                  self.dtype_is_object)
 */
    {
      __Pyx_PyThreadState_declare
      __Pyx_PyThreadState_assign
      __Pyx_ExceptionSave(&__pyx_t_3, &__pyx_t_4, &__pyx_t_5);
      __Pyx_XGOTREF(__pyx_t_3);
      __Pyx_XGOTREF(__pyx_t_4);
      __Pyx_XGOTREF(__pyx_t_5);
      /*try:*/ {

        /* "View.MemoryView":423
 *         if not isinstance(obj, memoryview):
 *             try:
 *                 obj = memoryview(obj, self.flags|PyBUF_ANY_CONTIGUOUS,             # <<<<<<<<<<<<<<
 *                                  self.dtype_is_object)
 *             except TypeError:
 */
        __pyx_t_6 = __Pyx_PyInt_From_int((__pyx_v_self->flags | PyBUF_ANY_CONTIGUOUS)); if (unlikely(!__pyx_t_6)) __PYX_ERR(2, 423, __pyx_L4_error)
        __Pyx_GOTREF(__pyx_t_6);

        /* "View.MemoryView":424
 *             try:
 *                 obj = memoryview(obj, self.flags|PyBUF_ANY_CONTIGUOUS,
 *                                  self.dtype_is_object)             # <<<<<<<<<<<<<<
 *             except TypeError:
 *                 return None
 */
        __pyx_t_7 = __Pyx_PyBool_FromLong(__pyx_v_self->dtype_is_object); if (unlikely(!__pyx_t_7)) __PYX_ERR(2, 424, __pyx_L4_error)
        __Pyx_GOTREF(__pyx_t_7);

        /* "View.MemoryView":423
 *         if not isinstance(obj, memoryview):
 *             try:
 *                 obj = memoryview(obj, self.flags|PyBUF_ANY_CONTIGUOUS,             # <<<<<<<<<<<<<<
 *                                  self.dtype_is_object)
 *             except TypeError:
 */
        __pyx_t_8 = PyTuple_New(3); if (unlikely(!__pyx_t_8)) __PYX_ERR(2, 423, __pyx_L4_error)
        __Pyx_GOTREF(__pyx_t_8);
        __Pyx_INCREF(__pyx_v_obj);
        __Pyx_GIVEREF(__pyx_v_obj);
        PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_v_obj);
        __Pyx_GIVEREF(__pyx_t_6);
        PyTuple_SET_ITEM(__pyx_t_8, 1, __pyx_t_6);
        __Pyx_GIVEREF(__pyx_t_7);
        PyTuple_SET_ITEM(__pyx_t_8, 2, __pyx_t_7);
        __pyx_t_6 = 0;
        __pyx_t_7 = 0;
        __pyx_t_7 = __Pyx_PyObject_Call(((PyObject *)__pyx_memoryview_type), __pyx_t_8, NULL); if (unlikely(!__pyx_t_7)) __PYX_ERR(2, 423, __pyx_L4_error)
        __Pyx_GOTREF(__pyx_t_7);
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        __Pyx_DECREF_SET(__pyx_v_obj, __pyx_t_7);
        __pyx_t_7 = 0;

        /* "View.MemoryView":422
 *     cdef is_slice(self, obj):
 *         if not isinstance(obj, memoryview):
 *             try:             # <<<<<<<<<<<<<<
 *                 obj = memoryview(obj, self.flags|PyBUF_ANY_CONTIGUOUS,
 *                                  self.dtype_is_object)
 */
      }
      __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
      goto __pyx_L11_try_end;
      __pyx_L4_error:;
      __Pyx_PyThreadState_assign
      __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;

      /* "View.MemoryView":425
 *                 obj = memoryview(obj, self.flags|PyBUF_ANY_CONTIGUOUS,
 *                                  self.dtype_is_object)
 *             except TypeError:             # <<<<<<<<<<<<<<
 *                 return None
 * 
 */
      __pyx_t_9 = __Pyx_PyErr_ExceptionMatches(__pyx_builtin_TypeError);
      if (__pyx_t_9) {
        __Pyx_AddTraceback("View.MemoryView.memoryview.is_slice", __pyx_clineno, __pyx_lineno, __pyx_filename);
        if (__Pyx_GetException(&__pyx_t_7, &__pyx_t_8, &__pyx_t_6) < 0) __PYX_ERR(2, 425, __pyx_L6_except_error)
        __Pyx_GOTREF(__pyx_t_7);
        __Pyx_GOTREF(__pyx_t_8);
        __Pyx_GOTREF(__pyx_t_6);

        /* "View.MemoryView":426
 *                                  self.dtype_is_object)
 *             except TypeError:
 *                 return None             # <<<<<<<<<<<<<<
 * 
 *         return obj
 */
        __Pyx_XDECREF(__pyx_r);
        __Pyx_INCREF(Py_None);
        __pyx_r = Py_None;
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        goto __pyx_L7_except_return;
      }
      goto __pyx_L6_except_error;
      __pyx_L6_except_error:;

      /* "View.MemoryView":422
 *     cdef is_slice(self, obj):
 *         if not isinstance(obj, memoryview):
 *             try:             # <<<<<<<<<<<<<<
 *                 obj = memoryview(obj, self.flags|PyBUF_ANY_CONTIGUOUS,
 *                                  self.dtype_is_object)
 */
      __Pyx_PyThreadState_assign
      __Pyx_XGIVEREF(__pyx_t_3);
      __Pyx_XGIVEREF(__pyx_t_4);
      __Pyx_XGIVEREF(__pyx_t_5);
      __Pyx_ExceptionReset(__pyx_t_3, __pyx_t_4, __pyx_t_5);
      goto __pyx_L1_error;
      __pyx_L7_except_return:;
      __Pyx_PyThreadState_assign
      __Pyx_XGIVEREF(__pyx_t_3);
      __Pyx_XGIVEREF(__pyx_t_4);
      __Pyx_XGIVEREF(__pyx_t_5);
      __Pyx_ExceptionReset(__pyx_t_3, __pyx_t_4, __pyx_t_5);
      goto __pyx_L0;
      __pyx_L11_try_end:;
    }

    /* "View.MemoryView":421
 * 
 *     cdef is_slice(self, obj):
 *         if not isinstance(obj, memoryview):             # <<<<<<<<<<<<<<
 *             try:
 *                 obj = memoryview(obj, self.flags|PyBUF_ANY_CONTIGUOUS,
 */
  }

  /* "View.MemoryView":428
 *                 return None
 * 
 *         return obj             # <<<<<<<<<<<<<<
 * 
 *     cdef setitem_slice_assignment(self, dst, src):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_obj);
  __pyx_r = __pyx_v_obj;
  goto __pyx_L0;

  /* "View.MemoryView":420
 *             self.setitem_indexed(index, value)
 * 
 *     cdef is_slice(self, obj):             # <<<<<<<<<<<<<<
 *         if not isinstance(obj, memoryview):
 *             try:
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("View.MemoryView.memoryview.is_slice", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_obj);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":430
 *         return obj
 * 
 *     cdef setitem_slice_assignment(self, dst, src):             # <<<<<<<<<<<<<<
 *         cdef __Pyx_memviewslice dst_slice
 *         cdef __Pyx_memviewslice src_slice
 */

static PyObject *__pyx_memoryview_setitem_slice_assignment(struct __pyx_memoryview_obj *__pyx_v_self, PyObject *__pyx_v_dst, PyObject *__pyx_v_src) {
  __Pyx_memviewslice __pyx_v_dst_slice;
  __Pyx_memviewslice __pyx_v_src_slice;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  int __pyx_t_3;
  int __pyx_t_4;
  __Pyx_RefNannySetupContext("setitem_slice_assignment", 0);

  /* "View.MemoryView":434
 *         cdef __Pyx_memviewslice src_slice
 * 
 *         memoryview_copy_contents(get_slice_from_memview(src, &src_slice)[0],             # <<<<<<<<<<<<<<
 *                                  get_slice_from_memview(dst, &dst_slice)[0],
 *                                  src.ndim, dst.ndim, self.dtype_is_object)
 */
  if (!(likely(((__pyx_v_src) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_src, __pyx_memoryview_type))))) __PYX_ERR(2, 434, __pyx_L1_error)

  /* "View.MemoryView":435
 * 
 *         memoryview_copy_contents(get_slice_from_memview(src, &src_slice)[0],
 *                                  get_slice_from_memview(dst, &dst_slice)[0],             # <<<<<<<<<<<<<<
 *                                  src.ndim, dst.ndim, self.dtype_is_object)
 * 
 */
  if (!(likely(((__pyx_v_dst) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_dst, __pyx_memoryview_type))))) __PYX_ERR(2, 435, __pyx_L1_error)

  /* "View.MemoryView":436
 *         memoryview_copy_contents(get_slice_from_memview(src, &src_slice)[0],
 *                                  get_slice_from_memview(dst, &dst_slice)[0],
 *                                  src.ndim, dst.ndim, self.dtype_is_object)             # <<<<<<<<<<<<<<
 * 
 *     cdef setitem_slice_assign_scalar(self, memoryview dst, value):
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_src, __pyx_n_s_ndim); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 436, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_2 == (int)-1) && PyErr_Occurred())) __PYX_ERR(2, 436, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_dst, __pyx_n_s_ndim); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 436, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(2, 436, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "View.MemoryView":434
 *         cdef __Pyx_memviewslice src_slice
 * 
 *         memoryview_copy_contents(get_slice_from_memview(src, &src_slice)[0],             # <<<<<<<<<<<<<<
 *                                  get_slice_from_memview(dst, &dst_slice)[0],
 *                                  src.ndim, dst.ndim, self.dtype_is_object)
 */
  __pyx_t_4 = __pyx_memoryview_copy_contents((__pyx_memoryview_get_slice_from_memoryview(((struct __pyx_memoryview_obj *)__pyx_v_src), (&__pyx_v_src_slice))[0]), (__pyx_memoryview_get_slice_from_memoryview(((struct __pyx_memoryview_obj *)__pyx_v_dst), (&__pyx_v_dst_slice))[0]), __pyx_t_2, __pyx_t_3, __pyx_v_self->dtype_is_object); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(2, 434, __pyx_L1_error)

  /* "View.MemoryView":430
 *         return obj
 * 
 *     cdef setitem_slice_assignment(self, dst, src):             # <<<<<<<<<<<<<<
 *         cdef __Pyx_memviewslice dst_slice
 *         cdef __Pyx_memviewslice src_slice
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("View.MemoryView.memoryview.setitem_slice_assignment", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":438
 *                                  src.ndim, dst.ndim, self.dtype_is_object)
 * 
 *     cdef setitem_slice_assign_scalar(self, memoryview dst, value):             # <<<<<<<<<<<<<<
 *         cdef int array[128]
 *         cdef void *tmp = NULL
 */

static PyObject *__pyx_memoryview_setitem_slice_assign_scalar(struct __pyx_memoryview_obj *__pyx_v_self, struct __pyx_memoryview_obj *__pyx_v_dst, PyObject *__pyx_v_value) {
  int __pyx_v_array[0x80];
  void *__pyx_v_tmp;
  void *__pyx_v_item;
  __Pyx_memviewslice *__pyx_v_dst_slice;
  __Pyx_memviewslice __pyx_v_tmp_slice;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  int __pyx_t_4;
  char const *__pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  PyObject *__pyx_t_10 = NULL;
  PyObject *__pyx_t_11 = NULL;
  __Pyx_RefNannySetupContext("setitem_slice_assign_scalar", 0);

  /* "View.MemoryView":440
 *     cdef setitem_slice_assign_scalar(self, memoryview dst, value):
 *         cdef int array[128]
 *         cdef void *tmp = NULL             # <<<<<<<<<<<<<<
 *         cdef void *item
 * 
 */
  __pyx_v_tmp = NULL;

  /* "View.MemoryView":445
 *         cdef __Pyx_memviewslice *dst_slice
 *         cdef __Pyx_memviewslice tmp_slice
 *         dst_slice = get_slice_from_memview(dst, &tmp_slice)             # <<<<<<<<<<<<<<
 * 
 *         if <size_t>self.view.itemsize > sizeof(array):
 */
  __pyx_v_dst_slice = __pyx_memoryview_get_slice_from_memoryview(__pyx_v_dst, (&__pyx_v_tmp_slice));

  /* "View.MemoryView":447
 *         dst_slice = get_slice_from_memview(dst, &tmp_slice)
 * 
 *         if <size_t>self.view.itemsize > sizeof(array):             # <<<<<<<<<<<<<<
 *             tmp = PyMem_Malloc(self.view.itemsize)
 *             if tmp == NULL:
 */
  __pyx_t_1 = ((((size_t)__pyx_v_self->view.itemsize) > (sizeof(__pyx_v_array))) != 0);
  if (__pyx_t_1) {

    /* "View.MemoryView":448
 * 
 *         if <size_t>self.view.itemsize > sizeof(array):
 *             tmp = PyMem_Malloc(self.view.itemsize)             # <<<<<<<<<<<<<<
 *             if tmp == NULL:
 *                 raise MemoryError
 */
    __pyx_v_tmp = PyMem_Malloc(__pyx_v_self->view.itemsize);

    /* "View.MemoryView":449
 *         if <size_t>self.view.itemsize > sizeof(array):
 *             tmp = PyMem_Malloc(self.view.itemsize)
 *             if tmp == NULL:             # <<<<<<<<<<<<<<
 *                 raise MemoryError
 *             item = tmp
 */
    __pyx_t_1 = ((__pyx_v_tmp == NULL) != 0);
    if (__pyx_t_1) {

      /* "View.MemoryView":450
 *             tmp = PyMem_Malloc(self.view.itemsize)
 *             if tmp == NULL:
 *                 raise MemoryError             # <<<<<<<<<<<<<<
 *             item = tmp
 *         else:
 */
      PyErr_NoMemory(); __PYX_ERR(2, 450, __pyx_L1_error)

      /* "View.MemoryView":449
 *         if <size_t>self.view.itemsize > sizeof(array):
 *             tmp = PyMem_Malloc(self.view.itemsize)
 *             if tmp == NULL:             # <<<<<<<<<<<<<<
 *                 raise MemoryError
 *             item = tmp
 */
    }

    /* "View.MemoryView":451
 *             if tmp == NULL:
 *                 raise MemoryError
 *             item = tmp             # <<<<<<<<<<<<<<
 *         else:
 *             item = <void *> array
 */
    __pyx_v_item = __pyx_v_tmp;

    /* "View.MemoryView":447
 *         dst_slice = get_slice_from_memview(dst, &tmp_slice)
 * 
 *         if <size_t>self.view.itemsize > sizeof(array):             # <<<<<<<<<<<<<<
 *             tmp = PyMem_Malloc(self.view.itemsize)
 *             if tmp == NULL:
 */
    goto __pyx_L3;
  }

  /* "View.MemoryView":453
 *             item = tmp
 *         else:
 *             item = <void *> array             # <<<<<<<<<<<<<<
 * 
 *         try:
 */
  /*else*/ {
    __pyx_v_item = ((void *)__pyx_v_array);
  }
  __pyx_L3:;

  /* "View.MemoryView":455
 *             item = <void *> array
 * 
 *         try:             # <<<<<<<<<<<<<<
 *             if self.dtype_is_object:
 *                 (<PyObject **> item)[0] = <PyObject *> value
 */
  /*try:*/ {

    /* "View.MemoryView":456
 * 
 *         try:
 *             if self.dtype_is_object:             # <<<<<<<<<<<<<<
 *                 (<PyObject **> item)[0] = <PyObject *> value
 *             else:
 */
    __pyx_t_1 = (__pyx_v_self->dtype_is_object != 0);
    if (__pyx_t_1) {

      /* "View.MemoryView":457
 *         try:
 *             if self.dtype_is_object:
 *                 (<PyObject **> item)[0] = <PyObject *> value             # <<<<<<<<<<<<<<
 *             else:
 *                 self.assign_item_from_object(<char *> item, value)
 */
      (((PyObject **)__pyx_v_item)[0]) = ((PyObject *)__pyx_v_value);

      /* "View.MemoryView":456
 * 
 *         try:
 *             if self.dtype_is_object:             # <<<<<<<<<<<<<<
 *                 (<PyObject **> item)[0] = <PyObject *> value
 *             else:
 */
      goto __pyx_L8;
    }

    /* "View.MemoryView":459
 *                 (<PyObject **> item)[0] = <PyObject *> value
 *             else:
 *                 self.assign_item_from_object(<char *> item, value)             # <<<<<<<<<<<<<<
 * 
 * 
 */
    /*else*/ {
      __pyx_t_2 = ((struct __pyx_vtabstruct_memoryview *)__pyx_v_self->__pyx_vtab)->assign_item_from_object(__pyx_v_self, ((char *)__pyx_v_item), __pyx_v_value); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 459, __pyx_L6_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    }
    __pyx_L8:;

    /* "View.MemoryView":463
 * 
 * 
 *             if self.view.suboffsets != NULL:             # <<<<<<<<<<<<<<
 *                 assert_direct_dimensions(self.view.suboffsets, self.view.ndim)
 *             slice_assign_scalar(dst_slice, dst.view.ndim, self.view.itemsize,
 */
    __pyx_t_1 = ((__pyx_v_self->view.suboffsets != NULL) != 0);
    if (__pyx_t_1) {

      /* "View.MemoryView":464
 * 
 *             if self.view.suboffsets != NULL:
 *                 assert_direct_dimensions(self.view.suboffsets, self.view.ndim)             # <<<<<<<<<<<<<<
 *             slice_assign_scalar(dst_slice, dst.view.ndim, self.view.itemsize,
 *                                 item, self.dtype_is_object)
 */
      __pyx_t_2 = assert_direct_dimensions(__pyx_v_self->view.suboffsets, __pyx_v_self->view.ndim); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 464, __pyx_L6_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

      /* "View.MemoryView":463
 * 
 * 
 *             if self.view.suboffsets != NULL:             # <<<<<<<<<<<<<<
 *                 assert_direct_dimensions(self.view.suboffsets, self.view.ndim)
 *             slice_assign_scalar(dst_slice, dst.view.ndim, self.view.itemsize,
 */
    }

    /* "View.MemoryView":465
 *             if self.view.suboffsets != NULL:
 *                 assert_direct_dimensions(self.view.suboffsets, self.view.ndim)
 *             slice_assign_scalar(dst_slice, dst.view.ndim, self.view.itemsize,             # <<<<<<<<<<<<<<
 *                                 item, self.dtype_is_object)
 *         finally:
 */
    __pyx_memoryview_slice_assign_scalar(__pyx_v_dst_slice, __pyx_v_dst->view.ndim, __pyx_v_self->view.itemsize, __pyx_v_item, __pyx_v_self->dtype_is_object);
  }

  /* "View.MemoryView":468
 *                                 item, self.dtype_is_object)
 *         finally:
 *             PyMem_Free(tmp)             # <<<<<<<<<<<<<<
 * 
 *     cdef setitem_indexed(self, index, value):
 */
  /*finally:*/ {
    /*normal exit:*/{
      PyMem_Free(__pyx_v_tmp);
      goto __pyx_L7;
    }
    /*exception exit:*/{
      __Pyx_PyThreadState_declare
      __pyx_L6_error:;
      __pyx_t_6 = 0; __pyx_t_7 = 0; __pyx_t_8 = 0; __pyx_t_9 = 0; __pyx_t_10 = 0; __pyx_t_11 = 0;
      __Pyx_PyThreadState_assign
      __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
      if (PY_MAJOR_VERSION >= 3) __Pyx_ExceptionSwap(&__pyx_t_9, &__pyx_t_10, &__pyx_t_11);
      if ((PY_MAJOR_VERSION < 3) || unlikely(__Pyx_GetException(&__pyx_t_6, &__pyx_t_7, &__pyx_t_8) < 0)) __Pyx_ErrFetch(&__pyx_t_6, &__pyx_t_7, &__pyx_t_8);
      __Pyx_XGOTREF(__pyx_t_6);
      __Pyx_XGOTREF(__pyx_t_7);
      __Pyx_XGOTREF(__pyx_t_8);
      __Pyx_XGOTREF(__pyx_t_9);
      __Pyx_XGOTREF(__pyx_t_10);
      __Pyx_XGOTREF(__pyx_t_11);
      __pyx_t_3 = __pyx_lineno; __pyx_t_4 = __pyx_clineno; __pyx_t_5 = __pyx_filename;
      {
        PyMem_Free(__pyx_v_tmp);
      }
      __Pyx_PyThreadState_assign
      if (PY_MAJOR_VERSION >= 3) {
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_XGIVEREF(__pyx_t_10);
        __Pyx_XGIVEREF(__pyx_t_11);
        __Pyx_ExceptionReset(__pyx_t_9, __pyx_t_10, __pyx_t_11);
      }
      __Pyx_XGIVEREF(__pyx_t_6);
      __Pyx_XGIVEREF(__pyx_t_7);
      __Pyx_XGIVEREF(__pyx_t_8);
      __Pyx_ErrRestore(__pyx_t_6, __pyx_t_7, __pyx_t_8);
      __pyx_t_6 = 0; __pyx_t_7 = 0; __pyx_t_8 = 0; __pyx_t_9 = 0; __pyx_t_10 = 0; __pyx_t_11 = 0;
      __pyx_lineno = __pyx_t_3; __pyx_clineno = __pyx_t_4; __pyx_filename = __pyx_t_5;
      goto __pyx_L1_error;
    }
    __pyx_L7:;
  }

  /* "View.MemoryView":438
 *                                  src.ndim, dst.ndim, self.dtype_is_object)
 * 
 *     cdef setitem_slice_assign_scalar(self, memoryview dst, value):             # <<<<<<<<<<<<<<
 *         cdef int array[128]
 *         cdef void *tmp = NULL
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("View.MemoryView.memoryview.setitem_slice_assign_scalar", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":470
 *             PyMem_Free(tmp)
 * 
 *     cdef setitem_indexed(self, index, value):             # <<<<<<<<<<<<<<
 *         cdef char *itemp = self.get_item_pointer(index)
 *         self.assign_item_from_object(itemp, value)
 */

static PyObject *__pyx_memoryview_setitem_indexed(struct __pyx_memoryview_obj *__pyx_v_self, PyObject *__pyx_v_index, PyObject *__pyx_v_value) {
  char *__pyx_v_itemp;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  char *__pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("setitem_indexed", 0);

  /* "View.MemoryView":471
 * 
 *     cdef setitem_indexed(self, index, value):
 *         cdef char *itemp = self.get_item_pointer(index)             # <<<<<<<<<<<<<<
 *         self.assign_item_from_object(itemp, value)
 * 
 */
  __pyx_t_1 = ((struct __pyx_vtabstruct_memoryview *)__pyx_v_self->__pyx_vtab)->get_item_pointer(__pyx_v_self, __pyx_v_index); if (unlikely(__pyx_t_1 == NULL)) __PYX_ERR(2, 471, __pyx_L1_error)
  __pyx_v_itemp = __pyx_t_1;

  /* "View.MemoryView":472
 *     cdef setitem_indexed(self, index, value):
 *         cdef char *itemp = self.get_item_pointer(index)
 *         self.assign_item_from_object(itemp, value)             # <<<<<<<<<<<<<<
 * 
 *     cdef convert_item_to_object(self, char *itemp):
 */
  __pyx_t_2 = ((struct __pyx_vtabstruct_memoryview *)__pyx_v_self->__pyx_vtab)->assign_item_from_object(__pyx_v_self, __pyx_v_itemp, __pyx_v_value); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 472, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "View.MemoryView":470
 *             PyMem_Free(tmp)
 * 
 *     cdef setitem_indexed(self, index, value):             # <<<<<<<<<<<<<<
 *         cdef char *itemp = self.get_item_pointer(index)
 *         self.assign_item_from_object(itemp, value)
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("View.MemoryView.memoryview.setitem_indexed", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":474
 *         self.assign_item_from_object(itemp, value)
 * 
 *     cdef convert_item_to_object(self, char *itemp):             # <<<<<<<<<<<<<<
 *         """Only used if instantiated manually by the user, or if Cython doesn't
 *         know how to convert the type"""
 */

static PyObject *__pyx_memoryview_convert_item_to_object(struct __pyx_memoryview_obj *__pyx_v_self, char *__pyx_v_itemp) {
  PyObject *__pyx_v_struct = NULL;
  PyObject *__pyx_v_bytesitem = 0;
  PyObject *__pyx_v_result = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  int __pyx_t_8;
  PyObject *__pyx_t_9 = NULL;
  size_t __pyx_t_10;
  int __pyx_t_11;
  __Pyx_RefNannySetupContext("convert_item_to_object", 0);

  /* "View.MemoryView":477
 *         """Only used if instantiated manually by the user, or if Cython doesn't
 *         know how to convert the type"""
 *         import struct             # <<<<<<<<<<<<<<
 *         cdef bytes bytesitem
 * 
 */
  __pyx_t_1 = __Pyx_Import(__pyx_n_s_struct, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 477, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_struct = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "View.MemoryView":480
 *         cdef bytes bytesitem
 * 
 *         bytesitem = itemp[:self.view.itemsize]             # <<<<<<<<<<<<<<
 *         try:
 *             result = struct.unpack(self.view.format, bytesitem)
 */
  __pyx_t_1 = __Pyx_PyBytes_FromStringAndSize(__pyx_v_itemp + 0, __pyx_v_self->view.itemsize - 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 480, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_bytesitem = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "View.MemoryView":481
 * 
 *         bytesitem = itemp[:self.view.itemsize]
 *         try:             # <<<<<<<<<<<<<<
 *             result = struct.unpack(self.view.format, bytesitem)
 *         except struct.error:
 */
  {
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ExceptionSave(&__pyx_t_2, &__pyx_t_3, &__pyx_t_4);
    __Pyx_XGOTREF(__pyx_t_2);
    __Pyx_XGOTREF(__pyx_t_3);
    __Pyx_XGOTREF(__pyx_t_4);
    /*try:*/ {

      /* "View.MemoryView":482
 *         bytesitem = itemp[:self.view.itemsize]
 *         try:
 *             result = struct.unpack(self.view.format, bytesitem)             # <<<<<<<<<<<<<<
 *         except struct.error:
 *             raise ValueError("Unable to convert item to object")
 */
      __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_struct, __pyx_n_s_unpack); if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 482, __pyx_L3_error)
      __Pyx_GOTREF(__pyx_t_5);
      __pyx_t_6 = __Pyx_PyBytes_FromString(__pyx_v_self->view.format); if (unlikely(!__pyx_t_6)) __PYX_ERR(2, 482, __pyx_L3_error)
      __Pyx_GOTREF(__pyx_t_6);
      __pyx_t_7 = NULL;
      __pyx_t_8 = 0;
      if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_5))) {
        __pyx_t_7 = PyMethod_GET_SELF(__pyx_t_5);
        if (likely(__pyx_t_7)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
          __Pyx_INCREF(__pyx_t_7);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_5, function);
          __pyx_t_8 = 1;
        }
      }
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_5)) {
        PyObject *__pyx_temp[3] = {__pyx_t_7, __pyx_t_6, __pyx_v_bytesitem};
        __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_8, 2+__pyx_t_8); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 482, __pyx_L3_error)
        __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
        PyObject *__pyx_temp[3] = {__pyx_t_7, __pyx_t_6, __pyx_v_bytesitem};
        __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_8, 2+__pyx_t_8); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 482, __pyx_L3_error)
        __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      } else
      #endif
      {
        __pyx_t_9 = PyTuple_New(2+__pyx_t_8); if (unlikely(!__pyx_t_9)) __PYX_ERR(2, 482, __pyx_L3_error)
        __Pyx_GOTREF(__pyx_t_9);
        if (__pyx_t_7) {
          __Pyx_GIVEREF(__pyx_t_7); PyTuple_SET_ITEM(__pyx_t_9, 0, __pyx_t_7); __pyx_t_7 = NULL;
        }
        __Pyx_GIVEREF(__pyx_t_6);
        PyTuple_SET_ITEM(__pyx_t_9, 0+__pyx_t_8, __pyx_t_6);
        __Pyx_INCREF(__pyx_v_bytesitem);
        __Pyx_GIVEREF(__pyx_v_bytesitem);
        PyTuple_SET_ITEM(__pyx_t_9, 1+__pyx_t_8, __pyx_v_bytesitem);
        __pyx_t_6 = 0;
        __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_9, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 482, __pyx_L3_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      }
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __pyx_v_result = __pyx_t_1;
      __pyx_t_1 = 0;

      /* "View.MemoryView":481
 * 
 *         bytesitem = itemp[:self.view.itemsize]
 *         try:             # <<<<<<<<<<<<<<
 *             result = struct.unpack(self.view.format, bytesitem)
 *         except struct.error:
 */
    }

    /* "View.MemoryView":486
 *             raise ValueError("Unable to convert item to object")
 *         else:
 *             if len(self.view.format) == 1:             # <<<<<<<<<<<<<<
 *                 return result[0]
 *             return result
 */
    /*else:*/ {
      __pyx_t_10 = strlen(__pyx_v_self->view.format); 
      __pyx_t_11 = ((__pyx_t_10 == 1) != 0);
      if (__pyx_t_11) {

        /* "View.MemoryView":487
 *         else:
 *             if len(self.view.format) == 1:
 *                 return result[0]             # <<<<<<<<<<<<<<
 *             return result
 * 
 */
        __Pyx_XDECREF(__pyx_r);
        __pyx_t_1 = __Pyx_GetItemInt(__pyx_v_result, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 487, __pyx_L5_except_error)
        __Pyx_GOTREF(__pyx_t_1);
        __pyx_r = __pyx_t_1;
        __pyx_t_1 = 0;
        goto __pyx_L6_except_return;

        /* "View.MemoryView":486
 *             raise ValueError("Unable to convert item to object")
 *         else:
 *             if len(self.view.format) == 1:             # <<<<<<<<<<<<<<
 *                 return result[0]
 *             return result
 */
      }

      /* "View.MemoryView":488
 *             if len(self.view.format) == 1:
 *                 return result[0]
 *             return result             # <<<<<<<<<<<<<<
 * 
 *     cdef assign_item_from_object(self, char *itemp, object value):
 */
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_v_result);
      __pyx_r = __pyx_v_result;
      goto __pyx_L6_except_return;
    }
    __pyx_L3_error:;
    __Pyx_PyThreadState_assign
    __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
    __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "View.MemoryView":483
 *         try:
 *             result = struct.unpack(self.view.format, bytesitem)
 *         except struct.error:             # <<<<<<<<<<<<<<
 *             raise ValueError("Unable to convert item to object")
 *         else:
 */
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_struct, __pyx_n_s_error); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 483, __pyx_L5_except_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_8 = __Pyx_PyErr_ExceptionMatches(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    if (__pyx_t_8) {
      __Pyx_AddTraceback("View.MemoryView.memoryview.convert_item_to_object", __pyx_clineno, __pyx_lineno, __pyx_filename);
      if (__Pyx_GetException(&__pyx_t_1, &__pyx_t_5, &__pyx_t_9) < 0) __PYX_ERR(2, 483, __pyx_L5_except_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_GOTREF(__pyx_t_9);

      /* "View.MemoryView":484
 *             result = struct.unpack(self.view.format, bytesitem)
 *         except struct.error:
 *             raise ValueError("Unable to convert item to object")             # <<<<<<<<<<<<<<
 *         else:
 *             if len(self.view.format) == 1:
 */
      __pyx_t_6 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__50, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(2, 484, __pyx_L5_except_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_Raise(__pyx_t_6, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __PYX_ERR(2, 484, __pyx_L5_except_error)
    }
    goto __pyx_L5_except_error;
    __pyx_L5_except_error:;

    /* "View.MemoryView":481
 * 
 *         bytesitem = itemp[:self.view.itemsize]
 *         try:             # <<<<<<<<<<<<<<
 *             result = struct.unpack(self.view.format, bytesitem)
 *         except struct.error:
 */
    __Pyx_PyThreadState_assign
    __Pyx_XGIVEREF(__pyx_t_2);
    __Pyx_XGIVEREF(__pyx_t_3);
    __Pyx_XGIVEREF(__pyx_t_4);
    __Pyx_ExceptionReset(__pyx_t_2, __pyx_t_3, __pyx_t_4);
    goto __pyx_L1_error;
    __pyx_L6_except_return:;
    __Pyx_PyThreadState_assign
    __Pyx_XGIVEREF(__pyx_t_2);
    __Pyx_XGIVEREF(__pyx_t_3);
    __Pyx_XGIVEREF(__pyx_t_4);
    __Pyx_ExceptionReset(__pyx_t_2, __pyx_t_3, __pyx_t_4);
    goto __pyx_L0;
  }

  /* "View.MemoryView":474
 *         self.assign_item_from_object(itemp, value)
 * 
 *     cdef convert_item_to_object(self, char *itemp):             # <<<<<<<<<<<<<<
 *         """Only used if instantiated manually by the user, or if Cython doesn't
 *         know how to convert the type"""
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_AddTraceback("View.MemoryView.memoryview.convert_item_to_object", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_struct);
  __Pyx_XDECREF(__pyx_v_bytesitem);
  __Pyx_XDECREF(__pyx_v_result);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":490
 *             return result
 * 
 *     cdef assign_item_from_object(self, char *itemp, object value):             # <<<<<<<<<<<<<<
 *         """Only used if instantiated manually by the user, or if Cython doesn't
 *         know how to convert the type"""
 */

static PyObject *__pyx_memoryview_assign_item_from_object(struct __pyx_memoryview_obj *__pyx_v_self, char *__pyx_v_itemp, PyObject *__pyx_v_value) {
  PyObject *__pyx_v_struct = NULL;
  char __pyx_v_c;
  PyObject *__pyx_v_bytesvalue = 0;
  Py_ssize_t __pyx_v_i;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  int __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  int __pyx_t_7;
  PyObject *__pyx_t_8 = NULL;
  Py_ssize_t __pyx_t_9;
  PyObject *__pyx_t_10 = NULL;
  char *__pyx_t_11;
  char *__pyx_t_12;
  char *__pyx_t_13;
  char *__pyx_t_14;
  __Pyx_RefNannySetupContext("assign_item_from_object", 0);

  /* "View.MemoryView":493
 *         """Only used if instantiated manually by the user, or if Cython doesn't
 *         know how to convert the type"""
 *         import struct             # <<<<<<<<<<<<<<
 *         cdef char c
 *         cdef bytes bytesvalue
 */
  __pyx_t_1 = __Pyx_Import(__pyx_n_s_struct, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 493, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_struct = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "View.MemoryView":498
 *         cdef Py_ssize_t i
 * 
 *         if isinstance(value, tuple):             # <<<<<<<<<<<<<<
 *             bytesvalue = struct.pack(self.view.format, *value)
 *         else:
 */
  __pyx_t_2 = PyTuple_Check(__pyx_v_value); 
  __pyx_t_3 = (__pyx_t_2 != 0);
  if (__pyx_t_3) {

    /* "View.MemoryView":499
 * 
 *         if isinstance(value, tuple):
 *             bytesvalue = struct.pack(self.view.format, *value)             # <<<<<<<<<<<<<<
 *         else:
 *             bytesvalue = struct.pack(self.view.format, value)
 */
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_struct, __pyx_n_s_pack); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 499, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_4 = __Pyx_PyBytes_FromString(__pyx_v_self->view.format); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 499, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_5 = PyTuple_New(1); if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 499, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_GIVEREF(__pyx_t_4);
    PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_4);
    __pyx_t_4 = 0;
    __pyx_t_4 = PySequence_Tuple(__pyx_v_value); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 499, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_6 = PyNumber_Add(__pyx_t_5, __pyx_t_4); if (unlikely(!__pyx_t_6)) __PYX_ERR(2, 499, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_4 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_6, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 499, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    if (!(likely(PyBytes_CheckExact(__pyx_t_4))||((__pyx_t_4) == Py_None)||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "bytes", Py_TYPE(__pyx_t_4)->tp_name), 0))) __PYX_ERR(2, 499, __pyx_L1_error)
    __pyx_v_bytesvalue = ((PyObject*)__pyx_t_4);
    __pyx_t_4 = 0;

    /* "View.MemoryView":498
 *         cdef Py_ssize_t i
 * 
 *         if isinstance(value, tuple):             # <<<<<<<<<<<<<<
 *             bytesvalue = struct.pack(self.view.format, *value)
 *         else:
 */
    goto __pyx_L3;
  }

  /* "View.MemoryView":501
 *             bytesvalue = struct.pack(self.view.format, *value)
 *         else:
 *             bytesvalue = struct.pack(self.view.format, value)             # <<<<<<<<<<<<<<
 * 
 *         for i, c in enumerate(bytesvalue):
 */
  /*else*/ {
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_struct, __pyx_n_s_pack); if (unlikely(!__pyx_t_6)) __PYX_ERR(2, 501, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_1 = __Pyx_PyBytes_FromString(__pyx_v_self->view.format); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 501, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_5 = NULL;
    __pyx_t_7 = 0;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_6))) {
      __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_6);
      if (likely(__pyx_t_5)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
        __Pyx_INCREF(__pyx_t_5);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_6, function);
        __pyx_t_7 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_6)) {
      PyObject *__pyx_temp[3] = {__pyx_t_5, __pyx_t_1, __pyx_v_value};
      __pyx_t_4 = __Pyx_PyFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_7, 2+__pyx_t_7); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 501, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_6)) {
      PyObject *__pyx_temp[3] = {__pyx_t_5, __pyx_t_1, __pyx_v_value};
      __pyx_t_4 = __Pyx_PyCFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_7, 2+__pyx_t_7); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 501, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    } else
    #endif
    {
      __pyx_t_8 = PyTuple_New(2+__pyx_t_7); if (unlikely(!__pyx_t_8)) __PYX_ERR(2, 501, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      if (__pyx_t_5) {
        __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_t_5); __pyx_t_5 = NULL;
      }
      __Pyx_GIVEREF(__pyx_t_1);
      PyTuple_SET_ITEM(__pyx_t_8, 0+__pyx_t_7, __pyx_t_1);
      __Pyx_INCREF(__pyx_v_value);
      __Pyx_GIVEREF(__pyx_v_value);
      PyTuple_SET_ITEM(__pyx_t_8, 1+__pyx_t_7, __pyx_v_value);
      __pyx_t_1 = 0;
      __pyx_t_4 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_8, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 501, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    }
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    if (!(likely(PyBytes_CheckExact(__pyx_t_4))||((__pyx_t_4) == Py_None)||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "bytes", Py_TYPE(__pyx_t_4)->tp_name), 0))) __PYX_ERR(2, 501, __pyx_L1_error)
    __pyx_v_bytesvalue = ((PyObject*)__pyx_t_4);
    __pyx_t_4 = 0;
  }
  __pyx_L3:;

  /* "View.MemoryView":503
 *             bytesvalue = struct.pack(self.view.format, value)
 * 
 *         for i, c in enumerate(bytesvalue):             # <<<<<<<<<<<<<<
 *             itemp[i] = c
 * 
 */
  __pyx_t_9 = 0;
  if (unlikely(__pyx_v_bytesvalue == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' is not iterable");
    __PYX_ERR(2, 503, __pyx_L1_error)
  }
  __Pyx_INCREF(__pyx_v_bytesvalue);
  __pyx_t_10 = __pyx_v_bytesvalue;
  __pyx_t_12 = PyBytes_AS_STRING(__pyx_t_10);
  __pyx_t_13 = (__pyx_t_12 + PyBytes_GET_SIZE(__pyx_t_10));
  for (__pyx_t_14 = __pyx_t_12; __pyx_t_14 < __pyx_t_13; __pyx_t_14++) {
    __pyx_t_11 = __pyx_t_14;
    __pyx_v_c = (__pyx_t_11[0]);

    /* "View.MemoryView":504
 * 
 *         for i, c in enumerate(bytesvalue):
 *             itemp[i] = c             # <<<<<<<<<<<<<<
 * 
 *     @cname('getbuffer')
 */
    __pyx_v_i = __pyx_t_9;

    /* "View.MemoryView":503
 *             bytesvalue = struct.pack(self.view.format, value)
 * 
 *         for i, c in enumerate(bytesvalue):             # <<<<<<<<<<<<<<
 *             itemp[i] = c
 * 
 */
    __pyx_t_9 = (__pyx_t_9 + 1);

    /* "View.MemoryView":504
 * 
 *         for i, c in enumerate(bytesvalue):
 *             itemp[i] = c             # <<<<<<<<<<<<<<
 * 
 *     @cname('getbuffer')
 */
    (__pyx_v_itemp[__pyx_v_i]) = __pyx_v_c;
  }
  __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;

  /* "View.MemoryView":490
 *             return result
 * 
 *     cdef assign_item_from_object(self, char *itemp, object value):             # <<<<<<<<<<<<<<
 *         """Only used if instantiated manually by the user, or if Cython doesn't
 *         know how to convert the type"""
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_10);
  __Pyx_AddTraceback("View.MemoryView.memoryview.assign_item_from_object", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_struct);
  __Pyx_XDECREF(__pyx_v_bytesvalue);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":507
 * 
 *     @cname('getbuffer')
 *     def __getbuffer__(self, Py_buffer *info, int flags):             # <<<<<<<<<<<<<<
 *         if flags & PyBUF_STRIDES:
 *             info.shape = self.view.shape
 */

/* Python wrapper */
static CYTHON_UNUSED int __pyx_memoryview_getbuffer(PyObject *__pyx_v_self, Py_buffer *__pyx_v_info, int __pyx_v_flags); /*proto*/
static CYTHON_UNUSED int __pyx_memoryview_getbuffer(PyObject *__pyx_v_self, Py_buffer *__pyx_v_info, int __pyx_v_flags) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__getbuffer__ (wrapper)", 0);
  __pyx_r = __pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_8__getbuffer__(((struct __pyx_memoryview_obj *)__pyx_v_self), ((Py_buffer *)__pyx_v_info), ((int)__pyx_v_flags));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_8__getbuffer__(struct __pyx_memoryview_obj *__pyx_v_self, Py_buffer *__pyx_v_info, int __pyx_v_flags) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  Py_ssize_t *__pyx_t_2;
  char *__pyx_t_3;
  void *__pyx_t_4;
  int __pyx_t_5;
  Py_ssize_t __pyx_t_6;
  __Pyx_RefNannySetupContext("__getbuffer__", 0);
  if (__pyx_v_info != NULL) {
    __pyx_v_info->obj = Py_None; __Pyx_INCREF(Py_None);
    __Pyx_GIVEREF(__pyx_v_info->obj);
  }

  /* "View.MemoryView":508
 *     @cname('getbuffer')
 *     def __getbuffer__(self, Py_buffer *info, int flags):
 *         if flags & PyBUF_STRIDES:             # <<<<<<<<<<<<<<
 *             info.shape = self.view.shape
 *         else:
 */
  __pyx_t_1 = ((__pyx_v_flags & PyBUF_STRIDES) != 0);
  if (__pyx_t_1) {

    /* "View.MemoryView":509
 *     def __getbuffer__(self, Py_buffer *info, int flags):
 *         if flags & PyBUF_STRIDES:
 *             info.shape = self.view.shape             # <<<<<<<<<<<<<<
 *         else:
 *             info.shape = NULL
 */
    __pyx_t_2 = __pyx_v_self->view.shape;
    __pyx_v_info->shape = __pyx_t_2;

    /* "View.MemoryView":508
 *     @cname('getbuffer')
 *     def __getbuffer__(self, Py_buffer *info, int flags):
 *         if flags & PyBUF_STRIDES:             # <<<<<<<<<<<<<<
 *             info.shape = self.view.shape
 *         else:
 */
    goto __pyx_L3;
  }

  /* "View.MemoryView":511
 *             info.shape = self.view.shape
 *         else:
 *             info.shape = NULL             # <<<<<<<<<<<<<<
 * 
 *         if flags & PyBUF_STRIDES:
 */
  /*else*/ {
    __pyx_v_info->shape = NULL;
  }
  __pyx_L3:;

  /* "View.MemoryView":513
 *             info.shape = NULL
 * 
 *         if flags & PyBUF_STRIDES:             # <<<<<<<<<<<<<<
 *             info.strides = self.view.strides
 *         else:
 */
  __pyx_t_1 = ((__pyx_v_flags & PyBUF_STRIDES) != 0);
  if (__pyx_t_1) {

    /* "View.MemoryView":514
 * 
 *         if flags & PyBUF_STRIDES:
 *             info.strides = self.view.strides             # <<<<<<<<<<<<<<
 *         else:
 *             info.strides = NULL
 */
    __pyx_t_2 = __pyx_v_self->view.strides;
    __pyx_v_info->strides = __pyx_t_2;

    /* "View.MemoryView":513
 *             info.shape = NULL
 * 
 *         if flags & PyBUF_STRIDES:             # <<<<<<<<<<<<<<
 *             info.strides = self.view.strides
 *         else:
 */
    goto __pyx_L4;
  }

  /* "View.MemoryView":516
 *             info.strides = self.view.strides
 *         else:
 *             info.strides = NULL             # <<<<<<<<<<<<<<
 * 
 *         if flags & PyBUF_INDIRECT:
 */
  /*else*/ {
    __pyx_v_info->strides = NULL;
  }
  __pyx_L4:;

  /* "View.MemoryView":518
 *             info.strides = NULL
 * 
 *         if flags & PyBUF_INDIRECT:             # <<<<<<<<<<<<<<
 *             info.suboffsets = self.view.suboffsets
 *         else:
 */
  __pyx_t_1 = ((__pyx_v_flags & PyBUF_INDIRECT) != 0);
  if (__pyx_t_1) {

    /* "View.MemoryView":519
 * 
 *         if flags & PyBUF_INDIRECT:
 *             info.suboffsets = self.view.suboffsets             # <<<<<<<<<<<<<<
 *         else:
 *             info.suboffsets = NULL
 */
    __pyx_t_2 = __pyx_v_self->view.suboffsets;
    __pyx_v_info->suboffsets = __pyx_t_2;

    /* "View.MemoryView":518
 *             info.strides = NULL
 * 
 *         if flags & PyBUF_INDIRECT:             # <<<<<<<<<<<<<<
 *             info.suboffsets = self.view.suboffsets
 *         else:
 */
    goto __pyx_L5;
  }

  /* "View.MemoryView":521
 *             info.suboffsets = self.view.suboffsets
 *         else:
 *             info.suboffsets = NULL             # <<<<<<<<<<<<<<
 * 
 *         if flags & PyBUF_FORMAT:
 */
  /*else*/ {
    __pyx_v_info->suboffsets = NULL;
  }
  __pyx_L5:;

  /* "View.MemoryView":523
 *             info.suboffsets = NULL
 * 
 *         if flags & PyBUF_FORMAT:             # <<<<<<<<<<<<<<
 *             info.format = self.view.format
 *         else:
 */
  __pyx_t_1 = ((__pyx_v_flags & PyBUF_FORMAT) != 0);
  if (__pyx_t_1) {

    /* "View.MemoryView":524
 * 
 *         if flags & PyBUF_FORMAT:
 *             info.format = self.view.format             # <<<<<<<<<<<<<<
 *         else:
 *             info.format = NULL
 */
    __pyx_t_3 = __pyx_v_self->view.format;
    __pyx_v_info->format = __pyx_t_3;

    /* "View.MemoryView":523
 *             info.suboffsets = NULL
 * 
 *         if flags & PyBUF_FORMAT:             # <<<<<<<<<<<<<<
 *             info.format = self.view.format
 *         else:
 */
    goto __pyx_L6;
  }

  /* "View.MemoryView":526
 *             info.format = self.view.format
 *         else:
 *             info.format = NULL             # <<<<<<<<<<<<<<
 * 
 *         info.buf = self.view.buf
 */
  /*else*/ {
    __pyx_v_info->format = NULL;
  }
  __pyx_L6:;

  /* "View.MemoryView":528
 *             info.format = NULL
 * 
 *         info.buf = self.view.buf             # <<<<<<<<<<<<<<
 *         info.ndim = self.view.ndim
 *         info.itemsize = self.view.itemsize
 */
  __pyx_t_4 = __pyx_v_self->view.buf;
  __pyx_v_info->buf = __pyx_t_4;

  /* "View.MemoryView":529
 * 
 *         info.buf = self.view.buf
 *         info.ndim = self.view.ndim             # <<<<<<<<<<<<<<
 *         info.itemsize = self.view.itemsize
 *         info.len = self.view.len
 */
  __pyx_t_5 = __pyx_v_self->view.ndim;
  __pyx_v_info->ndim = __pyx_t_5;

  /* "View.MemoryView":530
 *         info.buf = self.view.buf
 *         info.ndim = self.view.ndim
 *         info.itemsize = self.view.itemsize             # <<<<<<<<<<<<<<
 *         info.len = self.view.len
 *         info.readonly = 0
 */
  __pyx_t_6 = __pyx_v_self->view.itemsize;
  __pyx_v_info->itemsize = __pyx_t_6;

  /* "View.MemoryView":531
 *         info.ndim = self.view.ndim
 *         info.itemsize = self.view.itemsize
 *         info.len = self.view.len             # <<<<<<<<<<<<<<
 *         info.readonly = 0
 *         info.obj = self
 */
  __pyx_t_6 = __pyx_v_self->view.len;
  __pyx_v_info->len = __pyx_t_6;

  /* "View.MemoryView":532
 *         info.itemsize = self.view.itemsize
 *         info.len = self.view.len
 *         info.readonly = 0             # <<<<<<<<<<<<<<
 *         info.obj = self
 * 
 */
  __pyx_v_info->readonly = 0;

  /* "View.MemoryView":533
 *         info.len = self.view.len
 *         info.readonly = 0
 *         info.obj = self             # <<<<<<<<<<<<<<
 * 
 *     __pyx_getbuffer = capsule(<void *> &__pyx_memoryview_getbuffer, "getbuffer(obj, view, flags)")
 */
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
  __Pyx_GOTREF(__pyx_v_info->obj);
  __Pyx_DECREF(__pyx_v_info->obj);
  __pyx_v_info->obj = ((PyObject *)__pyx_v_self);

  /* "View.MemoryView":507
 * 
 *     @cname('getbuffer')
 *     def __getbuffer__(self, Py_buffer *info, int flags):             # <<<<<<<<<<<<<<
 *         if flags & PyBUF_STRIDES:
 *             info.shape = self.view.shape
 */

  /* function exit code */
  __pyx_r = 0;
  if (__pyx_v_info != NULL && __pyx_v_info->obj == Py_None) {
    __Pyx_GOTREF(Py_None);
    __Pyx_DECREF(Py_None); __pyx_v_info->obj = NULL;
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":539
 * 
 *     @property
 *     def T(self):             # <<<<<<<<<<<<<<
 *         cdef _memoryviewslice result = memoryview_copy(self)
 *         transpose_memslice(&result.from_slice)
 */

/* Python wrapper */
static PyObject *__pyx_pw_15View_dot_MemoryView_10memoryview_1T_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_15View_dot_MemoryView_10memoryview_1T_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_15View_dot_MemoryView_10memoryview_1T___get__(((struct __pyx_memoryview_obj *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_15View_dot_MemoryView_10memoryview_1T___get__(struct __pyx_memoryview_obj *__pyx_v_self) {
  struct __pyx_memoryviewslice_obj *__pyx_v_result = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "View.MemoryView":540
 *     @property
 *     def T(self):
 *         cdef _memoryviewslice result = memoryview_copy(self)             # <<<<<<<<<<<<<<
 *         transpose_memslice(&result.from_slice)
 *         return result
 */
  __pyx_t_1 = __pyx_memoryview_copy_object(__pyx_v_self); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 540, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_memoryviewslice_type))))) __PYX_ERR(2, 540, __pyx_L1_error)
  __pyx_v_result = ((struct __pyx_memoryviewslice_obj *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "View.MemoryView":541
 *     def T(self):
 *         cdef _memoryviewslice result = memoryview_copy(self)
 *         transpose_memslice(&result.from_slice)             # <<<<<<<<<<<<<<
 *         return result
 * 
 */
  __pyx_t_2 = __pyx_memslice_transpose((&__pyx_v_result->from_slice)); if (unlikely(__pyx_t_2 == 0)) __PYX_ERR(2, 541, __pyx_L1_error)

  /* "View.MemoryView":542
 *         cdef _memoryviewslice result = memoryview_copy(self)
 *         transpose_memslice(&result.from_slice)
 *         return result             # <<<<<<<<<<<<<<
 * 
 *     @property
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_result));
  __pyx_r = ((PyObject *)__pyx_v_result);
  goto __pyx_L0;

  /* "View.MemoryView":539
 * 
 *     @property
 *     def T(self):             # <<<<<<<<<<<<<<
 *         cdef _memoryviewslice result = memoryview_copy(self)
 *         transpose_memslice(&result.from_slice)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("View.MemoryView.memoryview.T.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_result);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":545
 * 
 *     @property
 *     def base(self):             # <<<<<<<<<<<<<<
 *         return self.obj
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_15View_dot_MemoryView_10memoryview_4base_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_15View_dot_MemoryView_10memoryview_4base_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_15View_dot_MemoryView_10memoryview_4base___get__(((struct __pyx_memoryview_obj *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_15View_dot_MemoryView_10memoryview_4base___get__(struct __pyx_memoryview_obj *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "View.MemoryView":546
 *     @property
 *     def base(self):
 *         return self.obj             # <<<<<<<<<<<<<<
 * 
 *     @property
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_self->obj);
  __pyx_r = __pyx_v_self->obj;
  goto __pyx_L0;

  /* "View.MemoryView":545
 * 
 *     @property
 *     def base(self):             # <<<<<<<<<<<<<<
 *         return self.obj
 * 
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":549
 * 
 *     @property
 *     def shape(self):             # <<<<<<<<<<<<<<
 *         return tuple([length for length in self.view.shape[:self.view.ndim]])
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_15View_dot_MemoryView_10memoryview_5shape_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_15View_dot_MemoryView_10memoryview_5shape_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_15View_dot_MemoryView_10memoryview_5shape___get__(((struct __pyx_memoryview_obj *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_15View_dot_MemoryView_10memoryview_5shape___get__(struct __pyx_memoryview_obj *__pyx_v_self) {
  Py_ssize_t __pyx_v_length;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  Py_ssize_t *__pyx_t_2;
  Py_ssize_t *__pyx_t_3;
  Py_ssize_t *__pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "View.MemoryView":550
 *     @property
 *     def shape(self):
 *         return tuple([length for length in self.view.shape[:self.view.ndim]])             # <<<<<<<<<<<<<<
 * 
 *     @property
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyList_New(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 550, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = (__pyx_v_self->view.shape + __pyx_v_self->view.ndim);
  for (__pyx_t_4 = __pyx_v_self->view.shape; __pyx_t_4 < __pyx_t_3; __pyx_t_4++) {
    __pyx_t_2 = __pyx_t_4;
    __pyx_v_length = (__pyx_t_2[0]);
    __pyx_t_5 = PyInt_FromSsize_t(__pyx_v_length); if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 550, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (unlikely(__Pyx_ListComp_Append(__pyx_t_1, (PyObject*)__pyx_t_5))) __PYX_ERR(2, 550, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __pyx_t_5 = PyList_AsTuple(((PyObject*)__pyx_t_1)); if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 550, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_r = __pyx_t_5;
  __pyx_t_5 = 0;
  goto __pyx_L0;

  /* "View.MemoryView":549
 * 
 *     @property
 *     def shape(self):             # <<<<<<<<<<<<<<
 *         return tuple([length for length in self.view.shape[:self.view.ndim]])
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("View.MemoryView.memoryview.shape.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":553
 * 
 *     @property
 *     def strides(self):             # <<<<<<<<<<<<<<
 *         if self.view.strides == NULL:
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_15View_dot_MemoryView_10memoryview_7strides_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_15View_dot_MemoryView_10memoryview_7strides_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_15View_dot_MemoryView_10memoryview_7strides___get__(((struct __pyx_memoryview_obj *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_15View_dot_MemoryView_10memoryview_7strides___get__(struct __pyx_memoryview_obj *__pyx_v_self) {
  Py_ssize_t __pyx_v_stride;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  Py_ssize_t *__pyx_t_3;
  Py_ssize_t *__pyx_t_4;
  Py_ssize_t *__pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "View.MemoryView":554
 *     @property
 *     def strides(self):
 *         if self.view.strides == NULL:             # <<<<<<<<<<<<<<
 * 
 *             raise ValueError("Buffer view does not expose strides")
 */
  __pyx_t_1 = ((__pyx_v_self->view.strides == NULL) != 0);
  if (__pyx_t_1) {

    /* "View.MemoryView":556
 *         if self.view.strides == NULL:
 * 
 *             raise ValueError("Buffer view does not expose strides")             # <<<<<<<<<<<<<<
 * 
 *         return tuple([stride for stride in self.view.strides[:self.view.ndim]])
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__51, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 556, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(2, 556, __pyx_L1_error)

    /* "View.MemoryView":554
 *     @property
 *     def strides(self):
 *         if self.view.strides == NULL:             # <<<<<<<<<<<<<<
 * 
 *             raise ValueError("Buffer view does not expose strides")
 */
  }

  /* "View.MemoryView":558
 *             raise ValueError("Buffer view does not expose strides")
 * 
 *         return tuple([stride for stride in self.view.strides[:self.view.ndim]])             # <<<<<<<<<<<<<<
 * 
 *     @property
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2 = PyList_New(0); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 558, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = (__pyx_v_self->view.strides + __pyx_v_self->view.ndim);
  for (__pyx_t_5 = __pyx_v_self->view.strides; __pyx_t_5 < __pyx_t_4; __pyx_t_5++) {
    __pyx_t_3 = __pyx_t_5;
    __pyx_v_stride = (__pyx_t_3[0]);
    __pyx_t_6 = PyInt_FromSsize_t(__pyx_v_stride); if (unlikely(!__pyx_t_6)) __PYX_ERR(2, 558, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    if (unlikely(__Pyx_ListComp_Append(__pyx_t_2, (PyObject*)__pyx_t_6))) __PYX_ERR(2, 558, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  }
  __pyx_t_6 = PyList_AsTuple(((PyObject*)__pyx_t_2)); if (unlikely(!__pyx_t_6)) __PYX_ERR(2, 558, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_r = __pyx_t_6;
  __pyx_t_6 = 0;
  goto __pyx_L0;

  /* "View.MemoryView":553
 * 
 *     @property
 *     def strides(self):             # <<<<<<<<<<<<<<
 *         if self.view.strides == NULL:
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("View.MemoryView.memoryview.strides.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":561
 * 
 *     @property
 *     def suboffsets(self):             # <<<<<<<<<<<<<<
 *         if self.view.suboffsets == NULL:
 *             return (-1,) * self.view.ndim
 */

/* Python wrapper */
static PyObject *__pyx_pw_15View_dot_MemoryView_10memoryview_10suboffsets_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_15View_dot_MemoryView_10memoryview_10suboffsets_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_15View_dot_MemoryView_10memoryview_10suboffsets___get__(((struct __pyx_memoryview_obj *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_15View_dot_MemoryView_10memoryview_10suboffsets___get__(struct __pyx_memoryview_obj *__pyx_v_self) {
  Py_ssize_t __pyx_v_suboffset;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  Py_ssize_t *__pyx_t_4;
  Py_ssize_t *__pyx_t_5;
  Py_ssize_t *__pyx_t_6;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "View.MemoryView":562
 *     @property
 *     def suboffsets(self):
 *         if self.view.suboffsets == NULL:             # <<<<<<<<<<<<<<
 *             return (-1,) * self.view.ndim
 * 
 */
  __pyx_t_1 = ((__pyx_v_self->view.suboffsets == NULL) != 0);
  if (__pyx_t_1) {

    /* "View.MemoryView":563
 *     def suboffsets(self):
 *         if self.view.suboffsets == NULL:
 *             return (-1,) * self.view.ndim             # <<<<<<<<<<<<<<
 * 
 *         return tuple([suboffset for suboffset in self.view.suboffsets[:self.view.ndim]])
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_2 = __Pyx_PyInt_From_int(__pyx_v_self->view.ndim); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 563, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = PyNumber_Multiply(__pyx_tuple__52, __pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 563, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_r = __pyx_t_3;
    __pyx_t_3 = 0;
    goto __pyx_L0;

    /* "View.MemoryView":562
 *     @property
 *     def suboffsets(self):
 *         if self.view.suboffsets == NULL:             # <<<<<<<<<<<<<<
 *             return (-1,) * self.view.ndim
 * 
 */
  }

  /* "View.MemoryView":565
 *             return (-1,) * self.view.ndim
 * 
 *         return tuple([suboffset for suboffset in self.view.suboffsets[:self.view.ndim]])             # <<<<<<<<<<<<<<
 * 
 *     @property
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_3 = PyList_New(0); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 565, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_5 = (__pyx_v_self->view.suboffsets + __pyx_v_self->view.ndim);
  for (__pyx_t_6 = __pyx_v_self->view.suboffsets; __pyx_t_6 < __pyx_t_5; __pyx_t_6++) {
    __pyx_t_4 = __pyx_t_6;
    __pyx_v_suboffset = (__pyx_t_4[0]);
    __pyx_t_2 = PyInt_FromSsize_t(__pyx_v_suboffset); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 565, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    if (unlikely(__Pyx_ListComp_Append(__pyx_t_3, (PyObject*)__pyx_t_2))) __PYX_ERR(2, 565, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  }
  __pyx_t_2 = PyList_AsTuple(((PyObject*)__pyx_t_3)); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 565, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "View.MemoryView":561
 * 
 *     @property
 *     def suboffsets(self):             # <<<<<<<<<<<<<<
 *         if self.view.suboffsets == NULL:
 *             return (-1,) * self.view.ndim
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("View.MemoryView.memoryview.suboffsets.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":568
 * 
 *     @property
 *     def ndim(self):             # <<<<<<<<<<<<<<
 *         return self.view.ndim
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_15View_dot_MemoryView_10memoryview_4ndim_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_15View_dot_MemoryView_10memoryview_4ndim_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_15View_dot_MemoryView_10memoryview_4ndim___get__(((struct __pyx_memoryview_obj *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_15View_dot_MemoryView_10memoryview_4ndim___get__(struct __pyx_memoryview_obj *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "View.MemoryView":569
 *     @property
 *     def ndim(self):
 *         return self.view.ndim             # <<<<<<<<<<<<<<
 * 
 *     @property
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_self->view.ndim); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 569, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "View.MemoryView":568
 * 
 *     @property
 *     def ndim(self):             # <<<<<<<<<<<<<<
 *         return self.view.ndim
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("View.MemoryView.memoryview.ndim.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":572
 * 
 *     @property
 *     def itemsize(self):             # <<<<<<<<<<<<<<
 *         return self.view.itemsize
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_15View_dot_MemoryView_10memoryview_8itemsize_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_15View_dot_MemoryView_10memoryview_8itemsize_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_15View_dot_MemoryView_10memoryview_8itemsize___get__(((struct __pyx_memoryview_obj *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_15View_dot_MemoryView_10memoryview_8itemsize___get__(struct __pyx_memoryview_obj *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "View.MemoryView":573
 *     @property
 *     def itemsize(self):
 *         return self.view.itemsize             # <<<<<<<<<<<<<<
 * 
 *     @property
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyInt_FromSsize_t(__pyx_v_self->view.itemsize); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 573, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "View.MemoryView":572
 * 
 *     @property
 *     def itemsize(self):             # <<<<<<<<<<<<<<
 *         return self.view.itemsize
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("View.MemoryView.memoryview.itemsize.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":576
 * 
 *     @property
 *     def nbytes(self):             # <<<<<<<<<<<<<<
 *         return self.size * self.view.itemsize
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_15View_dot_MemoryView_10memoryview_6nbytes_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_15View_dot_MemoryView_10memoryview_6nbytes_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_15View_dot_MemoryView_10memoryview_6nbytes___get__(((struct __pyx_memoryview_obj *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_15View_dot_MemoryView_10memoryview_6nbytes___get__(struct __pyx_memoryview_obj *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "View.MemoryView":577
 *     @property
 *     def nbytes(self):
 *         return self.size * self.view.itemsize             # <<<<<<<<<<<<<<
 * 
 *     @property
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 577, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = PyInt_FromSsize_t(__pyx_v_self->view.itemsize); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 577, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = PyNumber_Multiply(__pyx_t_1, __pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 577, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_r = __pyx_t_3;
  __pyx_t_3 = 0;
  goto __pyx_L0;

  /* "View.MemoryView":576
 * 
 *     @property
 *     def nbytes(self):             # <<<<<<<<<<<<<<
 *         return self.size * self.view.itemsize
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("View.MemoryView.memoryview.nbytes.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":580
 * 
 *     @property
 *     def size(self):             # <<<<<<<<<<<<<<
 *         if self._size is None:
 *             result = 1
 */

/* Python wrapper */
static PyObject *__pyx_pw_15View_dot_MemoryView_10memoryview_4size_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_15View_dot_MemoryView_10memoryview_4size_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_15View_dot_MemoryView_10memoryview_4size___get__(((struct __pyx_memoryview_obj *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_15View_dot_MemoryView_10memoryview_4size___get__(struct __pyx_memoryview_obj *__pyx_v_self) {
  PyObject *__pyx_v_result = NULL;
  PyObject *__pyx_v_length = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  Py_ssize_t *__pyx_t_3;
  Py_ssize_t *__pyx_t_4;
  Py_ssize_t *__pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "View.MemoryView":581
 *     @property
 *     def size(self):
 *         if self._size is None:             # <<<<<<<<<<<<<<
 *             result = 1
 * 
 */
  __pyx_t_1 = (__pyx_v_self->_size == Py_None);
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "View.MemoryView":582
 *     def size(self):
 *         if self._size is None:
 *             result = 1             # <<<<<<<<<<<<<<
 * 
 *             for length in self.view.shape[:self.view.ndim]:
 */
    __Pyx_INCREF(__pyx_int_1);
    __pyx_v_result = __pyx_int_1;

    /* "View.MemoryView":584
 *             result = 1
 * 
 *             for length in self.view.shape[:self.view.ndim]:             # <<<<<<<<<<<<<<
 *                 result *= length
 * 
 */
    __pyx_t_4 = (__pyx_v_self->view.shape + __pyx_v_self->view.ndim);
    for (__pyx_t_5 = __pyx_v_self->view.shape; __pyx_t_5 < __pyx_t_4; __pyx_t_5++) {
      __pyx_t_3 = __pyx_t_5;
      __pyx_t_6 = PyInt_FromSsize_t((__pyx_t_3[0])); if (unlikely(!__pyx_t_6)) __PYX_ERR(2, 584, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_XDECREF_SET(__pyx_v_length, __pyx_t_6);
      __pyx_t_6 = 0;

      /* "View.MemoryView":585
 * 
 *             for length in self.view.shape[:self.view.ndim]:
 *                 result *= length             # <<<<<<<<<<<<<<
 * 
 *             self._size = result
 */
      __pyx_t_6 = PyNumber_InPlaceMultiply(__pyx_v_result, __pyx_v_length); if (unlikely(!__pyx_t_6)) __PYX_ERR(2, 585, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF_SET(__pyx_v_result, __pyx_t_6);
      __pyx_t_6 = 0;
    }

    /* "View.MemoryView":587
 *                 result *= length
 * 
 *             self._size = result             # <<<<<<<<<<<<<<
 * 
 *         return self._size
 */
    __Pyx_INCREF(__pyx_v_result);
    __Pyx_GIVEREF(__pyx_v_result);
    __Pyx_GOTREF(__pyx_v_self->_size);
    __Pyx_DECREF(__pyx_v_self->_size);
    __pyx_v_self->_size = __pyx_v_result;

    /* "View.MemoryView":581
 *     @property
 *     def size(self):
 *         if self._size is None:             # <<<<<<<<<<<<<<
 *             result = 1
 * 
 */
  }

  /* "View.MemoryView":589
 *             self._size = result
 * 
 *         return self._size             # <<<<<<<<<<<<<<
 * 
 *     def __len__(self):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_self->_size);
  __pyx_r = __pyx_v_self->_size;
  goto __pyx_L0;

  /* "View.MemoryView":580
 * 
 *     @property
 *     def size(self):             # <<<<<<<<<<<<<<
 *         if self._size is None:
 *             result = 1
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("View.MemoryView.memoryview.size.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_result);
  __Pyx_XDECREF(__pyx_v_length);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":591
 *         return self._size
 * 
 *     def __len__(self):             # <<<<<<<<<<<<<<
 *         if self.view.ndim >= 1:
 *             return self.view.shape[0]
 */

/* Python wrapper */
static Py_ssize_t __pyx_memoryview___len__(PyObject *__pyx_v_self); /*proto*/
static Py_ssize_t __pyx_memoryview___len__(PyObject *__pyx_v_self) {
  Py_ssize_t __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__len__ (wrapper)", 0);
  __pyx_r = __pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_10__len__(((struct __pyx_memoryview_obj *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static Py_ssize_t __pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_10__len__(struct __pyx_memoryview_obj *__pyx_v_self) {
  Py_ssize_t __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  __Pyx_RefNannySetupContext("__len__", 0);

  /* "View.MemoryView":592
 * 
 *     def __len__(self):
 *         if self.view.ndim >= 1:             # <<<<<<<<<<<<<<
 *             return self.view.shape[0]
 * 
 */
  __pyx_t_1 = ((__pyx_v_self->view.ndim >= 1) != 0);
  if (__pyx_t_1) {

    /* "View.MemoryView":593
 *     def __len__(self):
 *         if self.view.ndim >= 1:
 *             return self.view.shape[0]             # <<<<<<<<<<<<<<
 * 
 *         return 0
 */
    __pyx_r = (__pyx_v_self->view.shape[0]);
    goto __pyx_L0;

    /* "View.MemoryView":592
 * 
 *     def __len__(self):
 *         if self.view.ndim >= 1:             # <<<<<<<<<<<<<<
 *             return self.view.shape[0]
 * 
 */
  }

  /* "View.MemoryView":595
 *             return self.view.shape[0]
 * 
 *         return 0             # <<<<<<<<<<<<<<
 * 
 *     def __repr__(self):
 */
  __pyx_r = 0;
  goto __pyx_L0;

  /* "View.MemoryView":591
 *         return self._size
 * 
 *     def __len__(self):             # <<<<<<<<<<<<<<
 *         if self.view.ndim >= 1:
 *             return self.view.shape[0]
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":597
 *         return 0
 * 
 *     def __repr__(self):             # <<<<<<<<<<<<<<
 *         return "<MemoryView of %r at 0x%x>" % (self.base.__class__.__name__,
 *                                                id(self))
 */

/* Python wrapper */
static PyObject *__pyx_memoryview___repr__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_memoryview___repr__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__repr__ (wrapper)", 0);
  __pyx_r = __pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_12__repr__(((struct __pyx_memoryview_obj *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_12__repr__(struct __pyx_memoryview_obj *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("__repr__", 0);

  /* "View.MemoryView":598
 * 
 *     def __repr__(self):
 *         return "<MemoryView of %r at 0x%x>" % (self.base.__class__.__name__,             # <<<<<<<<<<<<<<
 *                                                id(self))
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_base); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 598, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_class); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 598, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_name_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 598, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "View.MemoryView":599
 *     def __repr__(self):
 *         return "<MemoryView of %r at 0x%x>" % (self.base.__class__.__name__,
 *                                                id(self))             # <<<<<<<<<<<<<<
 * 
 *     def __str__(self):
 */
  __pyx_t_2 = PyTuple_New(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 599, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
  PyTuple_SET_ITEM(__pyx_t_2, 0, ((PyObject *)__pyx_v_self));
  __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_id, __pyx_t_2, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 599, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "View.MemoryView":598
 * 
 *     def __repr__(self):
 *         return "<MemoryView of %r at 0x%x>" % (self.base.__class__.__name__,             # <<<<<<<<<<<<<<
 *                                                id(self))
 * 
 */
  __pyx_t_2 = PyTuple_New(2); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 598, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_GIVEREF(__pyx_t_1);
  PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_3);
  PyTuple_SET_ITEM(__pyx_t_2, 1, __pyx_t_3);
  __pyx_t_1 = 0;
  __pyx_t_3 = 0;
  __pyx_t_3 = __Pyx_PyString_Format(__pyx_kp_s_MemoryView_of_r_at_0x_x, __pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 598, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_r = __pyx_t_3;
  __pyx_t_3 = 0;
  goto __pyx_L0;

  /* "View.MemoryView":597
 *         return 0
 * 
 *     def __repr__(self):             # <<<<<<<<<<<<<<
 *         return "<MemoryView of %r at 0x%x>" % (self.base.__class__.__name__,
 *                                                id(self))
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("View.MemoryView.memoryview.__repr__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":601
 *                                                id(self))
 * 
 *     def __str__(self):             # <<<<<<<<<<<<<<
 *         return "<MemoryView of %r object>" % (self.base.__class__.__name__,)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_memoryview___str__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_memoryview___str__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__str__ (wrapper)", 0);
  __pyx_r = __pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_14__str__(((struct __pyx_memoryview_obj *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_14__str__(struct __pyx_memoryview_obj *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("__str__", 0);

  /* "View.MemoryView":602
 * 
 *     def __str__(self):
 *         return "<MemoryView of %r object>" % (self.base.__class__.__name__,)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_base); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 602, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_class); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 602, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_name_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 602, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyTuple_New(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 602, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_GIVEREF(__pyx_t_1);
  PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_1);
  __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyString_Format(__pyx_kp_s_MemoryView_of_r_object, __pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 602, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "View.MemoryView":601
 *                                                id(self))
 * 
 *     def __str__(self):             # <<<<<<<<<<<<<<
 *         return "<MemoryView of %r object>" % (self.base.__class__.__name__,)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("View.MemoryView.memoryview.__str__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":605
 * 
 * 
 *     def is_c_contig(self):             # <<<<<<<<<<<<<<
 *         cdef __Pyx_memviewslice *mslice
 *         cdef __Pyx_memviewslice tmp
 */

/* Python wrapper */
static PyObject *__pyx_memoryview_is_c_contig(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_memoryview_is_c_contig(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("is_c_contig (wrapper)", 0);
  __pyx_r = __pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_16is_c_contig(((struct __pyx_memoryview_obj *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_16is_c_contig(struct __pyx_memoryview_obj *__pyx_v_self) {
  __Pyx_memviewslice *__pyx_v_mslice;
  __Pyx_memviewslice __pyx_v_tmp;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("is_c_contig", 0);

  /* "View.MemoryView":608
 *         cdef __Pyx_memviewslice *mslice
 *         cdef __Pyx_memviewslice tmp
 *         mslice = get_slice_from_memview(self, &tmp)             # <<<<<<<<<<<<<<
 *         return slice_is_contig(mslice[0], 'C', self.view.ndim)
 * 
 */
  __pyx_v_mslice = __pyx_memoryview_get_slice_from_memoryview(__pyx_v_self, (&__pyx_v_tmp));

  /* "View.MemoryView":609
 *         cdef __Pyx_memviewslice tmp
 *         mslice = get_slice_from_memview(self, &tmp)
 *         return slice_is_contig(mslice[0], 'C', self.view.ndim)             # <<<<<<<<<<<<<<
 * 
 *     def is_f_contig(self):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyBool_FromLong(__pyx_memviewslice_is_contig((__pyx_v_mslice[0]), 'C', __pyx_v_self->view.ndim)); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 609, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "View.MemoryView":605
 * 
 * 
 *     def is_c_contig(self):             # <<<<<<<<<<<<<<
 *         cdef __Pyx_memviewslice *mslice
 *         cdef __Pyx_memviewslice tmp
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("View.MemoryView.memoryview.is_c_contig", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":611
 *         return slice_is_contig(mslice[0], 'C', self.view.ndim)
 * 
 *     def is_f_contig(self):             # <<<<<<<<<<<<<<
 *         cdef __Pyx_memviewslice *mslice
 *         cdef __Pyx_memviewslice tmp
 */

/* Python wrapper */
static PyObject *__pyx_memoryview_is_f_contig(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_memoryview_is_f_contig(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("is_f_contig (wrapper)", 0);
  __pyx_r = __pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_18is_f_contig(((struct __pyx_memoryview_obj *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_18is_f_contig(struct __pyx_memoryview_obj *__pyx_v_self) {
  __Pyx_memviewslice *__pyx_v_mslice;
  __Pyx_memviewslice __pyx_v_tmp;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("is_f_contig", 0);

  /* "View.MemoryView":614
 *         cdef __Pyx_memviewslice *mslice
 *         cdef __Pyx_memviewslice tmp
 *         mslice = get_slice_from_memview(self, &tmp)             # <<<<<<<<<<<<<<
 *         return slice_is_contig(mslice[0], 'F', self.view.ndim)
 * 
 */
  __pyx_v_mslice = __pyx_memoryview_get_slice_from_memoryview(__pyx_v_self, (&__pyx_v_tmp));

  /* "View.MemoryView":615
 *         cdef __Pyx_memviewslice tmp
 *         mslice = get_slice_from_memview(self, &tmp)
 *         return slice_is_contig(mslice[0], 'F', self.view.ndim)             # <<<<<<<<<<<<<<
 * 
 *     def copy(self):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyBool_FromLong(__pyx_memviewslice_is_contig((__pyx_v_mslice[0]), 'F', __pyx_v_self->view.ndim)); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 615, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "View.MemoryView":611
 *         return slice_is_contig(mslice[0], 'C', self.view.ndim)
 * 
 *     def is_f_contig(self):             # <<<<<<<<<<<<<<
 *         cdef __Pyx_memviewslice *mslice
 *         cdef __Pyx_memviewslice tmp
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("View.MemoryView.memoryview.is_f_contig", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":617
 *         return slice_is_contig(mslice[0], 'F', self.view.ndim)
 * 
 *     def copy(self):             # <<<<<<<<<<<<<<
 *         cdef __Pyx_memviewslice mslice
 *         cdef int flags = self.flags & ~PyBUF_F_CONTIGUOUS
 */

/* Python wrapper */
static PyObject *__pyx_memoryview_copy(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_memoryview_copy(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("copy (wrapper)", 0);
  __pyx_r = __pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_20copy(((struct __pyx_memoryview_obj *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_20copy(struct __pyx_memoryview_obj *__pyx_v_self) {
  __Pyx_memviewslice __pyx_v_mslice;
  int __pyx_v_flags;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_memviewslice __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("copy", 0);

  /* "View.MemoryView":619
 *     def copy(self):
 *         cdef __Pyx_memviewslice mslice
 *         cdef int flags = self.flags & ~PyBUF_F_CONTIGUOUS             # <<<<<<<<<<<<<<
 * 
 *         slice_copy(self, &mslice)
 */
  __pyx_v_flags = (__pyx_v_self->flags & (~PyBUF_F_CONTIGUOUS));

  /* "View.MemoryView":621
 *         cdef int flags = self.flags & ~PyBUF_F_CONTIGUOUS
 * 
 *         slice_copy(self, &mslice)             # <<<<<<<<<<<<<<
 *         mslice = slice_copy_contig(&mslice, "c", self.view.ndim,
 *                                    self.view.itemsize,
 */
  __pyx_memoryview_slice_copy(__pyx_v_self, (&__pyx_v_mslice));

  /* "View.MemoryView":622
 * 
 *         slice_copy(self, &mslice)
 *         mslice = slice_copy_contig(&mslice, "c", self.view.ndim,             # <<<<<<<<<<<<<<
 *                                    self.view.itemsize,
 *                                    flags|PyBUF_C_CONTIGUOUS,
 */
  __pyx_t_1 = __pyx_memoryview_copy_new_contig((&__pyx_v_mslice), ((char *)"c"), __pyx_v_self->view.ndim, __pyx_v_self->view.itemsize, (__pyx_v_flags | PyBUF_C_CONTIGUOUS), __pyx_v_self->dtype_is_object); if (unlikely(PyErr_Occurred())) __PYX_ERR(2, 622, __pyx_L1_error)
  __pyx_v_mslice = __pyx_t_1;

  /* "View.MemoryView":627
 *                                    self.dtype_is_object)
 * 
 *         return memoryview_copy_from_slice(self, &mslice)             # <<<<<<<<<<<<<<
 * 
 *     def copy_fortran(self):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2 = __pyx_memoryview_copy_object_from_slice(__pyx_v_self, (&__pyx_v_mslice)); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 627, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "View.MemoryView":617
 *         return slice_is_contig(mslice[0], 'F', self.view.ndim)
 * 
 *     def copy(self):             # <<<<<<<<<<<<<<
 *         cdef __Pyx_memviewslice mslice
 *         cdef int flags = self.flags & ~PyBUF_F_CONTIGUOUS
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("View.MemoryView.memoryview.copy", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":629
 *         return memoryview_copy_from_slice(self, &mslice)
 * 
 *     def copy_fortran(self):             # <<<<<<<<<<<<<<
 *         cdef __Pyx_memviewslice src, dst
 *         cdef int flags = self.flags & ~PyBUF_C_CONTIGUOUS
 */

/* Python wrapper */
static PyObject *__pyx_memoryview_copy_fortran(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_memoryview_copy_fortran(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("copy_fortran (wrapper)", 0);
  __pyx_r = __pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_22copy_fortran(((struct __pyx_memoryview_obj *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_22copy_fortran(struct __pyx_memoryview_obj *__pyx_v_self) {
  __Pyx_memviewslice __pyx_v_src;
  __Pyx_memviewslice __pyx_v_dst;
  int __pyx_v_flags;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_memviewslice __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("copy_fortran", 0);

  /* "View.MemoryView":631
 *     def copy_fortran(self):
 *         cdef __Pyx_memviewslice src, dst
 *         cdef int flags = self.flags & ~PyBUF_C_CONTIGUOUS             # <<<<<<<<<<<<<<
 * 
 *         slice_copy(self, &src)
 */
  __pyx_v_flags = (__pyx_v_self->flags & (~PyBUF_C_CONTIGUOUS));

  /* "View.MemoryView":633
 *         cdef int flags = self.flags & ~PyBUF_C_CONTIGUOUS
 * 
 *         slice_copy(self, &src)             # <<<<<<<<<<<<<<
 *         dst = slice_copy_contig(&src, "fortran", self.view.ndim,
 *                                 self.view.itemsize,
 */
  __pyx_memoryview_slice_copy(__pyx_v_self, (&__pyx_v_src));

  /* "View.MemoryView":634
 * 
 *         slice_copy(self, &src)
 *         dst = slice_copy_contig(&src, "fortran", self.view.ndim,             # <<<<<<<<<<<<<<
 *                                 self.view.itemsize,
 *                                 flags|PyBUF_F_CONTIGUOUS,
 */
  __pyx_t_1 = __pyx_memoryview_copy_new_contig((&__pyx_v_src), ((char *)"fortran"), __pyx_v_self->view.ndim, __pyx_v_self->view.itemsize, (__pyx_v_flags | PyBUF_F_CONTIGUOUS), __pyx_v_self->dtype_is_object); if (unlikely(PyErr_Occurred())) __PYX_ERR(2, 634, __pyx_L1_error)
  __pyx_v_dst = __pyx_t_1;

  /* "View.MemoryView":639
 *                                 self.dtype_is_object)
 * 
 *         return memoryview_copy_from_slice(self, &dst)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2 = __pyx_memoryview_copy_object_from_slice(__pyx_v_self, (&__pyx_v_dst)); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 639, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "View.MemoryView":629
 *         return memoryview_copy_from_slice(self, &mslice)
 * 
 *     def copy_fortran(self):             # <<<<<<<<<<<<<<
 *         cdef __Pyx_memviewslice src, dst
 *         cdef int flags = self.flags & ~PyBUF_C_CONTIGUOUS
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("View.MemoryView.memoryview.copy_fortran", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":643
 * 
 * @cname('__pyx_memoryview_new')
 * cdef memoryview_cwrapper(object o, int flags, bint dtype_is_object, __Pyx_TypeInfo *typeinfo):             # <<<<<<<<<<<<<<
 *     cdef memoryview result = memoryview(o, flags, dtype_is_object)
 *     result.typeinfo = typeinfo
 */

static PyObject *__pyx_memoryview_new(PyObject *__pyx_v_o, int __pyx_v_flags, int __pyx_v_dtype_is_object, __Pyx_TypeInfo *__pyx_v_typeinfo) {
  struct __pyx_memoryview_obj *__pyx_v_result = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("memoryview_cwrapper", 0);

  /* "View.MemoryView":644
 * @cname('__pyx_memoryview_new')
 * cdef memoryview_cwrapper(object o, int flags, bint dtype_is_object, __Pyx_TypeInfo *typeinfo):
 *     cdef memoryview result = memoryview(o, flags, dtype_is_object)             # <<<<<<<<<<<<<<
 *     result.typeinfo = typeinfo
 *     return result
 */
  __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_flags); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 644, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyBool_FromLong(__pyx_v_dtype_is_object); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 644, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = PyTuple_New(3); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 644, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_INCREF(__pyx_v_o);
  __Pyx_GIVEREF(__pyx_v_o);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_v_o);
  __Pyx_GIVEREF(__pyx_t_1);
  PyTuple_SET_ITEM(__pyx_t_3, 1, __pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_2);
  PyTuple_SET_ITEM(__pyx_t_3, 2, __pyx_t_2);
  __pyx_t_1 = 0;
  __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)__pyx_memoryview_type), __pyx_t_3, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 644, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_result = ((struct __pyx_memoryview_obj *)__pyx_t_2);
  __pyx_t_2 = 0;

  /* "View.MemoryView":645
 * cdef memoryview_cwrapper(object o, int flags, bint dtype_is_object, __Pyx_TypeInfo *typeinfo):
 *     cdef memoryview result = memoryview(o, flags, dtype_is_object)
 *     result.typeinfo = typeinfo             # <<<<<<<<<<<<<<
 *     return result
 * 
 */
  __pyx_v_result->typeinfo = __pyx_v_typeinfo;

  /* "View.MemoryView":646
 *     cdef memoryview result = memoryview(o, flags, dtype_is_object)
 *     result.typeinfo = typeinfo
 *     return result             # <<<<<<<<<<<<<<
 * 
 * @cname('__pyx_memoryview_check')
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_result));
  __pyx_r = ((PyObject *)__pyx_v_result);
  goto __pyx_L0;

  /* "View.MemoryView":643
 * 
 * @cname('__pyx_memoryview_new')
 * cdef memoryview_cwrapper(object o, int flags, bint dtype_is_object, __Pyx_TypeInfo *typeinfo):             # <<<<<<<<<<<<<<
 *     cdef memoryview result = memoryview(o, flags, dtype_is_object)
 *     result.typeinfo = typeinfo
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("View.MemoryView.memoryview_cwrapper", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_result);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":649
 * 
 * @cname('__pyx_memoryview_check')
 * cdef inline bint memoryview_check(object o):             # <<<<<<<<<<<<<<
 *     return isinstance(o, memoryview)
 * 
 */

static CYTHON_INLINE int __pyx_memoryview_check(PyObject *__pyx_v_o) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  __Pyx_RefNannySetupContext("memoryview_check", 0);

  /* "View.MemoryView":650
 * @cname('__pyx_memoryview_check')
 * cdef inline bint memoryview_check(object o):
 *     return isinstance(o, memoryview)             # <<<<<<<<<<<<<<
 * 
 * cdef tuple _unellipsify(object index, int ndim):
 */
  __pyx_t_1 = __Pyx_TypeCheck(__pyx_v_o, __pyx_memoryview_type); 
  __pyx_r = __pyx_t_1;
  goto __pyx_L0;

  /* "View.MemoryView":649
 * 
 * @cname('__pyx_memoryview_check')
 * cdef inline bint memoryview_check(object o):             # <<<<<<<<<<<<<<
 *     return isinstance(o, memoryview)
 * 
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":652
 *     return isinstance(o, memoryview)
 * 
 * cdef tuple _unellipsify(object index, int ndim):             # <<<<<<<<<<<<<<
 *     """
 *     Replace all ellipses with full slices and fill incomplete indices with
 */

static PyObject *_unellipsify(PyObject *__pyx_v_index, int __pyx_v_ndim) {
  PyObject *__pyx_v_tup = NULL;
  PyObject *__pyx_v_result = NULL;
  int __pyx_v_have_slices;
  int __pyx_v_seen_ellipsis;
  CYTHON_UNUSED PyObject *__pyx_v_idx = NULL;
  PyObject *__pyx_v_item = NULL;
  Py_ssize_t __pyx_v_nslices;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  Py_ssize_t __pyx_t_5;
  PyObject *(*__pyx_t_6)(PyObject *);
  PyObject *__pyx_t_7 = NULL;
  Py_ssize_t __pyx_t_8;
  int __pyx_t_9;
  int __pyx_t_10;
  PyObject *__pyx_t_11 = NULL;
  __Pyx_RefNannySetupContext("_unellipsify", 0);

  /* "View.MemoryView":657
 *     full slices.
 *     """
 *     if not isinstance(index, tuple):             # <<<<<<<<<<<<<<
 *         tup = (index,)
 *     else:
 */
  __pyx_t_1 = PyTuple_Check(__pyx_v_index); 
  __pyx_t_2 = ((!(__pyx_t_1 != 0)) != 0);
  if (__pyx_t_2) {

    /* "View.MemoryView":658
 *     """
 *     if not isinstance(index, tuple):
 *         tup = (index,)             # <<<<<<<<<<<<<<
 *     else:
 *         tup = index
 */
    __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 658, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_INCREF(__pyx_v_index);
    __Pyx_GIVEREF(__pyx_v_index);
    PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_v_index);
    __pyx_v_tup = __pyx_t_3;
    __pyx_t_3 = 0;

    /* "View.MemoryView":657
 *     full slices.
 *     """
 *     if not isinstance(index, tuple):             # <<<<<<<<<<<<<<
 *         tup = (index,)
 *     else:
 */
    goto __pyx_L3;
  }

  /* "View.MemoryView":660
 *         tup = (index,)
 *     else:
 *         tup = index             # <<<<<<<<<<<<<<
 * 
 *     result = []
 */
  /*else*/ {
    __Pyx_INCREF(__pyx_v_index);
    __pyx_v_tup = __pyx_v_index;
  }
  __pyx_L3:;

  /* "View.MemoryView":662
 *         tup = index
 * 
 *     result = []             # <<<<<<<<<<<<<<
 *     have_slices = False
 *     seen_ellipsis = False
 */
  __pyx_t_3 = PyList_New(0); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 662, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_v_result = ((PyObject*)__pyx_t_3);
  __pyx_t_3 = 0;

  /* "View.MemoryView":663
 * 
 *     result = []
 *     have_slices = False             # <<<<<<<<<<<<<<
 *     seen_ellipsis = False
 *     for idx, item in enumerate(tup):
 */
  __pyx_v_have_slices = 0;

  /* "View.MemoryView":664
 *     result = []
 *     have_slices = False
 *     seen_ellipsis = False             # <<<<<<<<<<<<<<
 *     for idx, item in enumerate(tup):
 *         if item is Ellipsis:
 */
  __pyx_v_seen_ellipsis = 0;

  /* "View.MemoryView":665
 *     have_slices = False
 *     seen_ellipsis = False
 *     for idx, item in enumerate(tup):             # <<<<<<<<<<<<<<
 *         if item is Ellipsis:
 *             if not seen_ellipsis:
 */
  __Pyx_INCREF(__pyx_int_0);
  __pyx_t_3 = __pyx_int_0;
  if (likely(PyList_CheckExact(__pyx_v_tup)) || PyTuple_CheckExact(__pyx_v_tup)) {
    __pyx_t_4 = __pyx_v_tup; __Pyx_INCREF(__pyx_t_4); __pyx_t_5 = 0;
    __pyx_t_6 = NULL;
  } else {
    __pyx_t_5 = -1; __pyx_t_4 = PyObject_GetIter(__pyx_v_tup); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 665, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_6 = Py_TYPE(__pyx_t_4)->tp_iternext; if (unlikely(!__pyx_t_6)) __PYX_ERR(2, 665, __pyx_L1_error)
  }
  for (;;) {
    if (likely(!__pyx_t_6)) {
      if (likely(PyList_CheckExact(__pyx_t_4))) {
        if (__pyx_t_5 >= PyList_GET_SIZE(__pyx_t_4)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_7 = PyList_GET_ITEM(__pyx_t_4, __pyx_t_5); __Pyx_INCREF(__pyx_t_7); __pyx_t_5++; if (unlikely(0 < 0)) __PYX_ERR(2, 665, __pyx_L1_error)
        #else
        __pyx_t_7 = PySequence_ITEM(__pyx_t_4, __pyx_t_5); __pyx_t_5++; if (unlikely(!__pyx_t_7)) __PYX_ERR(2, 665, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        #endif
      } else {
        if (__pyx_t_5 >= PyTuple_GET_SIZE(__pyx_t_4)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_7 = PyTuple_GET_ITEM(__pyx_t_4, __pyx_t_5); __Pyx_INCREF(__pyx_t_7); __pyx_t_5++; if (unlikely(0 < 0)) __PYX_ERR(2, 665, __pyx_L1_error)
        #else
        __pyx_t_7 = PySequence_ITEM(__pyx_t_4, __pyx_t_5); __pyx_t_5++; if (unlikely(!__pyx_t_7)) __PYX_ERR(2, 665, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        #endif
      }
    } else {
      __pyx_t_7 = __pyx_t_6(__pyx_t_4);
      if (unlikely(!__pyx_t_7)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(exc_type == PyExc_StopIteration || PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(2, 665, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_7);
    }
    __Pyx_XDECREF_SET(__pyx_v_item, __pyx_t_7);
    __pyx_t_7 = 0;
    __Pyx_INCREF(__pyx_t_3);
    __Pyx_XDECREF_SET(__pyx_v_idx, __pyx_t_3);
    __pyx_t_7 = __Pyx_PyInt_AddObjC(__pyx_t_3, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_7)) __PYX_ERR(2, 665, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_3);
    __pyx_t_3 = __pyx_t_7;
    __pyx_t_7 = 0;

    /* "View.MemoryView":666
 *     seen_ellipsis = False
 *     for idx, item in enumerate(tup):
 *         if item is Ellipsis:             # <<<<<<<<<<<<<<
 *             if not seen_ellipsis:
 *                 result.extend([slice(None)] * (ndim - len(tup) + 1))
 */
    __pyx_t_2 = (__pyx_v_item == __pyx_builtin_Ellipsis);
    __pyx_t_1 = (__pyx_t_2 != 0);
    if (__pyx_t_1) {

      /* "View.MemoryView":667
 *     for idx, item in enumerate(tup):
 *         if item is Ellipsis:
 *             if not seen_ellipsis:             # <<<<<<<<<<<<<<
 *                 result.extend([slice(None)] * (ndim - len(tup) + 1))
 *                 seen_ellipsis = True
 */
      __pyx_t_1 = ((!(__pyx_v_seen_ellipsis != 0)) != 0);
      if (__pyx_t_1) {

        /* "View.MemoryView":668
 *         if item is Ellipsis:
 *             if not seen_ellipsis:
 *                 result.extend([slice(None)] * (ndim - len(tup) + 1))             # <<<<<<<<<<<<<<
 *                 seen_ellipsis = True
 *             else:
 */
        __pyx_t_8 = PyObject_Length(__pyx_v_tup); if (unlikely(__pyx_t_8 == -1)) __PYX_ERR(2, 668, __pyx_L1_error)
        __pyx_t_7 = PyList_New(1 * ((((__pyx_v_ndim - __pyx_t_8) + 1)<0) ? 0:((__pyx_v_ndim - __pyx_t_8) + 1))); if (unlikely(!__pyx_t_7)) __PYX_ERR(2, 668, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        { Py_ssize_t __pyx_temp;
          for (__pyx_temp=0; __pyx_temp < ((__pyx_v_ndim - __pyx_t_8) + 1); __pyx_temp++) {
            __Pyx_INCREF(__pyx_slice__53);
            __Pyx_GIVEREF(__pyx_slice__53);
            PyList_SET_ITEM(__pyx_t_7, __pyx_temp, __pyx_slice__53);
          }
        }
        __pyx_t_9 = __Pyx_PyList_Extend(__pyx_v_result, __pyx_t_7); if (unlikely(__pyx_t_9 == -1)) __PYX_ERR(2, 668, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;

        /* "View.MemoryView":669
 *             if not seen_ellipsis:
 *                 result.extend([slice(None)] * (ndim - len(tup) + 1))
 *                 seen_ellipsis = True             # <<<<<<<<<<<<<<
 *             else:
 *                 result.append(slice(None))
 */
        __pyx_v_seen_ellipsis = 1;

        /* "View.MemoryView":667
 *     for idx, item in enumerate(tup):
 *         if item is Ellipsis:
 *             if not seen_ellipsis:             # <<<<<<<<<<<<<<
 *                 result.extend([slice(None)] * (ndim - len(tup) + 1))
 *                 seen_ellipsis = True
 */
        goto __pyx_L7;
      }

      /* "View.MemoryView":671
 *                 seen_ellipsis = True
 *             else:
 *                 result.append(slice(None))             # <<<<<<<<<<<<<<
 *             have_slices = True
 *         else:
 */
      /*else*/ {
        __pyx_t_9 = __Pyx_PyList_Append(__pyx_v_result, __pyx_slice__54); if (unlikely(__pyx_t_9 == -1)) __PYX_ERR(2, 671, __pyx_L1_error)
      }
      __pyx_L7:;

      /* "View.MemoryView":672
 *             else:
 *                 result.append(slice(None))
 *             have_slices = True             # <<<<<<<<<<<<<<
 *         else:
 *             if not isinstance(item, slice) and not PyIndex_Check(item):
 */
      __pyx_v_have_slices = 1;

      /* "View.MemoryView":666
 *     seen_ellipsis = False
 *     for idx, item in enumerate(tup):
 *         if item is Ellipsis:             # <<<<<<<<<<<<<<
 *             if not seen_ellipsis:
 *                 result.extend([slice(None)] * (ndim - len(tup) + 1))
 */
      goto __pyx_L6;
    }

    /* "View.MemoryView":674
 *             have_slices = True
 *         else:
 *             if not isinstance(item, slice) and not PyIndex_Check(item):             # <<<<<<<<<<<<<<
 *                 raise TypeError("Cannot index with type '%s'" % type(item))
 * 
 */
    /*else*/ {
      __pyx_t_2 = PySlice_Check(__pyx_v_item); 
      __pyx_t_10 = ((!(__pyx_t_2 != 0)) != 0);
      if (__pyx_t_10) {
      } else {
        __pyx_t_1 = __pyx_t_10;
        goto __pyx_L9_bool_binop_done;
      }
      __pyx_t_10 = ((!(PyIndex_Check(__pyx_v_item) != 0)) != 0);
      __pyx_t_1 = __pyx_t_10;
      __pyx_L9_bool_binop_done:;
      if (__pyx_t_1) {

        /* "View.MemoryView":675
 *         else:
 *             if not isinstance(item, slice) and not PyIndex_Check(item):
 *                 raise TypeError("Cannot index with type '%s'" % type(item))             # <<<<<<<<<<<<<<
 * 
 *             have_slices = have_slices or isinstance(item, slice)
 */
        __pyx_t_7 = __Pyx_PyString_Format(__pyx_kp_s_Cannot_index_with_type_s, ((PyObject *)Py_TYPE(__pyx_v_item))); if (unlikely(!__pyx_t_7)) __PYX_ERR(2, 675, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        __pyx_t_11 = PyTuple_New(1); if (unlikely(!__pyx_t_11)) __PYX_ERR(2, 675, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_11);
        __Pyx_GIVEREF(__pyx_t_7);
        PyTuple_SET_ITEM(__pyx_t_11, 0, __pyx_t_7);
        __pyx_t_7 = 0;
        __pyx_t_7 = __Pyx_PyObject_Call(__pyx_builtin_TypeError, __pyx_t_11, NULL); if (unlikely(!__pyx_t_7)) __PYX_ERR(2, 675, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
        __Pyx_Raise(__pyx_t_7, 0, 0, 0);
        __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        __PYX_ERR(2, 675, __pyx_L1_error)

        /* "View.MemoryView":674
 *             have_slices = True
 *         else:
 *             if not isinstance(item, slice) and not PyIndex_Check(item):             # <<<<<<<<<<<<<<
 *                 raise TypeError("Cannot index with type '%s'" % type(item))
 * 
 */
      }

      /* "View.MemoryView":677
 *                 raise TypeError("Cannot index with type '%s'" % type(item))
 * 
 *             have_slices = have_slices or isinstance(item, slice)             # <<<<<<<<<<<<<<
 *             result.append(item)
 * 
 */
      __pyx_t_10 = (__pyx_v_have_slices != 0);
      if (!__pyx_t_10) {
      } else {
        __pyx_t_1 = __pyx_t_10;
        goto __pyx_L11_bool_binop_done;
      }
      __pyx_t_10 = PySlice_Check(__pyx_v_item); 
      __pyx_t_2 = (__pyx_t_10 != 0);
      __pyx_t_1 = __pyx_t_2;
      __pyx_L11_bool_binop_done:;
      __pyx_v_have_slices = __pyx_t_1;

      /* "View.MemoryView":678
 * 
 *             have_slices = have_slices or isinstance(item, slice)
 *             result.append(item)             # <<<<<<<<<<<<<<
 * 
 *     nslices = ndim - len(result)
 */
      __pyx_t_9 = __Pyx_PyList_Append(__pyx_v_result, __pyx_v_item); if (unlikely(__pyx_t_9 == -1)) __PYX_ERR(2, 678, __pyx_L1_error)
    }
    __pyx_L6:;

    /* "View.MemoryView":665
 *     have_slices = False
 *     seen_ellipsis = False
 *     for idx, item in enumerate(tup):             # <<<<<<<<<<<<<<
 *         if item is Ellipsis:
 *             if not seen_ellipsis:
 */
  }
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "View.MemoryView":680
 *             result.append(item)
 * 
 *     nslices = ndim - len(result)             # <<<<<<<<<<<<<<
 *     if nslices:
 *         result.extend([slice(None)] * nslices)
 */
  __pyx_t_5 = PyList_GET_SIZE(__pyx_v_result); if (unlikely(__pyx_t_5 == -1)) __PYX_ERR(2, 680, __pyx_L1_error)
  __pyx_v_nslices = (__pyx_v_ndim - __pyx_t_5);

  /* "View.MemoryView":681
 * 
 *     nslices = ndim - len(result)
 *     if nslices:             # <<<<<<<<<<<<<<
 *         result.extend([slice(None)] * nslices)
 * 
 */
  __pyx_t_1 = (__pyx_v_nslices != 0);
  if (__pyx_t_1) {

    /* "View.MemoryView":682
 *     nslices = ndim - len(result)
 *     if nslices:
 *         result.extend([slice(None)] * nslices)             # <<<<<<<<<<<<<<
 * 
 *     return have_slices or nslices, tuple(result)
 */
    __pyx_t_3 = PyList_New(1 * ((__pyx_v_nslices<0) ? 0:__pyx_v_nslices)); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 682, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    { Py_ssize_t __pyx_temp;
      for (__pyx_temp=0; __pyx_temp < __pyx_v_nslices; __pyx_temp++) {
        __Pyx_INCREF(__pyx_slice__55);
        __Pyx_GIVEREF(__pyx_slice__55);
        PyList_SET_ITEM(__pyx_t_3, __pyx_temp, __pyx_slice__55);
      }
    }
    __pyx_t_9 = __Pyx_PyList_Extend(__pyx_v_result, __pyx_t_3); if (unlikely(__pyx_t_9 == -1)) __PYX_ERR(2, 682, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

    /* "View.MemoryView":681
 * 
 *     nslices = ndim - len(result)
 *     if nslices:             # <<<<<<<<<<<<<<
 *         result.extend([slice(None)] * nslices)
 * 
 */
  }

  /* "View.MemoryView":684
 *         result.extend([slice(None)] * nslices)
 * 
 *     return have_slices or nslices, tuple(result)             # <<<<<<<<<<<<<<
 * 
 * cdef assert_direct_dimensions(Py_ssize_t *suboffsets, int ndim):
 */
  __Pyx_XDECREF(__pyx_r);
  if (!__pyx_v_have_slices) {
  } else {
    __pyx_t_4 = __Pyx_PyBool_FromLong(__pyx_v_have_slices); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 684, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_3 = __pyx_t_4;
    __pyx_t_4 = 0;
    goto __pyx_L14_bool_binop_done;
  }
  __pyx_t_4 = PyInt_FromSsize_t(__pyx_v_nslices); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 684, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_3 = __pyx_t_4;
  __pyx_t_4 = 0;
  __pyx_L14_bool_binop_done:;
  __pyx_t_4 = PyList_AsTuple(__pyx_v_result); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 684, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_7 = PyTuple_New(2); if (unlikely(!__pyx_t_7)) __PYX_ERR(2, 684, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_GIVEREF(__pyx_t_3);
  PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_7, 1, __pyx_t_4);
  __pyx_t_3 = 0;
  __pyx_t_4 = 0;
  __pyx_r = ((PyObject*)__pyx_t_7);
  __pyx_t_7 = 0;
  goto __pyx_L0;

  /* "View.MemoryView":652
 *     return isinstance(o, memoryview)
 * 
 * cdef tuple _unellipsify(object index, int ndim):             # <<<<<<<<<<<<<<
 *     """
 *     Replace all ellipses with full slices and fill incomplete indices with
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_11);
  __Pyx_AddTraceback("View.MemoryView._unellipsify", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_tup);
  __Pyx_XDECREF(__pyx_v_result);
  __Pyx_XDECREF(__pyx_v_idx);
  __Pyx_XDECREF(__pyx_v_item);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":686
 *     return have_slices or nslices, tuple(result)
 * 
 * cdef assert_direct_dimensions(Py_ssize_t *suboffsets, int ndim):             # <<<<<<<<<<<<<<
 *     for suboffset in suboffsets[:ndim]:
 *         if suboffset >= 0:
 */

static PyObject *assert_direct_dimensions(Py_ssize_t *__pyx_v_suboffsets, int __pyx_v_ndim) {
  Py_ssize_t __pyx_v_suboffset;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  Py_ssize_t *__pyx_t_1;
  Py_ssize_t *__pyx_t_2;
  Py_ssize_t *__pyx_t_3;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  __Pyx_RefNannySetupContext("assert_direct_dimensions", 0);

  /* "View.MemoryView":687
 * 
 * cdef assert_direct_dimensions(Py_ssize_t *suboffsets, int ndim):
 *     for suboffset in suboffsets[:ndim]:             # <<<<<<<<<<<<<<
 *         if suboffset >= 0:
 *             raise ValueError("Indirect dimensions not supported")
 */
  __pyx_t_2 = (__pyx_v_suboffsets + __pyx_v_ndim);
  for (__pyx_t_3 = __pyx_v_suboffsets; __pyx_t_3 < __pyx_t_2; __pyx_t_3++) {
    __pyx_t_1 = __pyx_t_3;
    __pyx_v_suboffset = (__pyx_t_1[0]);

    /* "View.MemoryView":688
 * cdef assert_direct_dimensions(Py_ssize_t *suboffsets, int ndim):
 *     for suboffset in suboffsets[:ndim]:
 *         if suboffset >= 0:             # <<<<<<<<<<<<<<
 *             raise ValueError("Indirect dimensions not supported")
 * 
 */
    __pyx_t_4 = ((__pyx_v_suboffset >= 0) != 0);
    if (__pyx_t_4) {

      /* "View.MemoryView":689
 *     for suboffset in suboffsets[:ndim]:
 *         if suboffset >= 0:
 *             raise ValueError("Indirect dimensions not supported")             # <<<<<<<<<<<<<<
 * 
 * 
 */
      __pyx_t_5 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__56, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 689, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_Raise(__pyx_t_5, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __PYX_ERR(2, 689, __pyx_L1_error)

      /* "View.MemoryView":688
 * cdef assert_direct_dimensions(Py_ssize_t *suboffsets, int ndim):
 *     for suboffset in suboffsets[:ndim]:
 *         if suboffset >= 0:             # <<<<<<<<<<<<<<
 *             raise ValueError("Indirect dimensions not supported")
 * 
 */
    }
  }

  /* "View.MemoryView":686
 *     return have_slices or nslices, tuple(result)
 * 
 * cdef assert_direct_dimensions(Py_ssize_t *suboffsets, int ndim):             # <<<<<<<<<<<<<<
 *     for suboffset in suboffsets[:ndim]:
 *         if suboffset >= 0:
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("View.MemoryView.assert_direct_dimensions", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":696
 * 
 * @cname('__pyx_memview_slice')
 * cdef memoryview memview_slice(memoryview memview, object indices):             # <<<<<<<<<<<<<<
 *     cdef int new_ndim = 0, suboffset_dim = -1, dim
 *     cdef bint negative_step
 */

static struct __pyx_memoryview_obj *__pyx_memview_slice(struct __pyx_memoryview_obj *__pyx_v_memview, PyObject *__pyx_v_indices) {
  int __pyx_v_new_ndim;
  int __pyx_v_suboffset_dim;
  int __pyx_v_dim;
  __Pyx_memviewslice __pyx_v_src;
  __Pyx_memviewslice __pyx_v_dst;
  __Pyx_memviewslice *__pyx_v_p_src;
  struct __pyx_memoryviewslice_obj *__pyx_v_memviewsliceobj = 0;
  __Pyx_memviewslice *__pyx_v_p_dst;
  int *__pyx_v_p_suboffset_dim;
  Py_ssize_t __pyx_v_start;
  Py_ssize_t __pyx_v_stop;
  Py_ssize_t __pyx_v_step;
  int __pyx_v_have_start;
  int __pyx_v_have_stop;
  int __pyx_v_have_step;
  PyObject *__pyx_v_index = NULL;
  struct __pyx_memoryview_obj *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  struct __pyx_memoryview_obj *__pyx_t_4;
  char *__pyx_t_5;
  int __pyx_t_6;
  Py_ssize_t __pyx_t_7;
  PyObject *(*__pyx_t_8)(PyObject *);
  PyObject *__pyx_t_9 = NULL;
  Py_ssize_t __pyx_t_10;
  int __pyx_t_11;
  Py_ssize_t __pyx_t_12;
  __Pyx_RefNannySetupContext("memview_slice", 0);

  /* "View.MemoryView":697
 * @cname('__pyx_memview_slice')
 * cdef memoryview memview_slice(memoryview memview, object indices):
 *     cdef int new_ndim = 0, suboffset_dim = -1, dim             # <<<<<<<<<<<<<<
 *     cdef bint negative_step
 *     cdef __Pyx_memviewslice src, dst
 */
  __pyx_v_new_ndim = 0;
  __pyx_v_suboffset_dim = -1;

  /* "View.MemoryView":704
 * 
 * 
 *     memset(&dst, 0, sizeof(dst))             # <<<<<<<<<<<<<<
 * 
 *     cdef _memoryviewslice memviewsliceobj
 */
  memset((&__pyx_v_dst), 0, (sizeof(__pyx_v_dst)));

  /* "View.MemoryView":708
 *     cdef _memoryviewslice memviewsliceobj
 * 
 *     assert memview.view.ndim > 0             # <<<<<<<<<<<<<<
 * 
 *     if isinstance(memview, _memoryviewslice):
 */
  #ifndef CYTHON_WITHOUT_ASSERTIONS
  if (unlikely(!Py_OptimizeFlag)) {
    if (unlikely(!((__pyx_v_memview->view.ndim > 0) != 0))) {
      PyErr_SetNone(PyExc_AssertionError);
      __PYX_ERR(2, 708, __pyx_L1_error)
    }
  }
  #endif

  /* "View.MemoryView":710
 *     assert memview.view.ndim > 0
 * 
 *     if isinstance(memview, _memoryviewslice):             # <<<<<<<<<<<<<<
 *         memviewsliceobj = memview
 *         p_src = &memviewsliceobj.from_slice
 */
  __pyx_t_1 = __Pyx_TypeCheck(((PyObject *)__pyx_v_memview), __pyx_memoryviewslice_type); 
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "View.MemoryView":711
 * 
 *     if isinstance(memview, _memoryviewslice):
 *         memviewsliceobj = memview             # <<<<<<<<<<<<<<
 *         p_src = &memviewsliceobj.from_slice
 *     else:
 */
    if (!(likely(((((PyObject *)__pyx_v_memview)) == Py_None) || likely(__Pyx_TypeTest(((PyObject *)__pyx_v_memview), __pyx_memoryviewslice_type))))) __PYX_ERR(2, 711, __pyx_L1_error)
    __pyx_t_3 = ((PyObject *)__pyx_v_memview);
    __Pyx_INCREF(__pyx_t_3);
    __pyx_v_memviewsliceobj = ((struct __pyx_memoryviewslice_obj *)__pyx_t_3);
    __pyx_t_3 = 0;

    /* "View.MemoryView":712
 *     if isinstance(memview, _memoryviewslice):
 *         memviewsliceobj = memview
 *         p_src = &memviewsliceobj.from_slice             # <<<<<<<<<<<<<<
 *     else:
 *         slice_copy(memview, &src)
 */
    __pyx_v_p_src = (&__pyx_v_memviewsliceobj->from_slice);

    /* "View.MemoryView":710
 *     assert memview.view.ndim > 0
 * 
 *     if isinstance(memview, _memoryviewslice):             # <<<<<<<<<<<<<<
 *         memviewsliceobj = memview
 *         p_src = &memviewsliceobj.from_slice
 */
    goto __pyx_L3;
  }

  /* "View.MemoryView":714
 *         p_src = &memviewsliceobj.from_slice
 *     else:
 *         slice_copy(memview, &src)             # <<<<<<<<<<<<<<
 *         p_src = &src
 * 
 */
  /*else*/ {
    __pyx_memoryview_slice_copy(__pyx_v_memview, (&__pyx_v_src));

    /* "View.MemoryView":715
 *     else:
 *         slice_copy(memview, &src)
 *         p_src = &src             # <<<<<<<<<<<<<<
 * 
 * 
 */
    __pyx_v_p_src = (&__pyx_v_src);
  }
  __pyx_L3:;

  /* "View.MemoryView":721
 * 
 * 
 *     dst.memview = p_src.memview             # <<<<<<<<<<<<<<
 *     dst.data = p_src.data
 * 
 */
  __pyx_t_4 = __pyx_v_p_src->memview;
  __pyx_v_dst.memview = __pyx_t_4;

  /* "View.MemoryView":722
 * 
 *     dst.memview = p_src.memview
 *     dst.data = p_src.data             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_5 = __pyx_v_p_src->data;
  __pyx_v_dst.data = __pyx_t_5;

  /* "View.MemoryView":727
 * 
 * 
 *     cdef __Pyx_memviewslice *p_dst = &dst             # <<<<<<<<<<<<<<
 *     cdef int *p_suboffset_dim = &suboffset_dim
 *     cdef Py_ssize_t start, stop, step
 */
  __pyx_v_p_dst = (&__pyx_v_dst);

  /* "View.MemoryView":728
 * 
 *     cdef __Pyx_memviewslice *p_dst = &dst
 *     cdef int *p_suboffset_dim = &suboffset_dim             # <<<<<<<<<<<<<<
 *     cdef Py_ssize_t start, stop, step
 *     cdef bint have_start, have_stop, have_step
 */
  __pyx_v_p_suboffset_dim = (&__pyx_v_suboffset_dim);

  /* "View.MemoryView":732
 *     cdef bint have_start, have_stop, have_step
 * 
 *     for dim, index in enumerate(indices):             # <<<<<<<<<<<<<<
 *         if PyIndex_Check(index):
 *             slice_memviewslice(
 */
  __pyx_t_6 = 0;
  if (likely(PyList_CheckExact(__pyx_v_indices)) || PyTuple_CheckExact(__pyx_v_indices)) {
    __pyx_t_3 = __pyx_v_indices; __Pyx_INCREF(__pyx_t_3); __pyx_t_7 = 0;
    __pyx_t_8 = NULL;
  } else {
    __pyx_t_7 = -1; __pyx_t_3 = PyObject_GetIter(__pyx_v_indices); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 732, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_8 = Py_TYPE(__pyx_t_3)->tp_iternext; if (unlikely(!__pyx_t_8)) __PYX_ERR(2, 732, __pyx_L1_error)
  }
  for (;;) {
    if (likely(!__pyx_t_8)) {
      if (likely(PyList_CheckExact(__pyx_t_3))) {
        if (__pyx_t_7 >= PyList_GET_SIZE(__pyx_t_3)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_9 = PyList_GET_ITEM(__pyx_t_3, __pyx_t_7); __Pyx_INCREF(__pyx_t_9); __pyx_t_7++; if (unlikely(0 < 0)) __PYX_ERR(2, 732, __pyx_L1_error)
        #else
        __pyx_t_9 = PySequence_ITEM(__pyx_t_3, __pyx_t_7); __pyx_t_7++; if (unlikely(!__pyx_t_9)) __PYX_ERR(2, 732, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_9);
        #endif
      } else {
        if (__pyx_t_7 >= PyTuple_GET_SIZE(__pyx_t_3)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_9 = PyTuple_GET_ITEM(__pyx_t_3, __pyx_t_7); __Pyx_INCREF(__pyx_t_9); __pyx_t_7++; if (unlikely(0 < 0)) __PYX_ERR(2, 732, __pyx_L1_error)
        #else
        __pyx_t_9 = PySequence_ITEM(__pyx_t_3, __pyx_t_7); __pyx_t_7++; if (unlikely(!__pyx_t_9)) __PYX_ERR(2, 732, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_9);
        #endif
      }
    } else {
      __pyx_t_9 = __pyx_t_8(__pyx_t_3);
      if (unlikely(!__pyx_t_9)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(exc_type == PyExc_StopIteration || PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(2, 732, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_9);
    }
    __Pyx_XDECREF_SET(__pyx_v_index, __pyx_t_9);
    __pyx_t_9 = 0;
    __pyx_v_dim = __pyx_t_6;
    __pyx_t_6 = (__pyx_t_6 + 1);

    /* "View.MemoryView":733
 * 
 *     for dim, index in enumerate(indices):
 *         if PyIndex_Check(index):             # <<<<<<<<<<<<<<
 *             slice_memviewslice(
 *                 p_dst, p_src.shape[dim], p_src.strides[dim], p_src.suboffsets[dim],
 */
    __pyx_t_2 = (PyIndex_Check(__pyx_v_index) != 0);
    if (__pyx_t_2) {

      /* "View.MemoryView":737
 *                 p_dst, p_src.shape[dim], p_src.strides[dim], p_src.suboffsets[dim],
 *                 dim, new_ndim, p_suboffset_dim,
 *                 index, 0, 0, # start, stop, step             # <<<<<<<<<<<<<<
 *                 0, 0, 0, # have_{start,stop,step}
 *                 False)
 */
      __pyx_t_10 = __Pyx_PyIndex_AsSsize_t(__pyx_v_index); if (unlikely((__pyx_t_10 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(2, 737, __pyx_L1_error)

      /* "View.MemoryView":734
 *     for dim, index in enumerate(indices):
 *         if PyIndex_Check(index):
 *             slice_memviewslice(             # <<<<<<<<<<<<<<
 *                 p_dst, p_src.shape[dim], p_src.strides[dim], p_src.suboffsets[dim],
 *                 dim, new_ndim, p_suboffset_dim,
 */
      __pyx_t_11 = __pyx_memoryview_slice_memviewslice(__pyx_v_p_dst, (__pyx_v_p_src->shape[__pyx_v_dim]), (__pyx_v_p_src->strides[__pyx_v_dim]), (__pyx_v_p_src->suboffsets[__pyx_v_dim]), __pyx_v_dim, __pyx_v_new_ndim, __pyx_v_p_suboffset_dim, __pyx_t_10, 0, 0, 0, 0, 0, 0); if (unlikely(__pyx_t_11 == -1)) __PYX_ERR(2, 734, __pyx_L1_error)

      /* "View.MemoryView":733
 * 
 *     for dim, index in enumerate(indices):
 *         if PyIndex_Check(index):             # <<<<<<<<<<<<<<
 *             slice_memviewslice(
 *                 p_dst, p_src.shape[dim], p_src.strides[dim], p_src.suboffsets[dim],
 */
      goto __pyx_L6;
    }

    /* "View.MemoryView":740
 *                 0, 0, 0, # have_{start,stop,step}
 *                 False)
 *         elif index is None:             # <<<<<<<<<<<<<<
 *             p_dst.shape[new_ndim] = 1
 *             p_dst.strides[new_ndim] = 0
 */
    __pyx_t_2 = (__pyx_v_index == Py_None);
    __pyx_t_1 = (__pyx_t_2 != 0);
    if (__pyx_t_1) {

      /* "View.MemoryView":741
 *                 False)
 *         elif index is None:
 *             p_dst.shape[new_ndim] = 1             # <<<<<<<<<<<<<<
 *             p_dst.strides[new_ndim] = 0
 *             p_dst.suboffsets[new_ndim] = -1
 */
      (__pyx_v_p_dst->shape[__pyx_v_new_ndim]) = 1;

      /* "View.MemoryView":742
 *         elif index is None:
 *             p_dst.shape[new_ndim] = 1
 *             p_dst.strides[new_ndim] = 0             # <<<<<<<<<<<<<<
 *             p_dst.suboffsets[new_ndim] = -1
 *             new_ndim += 1
 */
      (__pyx_v_p_dst->strides[__pyx_v_new_ndim]) = 0;

      /* "View.MemoryView":743
 *             p_dst.shape[new_ndim] = 1
 *             p_dst.strides[new_ndim] = 0
 *             p_dst.suboffsets[new_ndim] = -1             # <<<<<<<<<<<<<<
 *             new_ndim += 1
 *         else:
 */
      (__pyx_v_p_dst->suboffsets[__pyx_v_new_ndim]) = -1L;

      /* "View.MemoryView":744
 *             p_dst.strides[new_ndim] = 0
 *             p_dst.suboffsets[new_ndim] = -1
 *             new_ndim += 1             # <<<<<<<<<<<<<<
 *         else:
 *             start = index.start or 0
 */
      __pyx_v_new_ndim = (__pyx_v_new_ndim + 1);

      /* "View.MemoryView":740
 *                 0, 0, 0, # have_{start,stop,step}
 *                 False)
 *         elif index is None:             # <<<<<<<<<<<<<<
 *             p_dst.shape[new_ndim] = 1
 *             p_dst.strides[new_ndim] = 0
 */
      goto __pyx_L6;
    }

    /* "View.MemoryView":746
 *             new_ndim += 1
 *         else:
 *             start = index.start or 0             # <<<<<<<<<<<<<<
 *             stop = index.stop or 0
 *             step = index.step or 0
 */
    /*else*/ {
      __pyx_t_9 = __Pyx_PyObject_GetAttrStr(__pyx_v_index, __pyx_n_s_start); if (unlikely(!__pyx_t_9)) __PYX_ERR(2, 746, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_t_9); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(2, 746, __pyx_L1_error)
      if (!__pyx_t_1) {
        __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      } else {
        __pyx_t_12 = __Pyx_PyIndex_AsSsize_t(__pyx_t_9); if (unlikely((__pyx_t_12 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(2, 746, __pyx_L1_error)
        __pyx_t_10 = __pyx_t_12;
        __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
        goto __pyx_L7_bool_binop_done;
      }
      __pyx_t_10 = 0;
      __pyx_L7_bool_binop_done:;
      __pyx_v_start = __pyx_t_10;

      /* "View.MemoryView":747
 *         else:
 *             start = index.start or 0
 *             stop = index.stop or 0             # <<<<<<<<<<<<<<
 *             step = index.step or 0
 * 
 */
      __pyx_t_9 = __Pyx_PyObject_GetAttrStr(__pyx_v_index, __pyx_n_s_stop); if (unlikely(!__pyx_t_9)) __PYX_ERR(2, 747, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_t_9); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(2, 747, __pyx_L1_error)
      if (!__pyx_t_1) {
        __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      } else {
        __pyx_t_12 = __Pyx_PyIndex_AsSsize_t(__pyx_t_9); if (unlikely((__pyx_t_12 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(2, 747, __pyx_L1_error)
        __pyx_t_10 = __pyx_t_12;
        __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
        goto __pyx_L9_bool_binop_done;
      }
      __pyx_t_10 = 0;
      __pyx_L9_bool_binop_done:;
      __pyx_v_stop = __pyx_t_10;

      /* "View.MemoryView":748
 *             start = index.start or 0
 *             stop = index.stop or 0
 *             step = index.step or 0             # <<<<<<<<<<<<<<
 * 
 *             have_start = index.start is not None
 */
      __pyx_t_9 = __Pyx_PyObject_GetAttrStr(__pyx_v_index, __pyx_n_s_step); if (unlikely(!__pyx_t_9)) __PYX_ERR(2, 748, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_t_9); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(2, 748, __pyx_L1_error)
      if (!__pyx_t_1) {
        __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      } else {
        __pyx_t_12 = __Pyx_PyIndex_AsSsize_t(__pyx_t_9); if (unlikely((__pyx_t_12 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(2, 748, __pyx_L1_error)
        __pyx_t_10 = __pyx_t_12;
        __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
        goto __pyx_L11_bool_binop_done;
      }
      __pyx_t_10 = 0;
      __pyx_L11_bool_binop_done:;
      __pyx_v_step = __pyx_t_10;

      /* "View.MemoryView":750
 *             step = index.step or 0
 * 
 *             have_start = index.start is not None             # <<<<<<<<<<<<<<
 *             have_stop = index.stop is not None
 *             have_step = index.step is not None
 */
      __pyx_t_9 = __Pyx_PyObject_GetAttrStr(__pyx_v_index, __pyx_n_s_start); if (unlikely(!__pyx_t_9)) __PYX_ERR(2, 750, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __pyx_t_1 = (__pyx_t_9 != Py_None);
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      __pyx_v_have_start = __pyx_t_1;

      /* "View.MemoryView":751
 * 
 *             have_start = index.start is not None
 *             have_stop = index.stop is not None             # <<<<<<<<<<<<<<
 *             have_step = index.step is not None
 * 
 */
      __pyx_t_9 = __Pyx_PyObject_GetAttrStr(__pyx_v_index, __pyx_n_s_stop); if (unlikely(!__pyx_t_9)) __PYX_ERR(2, 751, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __pyx_t_1 = (__pyx_t_9 != Py_None);
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      __pyx_v_have_stop = __pyx_t_1;

      /* "View.MemoryView":752
 *             have_start = index.start is not None
 *             have_stop = index.stop is not None
 *             have_step = index.step is not None             # <<<<<<<<<<<<<<
 * 
 *             slice_memviewslice(
 */
      __pyx_t_9 = __Pyx_PyObject_GetAttrStr(__pyx_v_index, __pyx_n_s_step); if (unlikely(!__pyx_t_9)) __PYX_ERR(2, 752, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __pyx_t_1 = (__pyx_t_9 != Py_None);
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      __pyx_v_have_step = __pyx_t_1;

      /* "View.MemoryView":754
 *             have_step = index.step is not None
 * 
 *             slice_memviewslice(             # <<<<<<<<<<<<<<
 *                 p_dst, p_src.shape[dim], p_src.strides[dim], p_src.suboffsets[dim],
 *                 dim, new_ndim, p_suboffset_dim,
 */
      __pyx_t_11 = __pyx_memoryview_slice_memviewslice(__pyx_v_p_dst, (__pyx_v_p_src->shape[__pyx_v_dim]), (__pyx_v_p_src->strides[__pyx_v_dim]), (__pyx_v_p_src->suboffsets[__pyx_v_dim]), __pyx_v_dim, __pyx_v_new_ndim, __pyx_v_p_suboffset_dim, __pyx_v_start, __pyx_v_stop, __pyx_v_step, __pyx_v_have_start, __pyx_v_have_stop, __pyx_v_have_step, 1); if (unlikely(__pyx_t_11 == -1)) __PYX_ERR(2, 754, __pyx_L1_error)

      /* "View.MemoryView":760
 *                 have_start, have_stop, have_step,
 *                 True)
 *             new_ndim += 1             # <<<<<<<<<<<<<<
 * 
 *     if isinstance(memview, _memoryviewslice):
 */
      __pyx_v_new_ndim = (__pyx_v_new_ndim + 1);
    }
    __pyx_L6:;

    /* "View.MemoryView":732
 *     cdef bint have_start, have_stop, have_step
 * 
 *     for dim, index in enumerate(indices):             # <<<<<<<<<<<<<<
 *         if PyIndex_Check(index):
 *             slice_memviewslice(
 */
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "View.MemoryView":762
 *             new_ndim += 1
 * 
 *     if isinstance(memview, _memoryviewslice):             # <<<<<<<<<<<<<<
 *         return memoryview_fromslice(dst, new_ndim,
 *                                     memviewsliceobj.to_object_func,
 */
  __pyx_t_1 = __Pyx_TypeCheck(((PyObject *)__pyx_v_memview), __pyx_memoryviewslice_type); 
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "View.MemoryView":763
 * 
 *     if isinstance(memview, _memoryviewslice):
 *         return memoryview_fromslice(dst, new_ndim,             # <<<<<<<<<<<<<<
 *                                     memviewsliceobj.to_object_func,
 *                                     memviewsliceobj.to_dtype_func,
 */
    __Pyx_XDECREF(((PyObject *)__pyx_r));

    /* "View.MemoryView":764
 *     if isinstance(memview, _memoryviewslice):
 *         return memoryview_fromslice(dst, new_ndim,
 *                                     memviewsliceobj.to_object_func,             # <<<<<<<<<<<<<<
 *                                     memviewsliceobj.to_dtype_func,
 *                                     memview.dtype_is_object)
 */
    if (unlikely(!__pyx_v_memviewsliceobj)) { __Pyx_RaiseUnboundLocalError("memviewsliceobj"); __PYX_ERR(2, 764, __pyx_L1_error) }

    /* "View.MemoryView":765
 *         return memoryview_fromslice(dst, new_ndim,
 *                                     memviewsliceobj.to_object_func,
 *                                     memviewsliceobj.to_dtype_func,             # <<<<<<<<<<<<<<
 *                                     memview.dtype_is_object)
 *     else:
 */
    if (unlikely(!__pyx_v_memviewsliceobj)) { __Pyx_RaiseUnboundLocalError("memviewsliceobj"); __PYX_ERR(2, 765, __pyx_L1_error) }

    /* "View.MemoryView":763
 * 
 *     if isinstance(memview, _memoryviewslice):
 *         return memoryview_fromslice(dst, new_ndim,             # <<<<<<<<<<<<<<
 *                                     memviewsliceobj.to_object_func,
 *                                     memviewsliceobj.to_dtype_func,
 */
    __pyx_t_3 = __pyx_memoryview_fromslice(__pyx_v_dst, __pyx_v_new_ndim, __pyx_v_memviewsliceobj->to_object_func, __pyx_v_memviewsliceobj->to_dtype_func, __pyx_v_memview->dtype_is_object); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 763, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    if (!(likely(((__pyx_t_3) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_3, __pyx_memoryview_type))))) __PYX_ERR(2, 763, __pyx_L1_error)
    __pyx_r = ((struct __pyx_memoryview_obj *)__pyx_t_3);
    __pyx_t_3 = 0;
    goto __pyx_L0;

    /* "View.MemoryView":762
 *             new_ndim += 1
 * 
 *     if isinstance(memview, _memoryviewslice):             # <<<<<<<<<<<<<<
 *         return memoryview_fromslice(dst, new_ndim,
 *                                     memviewsliceobj.to_object_func,
 */
  }

  /* "View.MemoryView":768
 *                                     memview.dtype_is_object)
 *     else:
 *         return memoryview_fromslice(dst, new_ndim, NULL, NULL,             # <<<<<<<<<<<<<<
 *                                     memview.dtype_is_object)
 * 
 */
  /*else*/ {
    __Pyx_XDECREF(((PyObject *)__pyx_r));

    /* "View.MemoryView":769
 *     else:
 *         return memoryview_fromslice(dst, new_ndim, NULL, NULL,
 *                                     memview.dtype_is_object)             # <<<<<<<<<<<<<<
 * 
 * 
 */
    __pyx_t_3 = __pyx_memoryview_fromslice(__pyx_v_dst, __pyx_v_new_ndim, NULL, NULL, __pyx_v_memview->dtype_is_object); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 768, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);

    /* "View.MemoryView":768
 *                                     memview.dtype_is_object)
 *     else:
 *         return memoryview_fromslice(dst, new_ndim, NULL, NULL,             # <<<<<<<<<<<<<<
 *                                     memview.dtype_is_object)
 * 
 */
    if (!(likely(((__pyx_t_3) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_3, __pyx_memoryview_type))))) __PYX_ERR(2, 768, __pyx_L1_error)
    __pyx_r = ((struct __pyx_memoryview_obj *)__pyx_t_3);
    __pyx_t_3 = 0;
    goto __pyx_L0;
  }

  /* "View.MemoryView":696
 * 
 * @cname('__pyx_memview_slice')
 * cdef memoryview memview_slice(memoryview memview, object indices):             # <<<<<<<<<<<<<<
 *     cdef int new_ndim = 0, suboffset_dim = -1, dim
 *     cdef bint negative_step
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_AddTraceback("View.MemoryView.memview_slice", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_memviewsliceobj);
  __Pyx_XDECREF(__pyx_v_index);
  __Pyx_XGIVEREF((PyObject *)__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":793
 * 
 * @cname('__pyx_memoryview_slice_memviewslice')
 * cdef int slice_memviewslice(             # <<<<<<<<<<<<<<
 *         __Pyx_memviewslice *dst,
 *         Py_ssize_t shape, Py_ssize_t stride, Py_ssize_t suboffset,
 */

static int __pyx_memoryview_slice_memviewslice(__Pyx_memviewslice *__pyx_v_dst, Py_ssize_t __pyx_v_shape, Py_ssize_t __pyx_v_stride, Py_ssize_t __pyx_v_suboffset, int __pyx_v_dim, int __pyx_v_new_ndim, int *__pyx_v_suboffset_dim, Py_ssize_t __pyx_v_start, Py_ssize_t __pyx_v_stop, Py_ssize_t __pyx_v_step, int __pyx_v_have_start, int __pyx_v_have_stop, int __pyx_v_have_step, int __pyx_v_is_slice) {
  Py_ssize_t __pyx_v_new_shape;
  int __pyx_v_negative_step;
  int __pyx_r;
  int __pyx_t_1;
  int __pyx_t_2;
  int __pyx_t_3;

  /* "View.MemoryView":813
 *     cdef bint negative_step
 * 
 *     if not is_slice:             # <<<<<<<<<<<<<<
 * 
 *         if start < 0:
 */
  __pyx_t_1 = ((!(__pyx_v_is_slice != 0)) != 0);
  if (__pyx_t_1) {

    /* "View.MemoryView":815
 *     if not is_slice:
 * 
 *         if start < 0:             # <<<<<<<<<<<<<<
 *             start += shape
 *         if not 0 <= start < shape:
 */
    __pyx_t_1 = ((__pyx_v_start < 0) != 0);
    if (__pyx_t_1) {

      /* "View.MemoryView":816
 * 
 *         if start < 0:
 *             start += shape             # <<<<<<<<<<<<<<
 *         if not 0 <= start < shape:
 *             _err_dim(IndexError, "Index out of bounds (axis %d)", dim)
 */
      __pyx_v_start = (__pyx_v_start + __pyx_v_shape);

      /* "View.MemoryView":815
 *     if not is_slice:
 * 
 *         if start < 0:             # <<<<<<<<<<<<<<
 *             start += shape
 *         if not 0 <= start < shape:
 */
    }

    /* "View.MemoryView":817
 *         if start < 0:
 *             start += shape
 *         if not 0 <= start < shape:             # <<<<<<<<<<<<<<
 *             _err_dim(IndexError, "Index out of bounds (axis %d)", dim)
 *     else:
 */
    __pyx_t_1 = (0 <= __pyx_v_start);
    if (__pyx_t_1) {
      __pyx_t_1 = (__pyx_v_start < __pyx_v_shape);
    }
    __pyx_t_2 = ((!(__pyx_t_1 != 0)) != 0);
    if (__pyx_t_2) {

      /* "View.MemoryView":818
 *             start += shape
 *         if not 0 <= start < shape:
 *             _err_dim(IndexError, "Index out of bounds (axis %d)", dim)             # <<<<<<<<<<<<<<
 *     else:
 * 
 */
      __pyx_t_3 = __pyx_memoryview_err_dim(__pyx_builtin_IndexError, ((char *)"Index out of bounds (axis %d)"), __pyx_v_dim); if (unlikely(__pyx_t_3 == -1)) __PYX_ERR(2, 818, __pyx_L1_error)

      /* "View.MemoryView":817
 *         if start < 0:
 *             start += shape
 *         if not 0 <= start < shape:             # <<<<<<<<<<<<<<
 *             _err_dim(IndexError, "Index out of bounds (axis %d)", dim)
 *     else:
 */
    }

    /* "View.MemoryView":813
 *     cdef bint negative_step
 * 
 *     if not is_slice:             # <<<<<<<<<<<<<<
 * 
 *         if start < 0:
 */
    goto __pyx_L3;
  }

  /* "View.MemoryView":821
 *     else:
 * 
 *         negative_step = have_step != 0 and step < 0             # <<<<<<<<<<<<<<
 * 
 *         if have_step and step == 0:
 */
  /*else*/ {
    __pyx_t_1 = ((__pyx_v_have_step != 0) != 0);
    if (__pyx_t_1) {
    } else {
      __pyx_t_2 = __pyx_t_1;
      goto __pyx_L6_bool_binop_done;
    }
    __pyx_t_1 = ((__pyx_v_step < 0) != 0);
    __pyx_t_2 = __pyx_t_1;
    __pyx_L6_bool_binop_done:;
    __pyx_v_negative_step = __pyx_t_2;

    /* "View.MemoryView":823
 *         negative_step = have_step != 0 and step < 0
 * 
 *         if have_step and step == 0:             # <<<<<<<<<<<<<<
 *             _err_dim(ValueError, "Step may not be zero (axis %d)", dim)
 * 
 */
    __pyx_t_1 = (__pyx_v_have_step != 0);
    if (__pyx_t_1) {
    } else {
      __pyx_t_2 = __pyx_t_1;
      goto __pyx_L9_bool_binop_done;
    }
    __pyx_t_1 = ((__pyx_v_step == 0) != 0);
    __pyx_t_2 = __pyx_t_1;
    __pyx_L9_bool_binop_done:;
    if (__pyx_t_2) {

      /* "View.MemoryView":824
 * 
 *         if have_step and step == 0:
 *             _err_dim(ValueError, "Step may not be zero (axis %d)", dim)             # <<<<<<<<<<<<<<
 * 
 * 
 */
      __pyx_t_3 = __pyx_memoryview_err_dim(__pyx_builtin_ValueError, ((char *)"Step may not be zero (axis %d)"), __pyx_v_dim); if (unlikely(__pyx_t_3 == -1)) __PYX_ERR(2, 824, __pyx_L1_error)

      /* "View.MemoryView":823
 *         negative_step = have_step != 0 and step < 0
 * 
 *         if have_step and step == 0:             # <<<<<<<<<<<<<<
 *             _err_dim(ValueError, "Step may not be zero (axis %d)", dim)
 * 
 */
    }

    /* "View.MemoryView":827
 * 
 * 
 *         if have_start:             # <<<<<<<<<<<<<<
 *             if start < 0:
 *                 start += shape
 */
    __pyx_t_2 = (__pyx_v_have_start != 0);
    if (__pyx_t_2) {

      /* "View.MemoryView":828
 * 
 *         if have_start:
 *             if start < 0:             # <<<<<<<<<<<<<<
 *                 start += shape
 *                 if start < 0:
 */
      __pyx_t_2 = ((__pyx_v_start < 0) != 0);
      if (__pyx_t_2) {

        /* "View.MemoryView":829
 *         if have_start:
 *             if start < 0:
 *                 start += shape             # <<<<<<<<<<<<<<
 *                 if start < 0:
 *                     start = 0
 */
        __pyx_v_start = (__pyx_v_start + __pyx_v_shape);

        /* "View.MemoryView":830
 *             if start < 0:
 *                 start += shape
 *                 if start < 0:             # <<<<<<<<<<<<<<
 *                     start = 0
 *             elif start >= shape:
 */
        __pyx_t_2 = ((__pyx_v_start < 0) != 0);
        if (__pyx_t_2) {

          /* "View.MemoryView":831
 *                 start += shape
 *                 if start < 0:
 *                     start = 0             # <<<<<<<<<<<<<<
 *             elif start >= shape:
 *                 if negative_step:
 */
          __pyx_v_start = 0;

          /* "View.MemoryView":830
 *             if start < 0:
 *                 start += shape
 *                 if start < 0:             # <<<<<<<<<<<<<<
 *                     start = 0
 *             elif start >= shape:
 */
        }

        /* "View.MemoryView":828
 * 
 *         if have_start:
 *             if start < 0:             # <<<<<<<<<<<<<<
 *                 start += shape
 *                 if start < 0:
 */
        goto __pyx_L12;
      }

      /* "View.MemoryView":832
 *                 if start < 0:
 *                     start = 0
 *             elif start >= shape:             # <<<<<<<<<<<<<<
 *                 if negative_step:
 *                     start = shape - 1
 */
      __pyx_t_2 = ((__pyx_v_start >= __pyx_v_shape) != 0);
      if (__pyx_t_2) {

        /* "View.MemoryView":833
 *                     start = 0
 *             elif start >= shape:
 *                 if negative_step:             # <<<<<<<<<<<<<<
 *                     start = shape - 1
 *                 else:
 */
        __pyx_t_2 = (__pyx_v_negative_step != 0);
        if (__pyx_t_2) {

          /* "View.MemoryView":834
 *             elif start >= shape:
 *                 if negative_step:
 *                     start = shape - 1             # <<<<<<<<<<<<<<
 *                 else:
 *                     start = shape
 */
          __pyx_v_start = (__pyx_v_shape - 1);

          /* "View.MemoryView":833
 *                     start = 0
 *             elif start >= shape:
 *                 if negative_step:             # <<<<<<<<<<<<<<
 *                     start = shape - 1
 *                 else:
 */
          goto __pyx_L14;
        }

        /* "View.MemoryView":836
 *                     start = shape - 1
 *                 else:
 *                     start = shape             # <<<<<<<<<<<<<<
 *         else:
 *             if negative_step:
 */
        /*else*/ {
          __pyx_v_start = __pyx_v_shape;
        }
        __pyx_L14:;

        /* "View.MemoryView":832
 *                 if start < 0:
 *                     start = 0
 *             elif start >= shape:             # <<<<<<<<<<<<<<
 *                 if negative_step:
 *                     start = shape - 1
 */
      }
      __pyx_L12:;

      /* "View.MemoryView":827
 * 
 * 
 *         if have_start:             # <<<<<<<<<<<<<<
 *             if start < 0:
 *                 start += shape
 */
      goto __pyx_L11;
    }

    /* "View.MemoryView":838
 *                     start = shape
 *         else:
 *             if negative_step:             # <<<<<<<<<<<<<<
 *                 start = shape - 1
 *             else:
 */
    /*else*/ {
      __pyx_t_2 = (__pyx_v_negative_step != 0);
      if (__pyx_t_2) {

        /* "View.MemoryView":839
 *         else:
 *             if negative_step:
 *                 start = shape - 1             # <<<<<<<<<<<<<<
 *             else:
 *                 start = 0
 */
        __pyx_v_start = (__pyx_v_shape - 1);

        /* "View.MemoryView":838
 *                     start = shape
 *         else:
 *             if negative_step:             # <<<<<<<<<<<<<<
 *                 start = shape - 1
 *             else:
 */
        goto __pyx_L15;
      }

      /* "View.MemoryView":841
 *                 start = shape - 1
 *             else:
 *                 start = 0             # <<<<<<<<<<<<<<
 * 
 *         if have_stop:
 */
      /*else*/ {
        __pyx_v_start = 0;
      }
      __pyx_L15:;
    }
    __pyx_L11:;

    /* "View.MemoryView":843
 *                 start = 0
 * 
 *         if have_stop:             # <<<<<<<<<<<<<<
 *             if stop < 0:
 *                 stop += shape
 */
    __pyx_t_2 = (__pyx_v_have_stop != 0);
    if (__pyx_t_2) {

      /* "View.MemoryView":844
 * 
 *         if have_stop:
 *             if stop < 0:             # <<<<<<<<<<<<<<
 *                 stop += shape
 *                 if stop < 0:
 */
      __pyx_t_2 = ((__pyx_v_stop < 0) != 0);
      if (__pyx_t_2) {

        /* "View.MemoryView":845
 *         if have_stop:
 *             if stop < 0:
 *                 stop += shape             # <<<<<<<<<<<<<<
 *                 if stop < 0:
 *                     stop = 0
 */
        __pyx_v_stop = (__pyx_v_stop + __pyx_v_shape);

        /* "View.MemoryView":846
 *             if stop < 0:
 *                 stop += shape
 *                 if stop < 0:             # <<<<<<<<<<<<<<
 *                     stop = 0
 *             elif stop > shape:
 */
        __pyx_t_2 = ((__pyx_v_stop < 0) != 0);
        if (__pyx_t_2) {

          /* "View.MemoryView":847
 *                 stop += shape
 *                 if stop < 0:
 *                     stop = 0             # <<<<<<<<<<<<<<
 *             elif stop > shape:
 *                 stop = shape
 */
          __pyx_v_stop = 0;

          /* "View.MemoryView":846
 *             if stop < 0:
 *                 stop += shape
 *                 if stop < 0:             # <<<<<<<<<<<<<<
 *                     stop = 0
 *             elif stop > shape:
 */
        }

        /* "View.MemoryView":844
 * 
 *         if have_stop:
 *             if stop < 0:             # <<<<<<<<<<<<<<
 *                 stop += shape
 *                 if stop < 0:
 */
        goto __pyx_L17;
      }

      /* "View.MemoryView":848
 *                 if stop < 0:
 *                     stop = 0
 *             elif stop > shape:             # <<<<<<<<<<<<<<
 *                 stop = shape
 *         else:
 */
      __pyx_t_2 = ((__pyx_v_stop > __pyx_v_shape) != 0);
      if (__pyx_t_2) {

        /* "View.MemoryView":849
 *                     stop = 0
 *             elif stop > shape:
 *                 stop = shape             # <<<<<<<<<<<<<<
 *         else:
 *             if negative_step:
 */
        __pyx_v_stop = __pyx_v_shape;

        /* "View.MemoryView":848
 *                 if stop < 0:
 *                     stop = 0
 *             elif stop > shape:             # <<<<<<<<<<<<<<
 *                 stop = shape
 *         else:
 */
      }
      __pyx_L17:;

      /* "View.MemoryView":843
 *                 start = 0
 * 
 *         if have_stop:             # <<<<<<<<<<<<<<
 *             if stop < 0:
 *                 stop += shape
 */
      goto __pyx_L16;
    }

    /* "View.MemoryView":851
 *                 stop = shape
 *         else:
 *             if negative_step:             # <<<<<<<<<<<<<<
 *                 stop = -1
 *             else:
 */
    /*else*/ {
      __pyx_t_2 = (__pyx_v_negative_step != 0);
      if (__pyx_t_2) {

        /* "View.MemoryView":852
 *         else:
 *             if negative_step:
 *                 stop = -1             # <<<<<<<<<<<<<<
 *             else:
 *                 stop = shape
 */
        __pyx_v_stop = -1L;

        /* "View.MemoryView":851
 *                 stop = shape
 *         else:
 *             if negative_step:             # <<<<<<<<<<<<<<
 *                 stop = -1
 *             else:
 */
        goto __pyx_L19;
      }

      /* "View.MemoryView":854
 *                 stop = -1
 *             else:
 *                 stop = shape             # <<<<<<<<<<<<<<
 * 
 *         if not have_step:
 */
      /*else*/ {
        __pyx_v_stop = __pyx_v_shape;
      }
      __pyx_L19:;
    }
    __pyx_L16:;

    /* "View.MemoryView":856
 *                 stop = shape
 * 
 *         if not have_step:             # <<<<<<<<<<<<<<
 *             step = 1
 * 
 */
    __pyx_t_2 = ((!(__pyx_v_have_step != 0)) != 0);
    if (__pyx_t_2) {

      /* "View.MemoryView":857
 * 
 *         if not have_step:
 *             step = 1             # <<<<<<<<<<<<<<
 * 
 * 
 */
      __pyx_v_step = 1;

      /* "View.MemoryView":856
 *                 stop = shape
 * 
 *         if not have_step:             # <<<<<<<<<<<<<<
 *             step = 1
 * 
 */
    }

    /* "View.MemoryView":861
 * 
 *         with cython.cdivision(True):
 *             new_shape = (stop - start) // step             # <<<<<<<<<<<<<<
 * 
 *             if (stop - start) - step * new_shape:
 */
    __pyx_v_new_shape = ((__pyx_v_stop - __pyx_v_start) / __pyx_v_step);

    /* "View.MemoryView":863
 *             new_shape = (stop - start) // step
 * 
 *             if (stop - start) - step * new_shape:             # <<<<<<<<<<<<<<
 *                 new_shape += 1
 * 
 */
    __pyx_t_2 = (((__pyx_v_stop - __pyx_v_start) - (__pyx_v_step * __pyx_v_new_shape)) != 0);
    if (__pyx_t_2) {

      /* "View.MemoryView":864
 * 
 *             if (stop - start) - step * new_shape:
 *                 new_shape += 1             # <<<<<<<<<<<<<<
 * 
 *         if new_shape < 0:
 */
      __pyx_v_new_shape = (__pyx_v_new_shape + 1);

      /* "View.MemoryView":863
 *             new_shape = (stop - start) // step
 * 
 *             if (stop - start) - step * new_shape:             # <<<<<<<<<<<<<<
 *                 new_shape += 1
 * 
 */
    }

    /* "View.MemoryView":866
 *                 new_shape += 1
 * 
 *         if new_shape < 0:             # <<<<<<<<<<<<<<
 *             new_shape = 0
 * 
 */
    __pyx_t_2 = ((__pyx_v_new_shape < 0) != 0);
    if (__pyx_t_2) {

      /* "View.MemoryView":867
 * 
 *         if new_shape < 0:
 *             new_shape = 0             # <<<<<<<<<<<<<<
 * 
 * 
 */
      __pyx_v_new_shape = 0;

      /* "View.MemoryView":866
 *                 new_shape += 1
 * 
 *         if new_shape < 0:             # <<<<<<<<<<<<<<
 *             new_shape = 0
 * 
 */
    }

    /* "View.MemoryView":870
 * 
 * 
 *         dst.strides[new_ndim] = stride * step             # <<<<<<<<<<<<<<
 *         dst.shape[new_ndim] = new_shape
 *         dst.suboffsets[new_ndim] = suboffset
 */
    (__pyx_v_dst->strides[__pyx_v_new_ndim]) = (__pyx_v_stride * __pyx_v_step);

    /* "View.MemoryView":871
 * 
 *         dst.strides[new_ndim] = stride * step
 *         dst.shape[new_ndim] = new_shape             # <<<<<<<<<<<<<<
 *         dst.suboffsets[new_ndim] = suboffset
 * 
 */
    (__pyx_v_dst->shape[__pyx_v_new_ndim]) = __pyx_v_new_shape;

    /* "View.MemoryView":872
 *         dst.strides[new_ndim] = stride * step
 *         dst.shape[new_ndim] = new_shape
 *         dst.suboffsets[new_ndim] = suboffset             # <<<<<<<<<<<<<<
 * 
 * 
 */
    (__pyx_v_dst->suboffsets[__pyx_v_new_ndim]) = __pyx_v_suboffset;
  }
  __pyx_L3:;

  /* "View.MemoryView":875
 * 
 * 
 *     if suboffset_dim[0] < 0:             # <<<<<<<<<<<<<<
 *         dst.data += start * stride
 *     else:
 */
  __pyx_t_2 = (((__pyx_v_suboffset_dim[0]) < 0) != 0);
  if (__pyx_t_2) {

    /* "View.MemoryView":876
 * 
 *     if suboffset_dim[0] < 0:
 *         dst.data += start * stride             # <<<<<<<<<<<<<<
 *     else:
 *         dst.suboffsets[suboffset_dim[0]] += start * stride
 */
    __pyx_v_dst->data = (__pyx_v_dst->data + (__pyx_v_start * __pyx_v_stride));

    /* "View.MemoryView":875
 * 
 * 
 *     if suboffset_dim[0] < 0:             # <<<<<<<<<<<<<<
 *         dst.data += start * stride
 *     else:
 */
    goto __pyx_L23;
  }

  /* "View.MemoryView":878
 *         dst.data += start * stride
 *     else:
 *         dst.suboffsets[suboffset_dim[0]] += start * stride             # <<<<<<<<<<<<<<
 * 
 *     if suboffset >= 0:
 */
  /*else*/ {
    __pyx_t_3 = (__pyx_v_suboffset_dim[0]);
    (__pyx_v_dst->suboffsets[__pyx_t_3]) = ((__pyx_v_dst->suboffsets[__pyx_t_3]) + (__pyx_v_start * __pyx_v_stride));
  }
  __pyx_L23:;

  /* "View.MemoryView":880
 *         dst.suboffsets[suboffset_dim[0]] += start * stride
 * 
 *     if suboffset >= 0:             # <<<<<<<<<<<<<<
 *         if not is_slice:
 *             if new_ndim == 0:
 */
  __pyx_t_2 = ((__pyx_v_suboffset >= 0) != 0);
  if (__pyx_t_2) {

    /* "View.MemoryView":881
 * 
 *     if suboffset >= 0:
 *         if not is_slice:             # <<<<<<<<<<<<<<
 *             if new_ndim == 0:
 *                 dst.data = (<char **> dst.data)[0] + suboffset
 */
    __pyx_t_2 = ((!(__pyx_v_is_slice != 0)) != 0);
    if (__pyx_t_2) {

      /* "View.MemoryView":882
 *     if suboffset >= 0:
 *         if not is_slice:
 *             if new_ndim == 0:             # <<<<<<<<<<<<<<
 *                 dst.data = (<char **> dst.data)[0] + suboffset
 *             else:
 */
      __pyx_t_2 = ((__pyx_v_new_ndim == 0) != 0);
      if (__pyx_t_2) {

        /* "View.MemoryView":883
 *         if not is_slice:
 *             if new_ndim == 0:
 *                 dst.data = (<char **> dst.data)[0] + suboffset             # <<<<<<<<<<<<<<
 *             else:
 *                 _err_dim(IndexError, "All dimensions preceding dimension %d "
 */
        __pyx_v_dst->data = ((((char **)__pyx_v_dst->data)[0]) + __pyx_v_suboffset);

        /* "View.MemoryView":882
 *     if suboffset >= 0:
 *         if not is_slice:
 *             if new_ndim == 0:             # <<<<<<<<<<<<<<
 *                 dst.data = (<char **> dst.data)[0] + suboffset
 *             else:
 */
        goto __pyx_L26;
      }

      /* "View.MemoryView":885
 *                 dst.data = (<char **> dst.data)[0] + suboffset
 *             else:
 *                 _err_dim(IndexError, "All dimensions preceding dimension %d "             # <<<<<<<<<<<<<<
 *                                      "must be indexed and not sliced", dim)
 *         else:
 */
      /*else*/ {

        /* "View.MemoryView":886
 *             else:
 *                 _err_dim(IndexError, "All dimensions preceding dimension %d "
 *                                      "must be indexed and not sliced", dim)             # <<<<<<<<<<<<<<
 *         else:
 *             suboffset_dim[0] = new_ndim
 */
        __pyx_t_3 = __pyx_memoryview_err_dim(__pyx_builtin_IndexError, ((char *)"All dimensions preceding dimension %d must be indexed and not sliced"), __pyx_v_dim); if (unlikely(__pyx_t_3 == -1)) __PYX_ERR(2, 885, __pyx_L1_error)
      }
      __pyx_L26:;

      /* "View.MemoryView":881
 * 
 *     if suboffset >= 0:
 *         if not is_slice:             # <<<<<<<<<<<<<<
 *             if new_ndim == 0:
 *                 dst.data = (<char **> dst.data)[0] + suboffset
 */
      goto __pyx_L25;
    }

    /* "View.MemoryView":888
 *                                      "must be indexed and not sliced", dim)
 *         else:
 *             suboffset_dim[0] = new_ndim             # <<<<<<<<<<<<<<
 * 
 *     return 0
 */
    /*else*/ {
      (__pyx_v_suboffset_dim[0]) = __pyx_v_new_ndim;
    }
    __pyx_L25:;

    /* "View.MemoryView":880
 *         dst.suboffsets[suboffset_dim[0]] += start * stride
 * 
 *     if suboffset >= 0:             # <<<<<<<<<<<<<<
 *         if not is_slice:
 *             if new_ndim == 0:
 */
  }

  /* "View.MemoryView":890
 *             suboffset_dim[0] = new_ndim
 * 
 *     return 0             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_r = 0;
  goto __pyx_L0;

  /* "View.MemoryView":793
 * 
 * @cname('__pyx_memoryview_slice_memviewslice')
 * cdef int slice_memviewslice(             # <<<<<<<<<<<<<<
 *         __Pyx_memviewslice *dst,
 *         Py_ssize_t shape, Py_ssize_t stride, Py_ssize_t suboffset,
 */

  /* function exit code */
  __pyx_L1_error:;
  {
    #ifdef WITH_THREAD
    PyGILState_STATE __pyx_gilstate_save = PyGILState_Ensure();
    #endif
    __Pyx_AddTraceback("View.MemoryView.slice_memviewslice", __pyx_clineno, __pyx_lineno, __pyx_filename);
    #ifdef WITH_THREAD
    PyGILState_Release(__pyx_gilstate_save);
    #endif
  }
  __pyx_r = -1;
  __pyx_L0:;
  return __pyx_r;
}

/* "View.MemoryView":896
 * 
 * @cname('__pyx_pybuffer_index')
 * cdef char *pybuffer_index(Py_buffer *view, char *bufp, Py_ssize_t index,             # <<<<<<<<<<<<<<
 *                           Py_ssize_t dim) except NULL:
 *     cdef Py_ssize_t shape, stride, suboffset = -1
 */

static char *__pyx_pybuffer_index(Py_buffer *__pyx_v_view, char *__pyx_v_bufp, Py_ssize_t __pyx_v_index, Py_ssize_t __pyx_v_dim) {
  Py_ssize_t __pyx_v_shape;
  Py_ssize_t __pyx_v_stride;
  Py_ssize_t __pyx_v_suboffset;
  Py_ssize_t __pyx_v_itemsize;
  char *__pyx_v_resultp;
  char *__pyx_r;
  __Pyx_RefNannyDeclarations
  Py_ssize_t __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  __Pyx_RefNannySetupContext("pybuffer_index", 0);

  /* "View.MemoryView":898
 * cdef char *pybuffer_index(Py_buffer *view, char *bufp, Py_ssize_t index,
 *                           Py_ssize_t dim) except NULL:
 *     cdef Py_ssize_t shape, stride, suboffset = -1             # <<<<<<<<<<<<<<
 *     cdef Py_ssize_t itemsize = view.itemsize
 *     cdef char *resultp
 */
  __pyx_v_suboffset = -1L;

  /* "View.MemoryView":899
 *                           Py_ssize_t dim) except NULL:
 *     cdef Py_ssize_t shape, stride, suboffset = -1
 *     cdef Py_ssize_t itemsize = view.itemsize             # <<<<<<<<<<<<<<
 *     cdef char *resultp
 * 
 */
  __pyx_t_1 = __pyx_v_view->itemsize;
  __pyx_v_itemsize = __pyx_t_1;

  /* "View.MemoryView":902
 *     cdef char *resultp
 * 
 *     if view.ndim == 0:             # <<<<<<<<<<<<<<
 *         shape = view.len / itemsize
 *         stride = itemsize
 */
  __pyx_t_2 = ((__pyx_v_view->ndim == 0) != 0);
  if (__pyx_t_2) {

    /* "View.MemoryView":903
 * 
 *     if view.ndim == 0:
 *         shape = view.len / itemsize             # <<<<<<<<<<<<<<
 *         stride = itemsize
 *     else:
 */
    if (unlikely(__pyx_v_itemsize == 0)) {
      PyErr_SetString(PyExc_ZeroDivisionError, "integer division or modulo by zero");
      __PYX_ERR(2, 903, __pyx_L1_error)
    }
    else if (sizeof(Py_ssize_t) == sizeof(long) && (!(((Py_ssize_t)-1) > 0)) && unlikely(__pyx_v_itemsize == (Py_ssize_t)-1)  && unlikely(UNARY_NEG_WOULD_OVERFLOW(__pyx_v_view->len))) {
      PyErr_SetString(PyExc_OverflowError, "value too large to perform division");
      __PYX_ERR(2, 903, __pyx_L1_error)
    }
    __pyx_v_shape = __Pyx_div_Py_ssize_t(__pyx_v_view->len, __pyx_v_itemsize);

    /* "View.MemoryView":904
 *     if view.ndim == 0:
 *         shape = view.len / itemsize
 *         stride = itemsize             # <<<<<<<<<<<<<<
 *     else:
 *         shape = view.shape[dim]
 */
    __pyx_v_stride = __pyx_v_itemsize;

    /* "View.MemoryView":902
 *     cdef char *resultp
 * 
 *     if view.ndim == 0:             # <<<<<<<<<<<<<<
 *         shape = view.len / itemsize
 *         stride = itemsize
 */
    goto __pyx_L3;
  }

  /* "View.MemoryView":906
 *         stride = itemsize
 *     else:
 *         shape = view.shape[dim]             # <<<<<<<<<<<<<<
 *         stride = view.strides[dim]
 *         if view.suboffsets != NULL:
 */
  /*else*/ {
    __pyx_v_shape = (__pyx_v_view->shape[__pyx_v_dim]);

    /* "View.MemoryView":907
 *     else:
 *         shape = view.shape[dim]
 *         stride = view.strides[dim]             # <<<<<<<<<<<<<<
 *         if view.suboffsets != NULL:
 *             suboffset = view.suboffsets[dim]
 */
    __pyx_v_stride = (__pyx_v_view->strides[__pyx_v_dim]);

    /* "View.MemoryView":908
 *         shape = view.shape[dim]
 *         stride = view.strides[dim]
 *         if view.suboffsets != NULL:             # <<<<<<<<<<<<<<
 *             suboffset = view.suboffsets[dim]
 * 
 */
    __pyx_t_2 = ((__pyx_v_view->suboffsets != NULL) != 0);
    if (__pyx_t_2) {

      /* "View.MemoryView":909
 *         stride = view.strides[dim]
 *         if view.suboffsets != NULL:
 *             suboffset = view.suboffsets[dim]             # <<<<<<<<<<<<<<
 * 
 *     if index < 0:
 */
      __pyx_v_suboffset = (__pyx_v_view->suboffsets[__pyx_v_dim]);

      /* "View.MemoryView":908
 *         shape = view.shape[dim]
 *         stride = view.strides[dim]
 *         if view.suboffsets != NULL:             # <<<<<<<<<<<<<<
 *             suboffset = view.suboffsets[dim]
 * 
 */
    }
  }
  __pyx_L3:;

  /* "View.MemoryView":911
 *             suboffset = view.suboffsets[dim]
 * 
 *     if index < 0:             # <<<<<<<<<<<<<<
 *         index += view.shape[dim]
 *         if index < 0:
 */
  __pyx_t_2 = ((__pyx_v_index < 0) != 0);
  if (__pyx_t_2) {

    /* "View.MemoryView":912
 * 
 *     if index < 0:
 *         index += view.shape[dim]             # <<<<<<<<<<<<<<
 *         if index < 0:
 *             raise IndexError("Out of bounds on buffer access (axis %d)" % dim)
 */
    __pyx_v_index = (__pyx_v_index + (__pyx_v_view->shape[__pyx_v_dim]));

    /* "View.MemoryView":913
 *     if index < 0:
 *         index += view.shape[dim]
 *         if index < 0:             # <<<<<<<<<<<<<<
 *             raise IndexError("Out of bounds on buffer access (axis %d)" % dim)
 * 
 */
    __pyx_t_2 = ((__pyx_v_index < 0) != 0);
    if (__pyx_t_2) {

      /* "View.MemoryView":914
 *         index += view.shape[dim]
 *         if index < 0:
 *             raise IndexError("Out of bounds on buffer access (axis %d)" % dim)             # <<<<<<<<<<<<<<
 * 
 *     if index >= shape:
 */
      __pyx_t_3 = PyInt_FromSsize_t(__pyx_v_dim); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 914, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_4 = __Pyx_PyString_Format(__pyx_kp_s_Out_of_bounds_on_buffer_access_a, __pyx_t_3); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 914, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 914, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_GIVEREF(__pyx_t_4);
      PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
      __pyx_t_4 = 0;
      __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_IndexError, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 914, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_Raise(__pyx_t_4, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __PYX_ERR(2, 914, __pyx_L1_error)

      /* "View.MemoryView":913
 *     if index < 0:
 *         index += view.shape[dim]
 *         if index < 0:             # <<<<<<<<<<<<<<
 *             raise IndexError("Out of bounds on buffer access (axis %d)" % dim)
 * 
 */
    }

    /* "View.MemoryView":911
 *             suboffset = view.suboffsets[dim]
 * 
 *     if index < 0:             # <<<<<<<<<<<<<<
 *         index += view.shape[dim]
 *         if index < 0:
 */
  }

  /* "View.MemoryView":916
 *             raise IndexError("Out of bounds on buffer access (axis %d)" % dim)
 * 
 *     if index >= shape:             # <<<<<<<<<<<<<<
 *         raise IndexError("Out of bounds on buffer access (axis %d)" % dim)
 * 
 */
  __pyx_t_2 = ((__pyx_v_index >= __pyx_v_shape) != 0);
  if (__pyx_t_2) {

    /* "View.MemoryView":917
 * 
 *     if index >= shape:
 *         raise IndexError("Out of bounds on buffer access (axis %d)" % dim)             # <<<<<<<<<<<<<<
 * 
 *     resultp = bufp + index * stride
 */
    __pyx_t_4 = PyInt_FromSsize_t(__pyx_v_dim); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 917, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_3 = __Pyx_PyString_Format(__pyx_kp_s_Out_of_bounds_on_buffer_access_a, __pyx_t_4); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 917, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_4 = PyTuple_New(1); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 917, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_GIVEREF(__pyx_t_3);
    PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_3);
    __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_IndexError, __pyx_t_4, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 917, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(2, 917, __pyx_L1_error)

    /* "View.MemoryView":916
 *             raise IndexError("Out of bounds on buffer access (axis %d)" % dim)
 * 
 *     if index >= shape:             # <<<<<<<<<<<<<<
 *         raise IndexError("Out of bounds on buffer access (axis %d)" % dim)
 * 
 */
  }

  /* "View.MemoryView":919
 *         raise IndexError("Out of bounds on buffer access (axis %d)" % dim)
 * 
 *     resultp = bufp + index * stride             # <<<<<<<<<<<<<<
 *     if suboffset >= 0:
 *         resultp = (<char **> resultp)[0] + suboffset
 */
  __pyx_v_resultp = (__pyx_v_bufp + (__pyx_v_index * __pyx_v_stride));

  /* "View.MemoryView":920
 * 
 *     resultp = bufp + index * stride
 *     if suboffset >= 0:             # <<<<<<<<<<<<<<
 *         resultp = (<char **> resultp)[0] + suboffset
 * 
 */
  __pyx_t_2 = ((__pyx_v_suboffset >= 0) != 0);
  if (__pyx_t_2) {

    /* "View.MemoryView":921
 *     resultp = bufp + index * stride
 *     if suboffset >= 0:
 *         resultp = (<char **> resultp)[0] + suboffset             # <<<<<<<<<<<<<<
 * 
 *     return resultp
 */
    __pyx_v_resultp = ((((char **)__pyx_v_resultp)[0]) + __pyx_v_suboffset);

    /* "View.MemoryView":920
 * 
 *     resultp = bufp + index * stride
 *     if suboffset >= 0:             # <<<<<<<<<<<<<<
 *         resultp = (<char **> resultp)[0] + suboffset
 * 
 */
  }

  /* "View.MemoryView":923
 *         resultp = (<char **> resultp)[0] + suboffset
 * 
 *     return resultp             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_r = __pyx_v_resultp;
  goto __pyx_L0;

  /* "View.MemoryView":896
 * 
 * @cname('__pyx_pybuffer_index')
 * cdef char *pybuffer_index(Py_buffer *view, char *bufp, Py_ssize_t index,             # <<<<<<<<<<<<<<
 *                           Py_ssize_t dim) except NULL:
 *     cdef Py_ssize_t shape, stride, suboffset = -1
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("View.MemoryView.pybuffer_index", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":929
 * 
 * @cname('__pyx_memslice_transpose')
 * cdef int transpose_memslice(__Pyx_memviewslice *memslice) nogil except 0:             # <<<<<<<<<<<<<<
 *     cdef int ndim = memslice.memview.view.ndim
 * 
 */

static int __pyx_memslice_transpose(__Pyx_memviewslice *__pyx_v_memslice) {
  int __pyx_v_ndim;
  Py_ssize_t *__pyx_v_shape;
  Py_ssize_t *__pyx_v_strides;
  int __pyx_v_i;
  int __pyx_v_j;
  int __pyx_r;
  int __pyx_t_1;
  Py_ssize_t *__pyx_t_2;
  long __pyx_t_3;
  Py_ssize_t __pyx_t_4;
  Py_ssize_t __pyx_t_5;
  int __pyx_t_6;
  int __pyx_t_7;
  int __pyx_t_8;

  /* "View.MemoryView":930
 * @cname('__pyx_memslice_transpose')
 * cdef int transpose_memslice(__Pyx_memviewslice *memslice) nogil except 0:
 *     cdef int ndim = memslice.memview.view.ndim             # <<<<<<<<<<<<<<
 * 
 *     cdef Py_ssize_t *shape = memslice.shape
 */
  __pyx_t_1 = __pyx_v_memslice->memview->view.ndim;
  __pyx_v_ndim = __pyx_t_1;

  /* "View.MemoryView":932
 *     cdef int ndim = memslice.memview.view.ndim
 * 
 *     cdef Py_ssize_t *shape = memslice.shape             # <<<<<<<<<<<<<<
 *     cdef Py_ssize_t *strides = memslice.strides
 * 
 */
  __pyx_t_2 = __pyx_v_memslice->shape;
  __pyx_v_shape = __pyx_t_2;

  /* "View.MemoryView":933
 * 
 *     cdef Py_ssize_t *shape = memslice.shape
 *     cdef Py_ssize_t *strides = memslice.strides             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_2 = __pyx_v_memslice->strides;
  __pyx_v_strides = __pyx_t_2;

  /* "View.MemoryView":937
 * 
 *     cdef int i, j
 *     for i in range(ndim / 2):             # <<<<<<<<<<<<<<
 *         j = ndim - 1 - i
 *         strides[i], strides[j] = strides[j], strides[i]
 */
  __pyx_t_3 = __Pyx_div_long(__pyx_v_ndim, 2);
  for (__pyx_t_1 = 0; __pyx_t_1 < __pyx_t_3; __pyx_t_1+=1) {
    __pyx_v_i = __pyx_t_1;

    /* "View.MemoryView":938
 *     cdef int i, j
 *     for i in range(ndim / 2):
 *         j = ndim - 1 - i             # <<<<<<<<<<<<<<
 *         strides[i], strides[j] = strides[j], strides[i]
 *         shape[i], shape[j] = shape[j], shape[i]
 */
    __pyx_v_j = ((__pyx_v_ndim - 1) - __pyx_v_i);

    /* "View.MemoryView":939
 *     for i in range(ndim / 2):
 *         j = ndim - 1 - i
 *         strides[i], strides[j] = strides[j], strides[i]             # <<<<<<<<<<<<<<
 *         shape[i], shape[j] = shape[j], shape[i]
 * 
 */
    __pyx_t_4 = (__pyx_v_strides[__pyx_v_j]);
    __pyx_t_5 = (__pyx_v_strides[__pyx_v_i]);
    (__pyx_v_strides[__pyx_v_i]) = __pyx_t_4;
    (__pyx_v_strides[__pyx_v_j]) = __pyx_t_5;

    /* "View.MemoryView":940
 *         j = ndim - 1 - i
 *         strides[i], strides[j] = strides[j], strides[i]
 *         shape[i], shape[j] = shape[j], shape[i]             # <<<<<<<<<<<<<<
 * 
 *         if memslice.suboffsets[i] >= 0 or memslice.suboffsets[j] >= 0:
 */
    __pyx_t_5 = (__pyx_v_shape[__pyx_v_j]);
    __pyx_t_4 = (__pyx_v_shape[__pyx_v_i]);
    (__pyx_v_shape[__pyx_v_i]) = __pyx_t_5;
    (__pyx_v_shape[__pyx_v_j]) = __pyx_t_4;

    /* "View.MemoryView":942
 *         shape[i], shape[j] = shape[j], shape[i]
 * 
 *         if memslice.suboffsets[i] >= 0 or memslice.suboffsets[j] >= 0:             # <<<<<<<<<<<<<<
 *             _err(ValueError, "Cannot transpose memoryview with indirect dimensions")
 * 
 */
    __pyx_t_7 = (((__pyx_v_memslice->suboffsets[__pyx_v_i]) >= 0) != 0);
    if (!__pyx_t_7) {
    } else {
      __pyx_t_6 = __pyx_t_7;
      goto __pyx_L6_bool_binop_done;
    }
    __pyx_t_7 = (((__pyx_v_memslice->suboffsets[__pyx_v_j]) >= 0) != 0);
    __pyx_t_6 = __pyx_t_7;
    __pyx_L6_bool_binop_done:;
    if (__pyx_t_6) {

      /* "View.MemoryView":943
 * 
 *         if memslice.suboffsets[i] >= 0 or memslice.suboffsets[j] >= 0:
 *             _err(ValueError, "Cannot transpose memoryview with indirect dimensions")             # <<<<<<<<<<<<<<
 * 
 *     return 1
 */
      __pyx_t_8 = __pyx_memoryview_err(__pyx_builtin_ValueError, ((char *)"Cannot transpose memoryview with indirect dimensions")); if (unlikely(__pyx_t_8 == -1)) __PYX_ERR(2, 943, __pyx_L1_error)

      /* "View.MemoryView":942
 *         shape[i], shape[j] = shape[j], shape[i]
 * 
 *         if memslice.suboffsets[i] >= 0 or memslice.suboffsets[j] >= 0:             # <<<<<<<<<<<<<<
 *             _err(ValueError, "Cannot transpose memoryview with indirect dimensions")
 * 
 */
    }
  }

  /* "View.MemoryView":945
 *             _err(ValueError, "Cannot transpose memoryview with indirect dimensions")
 * 
 *     return 1             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_r = 1;
  goto __pyx_L0;

  /* "View.MemoryView":929
 * 
 * @cname('__pyx_memslice_transpose')
 * cdef int transpose_memslice(__Pyx_memviewslice *memslice) nogil except 0:             # <<<<<<<<<<<<<<
 *     cdef int ndim = memslice.memview.view.ndim
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  {
    #ifdef WITH_THREAD
    PyGILState_STATE __pyx_gilstate_save = PyGILState_Ensure();
    #endif
    __Pyx_AddTraceback("View.MemoryView.transpose_memslice", __pyx_clineno, __pyx_lineno, __pyx_filename);
    #ifdef WITH_THREAD
    PyGILState_Release(__pyx_gilstate_save);
    #endif
  }
  __pyx_r = 0;
  __pyx_L0:;
  return __pyx_r;
}

/* "View.MemoryView":962
 *     cdef int (*to_dtype_func)(char *, object) except 0
 * 
 *     def __dealloc__(self):             # <<<<<<<<<<<<<<
 *         __PYX_XDEC_MEMVIEW(&self.from_slice, 1)
 * 
 */

/* Python wrapper */
static void __pyx_memoryviewslice___dealloc__(PyObject *__pyx_v_self); /*proto*/
static void __pyx_memoryviewslice___dealloc__(PyObject *__pyx_v_self) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__dealloc__ (wrapper)", 0);
  __pyx_memoryviewslice___pyx_pf_15View_dot_MemoryView_16_memoryviewslice___dealloc__(((struct __pyx_memoryviewslice_obj *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

static void __pyx_memoryviewslice___pyx_pf_15View_dot_MemoryView_16_memoryviewslice___dealloc__(struct __pyx_memoryviewslice_obj *__pyx_v_self) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__dealloc__", 0);

  /* "View.MemoryView":963
 * 
 *     def __dealloc__(self):
 *         __PYX_XDEC_MEMVIEW(&self.from_slice, 1)             # <<<<<<<<<<<<<<
 * 
 *     cdef convert_item_to_object(self, char *itemp):
 */
  __PYX_XDEC_MEMVIEW((&__pyx_v_self->from_slice), 1);

  /* "View.MemoryView":962
 *     cdef int (*to_dtype_func)(char *, object) except 0
 * 
 *     def __dealloc__(self):             # <<<<<<<<<<<<<<
 *         __PYX_XDEC_MEMVIEW(&self.from_slice, 1)
 * 
 */

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

/* "View.MemoryView":965
 *         __PYX_XDEC_MEMVIEW(&self.from_slice, 1)
 * 
 *     cdef convert_item_to_object(self, char *itemp):             # <<<<<<<<<<<<<<
 *         if self.to_object_func != NULL:
 *             return self.to_object_func(itemp)
 */

static PyObject *__pyx_memoryviewslice_convert_item_to_object(struct __pyx_memoryviewslice_obj *__pyx_v_self, char *__pyx_v_itemp) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("convert_item_to_object", 0);

  /* "View.MemoryView":966
 * 
 *     cdef convert_item_to_object(self, char *itemp):
 *         if self.to_object_func != NULL:             # <<<<<<<<<<<<<<
 *             return self.to_object_func(itemp)
 *         else:
 */
  __pyx_t_1 = ((__pyx_v_self->to_object_func != NULL) != 0);
  if (__pyx_t_1) {

    /* "View.MemoryView":967
 *     cdef convert_item_to_object(self, char *itemp):
 *         if self.to_object_func != NULL:
 *             return self.to_object_func(itemp)             # <<<<<<<<<<<<<<
 *         else:
 *             return memoryview.convert_item_to_object(self, itemp)
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_2 = __pyx_v_self->to_object_func(__pyx_v_itemp); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 967, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_r = __pyx_t_2;
    __pyx_t_2 = 0;
    goto __pyx_L0;

    /* "View.MemoryView":966
 * 
 *     cdef convert_item_to_object(self, char *itemp):
 *         if self.to_object_func != NULL:             # <<<<<<<<<<<<<<
 *             return self.to_object_func(itemp)
 *         else:
 */
  }

  /* "View.MemoryView":969
 *             return self.to_object_func(itemp)
 *         else:
 *             return memoryview.convert_item_to_object(self, itemp)             # <<<<<<<<<<<<<<
 * 
 *     cdef assign_item_from_object(self, char *itemp, object value):
 */
  /*else*/ {
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_2 = __pyx_memoryview_convert_item_to_object(((struct __pyx_memoryview_obj *)__pyx_v_self), __pyx_v_itemp); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 969, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_r = __pyx_t_2;
    __pyx_t_2 = 0;
    goto __pyx_L0;
  }

  /* "View.MemoryView":965
 *         __PYX_XDEC_MEMVIEW(&self.from_slice, 1)
 * 
 *     cdef convert_item_to_object(self, char *itemp):             # <<<<<<<<<<<<<<
 *         if self.to_object_func != NULL:
 *             return self.to_object_func(itemp)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("View.MemoryView._memoryviewslice.convert_item_to_object", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":971
 *             return memoryview.convert_item_to_object(self, itemp)
 * 
 *     cdef assign_item_from_object(self, char *itemp, object value):             # <<<<<<<<<<<<<<
 *         if self.to_dtype_func != NULL:
 *             self.to_dtype_func(itemp, value)
 */

static PyObject *__pyx_memoryviewslice_assign_item_from_object(struct __pyx_memoryviewslice_obj *__pyx_v_self, char *__pyx_v_itemp, PyObject *__pyx_v_value) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("assign_item_from_object", 0);

  /* "View.MemoryView":972
 * 
 *     cdef assign_item_from_object(self, char *itemp, object value):
 *         if self.to_dtype_func != NULL:             # <<<<<<<<<<<<<<
 *             self.to_dtype_func(itemp, value)
 *         else:
 */
  __pyx_t_1 = ((__pyx_v_self->to_dtype_func != NULL) != 0);
  if (__pyx_t_1) {

    /* "View.MemoryView":973
 *     cdef assign_item_from_object(self, char *itemp, object value):
 *         if self.to_dtype_func != NULL:
 *             self.to_dtype_func(itemp, value)             # <<<<<<<<<<<<<<
 *         else:
 *             memoryview.assign_item_from_object(self, itemp, value)
 */
    __pyx_t_2 = __pyx_v_self->to_dtype_func(__pyx_v_itemp, __pyx_v_value); if (unlikely(__pyx_t_2 == 0)) __PYX_ERR(2, 973, __pyx_L1_error)

    /* "View.MemoryView":972
 * 
 *     cdef assign_item_from_object(self, char *itemp, object value):
 *         if self.to_dtype_func != NULL:             # <<<<<<<<<<<<<<
 *             self.to_dtype_func(itemp, value)
 *         else:
 */
    goto __pyx_L3;
  }

  /* "View.MemoryView":975
 *             self.to_dtype_func(itemp, value)
 *         else:
 *             memoryview.assign_item_from_object(self, itemp, value)             # <<<<<<<<<<<<<<
 * 
 *     @property
 */
  /*else*/ {
    __pyx_t_3 = __pyx_memoryview_assign_item_from_object(((struct __pyx_memoryview_obj *)__pyx_v_self), __pyx_v_itemp, __pyx_v_value); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 975, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  }
  __pyx_L3:;

  /* "View.MemoryView":971
 *             return memoryview.convert_item_to_object(self, itemp)
 * 
 *     cdef assign_item_from_object(self, char *itemp, object value):             # <<<<<<<<<<<<<<
 *         if self.to_dtype_func != NULL:
 *             self.to_dtype_func(itemp, value)
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("View.MemoryView._memoryviewslice.assign_item_from_object", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":978
 * 
 *     @property
 *     def base(self):             # <<<<<<<<<<<<<<
 *         return self.from_object
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_15View_dot_MemoryView_16_memoryviewslice_4base_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_15View_dot_MemoryView_16_memoryviewslice_4base_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_15View_dot_MemoryView_16_memoryviewslice_4base___get__(((struct __pyx_memoryviewslice_obj *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_15View_dot_MemoryView_16_memoryviewslice_4base___get__(struct __pyx_memoryviewslice_obj *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "View.MemoryView":979
 *     @property
 *     def base(self):
 *         return self.from_object             # <<<<<<<<<<<<<<
 * 
 *     __pyx_getbuffer = capsule(<void *> &__pyx_memoryview_getbuffer, "getbuffer(obj, view, flags)")
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_self->from_object);
  __pyx_r = __pyx_v_self->from_object;
  goto __pyx_L0;

  /* "View.MemoryView":978
 * 
 *     @property
 *     def base(self):             # <<<<<<<<<<<<<<
 *         return self.from_object
 * 
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":985
 * 
 * @cname('__pyx_memoryview_fromslice')
 * cdef memoryview_fromslice(__Pyx_memviewslice memviewslice,             # <<<<<<<<<<<<<<
 *                           int ndim,
 *                           object (*to_object_func)(char *),
 */

static PyObject *__pyx_memoryview_fromslice(__Pyx_memviewslice __pyx_v_memviewslice, int __pyx_v_ndim, PyObject *(*__pyx_v_to_object_func)(char *), int (*__pyx_v_to_dtype_func)(char *, PyObject *), int __pyx_v_dtype_is_object) {
  struct __pyx_memoryviewslice_obj *__pyx_v_result = 0;
  Py_ssize_t __pyx_v_suboffset;
  PyObject *__pyx_v_length = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_TypeInfo *__pyx_t_4;
  Py_buffer __pyx_t_5;
  Py_ssize_t *__pyx_t_6;
  Py_ssize_t *__pyx_t_7;
  Py_ssize_t *__pyx_t_8;
  Py_ssize_t __pyx_t_9;
  __Pyx_RefNannySetupContext("memoryview_fromslice", 0);

  /* "View.MemoryView":993
 *     cdef _memoryviewslice result
 * 
 *     if <PyObject *> memviewslice.memview == Py_None:             # <<<<<<<<<<<<<<
 *         return None
 * 
 */
  __pyx_t_1 = ((((PyObject *)__pyx_v_memviewslice.memview) == Py_None) != 0);
  if (__pyx_t_1) {

    /* "View.MemoryView":994
 * 
 *     if <PyObject *> memviewslice.memview == Py_None:
 *         return None             # <<<<<<<<<<<<<<
 * 
 * 
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(Py_None);
    __pyx_r = Py_None;
    goto __pyx_L0;

    /* "View.MemoryView":993
 *     cdef _memoryviewslice result
 * 
 *     if <PyObject *> memviewslice.memview == Py_None:             # <<<<<<<<<<<<<<
 *         return None
 * 
 */
  }

  /* "View.MemoryView":999
 * 
 * 
 *     result = _memoryviewslice(None, 0, dtype_is_object)             # <<<<<<<<<<<<<<
 * 
 *     result.from_slice = memviewslice
 */
  __pyx_t_2 = __Pyx_PyBool_FromLong(__pyx_v_dtype_is_object); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 999, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = PyTuple_New(3); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 999, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_INCREF(Py_None);
  __Pyx_GIVEREF(Py_None);
  PyTuple_SET_ITEM(__pyx_t_3, 0, Py_None);
  __Pyx_INCREF(__pyx_int_0);
  __Pyx_GIVEREF(__pyx_int_0);
  PyTuple_SET_ITEM(__pyx_t_3, 1, __pyx_int_0);
  __Pyx_GIVEREF(__pyx_t_2);
  PyTuple_SET_ITEM(__pyx_t_3, 2, __pyx_t_2);
  __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)__pyx_memoryviewslice_type), __pyx_t_3, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 999, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_result = ((struct __pyx_memoryviewslice_obj *)__pyx_t_2);
  __pyx_t_2 = 0;

  /* "View.MemoryView":1001
 *     result = _memoryviewslice(None, 0, dtype_is_object)
 * 
 *     result.from_slice = memviewslice             # <<<<<<<<<<<<<<
 *     __PYX_INC_MEMVIEW(&memviewslice, 1)
 * 
 */
  __pyx_v_result->from_slice = __pyx_v_memviewslice;

  /* "View.MemoryView":1002
 * 
 *     result.from_slice = memviewslice
 *     __PYX_INC_MEMVIEW(&memviewslice, 1)             # <<<<<<<<<<<<<<
 * 
 *     result.from_object = (<memoryview> memviewslice.memview).base
 */
  __PYX_INC_MEMVIEW((&__pyx_v_memviewslice), 1);

  /* "View.MemoryView":1004
 *     __PYX_INC_MEMVIEW(&memviewslice, 1)
 * 
 *     result.from_object = (<memoryview> memviewslice.memview).base             # <<<<<<<<<<<<<<
 *     result.typeinfo = memviewslice.memview.typeinfo
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_memviewslice.memview), __pyx_n_s_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 1004, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_GIVEREF(__pyx_t_2);
  __Pyx_GOTREF(__pyx_v_result->from_object);
  __Pyx_DECREF(__pyx_v_result->from_object);
  __pyx_v_result->from_object = __pyx_t_2;
  __pyx_t_2 = 0;

  /* "View.MemoryView":1005
 * 
 *     result.from_object = (<memoryview> memviewslice.memview).base
 *     result.typeinfo = memviewslice.memview.typeinfo             # <<<<<<<<<<<<<<
 * 
 *     result.view = memviewslice.memview.view
 */
  __pyx_t_4 = __pyx_v_memviewslice.memview->typeinfo;
  __pyx_v_result->__pyx_base.typeinfo = __pyx_t_4;

  /* "View.MemoryView":1007
 *     result.typeinfo = memviewslice.memview.typeinfo
 * 
 *     result.view = memviewslice.memview.view             # <<<<<<<<<<<<<<
 *     result.view.buf = <void *> memviewslice.data
 *     result.view.ndim = ndim
 */
  __pyx_t_5 = __pyx_v_memviewslice.memview->view;
  __pyx_v_result->__pyx_base.view = __pyx_t_5;

  /* "View.MemoryView":1008
 * 
 *     result.view = memviewslice.memview.view
 *     result.view.buf = <void *> memviewslice.data             # <<<<<<<<<<<<<<
 *     result.view.ndim = ndim
 *     (<__pyx_buffer *> &result.view).obj = Py_None
 */
  __pyx_v_result->__pyx_base.view.buf = ((void *)__pyx_v_memviewslice.data);

  /* "View.MemoryView":1009
 *     result.view = memviewslice.memview.view
 *     result.view.buf = <void *> memviewslice.data
 *     result.view.ndim = ndim             # <<<<<<<<<<<<<<
 *     (<__pyx_buffer *> &result.view).obj = Py_None
 *     Py_INCREF(Py_None)
 */
  __pyx_v_result->__pyx_base.view.ndim = __pyx_v_ndim;

  /* "View.MemoryView":1010
 *     result.view.buf = <void *> memviewslice.data
 *     result.view.ndim = ndim
 *     (<__pyx_buffer *> &result.view).obj = Py_None             # <<<<<<<<<<<<<<
 *     Py_INCREF(Py_None)
 * 
 */
  ((Py_buffer *)(&__pyx_v_result->__pyx_base.view))->obj = Py_None;

  /* "View.MemoryView":1011
 *     result.view.ndim = ndim
 *     (<__pyx_buffer *> &result.view).obj = Py_None
 *     Py_INCREF(Py_None)             # <<<<<<<<<<<<<<
 * 
 *     result.flags = PyBUF_RECORDS
 */
  Py_INCREF(Py_None);

  /* "View.MemoryView":1013
 *     Py_INCREF(Py_None)
 * 
 *     result.flags = PyBUF_RECORDS             # <<<<<<<<<<<<<<
 * 
 *     result.view.shape = <Py_ssize_t *> result.from_slice.shape
 */
  __pyx_v_result->__pyx_base.flags = PyBUF_RECORDS;

  /* "View.MemoryView":1015
 *     result.flags = PyBUF_RECORDS
 * 
 *     result.view.shape = <Py_ssize_t *> result.from_slice.shape             # <<<<<<<<<<<<<<
 *     result.view.strides = <Py_ssize_t *> result.from_slice.strides
 * 
 */
  __pyx_v_result->__pyx_base.view.shape = ((Py_ssize_t *)__pyx_v_result->from_slice.shape);

  /* "View.MemoryView":1016
 * 
 *     result.view.shape = <Py_ssize_t *> result.from_slice.shape
 *     result.view.strides = <Py_ssize_t *> result.from_slice.strides             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_v_result->__pyx_base.view.strides = ((Py_ssize_t *)__pyx_v_result->from_slice.strides);

  /* "View.MemoryView":1019
 * 
 * 
 *     result.view.suboffsets = NULL             # <<<<<<<<<<<<<<
 *     for suboffset in result.from_slice.suboffsets[:ndim]:
 *         if suboffset >= 0:
 */
  __pyx_v_result->__pyx_base.view.suboffsets = NULL;

  /* "View.MemoryView":1020
 * 
 *     result.view.suboffsets = NULL
 *     for suboffset in result.from_slice.suboffsets[:ndim]:             # <<<<<<<<<<<<<<
 *         if suboffset >= 0:
 *             result.view.suboffsets = <Py_ssize_t *> result.from_slice.suboffsets
 */
  __pyx_t_7 = (__pyx_v_result->from_slice.suboffsets + __pyx_v_ndim);
  for (__pyx_t_8 = __pyx_v_result->from_slice.suboffsets; __pyx_t_8 < __pyx_t_7; __pyx_t_8++) {
    __pyx_t_6 = __pyx_t_8;
    __pyx_v_suboffset = (__pyx_t_6[0]);

    /* "View.MemoryView":1021
 *     result.view.suboffsets = NULL
 *     for suboffset in result.from_slice.suboffsets[:ndim]:
 *         if suboffset >= 0:             # <<<<<<<<<<<<<<
 *             result.view.suboffsets = <Py_ssize_t *> result.from_slice.suboffsets
 *             break
 */
    __pyx_t_1 = ((__pyx_v_suboffset >= 0) != 0);
    if (__pyx_t_1) {

      /* "View.MemoryView":1022
 *     for suboffset in result.from_slice.suboffsets[:ndim]:
 *         if suboffset >= 0:
 *             result.view.suboffsets = <Py_ssize_t *> result.from_slice.suboffsets             # <<<<<<<<<<<<<<
 *             break
 * 
 */
      __pyx_v_result->__pyx_base.view.suboffsets = ((Py_ssize_t *)__pyx_v_result->from_slice.suboffsets);

      /* "View.MemoryView":1023
 *         if suboffset >= 0:
 *             result.view.suboffsets = <Py_ssize_t *> result.from_slice.suboffsets
 *             break             # <<<<<<<<<<<<<<
 * 
 *     result.view.len = result.view.itemsize
 */
      goto __pyx_L5_break;

      /* "View.MemoryView":1021
 *     result.view.suboffsets = NULL
 *     for suboffset in result.from_slice.suboffsets[:ndim]:
 *         if suboffset >= 0:             # <<<<<<<<<<<<<<
 *             result.view.suboffsets = <Py_ssize_t *> result.from_slice.suboffsets
 *             break
 */
    }
  }
  __pyx_L5_break:;

  /* "View.MemoryView":1025
 *             break
 * 
 *     result.view.len = result.view.itemsize             # <<<<<<<<<<<<<<
 *     for length in result.view.shape[:ndim]:
 *         result.view.len *= length
 */
  __pyx_t_9 = __pyx_v_result->__pyx_base.view.itemsize;
  __pyx_v_result->__pyx_base.view.len = __pyx_t_9;

  /* "View.MemoryView":1026
 * 
 *     result.view.len = result.view.itemsize
 *     for length in result.view.shape[:ndim]:             # <<<<<<<<<<<<<<
 *         result.view.len *= length
 * 
 */
  __pyx_t_7 = (__pyx_v_result->__pyx_base.view.shape + __pyx_v_ndim);
  for (__pyx_t_8 = __pyx_v_result->__pyx_base.view.shape; __pyx_t_8 < __pyx_t_7; __pyx_t_8++) {
    __pyx_t_6 = __pyx_t_8;
    __pyx_t_2 = PyInt_FromSsize_t((__pyx_t_6[0])); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 1026, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_XDECREF_SET(__pyx_v_length, __pyx_t_2);
    __pyx_t_2 = 0;

    /* "View.MemoryView":1027
 *     result.view.len = result.view.itemsize
 *     for length in result.view.shape[:ndim]:
 *         result.view.len *= length             # <<<<<<<<<<<<<<
 * 
 *     result.to_object_func = to_object_func
 */
    __pyx_t_2 = PyInt_FromSsize_t(__pyx_v_result->__pyx_base.view.len); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 1027, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = PyNumber_InPlaceMultiply(__pyx_t_2, __pyx_v_length); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 1027, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_9 = __Pyx_PyIndex_AsSsize_t(__pyx_t_3); if (unlikely((__pyx_t_9 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(2, 1027, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_v_result->__pyx_base.view.len = __pyx_t_9;
  }

  /* "View.MemoryView":1029
 *         result.view.len *= length
 * 
 *     result.to_object_func = to_object_func             # <<<<<<<<<<<<<<
 *     result.to_dtype_func = to_dtype_func
 * 
 */
  __pyx_v_result->to_object_func = __pyx_v_to_object_func;

  /* "View.MemoryView":1030
 * 
 *     result.to_object_func = to_object_func
 *     result.to_dtype_func = to_dtype_func             # <<<<<<<<<<<<<<
 * 
 *     return result
 */
  __pyx_v_result->to_dtype_func = __pyx_v_to_dtype_func;

  /* "View.MemoryView":1032
 *     result.to_dtype_func = to_dtype_func
 * 
 *     return result             # <<<<<<<<<<<<<<
 * 
 * @cname('__pyx_memoryview_get_slice_from_memoryview')
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_result));
  __pyx_r = ((PyObject *)__pyx_v_result);
  goto __pyx_L0;

  /* "View.MemoryView":985
 * 
 * @cname('__pyx_memoryview_fromslice')
 * cdef memoryview_fromslice(__Pyx_memviewslice memviewslice,             # <<<<<<<<<<<<<<
 *                           int ndim,
 *                           object (*to_object_func)(char *),
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("View.MemoryView.memoryview_fromslice", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_result);
  __Pyx_XDECREF(__pyx_v_length);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":1035
 * 
 * @cname('__pyx_memoryview_get_slice_from_memoryview')
 * cdef __Pyx_memviewslice *get_slice_from_memview(memoryview memview,             # <<<<<<<<<<<<<<
 *                                                    __Pyx_memviewslice *mslice):
 *     cdef _memoryviewslice obj
 */

static __Pyx_memviewslice *__pyx_memoryview_get_slice_from_memoryview(struct __pyx_memoryview_obj *__pyx_v_memview, __Pyx_memviewslice *__pyx_v_mslice) {
  struct __pyx_memoryviewslice_obj *__pyx_v_obj = 0;
  __Pyx_memviewslice *__pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("get_slice_from_memview", 0);

  /* "View.MemoryView":1038
 *                                                    __Pyx_memviewslice *mslice):
 *     cdef _memoryviewslice obj
 *     if isinstance(memview, _memoryviewslice):             # <<<<<<<<<<<<<<
 *         obj = memview
 *         return &obj.from_slice
 */
  __pyx_t_1 = __Pyx_TypeCheck(((PyObject *)__pyx_v_memview), __pyx_memoryviewslice_type); 
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "View.MemoryView":1039
 *     cdef _memoryviewslice obj
 *     if isinstance(memview, _memoryviewslice):
 *         obj = memview             # <<<<<<<<<<<<<<
 *         return &obj.from_slice
 *     else:
 */
    if (!(likely(((((PyObject *)__pyx_v_memview)) == Py_None) || likely(__Pyx_TypeTest(((PyObject *)__pyx_v_memview), __pyx_memoryviewslice_type))))) __PYX_ERR(2, 1039, __pyx_L1_error)
    __pyx_t_3 = ((PyObject *)__pyx_v_memview);
    __Pyx_INCREF(__pyx_t_3);
    __pyx_v_obj = ((struct __pyx_memoryviewslice_obj *)__pyx_t_3);
    __pyx_t_3 = 0;

    /* "View.MemoryView":1040
 *     if isinstance(memview, _memoryviewslice):
 *         obj = memview
 *         return &obj.from_slice             # <<<<<<<<<<<<<<
 *     else:
 *         slice_copy(memview, mslice)
 */
    __pyx_r = (&__pyx_v_obj->from_slice);
    goto __pyx_L0;

    /* "View.MemoryView":1038
 *                                                    __Pyx_memviewslice *mslice):
 *     cdef _memoryviewslice obj
 *     if isinstance(memview, _memoryviewslice):             # <<<<<<<<<<<<<<
 *         obj = memview
 *         return &obj.from_slice
 */
  }

  /* "View.MemoryView":1042
 *         return &obj.from_slice
 *     else:
 *         slice_copy(memview, mslice)             # <<<<<<<<<<<<<<
 *         return mslice
 * 
 */
  /*else*/ {
    __pyx_memoryview_slice_copy(__pyx_v_memview, __pyx_v_mslice);

    /* "View.MemoryView":1043
 *     else:
 *         slice_copy(memview, mslice)
 *         return mslice             # <<<<<<<<<<<<<<
 * 
 * @cname('__pyx_memoryview_slice_copy')
 */
    __pyx_r = __pyx_v_mslice;
    goto __pyx_L0;
  }

  /* "View.MemoryView":1035
 * 
 * @cname('__pyx_memoryview_get_slice_from_memoryview')
 * cdef __Pyx_memviewslice *get_slice_from_memview(memoryview memview,             # <<<<<<<<<<<<<<
 *                                                    __Pyx_memviewslice *mslice):
 *     cdef _memoryviewslice obj
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_WriteUnraisable("View.MemoryView.get_slice_from_memview", __pyx_clineno, __pyx_lineno, __pyx_filename, 0, 0);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_obj);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":1046
 * 
 * @cname('__pyx_memoryview_slice_copy')
 * cdef void slice_copy(memoryview memview, __Pyx_memviewslice *dst):             # <<<<<<<<<<<<<<
 *     cdef int dim
 *     cdef (Py_ssize_t*) shape, strides, suboffsets
 */

static void __pyx_memoryview_slice_copy(struct __pyx_memoryview_obj *__pyx_v_memview, __Pyx_memviewslice *__pyx_v_dst) {
  int __pyx_v_dim;
  Py_ssize_t *__pyx_v_shape;
  Py_ssize_t *__pyx_v_strides;
  Py_ssize_t *__pyx_v_suboffsets;
  __Pyx_RefNannyDeclarations
  Py_ssize_t *__pyx_t_1;
  int __pyx_t_2;
  int __pyx_t_3;
  Py_ssize_t __pyx_t_4;
  __Pyx_RefNannySetupContext("slice_copy", 0);

  /* "View.MemoryView":1050
 *     cdef (Py_ssize_t*) shape, strides, suboffsets
 * 
 *     shape = memview.view.shape             # <<<<<<<<<<<<<<
 *     strides = memview.view.strides
 *     suboffsets = memview.view.suboffsets
 */
  __pyx_t_1 = __pyx_v_memview->view.shape;
  __pyx_v_shape = __pyx_t_1;

  /* "View.MemoryView":1051
 * 
 *     shape = memview.view.shape
 *     strides = memview.view.strides             # <<<<<<<<<<<<<<
 *     suboffsets = memview.view.suboffsets
 * 
 */
  __pyx_t_1 = __pyx_v_memview->view.strides;
  __pyx_v_strides = __pyx_t_1;

  /* "View.MemoryView":1052
 *     shape = memview.view.shape
 *     strides = memview.view.strides
 *     suboffsets = memview.view.suboffsets             # <<<<<<<<<<<<<<
 * 
 *     dst.memview = <__pyx_memoryview *> memview
 */
  __pyx_t_1 = __pyx_v_memview->view.suboffsets;
  __pyx_v_suboffsets = __pyx_t_1;

  /* "View.MemoryView":1054
 *     suboffsets = memview.view.suboffsets
 * 
 *     dst.memview = <__pyx_memoryview *> memview             # <<<<<<<<<<<<<<
 *     dst.data = <char *> memview.view.buf
 * 
 */
  __pyx_v_dst->memview = ((struct __pyx_memoryview_obj *)__pyx_v_memview);

  /* "View.MemoryView":1055
 * 
 *     dst.memview = <__pyx_memoryview *> memview
 *     dst.data = <char *> memview.view.buf             # <<<<<<<<<<<<<<
 * 
 *     for dim in range(memview.view.ndim):
 */
  __pyx_v_dst->data = ((char *)__pyx_v_memview->view.buf);

  /* "View.MemoryView":1057
 *     dst.data = <char *> memview.view.buf
 * 
 *     for dim in range(memview.view.ndim):             # <<<<<<<<<<<<<<
 *         dst.shape[dim] = shape[dim]
 *         dst.strides[dim] = strides[dim]
 */
  __pyx_t_2 = __pyx_v_memview->view.ndim;
  for (__pyx_t_3 = 0; __pyx_t_3 < __pyx_t_2; __pyx_t_3+=1) {
    __pyx_v_dim = __pyx_t_3;

    /* "View.MemoryView":1058
 * 
 *     for dim in range(memview.view.ndim):
 *         dst.shape[dim] = shape[dim]             # <<<<<<<<<<<<<<
 *         dst.strides[dim] = strides[dim]
 *         dst.suboffsets[dim] = suboffsets[dim] if suboffsets else -1
 */
    (__pyx_v_dst->shape[__pyx_v_dim]) = (__pyx_v_shape[__pyx_v_dim]);

    /* "View.MemoryView":1059
 *     for dim in range(memview.view.ndim):
 *         dst.shape[dim] = shape[dim]
 *         dst.strides[dim] = strides[dim]             # <<<<<<<<<<<<<<
 *         dst.suboffsets[dim] = suboffsets[dim] if suboffsets else -1
 * 
 */
    (__pyx_v_dst->strides[__pyx_v_dim]) = (__pyx_v_strides[__pyx_v_dim]);

    /* "View.MemoryView":1060
 *         dst.shape[dim] = shape[dim]
 *         dst.strides[dim] = strides[dim]
 *         dst.suboffsets[dim] = suboffsets[dim] if suboffsets else -1             # <<<<<<<<<<<<<<
 * 
 * @cname('__pyx_memoryview_copy_object')
 */
    if ((__pyx_v_suboffsets != 0)) {
      __pyx_t_4 = (__pyx_v_suboffsets[__pyx_v_dim]);
    } else {
      __pyx_t_4 = -1L;
    }
    (__pyx_v_dst->suboffsets[__pyx_v_dim]) = __pyx_t_4;
  }

  /* "View.MemoryView":1046
 * 
 * @cname('__pyx_memoryview_slice_copy')
 * cdef void slice_copy(memoryview memview, __Pyx_memviewslice *dst):             # <<<<<<<<<<<<<<
 *     cdef int dim
 *     cdef (Py_ssize_t*) shape, strides, suboffsets
 */

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

/* "View.MemoryView":1063
 * 
 * @cname('__pyx_memoryview_copy_object')
 * cdef memoryview_copy(memoryview memview):             # <<<<<<<<<<<<<<
 *     "Create a new memoryview object"
 *     cdef __Pyx_memviewslice memviewslice
 */

static PyObject *__pyx_memoryview_copy_object(struct __pyx_memoryview_obj *__pyx_v_memview) {
  __Pyx_memviewslice __pyx_v_memviewslice;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("memoryview_copy", 0);

  /* "View.MemoryView":1066
 *     "Create a new memoryview object"
 *     cdef __Pyx_memviewslice memviewslice
 *     slice_copy(memview, &memviewslice)             # <<<<<<<<<<<<<<
 *     return memoryview_copy_from_slice(memview, &memviewslice)
 * 
 */
  __pyx_memoryview_slice_copy(__pyx_v_memview, (&__pyx_v_memviewslice));

  /* "View.MemoryView":1067
 *     cdef __Pyx_memviewslice memviewslice
 *     slice_copy(memview, &memviewslice)
 *     return memoryview_copy_from_slice(memview, &memviewslice)             # <<<<<<<<<<<<<<
 * 
 * @cname('__pyx_memoryview_copy_object_from_slice')
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_memoryview_copy_object_from_slice(__pyx_v_memview, (&__pyx_v_memviewslice)); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 1067, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "View.MemoryView":1063
 * 
 * @cname('__pyx_memoryview_copy_object')
 * cdef memoryview_copy(memoryview memview):             # <<<<<<<<<<<<<<
 *     "Create a new memoryview object"
 *     cdef __Pyx_memviewslice memviewslice
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("View.MemoryView.memoryview_copy", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":1070
 * 
 * @cname('__pyx_memoryview_copy_object_from_slice')
 * cdef memoryview_copy_from_slice(memoryview memview, __Pyx_memviewslice *memviewslice):             # <<<<<<<<<<<<<<
 *     """
 *     Create a new memoryview object from a given memoryview object and slice.
 */

static PyObject *__pyx_memoryview_copy_object_from_slice(struct __pyx_memoryview_obj *__pyx_v_memview, __Pyx_memviewslice *__pyx_v_memviewslice) {
  PyObject *(*__pyx_v_to_object_func)(char *);
  int (*__pyx_v_to_dtype_func)(char *, PyObject *);
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *(*__pyx_t_3)(char *);
  int (*__pyx_t_4)(char *, PyObject *);
  PyObject *__pyx_t_5 = NULL;
  __Pyx_RefNannySetupContext("memoryview_copy_from_slice", 0);

  /* "View.MemoryView":1077
 *     cdef int (*to_dtype_func)(char *, object) except 0
 * 
 *     if isinstance(memview, _memoryviewslice):             # <<<<<<<<<<<<<<
 *         to_object_func = (<_memoryviewslice> memview).to_object_func
 *         to_dtype_func = (<_memoryviewslice> memview).to_dtype_func
 */
  __pyx_t_1 = __Pyx_TypeCheck(((PyObject *)__pyx_v_memview), __pyx_memoryviewslice_type); 
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "View.MemoryView":1078
 * 
 *     if isinstance(memview, _memoryviewslice):
 *         to_object_func = (<_memoryviewslice> memview).to_object_func             # <<<<<<<<<<<<<<
 *         to_dtype_func = (<_memoryviewslice> memview).to_dtype_func
 *     else:
 */
    __pyx_t_3 = ((struct __pyx_memoryviewslice_obj *)__pyx_v_memview)->to_object_func;
    __pyx_v_to_object_func = __pyx_t_3;

    /* "View.MemoryView":1079
 *     if isinstance(memview, _memoryviewslice):
 *         to_object_func = (<_memoryviewslice> memview).to_object_func
 *         to_dtype_func = (<_memoryviewslice> memview).to_dtype_func             # <<<<<<<<<<<<<<
 *     else:
 *         to_object_func = NULL
 */
    __pyx_t_4 = ((struct __pyx_memoryviewslice_obj *)__pyx_v_memview)->to_dtype_func;
    __pyx_v_to_dtype_func = __pyx_t_4;

    /* "View.MemoryView":1077
 *     cdef int (*to_dtype_func)(char *, object) except 0
 * 
 *     if isinstance(memview, _memoryviewslice):             # <<<<<<<<<<<<<<
 *         to_object_func = (<_memoryviewslice> memview).to_object_func
 *         to_dtype_func = (<_memoryviewslice> memview).to_dtype_func
 */
    goto __pyx_L3;
  }

  /* "View.MemoryView":1081
 *         to_dtype_func = (<_memoryviewslice> memview).to_dtype_func
 *     else:
 *         to_object_func = NULL             # <<<<<<<<<<<<<<
 *         to_dtype_func = NULL
 * 
 */
  /*else*/ {
    __pyx_v_to_object_func = NULL;

    /* "View.MemoryView":1082
 *     else:
 *         to_object_func = NULL
 *         to_dtype_func = NULL             # <<<<<<<<<<<<<<
 * 
 *     return memoryview_fromslice(memviewslice[0], memview.view.ndim,
 */
    __pyx_v_to_dtype_func = NULL;
  }
  __pyx_L3:;

  /* "View.MemoryView":1084
 *         to_dtype_func = NULL
 * 
 *     return memoryview_fromslice(memviewslice[0], memview.view.ndim,             # <<<<<<<<<<<<<<
 *                                 to_object_func, to_dtype_func,
 *                                 memview.dtype_is_object)
 */
  __Pyx_XDECREF(__pyx_r);

  /* "View.MemoryView":1086
 *     return memoryview_fromslice(memviewslice[0], memview.view.ndim,
 *                                 to_object_func, to_dtype_func,
 *                                 memview.dtype_is_object)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_5 = __pyx_memoryview_fromslice((__pyx_v_memviewslice[0]), __pyx_v_memview->view.ndim, __pyx_v_to_object_func, __pyx_v_to_dtype_func, __pyx_v_memview->dtype_is_object); if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 1084, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_r = __pyx_t_5;
  __pyx_t_5 = 0;
  goto __pyx_L0;

  /* "View.MemoryView":1070
 * 
 * @cname('__pyx_memoryview_copy_object_from_slice')
 * cdef memoryview_copy_from_slice(memoryview memview, __Pyx_memviewslice *memviewslice):             # <<<<<<<<<<<<<<
 *     """
 *     Create a new memoryview object from a given memoryview object and slice.
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("View.MemoryView.memoryview_copy_from_slice", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "View.MemoryView":1092
 * 
 * 
 * cdef Py_ssize_t abs_py_ssize_t(Py_ssize_t arg) nogil:             # <<<<<<<<<<<<<<
 *     if arg < 0:
 *         return -arg
 */

static Py_ssize_t abs_py_ssize_t(Py_ssize_t __pyx_v_arg) {
  Py_ssize_t __pyx_r;
  int __pyx_t_1;

  /* "View.MemoryView":1093
 * 
 * cdef Py_ssize_t abs_py_ssize_t(Py_ssize_t arg) nogil:
 *     if arg < 0:             # <<<<<<<<<<<<<<
 *         return -arg
 *     else:
 */
  __pyx_t_1 = ((__pyx_v_arg < 0) != 0);
  if (__pyx_t_1) {

    /* "View.MemoryView":1094
 * cdef Py_ssize_t abs_py_ssize_t(Py_ssize_t arg) nogil:
 *     if arg < 0:
 *         return -arg             # <<<<<<<<<<<<<<
 *     else:
 *         return arg
 */
    __pyx_r = (-__pyx_v_arg);
    goto __pyx_L0;

    /* "View.MemoryView":1093
 * 
 * cdef Py_ssize_t abs_py_ssize_t(Py_ssize_t arg) nogil:
 *     if arg < 0:             # <<<<<<<<<<<<<<
 *         return -arg
 *     else:
 */
  }

  /* "View.MemoryView":1096
 *         return -arg
 *     else:
 *         return arg             # <<<<<<<<<<<<<<
 * 
 * @cname('__pyx_get_best_slice_order')
 */
  /*else*/ {
    __pyx_r = __pyx_v_arg;
    goto __pyx_L0;
  }

  /* "View.MemoryView":1092
 * 
 * 
 * cdef Py_ssize_t abs_py_ssize_t(Py_ssize_t arg) nogil:             # <<<<<<<<<<<<<<
 *     if arg < 0:
 *         return -arg
 */

  /* function exit code */
  __pyx_L0:;
  return __pyx_r;
}

/* "View.MemoryView":1099
 * 
 * @cname('__pyx_get_best_slice_order')
 * cdef char get_best_order(__Pyx_memviewslice *mslice, int ndim) nogil:             # <<<<<<<<<<<<<<
 *     """
 *     Figure out the best memory access order for a given slice.
 */

static char __pyx_get_best_slice_order(__Pyx_memviewslice *__pyx_v_mslice, int __pyx_v_ndim) {
  int __pyx_v_i;
  Py_ssize_t __pyx_v_c_stride;
  Py_ssize_t __pyx_v_f_stride;
  char __pyx_r;
  int __pyx_t_1;
  int __pyx_t_2;
  int __pyx_t_3;

  /* "View.MemoryView":1104
 *     """
 *     cdef int i
 *     cdef Py_ssize_t c_stride = 0             # <<<<<<<<<<<<<<
 *     cdef Py_ssize_t f_stride = 0
 * 
 */
  __pyx_v_c_stride = 0;

  /* "View.MemoryView":1105
 *     cdef int i
 *     cdef Py_ssize_t c_stride = 0
 *     cdef Py_ssize_t f_stride = 0             # <<<<<<<<<<<<<<
 * 
 *     for i in range(ndim - 1, -1, -1):
 */
  __pyx_v_f_stride = 0;

  /* "View.MemoryView":1107
 *     cdef Py_ssize_t f_stride = 0
 * 
 *     for i in range(ndim - 1, -1, -1):             # <<<<<<<<<<<<<<
 *         if mslice.shape[i] > 1:
 *             c_stride = mslice.strides[i]
 */
  for (__pyx_t_1 = (__pyx_v_ndim - 1); __pyx_t_1 > -1L; __pyx_t_1-=1) {
    __pyx_v_i = __pyx_t_1;

    /* "View.MemoryView":1108
 * 
 *     for i in range(ndim - 1, -1, -1):
 *         if mslice.shape[i] > 1:             # <<<<<<<<<<<<<<
 *             c_stride = mslice.strides[i]
 *             break
 */
    __pyx_t_2 = (((__pyx_v_mslice->shape[__pyx_v_i]) > 1) != 0);
    if (__pyx_t_2) {

      /* "View.MemoryView":1109
 *     for i in range(ndim - 1, -1, -1):
 *         if mslice.shape[i] > 1:
 *             c_stride = mslice.strides[i]             # <<<<<<<<<<<<<<
 *             break
 * 
 */
      __pyx_v_c_stride = (__pyx_v_mslice->strides[__pyx_v_i]);

      /* "View.MemoryView":1110
 *         if mslice.shape[i] > 1:
 *             c_stride = mslice.strides[i]
 *             break             # <<<<<<<<<<<<<<
 * 
 *     for i in range(ndim):
 */
      goto __pyx_L4_break;

      /* "View.MemoryView":1108
 * 
 *     for i in range(ndim - 1, -1, -1):
 *         if mslice.shape[i] > 1:             # <<<<<<<<<<<<<<
 *             c_stride = mslice.strides[i]
 *             break
 */
    }
  }
  __pyx_L4_break:;

  /* "View.MemoryView":1112
 *             break
 * 
 *     for i in range(ndim):             # <<<<<<<<<<<<<<
 *         if mslice.shape[i] > 1:
 *             f_stride = mslice.strides[i]
 */
  __pyx_t_1 = __pyx_v_ndim;
  for (__pyx_t_3 = 0; __pyx_t_3 < __pyx_t_1; __pyx_t_3+=1) {
    __pyx_v_i = __pyx_t_3;

    /* "View.MemoryView":1113
 * 
 *     for i in range(ndim):
 *         if mslice.shape[i] > 1:             # <<<<<<<<<<<<<<
 *             f_stride = mslice.strides[i]
 *             break
 */
    __pyx_t_2 = (((__pyx_v_mslice->shape[__pyx_v_i]) > 1) != 0);
    if (__pyx_t_2) {

      /* "View.MemoryView":1114
 *     for i in range(ndim):
 *         if mslice.shape[i] > 1:
 *             f_stride = mslice.strides[i]             # <<<<<<<<<<<<<<
 *             break
 * 
 */
      __pyx_v_f_stride = (__pyx_v_mslice->strides[__pyx_v_i]);

      /* "View.MemoryView":1115
 *         if mslice.shape[i] > 1:
 *             f_stride = mslice.strides[i]
 *             break             # <<<<<<<<<<<<<<
 * 
 *     if abs_py_ssize_t(c_stride) <= abs_py_ssize_t(f_stride):
 */
      goto __pyx_L7_break;

      /* "View.MemoryView":1113
 * 
 *     for i in range(ndim):
 *         if mslice.shape[i] > 1:             # <<<<<<<<<<<<<<
 *             f_stride = mslice.strides[i]
 *             break
 */
    }
  }
  __pyx_L7_break:;

  /* "View.MemoryView":1117
 *             break
 * 
 *     if abs_py_ssize_t(c_stride) <= abs_py_ssize_t(f_stride):             # <<<<<<<<<<<<<<
 *         return 'C'
 *     else:
 */
  __pyx_t_2 = ((abs_py_ssize_t(__pyx_v_c_stride) <= abs_py_ssize_t(__pyx_v_f_stride)) != 0);
  if (__pyx_t_2) {

    /* "View.MemoryView":1118
 * 
 *     if abs_py_ssize_t(c_stride) <= abs_py_ssize_t(f_stride):
 *         return 'C'             # <<<<<<<<<<<<<<
 *     else:
 *         return 'F'
 */
    __pyx_r = 'C';
    goto __pyx_L0;

    /* "View.MemoryView":1117
 *             break
 * 
 *     if abs_py_ssize_t(c_stride) <= abs_py_ssize_t(f_stride):             # <<<<<<<<<<<<<<
 *         return 'C'
 *     else:
 */
  }

  /* "View.MemoryView":1120
 *         return 'C'
 *     else:
 *         return 'F'             # <<<<<<<<<<<<<<
 * 
 * @cython.cdivision(True)
 */
  /*else*/ {
    __pyx_r = 'F';
    goto __pyx_L0;
  }

  /* "View.MemoryView":1099
 * 
 * @cname('__pyx_get_best_slice_order')
 * cdef char get_best_order(__Pyx_memviewslice *mslice, int ndim) nogil:             # <<<<<<<<<<<<<<
 *     """
 *     Figure out the best memory access order for a given slice.
 */

  /* function exit code */
  __pyx_L0:;
  return __pyx_r;
}

/* "View.MemoryView":1123
 * 
 * @cython.cdivision(True)
 * cdef void _copy_strided_to_strided(char *src_data, Py_ssize_t *src_strides,             # <<<<<<<<<<<<<<
 *                                    char *dst_data, Py_ssize_t *dst_strides,
 *                                    Py_ssize_t *src_shape, Py_ssize_t *dst_shape,
 */

static void _copy_strided_to_strided(char *__pyx_v_src_data, Py_ssize_t *__pyx_v_src_strides, char *__pyx_v_dst_data, Py_ssize_t *__pyx_v_dst_strides, Py_ssize_t *__pyx_v_src_shape, Py_ssize_t *__pyx_v_dst_shape, int __pyx_v_ndim, size_t __pyx_v_itemsize) {
  CYTHON_UNUSED Py_ssize_t __pyx_v_i;
  CYTHON_UNUSED Py_ssize_t __pyx_v_src_extent;
  Py_ssize_t __pyx_v_dst_extent;
  Py_ssize_t __pyx_v_src_stride;
  Py_ssize_t __pyx_v_dst_stride;
  int __pyx_t_1;
  int __pyx_t_2;
  int __pyx_t_3;
  Py_ssize_t __pyx_t_4;
  Py_ssize_t __pyx_t_5;

  /* "View.MemoryView":1130
 * 
 *     cdef Py_ssize_t i
 *     cdef Py_ssize_t src_extent = src_shape[0]             # <<<<<<<<<<<<<<
 *     cdef Py_ssize_t dst_extent = dst_shape[0]
 *     cdef Py_ssize_t src_stride = src_strides[0]
 */
  __pyx_v_src_extent = (__pyx_v_src_shape[0]);

  /* "View.MemoryView":1131
 *     cdef Py_ssize_t i
 *     cdef Py_ssize_t src_extent = src_shape[0]
 *     cdef Py_ssize_t dst_extent = dst_shape[0]             # <<<<<<<<<<<<<<
 *     cdef Py_ssize_t src_stride = src_strides[0]
 *     cdef Py_ssize_t dst_stride = dst_strides[0]
 */
  __pyx_v_dst_extent = (__pyx_v_dst_shape[0]);

  /* "View.MemoryView":1132
 *     cdef Py_ssize_t src_extent = src_shape[0]
 *     cdef Py_ssize_t dst_extent = dst_shape[0]
 *     cdef Py_ssize_t src_stride = src_strides[0]             # <<<<<<<<<<<<<<
 *     cdef Py_ssize_t dst_stride = dst_strides[0]
 * 
 */
  __pyx_v_src_stride = (__pyx_v_src_strides[0]);

  /* "View.MemoryView":1133
 *     cdef Py_ssize_t dst_extent = dst_shape[0]
 *     cdef Py_ssize_t src_stride = src_strides[0]
 *     cdef Py_ssize_t dst_stride = dst_strides[0]             # <<<<<<<<<<<<<<
 * 
 *     if ndim == 1:
 */
  __pyx_v_dst_stride = (__pyx_v_dst_strides[0]);

  /* "View.MemoryView":1135
 *     cdef Py_ssize_t dst_stride = dst_strides[0]
 * 
 *     if ndim == 1:             # <<<<<<<<<<<<<<
 *        if (src_stride > 0 and dst_stride > 0 and
 *            <size_t> src_stride == itemsize == <size_t> dst_stride):
 */
  __pyx_t_1 = ((__pyx_v_ndim == 1) != 0);
  if (__pyx_t_1) {

    /* "View.MemoryView":1136
 * 
 *     if ndim == 1:
 *        if (src_stride > 0 and dst_stride > 0 and             # <<<<<<<<<<<<<<
 *            <size_t> src_stride == itemsize == <size_t> dst_stride):
 *            memcpy(dst_data, src_data, itemsize * dst_extent)
 */
    __pyx_t_2 = ((__pyx_v_src_stride > 0) != 0);
    if (__pyx_t_2) {
    } else {
      __pyx_t_1 = __pyx_t_2;
      goto __pyx_L5_bool_binop_done;
    }
    __pyx_t_2 = ((__pyx_v_dst_stride > 0) != 0);
    if (__pyx_t_2) {
    } else {
      __pyx_t_1 = __pyx_t_2;
      goto __pyx_L5_bool_binop_done;
    }

    /* "View.MemoryView":1137
 *     if ndim == 1:
 *        if (src_stride > 0 and dst_stride > 0 and
 *            <size_t> src_stride == itemsize == <size_t> dst_stride):             # <<<<<<<<<<<<<<
 *            memcpy(dst_data, src_data, itemsize * dst_extent)
 *        else:
 */
    __pyx_t_2 = (((size_t)__pyx_v_src_stride) == __pyx_v_itemsize);
    if (__pyx_t_2) {
      __pyx_t_2 = (__pyx_v_itemsize == ((size_t)__pyx_v_dst_stride));
    }
    __pyx_t_3 = (__pyx_t_2 != 0);
    __pyx_t_1 = __pyx_t_3;
    __pyx_L5_bool_binop_done:;

    /* "View.MemoryView":1136
 * 
 *     if ndim == 1:
 *        if (src_stride > 0 and dst_stride > 0 and             # <<<<<<<<<<<<<<
 *            <size_t> src_stride == itemsize == <size_t> dst_stride):
 *            memcpy(dst_data, src_data, itemsize * dst_extent)
 */
    if (__pyx_t_1) {

      /* "View.MemoryView":1138
 *        if (src_stride > 0 and dst_stride > 0 and
 *            <size_t> src_stride == itemsize == <size_t> dst_stride):
 *            memcpy(dst_data, src_data, itemsize * dst_extent)             # <<<<<<<<<<<<<<
 *        else:
 *            for i in range(dst_extent):
 */
      memcpy(__pyx_v_dst_data, __pyx_v_src_data, (__pyx_v_itemsize * __pyx_v_dst_extent));

      /* "View.MemoryView":1136
 * 
 *     if ndim == 1:
 *        if (src_stride > 0 and dst_stride > 0 and             # <<<<<<<<<<<<<<
 *            <size_t> src_stride == itemsize == <size_t> dst_stride):
 *            memcpy(dst_data, src_data, itemsize * dst_extent)
 */
      goto __pyx_L4;
    }

    /* "View.MemoryView":1140
 *            memcpy(dst_data, src_data, itemsize * dst_extent)
 *        else:
 *            for i in range(dst_extent):             # <<<<<<<<<<<<<<
 *                memcpy(dst_data, src_data, itemsize)
 *                src_data += src_stride
 */
    /*else*/ {
      __pyx_t_4 = __pyx_v_dst_extent;
      for (__pyx_t_5 = 0; __pyx_t_5 < __pyx_t_4; __pyx_t_5+=1) {
        __pyx_v_i = __pyx_t_5;

        /* "View.MemoryView":1141
 *        else:
 *            for i in range(dst_extent):
 *                memcpy(dst_data, src_data, itemsize)             # <<<<<<<<<<<<<<
 *                src_data += src_stride
 *                dst_data += dst_stride
 */
        memcpy(__pyx_v_dst_data, __pyx_v_src_data, __pyx_v_itemsize);

        /* "View.MemoryView":1142
 *            for i in range(dst_extent):
 *                memcpy(dst_data, src_data, itemsize)
 *                src_data += src_stride             # <<<<<<<<<<<<<<
 *                dst_data += dst_stride
 *     else:
 */
        __pyx_v_src_data = (__pyx_v_src_data + __pyx_v_src_stride);

        /* "View.MemoryView":1143
 *                memcpy(dst_data, src_data, itemsize)
 *                src_data += src_stride
 *                dst_data += dst_stride             # <<<<<<<<<<<<<<
 *     else:
 *         for i in range(dst_extent):
 */
        __pyx_v_dst_data = (__pyx_v_dst_data + __pyx_v_dst_stride);
      }
    }
    __pyx_L4:;

    /* "View.MemoryView":1135
 *     cdef Py_ssize_t dst_stride = dst_strides[0]
 * 
 *     if ndim == 1:             # <<<<<<<<<<<<<<
 *        if (src_stride > 0 and dst_stride > 0 and
 *            <size_t> src_stride == itemsize == <size_t> dst_stride):
 */
    goto __pyx_L3;
  }

  /* "View.MemoryView":1145
 *                dst_data += dst_stride
 *     else:
 *         for i in range(dst_extent):             # <<<<<<<<<<<<<<
 *             _copy_strided_to_strided(src_data, src_strides + 1,
 *                                      dst_data, dst_strides + 1,
 */
  /*else*/ {
    __pyx_t_4 = __pyx_v_dst_extent;
    for (__pyx_t_5 = 0; __pyx_t_5 < __pyx_t_4; __pyx_t_5+=1) {
      __pyx_v_i = __pyx_t_5;

      /* "View.MemoryView":1146
 *     else:
 *         for i in range(dst_extent):
 *             _copy_strided_to_strided(src_data, src_strides + 1,             # <<<<<<<<<<<<<<
 *                                      dst_data, dst_strides + 1,
 *                                      src_shape + 1, dst_shape + 1,
 */
      _copy_strided_to_strided(__pyx_v_src_data, (__pyx_v_src_strides + 1), __pyx_v_dst_data, (__pyx_v_dst_strides + 1), (__pyx_v_src_shape + 1), (__pyx_v_dst_shape + 1), (__pyx_v_ndim - 1), __pyx_v_itemsize);

      /* "View.MemoryView":1150
 *                                      src_shape + 1, dst_shape + 1,
 *                                      ndim - 1, itemsize)
 *             src_data += src_stride             # <<<<<<<<<<<<<<
 *             dst_data += dst_stride
 * 
 */
      __pyx_v_src_data = (__pyx_v_src_data + __pyx_v_src_stride);

      /* "View.MemoryView":1151
 *                                      ndim - 1, itemsize)
 *             src_data += src_stride
 *             dst_data += dst_stride             # <<<<<<<<<<<<<<
 * 
 * cdef void copy_strided_to_strided(__Pyx_memviewslice *src,
 */
      __pyx_v_dst_data = (__pyx_v_dst_data + __pyx_v_dst_stride);
    }
  }
  __pyx_L3:;

  /* "View.MemoryView":1123
 * 
 * @cython.cdivision(True)
 * cdef void _copy_strided_to_strided(char *src_data, Py_ssize_t *src_strides,             # <<<<<<<<<<<<<<
 *                                    char *dst_data, Py_ssize_t *dst_strides,
 *                                    Py_ssize_t *src_shape, Py_ssize_t *dst_shape,
 */

  /* function exit code */
}

/* "View.MemoryView":1153
 *             dst_data += dst_stride
 * 
 * cdef void copy_strided_to_strided(__Pyx_memviewslice *src,             # <<<<<<<<<<<<<<
 *                                   __Pyx_memviewslice *dst,
 *                                   int ndim, size_t itemsize) nogil:
 */

static void copy_strided_to_strided(__Pyx_memviewslice *__pyx_v_src, __Pyx_memviewslice *__pyx_v_dst, int __pyx_v_ndim, size_t __pyx_v_itemsize) {

  /* "View.MemoryView":1156
 *                                   __Pyx_memviewslice *dst,
 *                                   int ndim, size_t itemsize) nogil:
 *     _copy_strided_to_strided(src.data, src.strides, dst.data, dst.strides,             # <<<<<<<<<<<<<<
 *                              src.shape, dst.shape, ndim, itemsize)
 * 
 */
  _copy_strided_to_strided(__pyx_v_src->data, __pyx_v_src->strides, __pyx_v_dst->data, __pyx_v_dst->strides, __pyx_v_src->shape, __pyx_v_dst->shape, __pyx_v_ndim, __pyx_v_itemsize);

  /* "View.MemoryView":1153
 *             dst_data += dst_stride
 * 
 * cdef void copy_strided_to_strided(__Pyx_memviewslice *src,             # <<<<<<<<<<<<<<
 *                                   __Pyx_memviewslice *dst,
 *                                   int ndim, size_t itemsize) nogil:
 */

  /* function exit code */
}

/* "View.MemoryView":1160
 * 
 * @cname('__pyx_memoryview_slice_get_size')
 * cdef Py_ssize_t slice_get_size(__Pyx_memviewslice *src, int ndim) nogil:             # <<<<<<<<<<<<<<
 *     "Return the size of the memory occupied by the slice in number of bytes"
 *     cdef int i
 */

static Py_ssize_t __pyx_memoryview_slice_get_size(__Pyx_memviewslice *__pyx_v_src, int __pyx_v_ndim) {
  int __pyx_v_i;
  Py_ssize_t __pyx_v_size;
  Py_ssize_t __pyx_r;
  Py_ssize_t __pyx_t_1;
  int __pyx_t_2;
  int __pyx_t_3;

  /* "View.MemoryView":1163
 *     "Return the size of the memory occupied by the slice in number of bytes"
 *     cdef int i
 *     cdef Py_ssize_t size = src.memview.view.itemsize             # <<<<<<<<<<<<<<
 * 
 *     for i in range(ndim):
 */
  __pyx_t_1 = __pyx_v_src->memview->view.itemsize;
  __pyx_v_size = __pyx_t_1;

  /* "View.MemoryView":1165
 *     cdef Py_ssize_t size = src.memview.view.itemsize
 * 
 *     for i in range(ndim):             # <<<<<<<<<<<<<<
 *         size *= src.shape[i]
 * 
 */
  __pyx_t_2 = __pyx_v_ndim;
  for (__pyx_t_3 = 0; __pyx_t_3 < __pyx_t_2; __pyx_t_3+=1) {
    __pyx_v_i = __pyx_t_3;

    /* "View.MemoryView":1166
 * 
 *     for i in range(ndim):
 *         size *= src.shape[i]             # <<<<<<<<<<<<<<
 * 
 *     return size
 */
    __pyx_v_size = (__pyx_v_size * (__pyx_v_src->shape[__pyx_v_i]));
  }

  /* "View.MemoryView":1168
 *         size *= src.shape[i]
 * 
 *     return size             # <<<<<<<<<<<<<<
 * 
 * @cname('__pyx_fill_contig_strides_array')
 */
  __pyx_r = __pyx_v_size;
  goto __pyx_L0;

  /* "View.MemoryView":1160
 * 
 * @cname('__pyx_memoryview_slice_get_size')
 * cdef Py_ssize_t slice_get_size(__Pyx_memviewslice *src, int ndim) nogil:             # <<<<<<<<<<<<<<
 *     "Return the size of the memory occupied by the slice in number of bytes"
 *     cdef int i
 */

  /* function exit code */
  __pyx_L0:;
  return __pyx_r;
}

/* "View.MemoryView":1171
 * 
 * @cname('__pyx_fill_contig_strides_array')
 * cdef Py_ssize_t fill_contig_strides_array(             # <<<<<<<<<<<<<<
 *                 Py_ssize_t *shape, Py_ssize_t *strides, Py_ssize_t stride,
 *                 int ndim, char order) nogil:
 */

static Py_ssize_t __pyx_fill_contig_strides_array(Py_ssize_t *__pyx_v_shape, Py_ssize_t *__pyx_v_strides, Py_ssize_t __pyx_v_stride, int __pyx_v_ndim, char __pyx_v_order) {
  int __pyx_v_idx;
  Py_ssize_t __pyx_r;
  int __pyx_t_1;
  int __pyx_t_2;
  int __pyx_t_3;

  /* "View.MemoryView":1180
 *     cdef int idx
 * 
 *     if order == 'F':             # <<<<<<<<<<<<<<
 *         for idx in range(ndim):
 *             strides[idx] = stride
 */
  __pyx_t_1 = ((__pyx_v_order == 'F') != 0);
  if (__pyx_t_1) {

    /* "View.MemoryView":1181
 * 
 *     if order == 'F':
 *         for idx in range(ndim):             # <<<<<<<<<<<<<<
 *             strides[idx] = stride
 *             stride = stride * shape[idx]
 */
    __pyx_t_2 = __pyx_v_ndim;
    for (__pyx_t_3 = 0; __pyx_t_3 < __pyx_t_2; __pyx_t_3+=1) {
      __pyx_v_idx = __pyx_t_3;

      /* "View.MemoryView":1182
 *     if order == 'F':
 *         for idx in range(ndim):
 *             strides[idx] = stride             # <<<<<<<<<<<<<<
 *             stride = stride * shape[idx]
 *     else:
 */
      (__pyx_v_strides[__pyx_v_idx]) = __pyx_v_stride;

      /* "View.MemoryView":1183
 *         for idx in range(ndim):
 *             strides[idx] = stride
 *             stride = stride * shape[idx]             # <<<<<<<<<<<<<<
 *     else:
 *         for idx in range(ndim - 1, -1, -1):
 */
      __pyx_v_stride = (__pyx_v_stride * (__pyx_v_shape[__pyx_v_idx]));
    }

    /* "View.MemoryView":1180
 *     cdef int idx
 * 
 *     if order == 'F':             # <<<<<<<<<<<<<<
 *         for idx in range(ndim):
 *             strides[idx] = stride
 */
    goto __pyx_L3;
  }

  /* "View.MemoryView":1185
 *             stride = stride * shape[idx]
 *     else:
 *         for idx in range(ndim - 1, -1, -1):             # <<<<<<<<<<<<<<
 *             strides[idx] = stride
 *             stride = stride * shape[idx]
 */
  /*else*/ {
    for (__pyx_t_2 = (__pyx_v_ndim - 1); __pyx_t_2 > -1L; __pyx_t_2-=1) {
      __pyx_v_idx = __pyx_t_2;

      /* "View.MemoryView":1186
 *     else:
 *         for idx in range(ndim - 1, -1, -1):
 *             strides[idx] = stride             # <<<<<<<<<<<<<<
 *             stride = stride * shape[idx]
 * 
 */
      (__pyx_v_strides[__pyx_v_idx]) = __pyx_v_stride;

      /* "View.MemoryView":1187
 *         for idx in range(ndim - 1, -1, -1):
 *             strides[idx] = stride
 *             stride = stride * shape[idx]             # <<<<<<<<<<<<<<
 * 
 *     return stride
 */
      __pyx_v_stride = (__pyx_v_stride * (__pyx_v_shape[__pyx_v_idx]));
    }
  }
  __pyx_L3:;

  /* "View.MemoryView":1189
 *             stride = stride * shape[idx]
 * 
 *     return stride             # <<<<<<<<<<<<<<
 * 
 * @cname('__pyx_memoryview_copy_data_to_temp')
 */
  __pyx_r = __pyx_v_stride;
  goto __pyx_L0;

  /* "View.MemoryView":1171
 * 
 * @cname('__pyx_fill_contig_strides_array')
 * cdef Py_ssize_t fill_contig_strides_array(             # <<<<<<<<<<<<<<
 *                 Py_ssize_t *shape, Py_ssize_t *strides, Py_ssize_t stride,
 *                 int ndim, char order) nogil:
 */

  /* function exit code */
  __pyx_L0:;
  return __pyx_r;
}

/* "View.MemoryView":1192
 * 
 * @cname('__pyx_memoryview_copy_data_to_temp')
 * cdef void *copy_data_to_temp(__Pyx_memviewslice *src,             # <<<<<<<<<<<<<<
 *                              __Pyx_memviewslice *tmpslice,
 *                              char order,
 */

static void *__pyx_memoryview_copy_data_to_temp(__Pyx_memviewslice *__pyx_v_src, __Pyx_memviewslice *__pyx_v_tmpslice, char __pyx_v_order, int __pyx_v_ndim) {
  int __pyx_v_i;
  void *__pyx_v_result;
  size_t __pyx_v_itemsize;
  size_t __pyx_v_size;
  void *__pyx_r;
  Py_ssize_t __pyx_t_1;
  int __pyx_t_2;
  int __pyx_t_3;
  struct __pyx_memoryview_obj *__pyx_t_4;
  int __pyx_t_5;

  /* "View.MemoryView":1203
 *     cdef void *result
 * 
 *     cdef size_t itemsize = src.memview.view.itemsize             # <<<<<<<<<<<<<<
 *     cdef size_t size = slice_get_size(src, ndim)
 * 
 */
  __pyx_t_1 = __pyx_v_src->memview->view.itemsize;
  __pyx_v_itemsize = __pyx_t_1;

  /* "View.MemoryView":1204
 * 
 *     cdef size_t itemsize = src.memview.view.itemsize
 *     cdef size_t size = slice_get_size(src, ndim)             # <<<<<<<<<<<<<<
 * 
 *     result = malloc(size)
 */
  __pyx_v_size = __pyx_memoryview_slice_get_size(__pyx_v_src, __pyx_v_ndim);

  /* "View.MemoryView":1206
 *     cdef size_t size = slice_get_size(src, ndim)
 * 
 *     result = malloc(size)             # <<<<<<<<<<<<<<
 *     if not result:
 *         _err(MemoryError, NULL)
 */
  __pyx_v_result = malloc(__pyx_v_size);

  /* "View.MemoryView":1207
 * 
 *     result = malloc(size)
 *     if not result:             # <<<<<<<<<<<<<<
 *         _err(MemoryError, NULL)
 * 
 */
  __pyx_t_2 = ((!(__pyx_v_result != 0)) != 0);
  if (__pyx_t_2) {

    /* "View.MemoryView":1208
 *     result = malloc(size)
 *     if not result:
 *         _err(MemoryError, NULL)             # <<<<<<<<<<<<<<
 * 
 * 
 */
    __pyx_t_3 = __pyx_memoryview_err(__pyx_builtin_MemoryError, NULL); if (unlikely(__pyx_t_3 == -1)) __PYX_ERR(2, 1208, __pyx_L1_error)

    /* "View.MemoryView":1207
 * 
 *     result = malloc(size)
 *     if not result:             # <<<<<<<<<<<<<<
 *         _err(MemoryError, NULL)
 * 
 */
  }

  /* "View.MemoryView":1211
 * 
 * 
 *     tmpslice.data = <char *> result             # <<<<<<<<<<<<<<
 *     tmpslice.memview = src.memview
 *     for i in range(ndim):
 */
  __pyx_v_tmpslice->data = ((char *)__pyx_v_result);

  /* "View.MemoryView":1212
 * 
 *     tmpslice.data = <char *> result
 *     tmpslice.memview = src.memview             # <<<<<<<<<<<<<<
 *     for i in range(ndim):
 *         tmpslice.shape[i] = src.shape[i]
 */
  __pyx_t_4 = __pyx_v_src->memview;
  __pyx_v_tmpslice->memview = __pyx_t_4;

  /* "View.MemoryView":1213
 *     tmpslice.data = <char *> result
 *     tmpslice.memview = src.memview
 *     for i in range(ndim):             # <<<<<<<<<<<<<<
 *         tmpslice.shape[i] = src.shape[i]
 *         tmpslice.suboffsets[i] = -1
 */
  __pyx_t_3 = __pyx_v_ndim;
  for (__pyx_t_5 = 0; __pyx_t_5 < __pyx_t_3; __pyx_t_5+=1) {
    __pyx_v_i = __pyx_t_5;

    /* "View.MemoryView":1214
 *     tmpslice.memview = src.memview
 *     for i in range(ndim):
 *         tmpslice.shape[i] = src.shape[i]             # <<<<<<<<<<<<<<
 *         tmpslice.suboffsets[i] = -1
 * 
 */
    (__pyx_v_tmpslice->shape[__pyx_v_i]) = (__pyx_v_src->shape[__pyx_v_i]);

    /* "View.MemoryView":1215
 *     for i in range(ndim):
 *         tmpslice.shape[i] = src.shape[i]
 *         tmpslice.suboffsets[i] = -1             # <<<<<<<<<<<<<<
 * 
 *     fill_contig_strides_array(&tmpslice.shape[0], &tmpslice.strides[0], itemsize,
 */
    (__pyx_v_tmpslice->suboffsets[__pyx_v_i]) = -1L;
  }

  /* "View.MemoryView":1217
 *         tmpslice.suboffsets[i] = -1
 * 
 *     fill_contig_strides_array(&tmpslice.shape[0], &tmpslice.strides[0], itemsize,             # <<<<<<<<<<<<<<
 *                               ndim, order)
 * 
 */
  __pyx_fill_contig_strides_array((&(__pyx_v_tmpslice->shape[0])), (&(__pyx_v_tmpslice->strides[0])), __pyx_v_itemsize, __pyx_v_ndim, __pyx_v_order);

  /* "View.MemoryView":1221
 * 
 * 
 *     for i in range(ndim):             # <<<<<<<<<<<<<<
 *         if tmpslice.shape[i] == 1:
 *             tmpslice.strides[i] = 0
 */
  __pyx_t_3 = __pyx_v_ndim;
  for (__pyx_t_5 = 0; __pyx_t_5 < __pyx_t_3; __pyx_t_5+=1) {
    __pyx_v_i = __pyx_t_5;

    /* "View.MemoryView":1222
 * 
 *     for i in range(ndim):
 *         if tmpslice.shape[i] == 1:             # <<<<<<<<<<<<<<
 *             tmpslice.strides[i] = 0
 * 
 */
    __pyx_t_2 = (((__pyx_v_tmpslice->shape[__pyx_v_i]) == 1) != 0);
    if (__pyx_t_2) {

      /* "View.MemoryView":1223
 *     for i in range(ndim):
 *         if tmpslice.shape[i] == 1:
 *             tmpslice.strides[i] = 0             # <<<<<<<<<<<<<<
 * 
 *     if slice_is_contig(src[0], order, ndim):
 */
      (__pyx_v_tmpslice->strides[__pyx_v_i]) = 0;

      /* "View.MemoryView":1222
 * 
 *     for i in range(ndim):
 *         if tmpslice.shape[i] == 1:             # <<<<<<<<<<<<<<
 *             tmpslice.strides[i] = 0
 * 
 */
    }
  }

  /* "View.MemoryView":1225
 *             tmpslice.strides[i] = 0
 * 
 *     if slice_is_contig(src[0], order, ndim):             # <<<<<<<<<<<<<<
 *         memcpy(result, src.data, size)
 *     else:
 */
  __pyx_t_2 = (__pyx_memviewslice_is_contig((__pyx_v_src[0]), __pyx_v_order, __pyx_v_ndim) != 0);
  if (__pyx_t_2) {

    /* "View.MemoryView":1226
 * 
 *     if slice_is_contig(src[0], order, ndim):
 *         memcpy(result, src.data, size)             # <<<<<<<<<<<<<<
 *     else:
 *         copy_strided_to_strided(src, tmpslice, ndim, itemsize)
 */
    memcpy(__pyx_v_result, __pyx_v_src->data, __pyx_v_size);

    /* "View.MemoryView":1225
 *             tmpslice.strides[i] = 0
 * 
 *     if slice_is_contig(src[0], order, ndim):             # <<<<<<<<<<<<<<
 *         memcpy(result, src.data, size)
 *     else:
 */
    goto __pyx_L9;
  }

  /* "View.MemoryView":1228
 *         memcpy(result, src.data, size)
 *     else:
 *         copy_strided_to_strided(src, tmpslice, ndim, itemsize)             # <<<<<<<<<<<<<<
 * 
 *     return result
 */
  /*else*/ {
    copy_strided_to_strided(__pyx_v_src, __pyx_v_tmpslice, __pyx_v_ndim, __pyx_v_itemsize);
  }
  __pyx_L9:;

  /* "View.MemoryView":1230
 *         copy_strided_to_strided(src, tmpslice, ndim, itemsize)
 * 
 *     return result             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_r = __pyx_v_result;
  goto __pyx_L0;

  /* "View.MemoryView":1192
 * 
 * @cname('__pyx_memoryview_copy_data_to_temp')
 * cdef void *copy_data_to_temp(__Pyx_memviewslice *src,             # <<<<<<<<<<<<<<
 *                              __Pyx_memviewslice *tmpslice,
 *                              char order,
 */

  /* function exit code */
  __pyx_L1_error:;
  {
    #ifdef WITH_THREAD
    PyGILState_STATE __pyx_gilstate_save = PyGILState_Ensure();
    #endif
    __Pyx_AddTraceback("View.MemoryView.copy_data_to_temp", __pyx_clineno, __pyx_lineno, __pyx_filename);
    #ifdef WITH_THREAD
    PyGILState_Release(__pyx_gilstate_save);
    #endif
  }
  __pyx_r = NULL;
  __pyx_L0:;
  return __pyx_r;
}

/* "View.MemoryView":1235
 * 
 * @cname('__pyx_memoryview_err_extents')
 * cdef int _err_extents(int i, Py_ssize_t extent1,             # <<<<<<<<<<<<<<
 *                              Py_ssize_t extent2) except -1 with gil:
 *     raise ValueError("got differing extents in dimension %d (got %d and %d)" %
 */

static int __pyx_memoryview_err_extents(int __pyx_v_i, Py_ssize_t __pyx_v_extent1, Py_ssize_t __pyx_v_extent2) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  #ifdef WITH_THREAD
  PyGILState_STATE __pyx_gilstate_save = PyGILState_Ensure();
  #endif
  __Pyx_RefNannySetupContext("_err_extents", 0);

  /* "View.MemoryView":1238
 *                              Py_ssize_t extent2) except -1 with gil:
 *     raise ValueError("got differing extents in dimension %d (got %d and %d)" %
 *                                                         (i, extent1, extent2))             # <<<<<<<<<<<<<<
 * 
 * @cname('__pyx_memoryview_err_dim')
 */
  __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_i); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 1238, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = PyInt_FromSsize_t(__pyx_v_extent1); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 1238, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = PyInt_FromSsize_t(__pyx_v_extent2); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 1238, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = PyTuple_New(3); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 1238, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_GIVEREF(__pyx_t_1);
  PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_2);
  PyTuple_SET_ITEM(__pyx_t_4, 1, __pyx_t_2);
  __Pyx_GIVEREF(__pyx_t_3);
  PyTuple_SET_ITEM(__pyx_t_4, 2, __pyx_t_3);
  __pyx_t_1 = 0;
  __pyx_t_2 = 0;
  __pyx_t_3 = 0;

  /* "View.MemoryView":1237
 * cdef int _err_extents(int i, Py_ssize_t extent1,
 *                              Py_ssize_t extent2) except -1 with gil:
 *     raise ValueError("got differing extents in dimension %d (got %d and %d)" %             # <<<<<<<<<<<<<<
 *                                                         (i, extent1, extent2))
 * 
 */
  __pyx_t_3 = __Pyx_PyString_Format(__pyx_kp_s_got_differing_extents_in_dimensi, __pyx_t_4); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 1237, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = PyTuple_New(1); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 1237, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_GIVEREF(__pyx_t_3);
  PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_3);
  __pyx_t_3 = 0;
  __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_t_4, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 1237, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __Pyx_Raise(__pyx_t_3, 0, 0, 0);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __PYX_ERR(2, 1237, __pyx_L1_error)

  /* "View.MemoryView":1235
 * 
 * @cname('__pyx_memoryview_err_extents')
 * cdef int _err_extents(int i, Py_ssize_t extent1,             # <<<<<<<<<<<<<<
 *                              Py_ssize_t extent2) except -1 with gil:
 *     raise ValueError("got differing extents in dimension %d (got %d and %d)" %
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("View.MemoryView._err_extents", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __Pyx_RefNannyFinishContext();
  #ifdef WITH_THREAD
  PyGILState_Release(__pyx_gilstate_save);
  #endif
  return __pyx_r;
}

/* "View.MemoryView":1241
 * 
 * @cname('__pyx_memoryview_err_dim')
 * cdef int _err_dim(object error, char *msg, int dim) except -1 with gil:             # <<<<<<<<<<<<<<
 *     raise error(msg.decode('ascii') % dim)
 * 
 */

static int __pyx_memoryview_err_dim(PyObject *__pyx_v_error, char *__pyx_v_msg, int __pyx_v_dim) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  #ifdef WITH_THREAD
  PyGILState_STATE __pyx_gilstate_save = PyGILState_Ensure();
  #endif
  __Pyx_RefNannySetupContext("_err_dim", 0);
  __Pyx_INCREF(__pyx_v_error);

  /* "View.MemoryView":1242
 * @cname('__pyx_memoryview_err_dim')
 * cdef int _err_dim(object error, char *msg, int dim) except -1 with gil:
 *     raise error(msg.decode('ascii') % dim)             # <<<<<<<<<<<<<<
 * 
 * @cname('__pyx_memoryview_err')
 */
  __pyx_t_2 = __Pyx_decode_c_string(__pyx_v_msg, 0, strlen(__pyx_v_msg), NULL, NULL, PyUnicode_DecodeASCII); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 1242, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_dim); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 1242, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = PyUnicode_Format(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 1242, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_INCREF(__pyx_v_error);
  __pyx_t_3 = __pyx_v_error; __pyx_t_2 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
    }
  }
  if (!__pyx_t_2) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 1242, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else {
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_3)) {
      PyObject *__pyx_temp[2] = {__pyx_t_2, __pyx_t_4};
      __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 1242, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
      PyObject *__pyx_temp[2] = {__pyx_t_2, __pyx_t_4};
      __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 1242, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    } else
    #endif
    {
      __pyx_t_5 = PyTuple_New(1+1); if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 1242, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
      __Pyx_GIVEREF(__pyx_t_4);
      PyTuple_SET_ITEM(__pyx_t_5, 0+1, __pyx_t_4);
      __pyx_t_4 = 0;
      __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 1242, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    }
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_Raise(__pyx_t_1, 0, 0, 0);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __PYX_ERR(2, 1242, __pyx_L1_error)

  /* "View.MemoryView":1241
 * 
 * @cname('__pyx_memoryview_err_dim')
 * cdef int _err_dim(object error, char *msg, int dim) except -1 with gil:             # <<<<<<<<<<<<<<
 *     raise error(msg.decode('ascii') % dim)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("View.MemoryView._err_dim", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __Pyx_XDECREF(__pyx_v_error);
  __Pyx_RefNannyFinishContext();
  #ifdef WITH_THREAD
  PyGILState_Release(__pyx_gilstate_save);
  #endif
  return __pyx_r;
}

/* "View.MemoryView":1245
 * 
 * @cname('__pyx_memoryview_err')
 * cdef int _err(object error, char *msg) except -1 with gil:             # <<<<<<<<<<<<<<
 *     if msg != NULL:
 *         raise error(msg.decode('ascii'))
 */

static int __pyx_memoryview_err(PyObject *__pyx_v_error, char *__pyx_v_msg) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  #ifdef WITH_THREAD
  PyGILState_STATE __pyx_gilstate_save = PyGILState_Ensure();
  #endif
  __Pyx_RefNannySetupContext("_err", 0);
  __Pyx_INCREF(__pyx_v_error);

  /* "View.MemoryView":1246
 * @cname('__pyx_memoryview_err')
 * cdef int _err(object error, char *msg) except -1 with gil:
 *     if msg != NULL:             # <<<<<<<<<<<<<<
 *         raise error(msg.decode('ascii'))
 *     else:
 */
  __pyx_t_1 = ((__pyx_v_msg != NULL) != 0);
  if (__pyx_t_1) {

    /* "View.MemoryView":1247
 * cdef int _err(object error, char *msg) except -1 with gil:
 *     if msg != NULL:
 *         raise error(msg.decode('ascii'))             # <<<<<<<<<<<<<<
 *     else:
 *         raise error
 */
    __pyx_t_3 = __Pyx_decode_c_string(__pyx_v_msg, 0, strlen(__pyx_v_msg), NULL, NULL, PyUnicode_DecodeASCII); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 1247, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_INCREF(__pyx_v_error);
    __pyx_t_4 = __pyx_v_error; __pyx_t_5 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_4))) {
      __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_4);
      if (likely(__pyx_t_5)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
        __Pyx_INCREF(__pyx_t_5);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_4, function);
      }
    }
    if (!__pyx_t_5) {
      __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 1247, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_GOTREF(__pyx_t_2);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_4)) {
        PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_t_3};
        __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_4, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 1247, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_4)) {
        PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_t_3};
        __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_4, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 1247, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      } else
      #endif
      {
        __pyx_t_6 = PyTuple_New(1+1); if (unlikely(!__pyx_t_6)) __PYX_ERR(2, 1247, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_5); __pyx_t_5 = NULL;
        __Pyx_GIVEREF(__pyx_t_3);
        PyTuple_SET_ITEM(__pyx_t_6, 0+1, __pyx_t_3);
        __pyx_t_3 = 0;
        __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_4, __pyx_t_6, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 1247, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(2, 1247, __pyx_L1_error)

    /* "View.MemoryView":1246
 * @cname('__pyx_memoryview_err')
 * cdef int _err(object error, char *msg) except -1 with gil:
 *     if msg != NULL:             # <<<<<<<<<<<<<<
 *         raise error(msg.decode('ascii'))
 *     else:
 */
  }

  /* "View.MemoryView":1249
 *         raise error(msg.decode('ascii'))
 *     else:
 *         raise error             # <<<<<<<<<<<<<<
 * 
 * @cname('__pyx_memoryview_copy_contents')
 */
  /*else*/ {
    __Pyx_Raise(__pyx_v_error, 0, 0, 0);
    __PYX_ERR(2, 1249, __pyx_L1_error)
  }

  /* "View.MemoryView":1245
 * 
 * @cname('__pyx_memoryview_err')
 * cdef int _err(object error, char *msg) except -1 with gil:             # <<<<<<<<<<<<<<
 *     if msg != NULL:
 *         raise error(msg.decode('ascii'))
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("View.MemoryView._err", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __Pyx_XDECREF(__pyx_v_error);
  __Pyx_RefNannyFinishContext();
  #ifdef WITH_THREAD
  PyGILState_Release(__pyx_gilstate_save);
  #endif
  return __pyx_r;
}

/* "View.MemoryView":1252
 * 
 * @cname('__pyx_memoryview_copy_contents')
 * cdef int memoryview_copy_contents(__Pyx_memviewslice src,             # <<<<<<<<<<<<<<
 *                                   __Pyx_memviewslice dst,
 *                                   int src_ndim, int dst_ndim,
 */

static int __pyx_memoryview_copy_contents(__Pyx_memviewslice __pyx_v_src, __Pyx_memviewslice __pyx_v_dst, int __pyx_v_src_ndim, int __pyx_v_dst_ndim, int __pyx_v_dtype_is_object) {
  void *__pyx_v_tmpdata;
  size_t __pyx_v_itemsize;
  int __pyx_v_i;
  char __pyx_v_order;
  int __pyx_v_broadcasting;
  int __pyx_v_direct_copy;
  __Pyx_memviewslice __pyx_v_tmp;
  int __pyx_v_ndim;
  int __pyx_r;
  Py_ssize_t __pyx_t_1;
  int __pyx_t_2;
  int __pyx_t_3;
  int __pyx_t_4;
  int __pyx_t_5;
  void *__pyx_t_6;
  int __pyx_t_7;

  /* "View.MemoryView":1260
 *     Check for overlapping memory and verify the shapes.
 *     """
 *     cdef void *tmpdata = NULL             # <<<<<<<<<<<<<<
 *     cdef size_t itemsize = src.memview.view.itemsize
 *     cdef int i
 */
  __pyx_v_tmpdata = NULL;

  /* "View.MemoryView":1261
 *     """
 *     cdef void *tmpdata = NULL
 *     cdef size_t itemsize = src.memview.view.itemsize             # <<<<<<<<<<<<<<
 *     cdef int i
 *     cdef char order = get_best_order(&src, src_ndim)
 */
  __pyx_t_1 = __pyx_v_src.memview->view.itemsize;
  __pyx_v_itemsize = __pyx_t_1;

  /* "View.MemoryView":1263
 *     cdef size_t itemsize = src.memview.view.itemsize
 *     cdef int i
 *     cdef char order = get_best_order(&src, src_ndim)             # <<<<<<<<<<<<<<
 *     cdef bint broadcasting = False
 *     cdef bint direct_copy = False
 */
  __pyx_v_order = __pyx_get_best_slice_order((&__pyx_v_src), __pyx_v_src_ndim);

  /* "View.MemoryView":1264
 *     cdef int i
 *     cdef char order = get_best_order(&src, src_ndim)
 *     cdef bint broadcasting = False             # <<<<<<<<<<<<<<
 *     cdef bint direct_copy = False
 *     cdef __Pyx_memviewslice tmp
 */
  __pyx_v_broadcasting = 0;

  /* "View.MemoryView":1265
 *     cdef char order = get_best_order(&src, src_ndim)
 *     cdef bint broadcasting = False
 *     cdef bint direct_copy = False             # <<<<<<<<<<<<<<
 *     cdef __Pyx_memviewslice tmp
 * 
 */
  __pyx_v_direct_copy = 0;

  /* "View.MemoryView":1268
 *     cdef __Pyx_memviewslice tmp
 * 
 *     if src_ndim < dst_ndim:             # <<<<<<<<<<<<<<
 *         broadcast_leading(&src, src_ndim, dst_ndim)
 *     elif dst_ndim < src_ndim:
 */
  __pyx_t_2 = ((__pyx_v_src_ndim < __pyx_v_dst_ndim) != 0);
  if (__pyx_t_2) {

    /* "View.MemoryView":1269
 * 
 *     if src_ndim < dst_ndim:
 *         broadcast_leading(&src, src_ndim, dst_ndim)             # <<<<<<<<<<<<<<
 *     elif dst_ndim < src_ndim:
 *         broadcast_leading(&dst, dst_ndim, src_ndim)
 */
    __pyx_memoryview_broadcast_leading((&__pyx_v_src), __pyx_v_src_ndim, __pyx_v_dst_ndim);

    /* "View.MemoryView":1268
 *     cdef __Pyx_memviewslice tmp
 * 
 *     if src_ndim < dst_ndim:             # <<<<<<<<<<<<<<
 *         broadcast_leading(&src, src_ndim, dst_ndim)
 *     elif dst_ndim < src_ndim:
 */
    goto __pyx_L3;
  }

  /* "View.MemoryView":1270
 *     if src_ndim < dst_ndim:
 *         broadcast_leading(&src, src_ndim, dst_ndim)
 *     elif dst_ndim < src_ndim:             # <<<<<<<<<<<<<<
 *         broadcast_leading(&dst, dst_ndim, src_ndim)
 * 
 */
  __pyx_t_2 = ((__pyx_v_dst_ndim < __pyx_v_src_ndim) != 0);
  if (__pyx_t_2) {

    /* "View.MemoryView":1271
 *         broadcast_leading(&src, src_ndim, dst_ndim)
 *     elif dst_ndim < src_ndim:
 *         broadcast_leading(&dst, dst_ndim, src_ndim)             # <<<<<<<<<<<<<<
 * 
 *     cdef int ndim = max(src_ndim, dst_ndim)
 */
    __pyx_memoryview_broadcast_leading((&__pyx_v_dst), __pyx_v_dst_ndim, __pyx_v_src_ndim);

    /* "View.MemoryView":1270
 *     if src_ndim < dst_ndim:
 *         broadcast_leading(&src, src_ndim, dst_ndim)
 *     elif dst_ndim < src_ndim:             # <<<<<<<<<<<<<<
 *         broadcast_leading(&dst, dst_ndim, src_ndim)
 * 
 */
  }
  __pyx_L3:;

  /* "View.MemoryView":1273
 *         broadcast_leading(&dst, dst_ndim, src_ndim)
 * 
 *     cdef int ndim = max(src_ndim, dst_ndim)             # <<<<<<<<<<<<<<
 * 
 *     for i in range(ndim):
 */
  __pyx_t_3 = __pyx_v_dst_ndim;
  __pyx_t_4 = __pyx_v_src_ndim;
  if (((__pyx_t_3 > __pyx_t_4) != 0)) {
    __pyx_t_5 = __pyx_t_3;
  } else {
    __pyx_t_5 = __pyx_t_4;
  }
  __pyx_v_ndim = __pyx_t_5;

  /* "View.MemoryView":1275
 *     cdef int ndim = max(src_ndim, dst_ndim)
 * 
 *     for i in range(ndim):             # <<<<<<<<<<<<<<
 *         if src.shape[i] != dst.shape[i]:
 *             if src.shape[i] == 1:
 */
  __pyx_t_5 = __pyx_v_ndim;
  for (__pyx_t_3 = 0; __pyx_t_3 < __pyx_t_5; __pyx_t_3+=1) {
    __pyx_v_i = __pyx_t_3;

    /* "View.MemoryView":1276
 * 
 *     for i in range(ndim):
 *         if src.shape[i] != dst.shape[i]:             # <<<<<<<<<<<<<<
 *             if src.shape[i] == 1:
 *                 broadcasting = True
 */
    __pyx_t_2 = (((__pyx_v_src.shape[__pyx_v_i]) != (__pyx_v_dst.shape[__pyx_v_i])) != 0);
    if (__pyx_t_2) {

      /* "View.MemoryView":1277
 *     for i in range(ndim):
 *         if src.shape[i] != dst.shape[i]:
 *             if src.shape[i] == 1:             # <<<<<<<<<<<<<<
 *                 broadcasting = True
 *                 src.strides[i] = 0
 */
      __pyx_t_2 = (((__pyx_v_src.shape[__pyx_v_i]) == 1) != 0);
      if (__pyx_t_2) {

        /* "View.MemoryView":1278
 *         if src.shape[i] != dst.shape[i]:
 *             if src.shape[i] == 1:
 *                 broadcasting = True             # <<<<<<<<<<<<<<
 *                 src.strides[i] = 0
 *             else:
 */
        __pyx_v_broadcasting = 1;

        /* "View.MemoryView":1279
 *             if src.shape[i] == 1:
 *                 broadcasting = True
 *                 src.strides[i] = 0             # <<<<<<<<<<<<<<
 *             else:
 *                 _err_extents(i, dst.shape[i], src.shape[i])
 */
        (__pyx_v_src.strides[__pyx_v_i]) = 0;

        /* "View.MemoryView":1277
 *     for i in range(ndim):
 *         if src.shape[i] != dst.shape[i]:
 *             if src.shape[i] == 1:             # <<<<<<<<<<<<<<
 *                 broadcasting = True
 *                 src.strides[i] = 0
 */
        goto __pyx_L7;
      }

      /* "View.MemoryView":1281
 *                 src.strides[i] = 0
 *             else:
 *                 _err_extents(i, dst.shape[i], src.shape[i])             # <<<<<<<<<<<<<<
 * 
 *         if src.suboffsets[i] >= 0:
 */
      /*else*/ {
        __pyx_t_4 = __pyx_memoryview_err_extents(__pyx_v_i, (__pyx_v_dst.shape[__pyx_v_i]), (__pyx_v_src.shape[__pyx_v_i])); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(2, 1281, __pyx_L1_error)
      }
      __pyx_L7:;

      /* "View.MemoryView":1276
 * 
 *     for i in range(ndim):
 *         if src.shape[i] != dst.shape[i]:             # <<<<<<<<<<<<<<
 *             if src.shape[i] == 1:
 *                 broadcasting = True
 */
    }

    /* "View.MemoryView":1283
 *                 _err_extents(i, dst.shape[i], src.shape[i])
 * 
 *         if src.suboffsets[i] >= 0:             # <<<<<<<<<<<<<<
 *             _err_dim(ValueError, "Dimension %d is not direct", i)
 * 
 */
    __pyx_t_2 = (((__pyx_v_src.suboffsets[__pyx_v_i]) >= 0) != 0);
    if (__pyx_t_2) {

      /* "View.MemoryView":1284
 * 
 *         if src.suboffsets[i] >= 0:
 *             _err_dim(ValueError, "Dimension %d is not direct", i)             # <<<<<<<<<<<<<<
 * 
 *     if slices_overlap(&src, &dst, ndim, itemsize):
 */
      __pyx_t_4 = __pyx_memoryview_err_dim(__pyx_builtin_ValueError, ((char *)"Dimension %d is not direct"), __pyx_v_i); if (unlikely(__pyx_t_4 == -1)) __PYX_ERR(2, 1284, __pyx_L1_error)

      /* "View.MemoryView":1283
 *                 _err_extents(i, dst.shape[i], src.shape[i])
 * 
 *         if src.suboffsets[i] >= 0:             # <<<<<<<<<<<<<<
 *             _err_dim(ValueError, "Dimension %d is not direct", i)
 * 
 */
    }
  }

  /* "View.MemoryView":1286
 *             _err_dim(ValueError, "Dimension %d is not direct", i)
 * 
 *     if slices_overlap(&src, &dst, ndim, itemsize):             # <<<<<<<<<<<<<<
 * 
 *         if not slice_is_contig(src, order, ndim):
 */
  __pyx_t_2 = (__pyx_slices_overlap((&__pyx_v_src), (&__pyx_v_dst), __pyx_v_ndim, __pyx_v_itemsize) != 0);
  if (__pyx_t_2) {

    /* "View.MemoryView":1288
 *     if slices_overlap(&src, &dst, ndim, itemsize):
 * 
 *         if not slice_is_contig(src, order, ndim):             # <<<<<<<<<<<<<<
 *             order = get_best_order(&dst, ndim)
 * 
 */
    __pyx_t_2 = ((!(__pyx_memviewslice_is_contig(__pyx_v_src, __pyx_v_order, __pyx_v_ndim) != 0)) != 0);
    if (__pyx_t_2) {

      /* "View.MemoryView":1289
 * 
 *         if not slice_is_contig(src, order, ndim):
 *             order = get_best_order(&dst, ndim)             # <<<<<<<<<<<<<<
 * 
 *         tmpdata = copy_data_to_temp(&src, &tmp, order, ndim)
 */
      __pyx_v_order = __pyx_get_best_slice_order((&__pyx_v_dst), __pyx_v_ndim);

      /* "View.MemoryView":1288
 *     if slices_overlap(&src, &dst, ndim, itemsize):
 * 
 *         if not slice_is_contig(src, order, ndim):             # <<<<<<<<<<<<<<
 *             order = get_best_order(&dst, ndim)
 * 
 */
    }

    /* "View.MemoryView":1291
 *             order = get_best_order(&dst, ndim)
 * 
 *         tmpdata = copy_data_to_temp(&src, &tmp, order, ndim)             # <<<<<<<<<<<<<<
 *         src = tmp
 * 
 */
    __pyx_t_6 = __pyx_memoryview_copy_data_to_temp((&__pyx_v_src), (&__pyx_v_tmp), __pyx_v_order, __pyx_v_ndim); if (unlikely(__pyx_t_6 == NULL)) __PYX_ERR(2, 1291, __pyx_L1_error)
    __pyx_v_tmpdata = __pyx_t_6;

    /* "View.MemoryView":1292
 * 
 *         tmpdata = copy_data_to_temp(&src, &tmp, order, ndim)
 *         src = tmp             # <<<<<<<<<<<<<<
 * 
 *     if not broadcasting:
 */
    __pyx_v_src = __pyx_v_tmp;

    /* "View.MemoryView":1286
 *             _err_dim(ValueError, "Dimension %d is not direct", i)
 * 
 *     if slices_overlap(&src, &dst, ndim, itemsize):             # <<<<<<<<<<<<<<
 * 
 *         if not slice_is_contig(src, order, ndim):
 */
  }

  /* "View.MemoryView":1294
 *         src = tmp
 * 
 *     if not broadcasting:             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_2 = ((!(__pyx_v_broadcasting != 0)) != 0);
  if (__pyx_t_2) {

    /* "View.MemoryView":1297
 * 
 * 
 *         if slice_is_contig(src, 'C', ndim):             # <<<<<<<<<<<<<<
 *             direct_copy = slice_is_contig(dst, 'C', ndim)
 *         elif slice_is_contig(src, 'F', ndim):
 */
    __pyx_t_2 = (__pyx_memviewslice_is_contig(__pyx_v_src, 'C', __pyx_v_ndim) != 0);
    if (__pyx_t_2) {

      /* "View.MemoryView":1298
 * 
 *         if slice_is_contig(src, 'C', ndim):
 *             direct_copy = slice_is_contig(dst, 'C', ndim)             # <<<<<<<<<<<<<<
 *         elif slice_is_contig(src, 'F', ndim):
 *             direct_copy = slice_is_contig(dst, 'F', ndim)
 */
      __pyx_v_direct_copy = __pyx_memviewslice_is_contig(__pyx_v_dst, 'C', __pyx_v_ndim);

      /* "View.MemoryView":1297
 * 
 * 
 *         if slice_is_contig(src, 'C', ndim):             # <<<<<<<<<<<<<<
 *             direct_copy = slice_is_contig(dst, 'C', ndim)
 *         elif slice_is_contig(src, 'F', ndim):
 */
      goto __pyx_L12;
    }

    /* "View.MemoryView":1299
 *         if slice_is_contig(src, 'C', ndim):
 *             direct_copy = slice_is_contig(dst, 'C', ndim)
 *         elif slice_is_contig(src, 'F', ndim):             # <<<<<<<<<<<<<<
 *             direct_copy = slice_is_contig(dst, 'F', ndim)
 * 
 */
    __pyx_t_2 = (__pyx_memviewslice_is_contig(__pyx_v_src, 'F', __pyx_v_ndim) != 0);
    if (__pyx_t_2) {

      /* "View.MemoryView":1300
 *             direct_copy = slice_is_contig(dst, 'C', ndim)
 *         elif slice_is_contig(src, 'F', ndim):
 *             direct_copy = slice_is_contig(dst, 'F', ndim)             # <<<<<<<<<<<<<<
 * 
 *         if direct_copy:
 */
      __pyx_v_direct_copy = __pyx_memviewslice_is_contig(__pyx_v_dst, 'F', __pyx_v_ndim);

      /* "View.MemoryView":1299
 *         if slice_is_contig(src, 'C', ndim):
 *             direct_copy = slice_is_contig(dst, 'C', ndim)
 *         elif slice_is_contig(src, 'F', ndim):             # <<<<<<<<<<<<<<
 *             direct_copy = slice_is_contig(dst, 'F', ndim)
 * 
 */
    }
    __pyx_L12:;

    /* "View.MemoryView":1302
 *             direct_copy = slice_is_contig(dst, 'F', ndim)
 * 
 *         if direct_copy:             # <<<<<<<<<<<<<<
 * 
 *             refcount_copying(&dst, dtype_is_object, ndim, False)
 */
    __pyx_t_2 = (__pyx_v_direct_copy != 0);
    if (__pyx_t_2) {

      /* "View.MemoryView":1304
 *         if direct_copy:
 * 
 *             refcount_copying(&dst, dtype_is_object, ndim, False)             # <<<<<<<<<<<<<<
 *             memcpy(dst.data, src.data, slice_get_size(&src, ndim))
 *             refcount_copying(&dst, dtype_is_object, ndim, True)
 */
      __pyx_memoryview_refcount_copying((&__pyx_v_dst), __pyx_v_dtype_is_object, __pyx_v_ndim, 0);

      /* "View.MemoryView":1305
 * 
 *             refcount_copying(&dst, dtype_is_object, ndim, False)
 *             memcpy(dst.data, src.data, slice_get_size(&src, ndim))             # <<<<<<<<<<<<<<
 *             refcount_copying(&dst, dtype_is_object, ndim, True)
 *             free(tmpdata)
 */
      memcpy(__pyx_v_dst.data, __pyx_v_src.data, __pyx_memoryview_slice_get_size((&__pyx_v_src), __pyx_v_ndim));

      /* "View.MemoryView":1306
 *             refcount_copying(&dst, dtype_is_object, ndim, False)
 *             memcpy(dst.data, src.data, slice_get_size(&src, ndim))
 *             refcount_copying(&dst, dtype_is_object, ndim, True)             # <<<<<<<<<<<<<<
 *             free(tmpdata)
 *             return 0
 */
      __pyx_memoryview_refcount_copying((&__pyx_v_dst), __pyx_v_dtype_is_object, __pyx_v_ndim, 1);

      /* "View.MemoryView":1307
 *             memcpy(dst.data, src.data, slice_get_size(&src, ndim))
 *             refcount_copying(&dst, dtype_is_object, ndim, True)
 *             free(tmpdata)             # <<<<<<<<<<<<<<
 *             return 0
 * 
 */
      free(__pyx_v_tmpdata);

      /* "View.MemoryView":1308
 *             refcount_copying(&dst, dtype_is_object, ndim, True)
 *             free(tmpdata)
 *             return 0             # <<<<<<<<<<<<<<
 * 
 *     if order == 'F' == get_best_order(&dst, ndim):
 */
      __pyx_r = 0;
      goto __pyx_L0;

      /* "View.MemoryView":1302
 *             direct_copy = slice_is_contig(dst, 'F', ndim)
 * 
 *         if direct_copy:             # <<<<<<<<<<<<<<
 * 
 *             refcount_copying(&dst, dtype_is_object, ndim, False)
 */
    }

    /* "View.MemoryView":1294
 *         src = tmp
 * 
 *     if not broadcasting:             # <<<<<<<<<<<<<<
 * 
 * 
 */
  }

  /* "View.MemoryView":1310
 *             return 0
 * 
 *     if order == 'F' == get_best_order(&dst, ndim):             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_2 = (__pyx_v_order == 'F');
  if (__pyx_t_2) {
    __pyx_t_2 = ('F' == __pyx_get_best_slice_order((&__pyx_v_dst), __pyx_v_ndim));
  }
  __pyx_t_7 = (__pyx_t_2 != 0);
  if (__pyx_t_7) {

    /* "View.MemoryView":1313
 * 
 * 
 *         transpose_memslice(&src)             # <<<<<<<<<<<<<<
 *         transpose_memslice(&dst)
 * 
 */
    __pyx_t_5 = __pyx_memslice_transpose((&__pyx_v_src)); if (unlikely(__pyx_t_5 == 0)) __PYX_ERR(2, 1313, __pyx_L1_error)

    /* "View.MemoryView":1314
 * 
 *         transpose_memslice(&src)
 *         transpose_memslice(&dst)             # <<<<<<<<<<<<<<
 * 
 *     refcount_copying(&dst, dtype_is_object, ndim, False)
 */
    __pyx_t_5 = __pyx_memslice_transpose((&__pyx_v_dst)); if (unlikely(__pyx_t_5 == 0)) __PYX_ERR(2, 1314, __pyx_L1_error)

    /* "View.MemoryView":1310
 *             return 0
 * 
 *     if order == 'F' == get_best_order(&dst, ndim):             # <<<<<<<<<<<<<<
 * 
 * 
 */
  }

  /* "View.MemoryView":1316
 *         transpose_memslice(&dst)
 * 
 *     refcount_copying(&dst, dtype_is_object, ndim, False)             # <<<<<<<<<<<<<<
 *     copy_strided_to_strided(&src, &dst, ndim, itemsize)
 *     refcount_copying(&dst, dtype_is_object, ndim, True)
 */
  __pyx_memoryview_refcount_copying((&__pyx_v_dst), __pyx_v_dtype_is_object, __pyx_v_ndim, 0);

  /* "View.MemoryView":1317
 * 
 *     refcount_copying(&dst, dtype_is_object, ndim, False)
 *     copy_strided_to_strided(&src, &dst, ndim, itemsize)             # <<<<<<<<<<<<<<
 *     refcount_copying(&dst, dtype_is_object, ndim, True)
 * 
 */
  copy_strided_to_strided((&__pyx_v_src), (&__pyx_v_dst), __pyx_v_ndim, __pyx_v_itemsize);

  /* "View.MemoryView":1318
 *     refcount_copying(&dst, dtype_is_object, ndim, False)
 *     copy_strided_to_strided(&src, &dst, ndim, itemsize)
 *     refcount_copying(&dst, dtype_is_object, ndim, True)             # <<<<<<<<<<<<<<
 * 
 *     free(tmpdata)
 */
  __pyx_memoryview_refcount_copying((&__pyx_v_dst), __pyx_v_dtype_is_object, __pyx_v_ndim, 1);

  /* "View.MemoryView":1320
 *     refcount_copying(&dst, dtype_is_object, ndim, True)
 * 
 *     free(tmpdata)             # <<<<<<<<<<<<<<
 *     return 0
 * 
 */
  free(__pyx_v_tmpdata);

  /* "View.MemoryView":1321
 * 
 *     free(tmpdata)
 *     return 0             # <<<<<<<<<<<<<<
 * 
 * @cname('__pyx_memoryview_broadcast_leading')
 */
  __pyx_r = 0;
  goto __pyx_L0;

  /* "View.MemoryView":1252
 * 
 * @cname('__pyx_memoryview_copy_contents')
 * cdef int memoryview_copy_contents(__Pyx_memviewslice src,             # <<<<<<<<<<<<<<
 *                                   __Pyx_memviewslice dst,
 *                                   int src_ndim, int dst_ndim,
 */

  /* function exit code */
  __pyx_L1_error:;
  {
    #ifdef WITH_THREAD
    PyGILState_STATE __pyx_gilstate_save = PyGILState_Ensure();
    #endif
    __Pyx_AddTraceback("View.MemoryView.memoryview_copy_contents", __pyx_clineno, __pyx_lineno, __pyx_filename);
    #ifdef WITH_THREAD
    PyGILState_Release(__pyx_gilstate_save);
    #endif
  }
  __pyx_r = -1;
  __pyx_L0:;
  return __pyx_r;
}

/* "View.MemoryView":1324
 * 
 * @cname('__pyx_memoryview_broadcast_leading')
 * cdef void broadcast_leading(__Pyx_memviewslice *mslice,             # <<<<<<<<<<<<<<
 *                             int ndim,
 *                             int ndim_other) nogil:
 */

static void __pyx_memoryview_broadcast_leading(__Pyx_memviewslice *__pyx_v_mslice, int __pyx_v_ndim, int __pyx_v_ndim_other) {
  int __pyx_v_i;
  int __pyx_v_offset;
  int __pyx_t_1;
  int __pyx_t_2;

  /* "View.MemoryView":1328
 *                             int ndim_other) nogil:
 *     cdef int i
 *     cdef int offset = ndim_other - ndim             # <<<<<<<<<<<<<<
 * 
 *     for i in range(ndim - 1, -1, -1):
 */
  __pyx_v_offset = (__pyx_v_ndim_other - __pyx_v_ndim);

  /* "View.MemoryView":1330
 *     cdef int offset = ndim_other - ndim
 * 
 *     for i in range(ndim - 1, -1, -1):             # <<<<<<<<<<<<<<
 *         mslice.shape[i + offset] = mslice.shape[i]
 *         mslice.strides[i + offset] = mslice.strides[i]
 */
  for (__pyx_t_1 = (__pyx_v_ndim - 1); __pyx_t_1 > -1L; __pyx_t_1-=1) {
    __pyx_v_i = __pyx_t_1;

    /* "View.MemoryView":1331
 * 
 *     for i in range(ndim - 1, -1, -1):
 *         mslice.shape[i + offset] = mslice.shape[i]             # <<<<<<<<<<<<<<
 *         mslice.strides[i + offset] = mslice.strides[i]
 *         mslice.suboffsets[i + offset] = mslice.suboffsets[i]
 */
    (__pyx_v_mslice->shape[(__pyx_v_i + __pyx_v_offset)]) = (__pyx_v_mslice->shape[__pyx_v_i]);

    /* "View.MemoryView":1332
 *     for i in range(ndim - 1, -1, -1):
 *         mslice.shape[i + offset] = mslice.shape[i]
 *         mslice.strides[i + offset] = mslice.strides[i]             # <<<<<<<<<<<<<<
 *         mslice.suboffsets[i + offset] = mslice.suboffsets[i]
 * 
 */
    (__pyx_v_mslice->strides[(__pyx_v_i + __pyx_v_offset)]) = (__pyx_v_mslice->strides[__pyx_v_i]);

    /* "View.MemoryView":1333
 *         mslice.shape[i + offset] = mslice.shape[i]
 *         mslice.strides[i + offset] = mslice.strides[i]
 *         mslice.suboffsets[i + offset] = mslice.suboffsets[i]             # <<<<<<<<<<<<<<
 * 
 *     for i in range(offset):
 */
    (__pyx_v_mslice->suboffsets[(__pyx_v_i + __pyx_v_offset)]) = (__pyx_v_mslice->suboffsets[__pyx_v_i]);
  }

  /* "View.MemoryView":1335
 *         mslice.suboffsets[i + offset] = mslice.suboffsets[i]
 * 
 *     for i in range(offset):             # <<<<<<<<<<<<<<
 *         mslice.shape[i] = 1
 *         mslice.strides[i] = mslice.strides[0]
 */
  __pyx_t_1 = __pyx_v_offset;
  for (__pyx_t_2 = 0; __pyx_t_2 < __pyx_t_1; __pyx_t_2+=1) {
    __pyx_v_i = __pyx_t_2;

    /* "View.MemoryView":1336
 * 
 *     for i in range(offset):
 *         mslice.shape[i] = 1             # <<<<<<<<<<<<<<
 *         mslice.strides[i] = mslice.strides[0]
 *         mslice.suboffsets[i] = -1
 */
    (__pyx_v_mslice->shape[__pyx_v_i]) = 1;

    /* "View.MemoryView":1337
 *     for i in range(offset):
 *         mslice.shape[i] = 1
 *         mslice.strides[i] = mslice.strides[0]             # <<<<<<<<<<<<<<
 *         mslice.suboffsets[i] = -1
 * 
 */
    (__pyx_v_mslice->strides[__pyx_v_i]) = (__pyx_v_mslice->strides[0]);

    /* "View.MemoryView":1338
 *         mslice.shape[i] = 1
 *         mslice.strides[i] = mslice.strides[0]
 *         mslice.suboffsets[i] = -1             # <<<<<<<<<<<<<<
 * 
 * 
 */
    (__pyx_v_mslice->suboffsets[__pyx_v_i]) = -1L;
  }

  /* "View.MemoryView":1324
 * 
 * @cname('__pyx_memoryview_broadcast_leading')
 * cdef void broadcast_leading(__Pyx_memviewslice *mslice,             # <<<<<<<<<<<<<<
 *                             int ndim,
 *                             int ndim_other) nogil:
 */

  /* function exit code */
}

/* "View.MemoryView":1346
 * 
 * @cname('__pyx_memoryview_refcount_copying')
 * cdef void refcount_copying(__Pyx_memviewslice *dst, bint dtype_is_object,             # <<<<<<<<<<<<<<
 *                            int ndim, bint inc) nogil:
 * 
 */

static void __pyx_memoryview_refcount_copying(__Pyx_memviewslice *__pyx_v_dst, int __pyx_v_dtype_is_object, int __pyx_v_ndim, int __pyx_v_inc) {
  int __pyx_t_1;

  /* "View.MemoryView":1350
 * 
 * 
 *     if dtype_is_object:             # <<<<<<<<<<<<<<
 *         refcount_objects_in_slice_with_gil(dst.data, dst.shape,
 *                                            dst.strides, ndim, inc)
 */
  __pyx_t_1 = (__pyx_v_dtype_is_object != 0);
  if (__pyx_t_1) {

    /* "View.MemoryView":1351
 * 
 *     if dtype_is_object:
 *         refcount_objects_in_slice_with_gil(dst.data, dst.shape,             # <<<<<<<<<<<<<<
 *                                            dst.strides, ndim, inc)
 * 
 */
    __pyx_memoryview_refcount_objects_in_slice_with_gil(__pyx_v_dst->data, __pyx_v_dst->shape, __pyx_v_dst->strides, __pyx_v_ndim, __pyx_v_inc);

    /* "View.MemoryView":1350
 * 
 * 
 *     if dtype_is_object:             # <<<<<<<<<<<<<<
 *         refcount_objects_in_slice_with_gil(dst.data, dst.shape,
 *                                            dst.strides, ndim, inc)
 */
  }

  /* "View.MemoryView":1346
 * 
 * @cname('__pyx_memoryview_refcount_copying')
 * cdef void refcount_copying(__Pyx_memviewslice *dst, bint dtype_is_object,             # <<<<<<<<<<<<<<
 *                            int ndim, bint inc) nogil:
 * 
 */

  /* function exit code */
}

/* "View.MemoryView":1355
 * 
 * @cname('__pyx_memoryview_refcount_objects_in_slice_with_gil')
 * cdef void refcount_objects_in_slice_with_gil(char *data, Py_ssize_t *shape,             # <<<<<<<<<<<<<<
 *                                              Py_ssize_t *strides, int ndim,
 *                                              bint inc) with gil:
 */

static void __pyx_memoryview_refcount_objects_in_slice_with_gil(char *__pyx_v_data, Py_ssize_t *__pyx_v_shape, Py_ssize_t *__pyx_v_strides, int __pyx_v_ndim, int __pyx_v_inc) {
  __Pyx_RefNannyDeclarations
  #ifdef WITH_THREAD
  PyGILState_STATE __pyx_gilstate_save = PyGILState_Ensure();
  #endif
  __Pyx_RefNannySetupContext("refcount_objects_in_slice_with_gil", 0);

  /* "View.MemoryView":1358
 *                                              Py_ssize_t *strides, int ndim,
 *                                              bint inc) with gil:
 *     refcount_objects_in_slice(data, shape, strides, ndim, inc)             # <<<<<<<<<<<<<<
 * 
 * @cname('__pyx_memoryview_refcount_objects_in_slice')
 */
  __pyx_memoryview_refcount_objects_in_slice(__pyx_v_data, __pyx_v_shape, __pyx_v_strides, __pyx_v_ndim, __pyx_v_inc);

  /* "View.MemoryView":1355
 * 
 * @cname('__pyx_memoryview_refcount_objects_in_slice_with_gil')
 * cdef void refcount_objects_in_slice_with_gil(char *data, Py_ssize_t *shape,             # <<<<<<<<<<<<<<
 *                                              Py_ssize_t *strides, int ndim,
 *                                              bint inc) with gil:
 */

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  #ifdef WITH_THREAD
  PyGILState_Release(__pyx_gilstate_save);
  #endif
}

/* "View.MemoryView":1361
 * 
 * @cname('__pyx_memoryview_refcount_objects_in_slice')
 * cdef void refcount_objects_in_slice(char *data, Py_ssize_t *shape,             # <<<<<<<<<<<<<<
 *                                     Py_ssize_t *strides, int ndim, bint inc):
 *     cdef Py_ssize_t i
 */

static void __pyx_memoryview_refcount_objects_in_slice(char *__pyx_v_data, Py_ssize_t *__pyx_v_shape, Py_ssize_t *__pyx_v_strides, int __pyx_v_ndim, int __pyx_v_inc) {
  CYTHON_UNUSED Py_ssize_t __pyx_v_i;
  __Pyx_RefNannyDeclarations
  Py_ssize_t __pyx_t_1;
  Py_ssize_t __pyx_t_2;
  int __pyx_t_3;
  __Pyx_RefNannySetupContext("refcount_objects_in_slice", 0);

  /* "View.MemoryView":1365
 *     cdef Py_ssize_t i
 * 
 *     for i in range(shape[0]):             # <<<<<<<<<<<<<<
 *         if ndim == 1:
 *             if inc:
 */
  __pyx_t_1 = (__pyx_v_shape[0]);
  for (__pyx_t_2 = 0; __pyx_t_2 < __pyx_t_1; __pyx_t_2+=1) {
    __pyx_v_i = __pyx_t_2;

    /* "View.MemoryView":1366
 * 
 *     for i in range(shape[0]):
 *         if ndim == 1:             # <<<<<<<<<<<<<<
 *             if inc:
 *                 Py_INCREF((<PyObject **> data)[0])
 */
    __pyx_t_3 = ((__pyx_v_ndim == 1) != 0);
    if (__pyx_t_3) {

      /* "View.MemoryView":1367
 *     for i in range(shape[0]):
 *         if ndim == 1:
 *             if inc:             # <<<<<<<<<<<<<<
 *                 Py_INCREF((<PyObject **> data)[0])
 *             else:
 */
      __pyx_t_3 = (__pyx_v_inc != 0);
      if (__pyx_t_3) {

        /* "View.MemoryView":1368
 *         if ndim == 1:
 *             if inc:
 *                 Py_INCREF((<PyObject **> data)[0])             # <<<<<<<<<<<<<<
 *             else:
 *                 Py_DECREF((<PyObject **> data)[0])
 */
        Py_INCREF((((PyObject **)__pyx_v_data)[0]));

        /* "View.MemoryView":1367
 *     for i in range(shape[0]):
 *         if ndim == 1:
 *             if inc:             # <<<<<<<<<<<<<<
 *                 Py_INCREF((<PyObject **> data)[0])
 *             else:
 */
        goto __pyx_L6;
      }

      /* "View.MemoryView":1370
 *                 Py_INCREF((<PyObject **> data)[0])
 *             else:
 *                 Py_DECREF((<PyObject **> data)[0])             # <<<<<<<<<<<<<<
 *         else:
 *             refcount_objects_in_slice(data, shape + 1, strides + 1,
 */
      /*else*/ {
        Py_DECREF((((PyObject **)__pyx_v_data)[0]));
      }
      __pyx_L6:;

      /* "View.MemoryView":1366
 * 
 *     for i in range(shape[0]):
 *         if ndim == 1:             # <<<<<<<<<<<<<<
 *             if inc:
 *                 Py_INCREF((<PyObject **> data)[0])
 */
      goto __pyx_L5;
    }

    /* "View.MemoryView":1372
 *                 Py_DECREF((<PyObject **> data)[0])
 *         else:
 *             refcount_objects_in_slice(data, shape + 1, strides + 1,             # <<<<<<<<<<<<<<
 *                                       ndim - 1, inc)
 * 
 */
    /*else*/ {

      /* "View.MemoryView":1373
 *         else:
 *             refcount_objects_in_slice(data, shape + 1, strides + 1,
 *                                       ndim - 1, inc)             # <<<<<<<<<<<<<<
 * 
 *         data += strides[0]
 */
      __pyx_memoryview_refcount_objects_in_slice(__pyx_v_data, (__pyx_v_shape + 1), (__pyx_v_strides + 1), (__pyx_v_ndim - 1), __pyx_v_inc);
    }
    __pyx_L5:;

    /* "View.MemoryView":1375
 *                                       ndim - 1, inc)
 * 
 *         data += strides[0]             # <<<<<<<<<<<<<<
 * 
 * 
 */
    __pyx_v_data = (__pyx_v_data + (__pyx_v_strides[0]));
  }

  /* "View.MemoryView":1361
 * 
 * @cname('__pyx_memoryview_refcount_objects_in_slice')
 * cdef void refcount_objects_in_slice(char *data, Py_ssize_t *shape,             # <<<<<<<<<<<<<<
 *                                     Py_ssize_t *strides, int ndim, bint inc):
 *     cdef Py_ssize_t i
 */

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

/* "View.MemoryView":1381
 * 
 * @cname('__pyx_memoryview_slice_assign_scalar')
 * cdef void slice_assign_scalar(__Pyx_memviewslice *dst, int ndim,             # <<<<<<<<<<<<<<
 *                               size_t itemsize, void *item,
 *                               bint dtype_is_object) nogil:
 */

static void __pyx_memoryview_slice_assign_scalar(__Pyx_memviewslice *__pyx_v_dst, int __pyx_v_ndim, size_t __pyx_v_itemsize, void *__pyx_v_item, int __pyx_v_dtype_is_object) {

  /* "View.MemoryView":1384
 *                               size_t itemsize, void *item,
 *                               bint dtype_is_object) nogil:
 *     refcount_copying(dst, dtype_is_object, ndim, False)             # <<<<<<<<<<<<<<
 *     _slice_assign_scalar(dst.data, dst.shape, dst.strides, ndim,
 *                          itemsize, item)
 */
  __pyx_memoryview_refcount_copying(__pyx_v_dst, __pyx_v_dtype_is_object, __pyx_v_ndim, 0);

  /* "View.MemoryView":1385
 *                               bint dtype_is_object) nogil:
 *     refcount_copying(dst, dtype_is_object, ndim, False)
 *     _slice_assign_scalar(dst.data, dst.shape, dst.strides, ndim,             # <<<<<<<<<<<<<<
 *                          itemsize, item)
 *     refcount_copying(dst, dtype_is_object, ndim, True)
 */
  __pyx_memoryview__slice_assign_scalar(__pyx_v_dst->data, __pyx_v_dst->shape, __pyx_v_dst->strides, __pyx_v_ndim, __pyx_v_itemsize, __pyx_v_item);

  /* "View.MemoryView":1387
 *     _slice_assign_scalar(dst.data, dst.shape, dst.strides, ndim,
 *                          itemsize, item)
 *     refcount_copying(dst, dtype_is_object, ndim, True)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_memoryview_refcount_copying(__pyx_v_dst, __pyx_v_dtype_is_object, __pyx_v_ndim, 1);

  /* "View.MemoryView":1381
 * 
 * @cname('__pyx_memoryview_slice_assign_scalar')
 * cdef void slice_assign_scalar(__Pyx_memviewslice *dst, int ndim,             # <<<<<<<<<<<<<<
 *                               size_t itemsize, void *item,
 *                               bint dtype_is_object) nogil:
 */

  /* function exit code */
}

/* "View.MemoryView":1391
 * 
 * @cname('__pyx_memoryview__slice_assign_scalar')
 * cdef void _slice_assign_scalar(char *data, Py_ssize_t *shape,             # <<<<<<<<<<<<<<
 *                               Py_ssize_t *strides, int ndim,
 *                               size_t itemsize, void *item) nogil:
 */

static void __pyx_memoryview__slice_assign_scalar(char *__pyx_v_data, Py_ssize_t *__pyx_v_shape, Py_ssize_t *__pyx_v_strides, int __pyx_v_ndim, size_t __pyx_v_itemsize, void *__pyx_v_item) {
  CYTHON_UNUSED Py_ssize_t __pyx_v_i;
  Py_ssize_t __pyx_v_stride;
  Py_ssize_t __pyx_v_extent;
  int __pyx_t_1;
  Py_ssize_t __pyx_t_2;
  Py_ssize_t __pyx_t_3;

  /* "View.MemoryView":1395
 *                               size_t itemsize, void *item) nogil:
 *     cdef Py_ssize_t i
 *     cdef Py_ssize_t stride = strides[0]             # <<<<<<<<<<<<<<
 *     cdef Py_ssize_t extent = shape[0]
 * 
 */
  __pyx_v_stride = (__pyx_v_strides[0]);

  /* "View.MemoryView":1396
 *     cdef Py_ssize_t i
 *     cdef Py_ssize_t stride = strides[0]
 *     cdef Py_ssize_t extent = shape[0]             # <<<<<<<<<<<<<<
 * 
 *     if ndim == 1:
 */
  __pyx_v_extent = (__pyx_v_shape[0]);

  /* "View.MemoryView":1398
 *     cdef Py_ssize_t extent = shape[0]
 * 
 *     if ndim == 1:             # <<<<<<<<<<<<<<
 *         for i in range(extent):
 *             memcpy(data, item, itemsize)
 */
  __pyx_t_1 = ((__pyx_v_ndim == 1) != 0);
  if (__pyx_t_1) {

    /* "View.MemoryView":1399
 * 
 *     if ndim == 1:
 *         for i in range(extent):             # <<<<<<<<<<<<<<
 *             memcpy(data, item, itemsize)
 *             data += stride
 */
    __pyx_t_2 = __pyx_v_extent;
    for (__pyx_t_3 = 0; __pyx_t_3 < __pyx_t_2; __pyx_t_3+=1) {
      __pyx_v_i = __pyx_t_3;

      /* "View.MemoryView":1400
 *     if ndim == 1:
 *         for i in range(extent):
 *             memcpy(data, item, itemsize)             # <<<<<<<<<<<<<<
 *             data += stride
 *     else:
 */
      memcpy(__pyx_v_data, __pyx_v_item, __pyx_v_itemsize);

      /* "View.MemoryView":1401
 *         for i in range(extent):
 *             memcpy(data, item, itemsize)
 *             data += stride             # <<<<<<<<<<<<<<
 *     else:
 *         for i in range(extent):
 */
      __pyx_v_data = (__pyx_v_data + __pyx_v_stride);
    }

    /* "View.MemoryView":1398
 *     cdef Py_ssize_t extent = shape[0]
 * 
 *     if ndim == 1:             # <<<<<<<<<<<<<<
 *         for i in range(extent):
 *             memcpy(data, item, itemsize)
 */
    goto __pyx_L3;
  }

  /* "View.MemoryView":1403
 *             data += stride
 *     else:
 *         for i in range(extent):             # <<<<<<<<<<<<<<
 *             _slice_assign_scalar(data, shape + 1, strides + 1,
 *                                 ndim - 1, itemsize, item)
 */
  /*else*/ {
    __pyx_t_2 = __pyx_v_extent;
    for (__pyx_t_3 = 0; __pyx_t_3 < __pyx_t_2; __pyx_t_3+=1) {
      __pyx_v_i = __pyx_t_3;

      /* "View.MemoryView":1404
 *     else:
 *         for i in range(extent):
 *             _slice_assign_scalar(data, shape + 1, strides + 1,             # <<<<<<<<<<<<<<
 *                                 ndim - 1, itemsize, item)
 *             data += stride
 */
      __pyx_memoryview__slice_assign_scalar(__pyx_v_data, (__pyx_v_shape + 1), (__pyx_v_strides + 1), (__pyx_v_ndim - 1), __pyx_v_itemsize, __pyx_v_item);

      /* "View.MemoryView":1406
 *             _slice_assign_scalar(data, shape + 1, strides + 1,
 *                                 ndim - 1, itemsize, item)
 *             data += stride             # <<<<<<<<<<<<<<
 * 
 * 
 */
      __pyx_v_data = (__pyx_v_data + __pyx_v_stride);
    }
  }
  __pyx_L3:;

  /* "View.MemoryView":1391
 * 
 * @cname('__pyx_memoryview__slice_assign_scalar')
 * cdef void _slice_assign_scalar(char *data, Py_ssize_t *shape,             # <<<<<<<<<<<<<<
 *                               Py_ssize_t *strides, int ndim,
 *                               size_t itemsize, void *item) nogil:
 */

  /* function exit code */
}
static struct __pyx_vtabstruct_7PyTorch__LongTensor __pyx_vtable_7PyTorch__LongTensor;

static PyObject *__pyx_tp_new_7PyTorch__LongTensor(PyTypeObject *t, PyObject *a, PyObject *k) {
  struct __pyx_obj_7PyTorch__LongTensor *p;
  PyObject *o;
  if (likely((t->tp_flags & Py_TPFLAGS_IS_ABSTRACT) == 0)) {
    o = (*t->tp_alloc)(t, 0);
  } else {
    o = (PyObject *) PyBaseObject_Type.tp_new(t, __pyx_empty_tuple, 0);
  }
  if (unlikely(!o)) return 0;
  p = ((struct __pyx_obj_7PyTorch__LongTensor *)o);
  p->__pyx_vtab = __pyx_vtabptr_7PyTorch__LongTensor;
  if (unlikely(__pyx_pw_7PyTorch_11_LongTensor_1__cinit__(o, a, k) < 0)) goto bad;
  return o;
  bad:
  Py_DECREF(o); o = 0;
  return NULL;
}

static void __pyx_tp_dealloc_7PyTorch__LongTensor(PyObject *o) {
  #if PY_VERSION_HEX >= 0x030400a1
  if (unlikely(Py_TYPE(o)->tp_finalize) && (!PyType_IS_GC(Py_TYPE(o)) || !_PyGC_FINALIZED(o))) {
    if (PyObject_CallFinalizerFromDealloc(o)) return;
  }
  #endif
  {
    PyObject *etype, *eval, *etb;
    PyErr_Fetch(&etype, &eval, &etb);
    ++Py_REFCNT(o);
    __pyx_pw_7PyTorch_11_LongTensor_3__dealloc__(o);
    --Py_REFCNT(o);
    PyErr_Restore(etype, eval, etb);
  }
  (*Py_TYPE(o)->tp_free)(o);
}
static PyObject *__pyx_sq_item_7PyTorch__LongTensor(PyObject *o, Py_ssize_t i) {
  PyObject *r;
  PyObject *x = PyInt_FromSsize_t(i); if(!x) return 0;
  r = Py_TYPE(o)->tp_as_mapping->mp_subscript(o, x);
  Py_DECREF(x);
  return r;
}

static int __pyx_mp_ass_subscript_7PyTorch__LongTensor(PyObject *o, PyObject *i, PyObject *v) {
  if (v) {
    return __pyx_pw_7PyTorch_11_LongTensor_31__setitem__(o, i, v);
  }
  else {
    PyErr_Format(PyExc_NotImplementedError,
      "Subscript deletion not supported by %.200s", Py_TYPE(o)->tp_name);
    return -1;
  }
}

static PyObject *__pyx_getprop_7PyTorch_11_LongTensor_refCount(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_7PyTorch_11_LongTensor_8refCount_1__get__(o);
}

static PyMethodDef __pyx_methods_7PyTorch__LongTensor[] = {
  {"nElement", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_5nElement, METH_NOARGS, 0},
  {"asNumpyTensor", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_7asNumpyTensor, METH_NOARGS, 0},
  {"dims", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_9dims, METH_NOARGS, 0},
  {"set1d", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_11set1d, METH_VARARGS|METH_KEYWORDS, 0},
  {"set2d", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_13set2d, METH_VARARGS|METH_KEYWORDS, 0},
  {"get1d", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_15get1d, METH_O, 0},
  {"get2d", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_17get2d, METH_VARARGS|METH_KEYWORDS, 0},
  {"isContiguous", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_19isContiguous, METH_NOARGS, 0},
  {"max", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_21max, METH_NOARGS, 0},
  {"min", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_23min, METH_NOARGS, 0},
  {"as_string", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_27as_string, METH_VARARGS|METH_KEYWORDS, 0},
  {"fill", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_33fill, METH_O, 0},
  {"sum", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_35sum, METH_NOARGS, 0},
  {"abs", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_37abs, METH_NOARGS, 0},
  {"iabs", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_39iabs, METH_NOARGS, 0},
  {"size", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_41size, METH_NOARGS, 0},
  {"new", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_43new, METH_VARARGS|METH_KEYWORDS, 0},
  {"narrow", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_45narrow, METH_VARARGS|METH_KEYWORDS, 0},
  {"contiguous", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_47contiguous, METH_NOARGS, 0},
  {"resize1d", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_49resize1d, METH_O, 0},
  {"resize2d", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_51resize2d, METH_VARARGS|METH_KEYWORDS, 0},
  {"resize3d", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_53resize3d, METH_VARARGS|METH_KEYWORDS, 0},
  {"resize4d", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_55resize4d, METH_VARARGS|METH_KEYWORDS, 0},
  {"resizeAs", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_57resizeAs, METH_O, 0},
  {"resize", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_59resize, METH_O, 0},
  {"newWithStorage", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_61newWithStorage, METH_VARARGS|METH_KEYWORDS, 0},
  {"newWithStorage1d", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_63newWithStorage1d, METH_VARARGS|METH_KEYWORDS, 0},
  {"newWithStorage2d", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_65newWithStorage2d, METH_VARARGS|METH_KEYWORDS, 0},
  {"newWithStorage3d", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_67newWithStorage3d, METH_VARARGS|METH_KEYWORDS, 0},
  {"newWithStorage4d", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_69newWithStorage4d, METH_VARARGS|METH_KEYWORDS, 0},
  {"clone", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_71clone, METH_NOARGS, 0},
  {"storage", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_73storage, METH_NOARGS, 0},
  {"cmul", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_77cmul, METH_O, 0},
  {"eq", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_81eq, METH_O, 0},
  {"icmin", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_83icmin, METH_O, 0},
  {"icmax", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_85icmax, METH_O, 0},
  {"bernoulli", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_99bernoulli, METH_VARARGS|METH_KEYWORDS, 0},
  {"geometric", (PyCFunction)__pyx_pw_7PyTorch_11_LongTensor_101geometric, METH_VARARGS|METH_KEYWORDS, 0},
  {0, 0, 0, 0}
};

static struct PyGetSetDef __pyx_getsets_7PyTorch__LongTensor[] = {
  {(char *)"refCount", __pyx_getprop_7PyTorch_11_LongTensor_refCount, 0, (char *)0, 0},
  {0, 0, 0, 0, 0}
};

static PyNumberMethods __pyx_tp_as_number__LongTensor = {
  __pyx_pw_7PyTorch_11_LongTensor_75__add__, /*nb_add*/
  __pyx_pw_7PyTorch_11_LongTensor_79__sub__, /*nb_subtract*/
  __pyx_pw_7PyTorch_11_LongTensor_97__mul__, /*nb_multiply*/
  #if PY_MAJOR_VERSION < 3 || CYTHON_COMPILING_IN_PYPY
  0, /*nb_divide*/
  #endif
  0, /*nb_remainder*/
  0, /*nb_divmod*/
  0, /*nb_power*/
  0, /*nb_negative*/
  0, /*nb_positive*/
  0, /*nb_absolute*/
  0, /*nb_nonzero*/
  0, /*nb_invert*/
  0, /*nb_lshift*/
  0, /*nb_rshift*/
  0, /*nb_and*/
  0, /*nb_xor*/
  0, /*nb_or*/
  #if PY_MAJOR_VERSION < 3 || CYTHON_COMPILING_IN_PYPY
  0, /*nb_coerce*/
  #endif
  0, /*nb_int*/
  #if PY_MAJOR_VERSION < 3
  0, /*nb_long*/
  #else
  0, /*reserved*/
  #endif
  0, /*nb_float*/
  #if PY_MAJOR_VERSION < 3 || CYTHON_COMPILING_IN_PYPY
  0, /*nb_oct*/
  #endif
  #if PY_MAJOR_VERSION < 3 || CYTHON_COMPILING_IN_PYPY
  0, /*nb_hex*/
  #endif
  __pyx_pw_7PyTorch_11_LongTensor_91__iadd__, /*nb_inplace_add*/
  __pyx_pw_7PyTorch_11_LongTensor_93__isub__, /*nb_inplace_subtract*/
  __pyx_pw_7PyTorch_11_LongTensor_95__imul__, /*nb_inplace_multiply*/
  #if PY_MAJOR_VERSION < 3 || CYTHON_COMPILING_IN_PYPY
  0, /*nb_inplace_divide*/
  #endif
  0, /*nb_inplace_remainder*/
  0, /*nb_inplace_power*/
  0, /*nb_inplace_lshift*/
  0, /*nb_inplace_rshift*/
  0, /*nb_inplace_and*/
  0, /*nb_inplace_xor*/
  0, /*nb_inplace_or*/
  __pyx_pw_7PyTorch_11_LongTensor_87__floordiv__, /*nb_floor_divide*/
  0, /*nb_true_divide*/
  __pyx_pw_7PyTorch_11_LongTensor_89__ifloordiv__, /*nb_inplace_floor_divide*/
  0, /*nb_inplace_true_divide*/
  0, /*nb_index*/
  #if PY_VERSION_HEX >= 0x03050000
  0, /*nb_matrix_multiply*/
  #endif
  #if PY_VERSION_HEX >= 0x03050000
  0, /*nb_inplace_matrix_multiply*/
  #endif
};

static PySequenceMethods __pyx_tp_as_sequence__LongTensor = {
  0, /*sq_length*/
  0, /*sq_concat*/
  0, /*sq_repeat*/
  __pyx_sq_item_7PyTorch__LongTensor, /*sq_item*/
  0, /*sq_slice*/
  0, /*sq_ass_item*/
  0, /*sq_ass_slice*/
  0, /*sq_contains*/
  0, /*sq_inplace_concat*/
  0, /*sq_inplace_repeat*/
};

static PyMappingMethods __pyx_tp_as_mapping__LongTensor = {
  0, /*mp_length*/
  __pyx_pw_7PyTorch_11_LongTensor_29__getitem__, /*mp_subscript*/
  __pyx_mp_ass_subscript_7PyTorch__LongTensor, /*mp_ass_subscript*/
};

static PyTypeObject __pyx_type_7PyTorch__LongTensor = {
  PyVarObject_HEAD_INIT(0, 0)
  "PyTorch._LongTensor", /*tp_name*/
  sizeof(struct __pyx_obj_7PyTorch__LongTensor), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_7PyTorch__LongTensor, /*tp_dealloc*/
  0, /*tp_print*/
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  __pyx_pw_7PyTorch_11_LongTensor_25__repr__, /*tp_repr*/
  &__pyx_tp_as_number__LongTensor, /*tp_as_number*/
  &__pyx_tp_as_sequence__LongTensor, /*tp_as_sequence*/
  &__pyx_tp_as_mapping__LongTensor, /*tp_as_mapping*/
  0, /*tp_hash*/
  0, /*tp_call*/
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_BASETYPE, /*tp_flags*/
  0, /*tp_doc*/
  0, /*tp_traverse*/
  0, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  0, /*tp_iter*/
  0, /*tp_iternext*/
  __pyx_methods_7PyTorch__LongTensor, /*tp_methods*/
  0, /*tp_members*/
  __pyx_getsets_7PyTorch__LongTensor, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  0, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_7PyTorch__LongTensor, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
};
static struct __pyx_vtabstruct_7PyTorch__FloatTensor __pyx_vtable_7PyTorch__FloatTensor;

static PyObject *__pyx_tp_new_7PyTorch__FloatTensor(PyTypeObject *t, PyObject *a, PyObject *k) {
  struct __pyx_obj_7PyTorch__FloatTensor *p;
  PyObject *o;
  if (likely((t->tp_flags & Py_TPFLAGS_IS_ABSTRACT) == 0)) {
    o = (*t->tp_alloc)(t, 0);
  } else {
    o = (PyObject *) PyBaseObject_Type.tp_new(t, __pyx_empty_tuple, 0);
  }
  if (unlikely(!o)) return 0;
  p = ((struct __pyx_obj_7PyTorch__FloatTensor *)o);
  p->__pyx_vtab = __pyx_vtabptr_7PyTorch__FloatTensor;
  if (unlikely(__pyx_pw_7PyTorch_12_FloatTensor_1__cinit__(o, a, k) < 0)) goto bad;
  return o;
  bad:
  Py_DECREF(o); o = 0;
  return NULL;
}

static void __pyx_tp_dealloc_7PyTorch__FloatTensor(PyObject *o) {
  #if PY_VERSION_HEX >= 0x030400a1
  if (unlikely(Py_TYPE(o)->tp_finalize) && (!PyType_IS_GC(Py_TYPE(o)) || !_PyGC_FINALIZED(o))) {
    if (PyObject_CallFinalizerFromDealloc(o)) return;
  }
  #endif
  {
    PyObject *etype, *eval, *etb;
    PyErr_Fetch(&etype, &eval, &etb);
    ++Py_REFCNT(o);
    __pyx_pw_7PyTorch_12_FloatTensor_3__dealloc__(o);
    --Py_REFCNT(o);
    PyErr_Restore(etype, eval, etb);
  }
  (*Py_TYPE(o)->tp_free)(o);
}
static PyObject *__pyx_sq_item_7PyTorch__FloatTensor(PyObject *o, Py_ssize_t i) {
  PyObject *r;
  PyObject *x = PyInt_FromSsize_t(i); if(!x) return 0;
  r = Py_TYPE(o)->tp_as_mapping->mp_subscript(o, x);
  Py_DECREF(x);
  return r;
}

static int __pyx_mp_ass_subscript_7PyTorch__FloatTensor(PyObject *o, PyObject *i, PyObject *v) {
  if (v) {
    return __pyx_pw_7PyTorch_12_FloatTensor_31__setitem__(o, i, v);
  }
  else {
    PyErr_Format(PyExc_NotImplementedError,
      "Subscript deletion not supported by %.200s", Py_TYPE(o)->tp_name);
    return -1;
  }
}

static PyObject *__pyx_getprop_7PyTorch_12_FloatTensor_refCount(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_7PyTorch_12_FloatTensor_8refCount_1__get__(o);
}

static PyMethodDef __pyx_methods_7PyTorch__FloatTensor[] = {
  {"nElement", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_5nElement, METH_NOARGS, 0},
  {"asNumpyTensor", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_7asNumpyTensor, METH_NOARGS, 0},
  {"dims", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_9dims, METH_NOARGS, 0},
  {"set1d", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_11set1d, METH_VARARGS|METH_KEYWORDS, 0},
  {"set2d", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_13set2d, METH_VARARGS|METH_KEYWORDS, 0},
  {"get1d", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_15get1d, METH_O, 0},
  {"get2d", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_17get2d, METH_VARARGS|METH_KEYWORDS, 0},
  {"isContiguous", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_19isContiguous, METH_NOARGS, 0},
  {"max", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_21max, METH_NOARGS, 0},
  {"min", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_23min, METH_NOARGS, 0},
  {"as_string", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_27as_string, METH_VARARGS|METH_KEYWORDS, 0},
  {"fill", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_33fill, METH_O, 0},
  {"sum", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_35sum, METH_NOARGS, 0},
  {"itanh", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_37itanh, METH_NOARGS, 0},
  {"isigmoid", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_39isigmoid, METH_NOARGS, 0},
  {"icinv", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_41icinv, METH_NOARGS, 0},
  {"tanh", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_43tanh, METH_NOARGS, 0},
  {"sigmoid", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_45sigmoid, METH_NOARGS, 0},
  {"cinv", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_47cinv, METH_NOARGS, 0},
  {"neg", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_49neg, METH_NOARGS, 0},
  {"ineg", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_51ineg, METH_NOARGS, 0},
  {"abs", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_53abs, METH_NOARGS, 0},
  {"iabs", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_55iabs, METH_NOARGS, 0},
  {"size", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_57size, METH_NOARGS, 0},
  {"new", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_59new, METH_VARARGS|METH_KEYWORDS, 0},
  {"narrow", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_61narrow, METH_VARARGS|METH_KEYWORDS, 0},
  {"contiguous", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_63contiguous, METH_NOARGS, 0},
  {"resize1d", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_65resize1d, METH_O, 0},
  {"resize2d", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_67resize2d, METH_VARARGS|METH_KEYWORDS, 0},
  {"resize3d", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_69resize3d, METH_VARARGS|METH_KEYWORDS, 0},
  {"resize4d", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_71resize4d, METH_VARARGS|METH_KEYWORDS, 0},
  {"resizeAs", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_73resizeAs, METH_O, 0},
  {"resize", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_75resize, METH_O, 0},
  {"newWithStorage", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_77newWithStorage, METH_VARARGS|METH_KEYWORDS, 0},
  {"newWithStorage1d", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_79newWithStorage1d, METH_VARARGS|METH_KEYWORDS, 0},
  {"newWithStorage2d", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_81newWithStorage2d, METH_VARARGS|METH_KEYWORDS, 0},
  {"newWithStorage3d", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_83newWithStorage3d, METH_VARARGS|METH_KEYWORDS, 0},
  {"newWithStorage4d", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_85newWithStorage4d, METH_VARARGS|METH_KEYWORDS, 0},
  {"clone", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_87clone, METH_NOARGS, 0},
  {"storage", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_89storage, METH_NOARGS, 0},
  {"cmul", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_93cmul, METH_O, 0},
  {"eq", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_97eq, METH_O, 0},
  {"icmin", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_99icmin, METH_O, 0},
  {"icmax", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_101icmax, METH_O, 0},
  {"bernoulli", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_115bernoulli, METH_VARARGS|METH_KEYWORDS, 0},
  {"geometric", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_117geometric, METH_VARARGS|METH_KEYWORDS, 0},
  {"normal", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_119normal, METH_VARARGS|METH_KEYWORDS, 0},
  {"exponential", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_121exponential, METH_VARARGS|METH_KEYWORDS, 0},
  {"cauchy", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_123cauchy, METH_VARARGS|METH_KEYWORDS, 0},
  {"logNormal", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_125logNormal, METH_VARARGS|METH_KEYWORDS, 0},
  {"uniform", (PyCFunction)__pyx_pw_7PyTorch_12_FloatTensor_127uniform, METH_VARARGS|METH_KEYWORDS, 0},
  {0, 0, 0, 0}
};

static struct PyGetSetDef __pyx_getsets_7PyTorch__FloatTensor[] = {
  {(char *)"refCount", __pyx_getprop_7PyTorch_12_FloatTensor_refCount, 0, (char *)0, 0},
  {0, 0, 0, 0, 0}
};

static PyNumberMethods __pyx_tp_as_number__FloatTensor = {
  __pyx_pw_7PyTorch_12_FloatTensor_91__add__, /*nb_add*/
  __pyx_pw_7PyTorch_12_FloatTensor_95__sub__, /*nb_subtract*/
  __pyx_pw_7PyTorch_12_FloatTensor_113__mul__, /*nb_multiply*/
  #if PY_MAJOR_VERSION < 3 || CYTHON_COMPILING_IN_PYPY
  0, /*nb_divide*/
  #endif
  0, /*nb_remainder*/
  0, /*nb_divmod*/
  0, /*nb_power*/
  0, /*nb_negative*/
  0, /*nb_positive*/
  0, /*nb_absolute*/
  0, /*nb_nonzero*/
  0, /*nb_invert*/
  0, /*nb_lshift*/
  0, /*nb_rshift*/
  0, /*nb_and*/
  0, /*nb_xor*/
  0, /*nb_or*/
  #if PY_MAJOR_VERSION < 3 || CYTHON_COMPILING_IN_PYPY
  0, /*nb_coerce*/
  #endif
  0, /*nb_int*/
  #if PY_MAJOR_VERSION < 3
  0, /*nb_long*/
  #else
  0, /*reserved*/
  #endif
  0, /*nb_float*/
  #if PY_MAJOR_VERSION < 3 || CYTHON_COMPILING_IN_PYPY
  0, /*nb_oct*/
  #endif
  #if PY_MAJOR_VERSION < 3 || CYTHON_COMPILING_IN_PYPY
  0, /*nb_hex*/
  #endif
  __pyx_pw_7PyTorch_12_FloatTensor_107__iadd__, /*nb_inplace_add*/
  __pyx_pw_7PyTorch_12_FloatTensor_109__isub__, /*nb_inplace_subtract*/
  __pyx_pw_7PyTorch_12_FloatTensor_111__imul__, /*nb_inplace_multiply*/
  #if PY_MAJOR_VERSION < 3 || CYTHON_COMPILING_IN_PYPY
  0, /*nb_inplace_divide*/
  #endif
  0, /*nb_inplace_remainder*/
  0, /*nb_inplace_power*/
  0, /*nb_inplace_lshift*/
  0, /*nb_inplace_rshift*/
  0, /*nb_inplace_and*/
  0, /*nb_inplace_xor*/
  0, /*nb_inplace_or*/
  0, /*nb_floor_divide*/
  __pyx_pw_7PyTorch_12_FloatTensor_103__truediv__, /*nb_true_divide*/
  0, /*nb_inplace_floor_divide*/
  __pyx_pw_7PyTorch_12_FloatTensor_105__itruediv__, /*nb_inplace_true_divide*/
  0, /*nb_index*/
  #if PY_VERSION_HEX >= 0x03050000
  0, /*nb_matrix_multiply*/
  #endif
  #if PY_VERSION_HEX >= 0x03050000
  0, /*nb_inplace_matrix_multiply*/
  #endif
};

static PySequenceMethods __pyx_tp_as_sequence__FloatTensor = {
  0, /*sq_length*/
  0, /*sq_concat*/
  0, /*sq_repeat*/
  __pyx_sq_item_7PyTorch__FloatTensor, /*sq_item*/
  0, /*sq_slice*/
  0, /*sq_ass_item*/
  0, /*sq_ass_slice*/
  0, /*sq_contains*/
  0, /*sq_inplace_concat*/
  0, /*sq_inplace_repeat*/
};

static PyMappingMethods __pyx_tp_as_mapping__FloatTensor = {
  0, /*mp_length*/
  __pyx_pw_7PyTorch_12_FloatTensor_29__getitem__, /*mp_subscript*/
  __pyx_mp_ass_subscript_7PyTorch__FloatTensor, /*mp_ass_subscript*/
};

static PyTypeObject __pyx_type_7PyTorch__FloatTensor = {
  PyVarObject_HEAD_INIT(0, 0)
  "PyTorch._FloatTensor", /*tp_name*/
  sizeof(struct __pyx_obj_7PyTorch__FloatTensor), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_7PyTorch__FloatTensor, /*tp_dealloc*/
  0, /*tp_print*/
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  __pyx_pw_7PyTorch_12_FloatTensor_25__repr__, /*tp_repr*/
  &__pyx_tp_as_number__FloatTensor, /*tp_as_number*/
  &__pyx_tp_as_sequence__FloatTensor, /*tp_as_sequence*/
  &__pyx_tp_as_mapping__FloatTensor, /*tp_as_mapping*/
  0, /*tp_hash*/
  0, /*tp_call*/
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_BASETYPE, /*tp_flags*/
  0, /*tp_doc*/
  0, /*tp_traverse*/
  0, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  0, /*tp_iter*/
  0, /*tp_iternext*/
  __pyx_methods_7PyTorch__FloatTensor, /*tp_methods*/
  0, /*tp_members*/
  __pyx_getsets_7PyTorch__FloatTensor, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  0, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_7PyTorch__FloatTensor, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
};
static struct __pyx_vtabstruct_7PyTorch__DoubleTensor __pyx_vtable_7PyTorch__DoubleTensor;

static PyObject *__pyx_tp_new_7PyTorch__DoubleTensor(PyTypeObject *t, PyObject *a, PyObject *k) {
  struct __pyx_obj_7PyTorch__DoubleTensor *p;
  PyObject *o;
  if (likely((t->tp_flags & Py_TPFLAGS_IS_ABSTRACT) == 0)) {
    o = (*t->tp_alloc)(t, 0);
  } else {
    o = (PyObject *) PyBaseObject_Type.tp_new(t, __pyx_empty_tuple, 0);
  }
  if (unlikely(!o)) return 0;
  p = ((struct __pyx_obj_7PyTorch__DoubleTensor *)o);
  p->__pyx_vtab = __pyx_vtabptr_7PyTorch__DoubleTensor;
  if (unlikely(__pyx_pw_7PyTorch_13_DoubleTensor_1__cinit__(o, a, k) < 0)) goto bad;
  return o;
  bad:
  Py_DECREF(o); o = 0;
  return NULL;
}

static void __pyx_tp_dealloc_7PyTorch__DoubleTensor(PyObject *o) {
  #if PY_VERSION_HEX >= 0x030400a1
  if (unlikely(Py_TYPE(o)->tp_finalize) && (!PyType_IS_GC(Py_TYPE(o)) || !_PyGC_FINALIZED(o))) {
    if (PyObject_CallFinalizerFromDealloc(o)) return;
  }
  #endif
  {
    PyObject *etype, *eval, *etb;
    PyErr_Fetch(&etype, &eval, &etb);
    ++Py_REFCNT(o);
    __pyx_pw_7PyTorch_13_DoubleTensor_3__dealloc__(o);
    --Py_REFCNT(o);
    PyErr_Restore(etype, eval, etb);
  }
  (*Py_TYPE(o)->tp_free)(o);
}
static PyObject *__pyx_sq_item_7PyTorch__DoubleTensor(PyObject *o, Py_ssize_t i) {
  PyObject *r;
  PyObject *x = PyInt_FromSsize_t(i); if(!x) return 0;
  r = Py_TYPE(o)->tp_as_mapping->mp_subscript(o, x);
  Py_DECREF(x);
  return r;
}

static int __pyx_mp_ass_subscript_7PyTorch__DoubleTensor(PyObject *o, PyObject *i, PyObject *v) {
  if (v) {
    return __pyx_pw_7PyTorch_13_DoubleTensor_31__setitem__(o, i, v);
  }
  else {
    PyErr_Format(PyExc_NotImplementedError,
      "Subscript deletion not supported by %.200s", Py_TYPE(o)->tp_name);
    return -1;
  }
}

static PyObject *__pyx_getprop_7PyTorch_13_DoubleTensor_refCount(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_7PyTorch_13_DoubleTensor_8refCount_1__get__(o);
}

static PyMethodDef __pyx_methods_7PyTorch__DoubleTensor[] = {
  {"nElement", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_5nElement, METH_NOARGS, 0},
  {"asNumpyTensor", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_7asNumpyTensor, METH_NOARGS, 0},
  {"dims", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_9dims, METH_NOARGS, 0},
  {"set1d", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_11set1d, METH_VARARGS|METH_KEYWORDS, 0},
  {"set2d", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_13set2d, METH_VARARGS|METH_KEYWORDS, 0},
  {"get1d", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_15get1d, METH_O, 0},
  {"get2d", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_17get2d, METH_VARARGS|METH_KEYWORDS, 0},
  {"isContiguous", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_19isContiguous, METH_NOARGS, 0},
  {"max", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_21max, METH_NOARGS, 0},
  {"min", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_23min, METH_NOARGS, 0},
  {"as_string", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_27as_string, METH_VARARGS|METH_KEYWORDS, 0},
  {"fill", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_33fill, METH_O, 0},
  {"sum", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_35sum, METH_NOARGS, 0},
  {"itanh", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_37itanh, METH_NOARGS, 0},
  {"isigmoid", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_39isigmoid, METH_NOARGS, 0},
  {"icinv", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_41icinv, METH_NOARGS, 0},
  {"tanh", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_43tanh, METH_NOARGS, 0},
  {"sigmoid", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_45sigmoid, METH_NOARGS, 0},
  {"cinv", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_47cinv, METH_NOARGS, 0},
  {"neg", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_49neg, METH_NOARGS, 0},
  {"ineg", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_51ineg, METH_NOARGS, 0},
  {"abs", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_53abs, METH_NOARGS, 0},
  {"iabs", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_55iabs, METH_NOARGS, 0},
  {"size", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_57size, METH_NOARGS, 0},
  {"new", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_59new, METH_VARARGS|METH_KEYWORDS, 0},
  {"narrow", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_61narrow, METH_VARARGS|METH_KEYWORDS, 0},
  {"contiguous", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_63contiguous, METH_NOARGS, 0},
  {"resize1d", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_65resize1d, METH_O, 0},
  {"resize2d", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_67resize2d, METH_VARARGS|METH_KEYWORDS, 0},
  {"resize3d", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_69resize3d, METH_VARARGS|METH_KEYWORDS, 0},
  {"resize4d", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_71resize4d, METH_VARARGS|METH_KEYWORDS, 0},
  {"resizeAs", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_73resizeAs, METH_O, 0},
  {"resize", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_75resize, METH_O, 0},
  {"newWithStorage", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_77newWithStorage, METH_VARARGS|METH_KEYWORDS, 0},
  {"newWithStorage1d", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_79newWithStorage1d, METH_VARARGS|METH_KEYWORDS, 0},
  {"newWithStorage2d", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_81newWithStorage2d, METH_VARARGS|METH_KEYWORDS, 0},
  {"newWithStorage3d", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_83newWithStorage3d, METH_VARARGS|METH_KEYWORDS, 0},
  {"newWithStorage4d", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_85newWithStorage4d, METH_VARARGS|METH_KEYWORDS, 0},
  {"clone", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_87clone, METH_NOARGS, 0},
  {"storage", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_89storage, METH_NOARGS, 0},
  {"cmul", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_93cmul, METH_O, 0},
  {"eq", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_97eq, METH_O, 0},
  {"icmin", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_99icmin, METH_O, 0},
  {"icmax", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_101icmax, METH_O, 0},
  {"bernoulli", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_115bernoulli, METH_VARARGS|METH_KEYWORDS, 0},
  {"geometric", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_117geometric, METH_VARARGS|METH_KEYWORDS, 0},
  {"normal", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_119normal, METH_VARARGS|METH_KEYWORDS, 0},
  {"exponential", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_121exponential, METH_VARARGS|METH_KEYWORDS, 0},
  {"cauchy", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_123cauchy, METH_VARARGS|METH_KEYWORDS, 0},
  {"logNormal", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_125logNormal, METH_VARARGS|METH_KEYWORDS, 0},
  {"uniform", (PyCFunction)__pyx_pw_7PyTorch_13_DoubleTensor_127uniform, METH_VARARGS|METH_KEYWORDS, 0},
  {0, 0, 0, 0}
};

static struct PyGetSetDef __pyx_getsets_7PyTorch__DoubleTensor[] = {
  {(char *)"refCount", __pyx_getprop_7PyTorch_13_DoubleTensor_refCount, 0, (char *)0, 0},
  {0, 0, 0, 0, 0}
};

static PyNumberMethods __pyx_tp_as_number__DoubleTensor = {
  __pyx_pw_7PyTorch_13_DoubleTensor_91__add__, /*nb_add*/
  __pyx_pw_7PyTorch_13_DoubleTensor_95__sub__, /*nb_subtract*/
  __pyx_pw_7PyTorch_13_DoubleTensor_113__mul__, /*nb_multiply*/
  #if PY_MAJOR_VERSION < 3 || CYTHON_COMPILING_IN_PYPY
  0, /*nb_divide*/
  #endif
  0, /*nb_remainder*/
  0, /*nb_divmod*/
  0, /*nb_power*/
  0, /*nb_negative*/
  0, /*nb_positive*/
  0, /*nb_absolute*/
  0, /*nb_nonzero*/
  0, /*nb_invert*/
  0, /*nb_lshift*/
  0, /*nb_rshift*/
  0, /*nb_and*/
  0, /*nb_xor*/
  0, /*nb_or*/
  #if PY_MAJOR_VERSION < 3 || CYTHON_COMPILING_IN_PYPY
  0, /*nb_coerce*/
  #endif
  0, /*nb_int*/
  #if PY_MAJOR_VERSION < 3
  0, /*nb_long*/
  #else
  0, /*reserved*/
  #endif
  0, /*nb_float*/
  #if PY_MAJOR_VERSION < 3 || CYTHON_COMPILING_IN_PYPY
  0, /*nb_oct*/
  #endif
  #if PY_MAJOR_VERSION < 3 || CYTHON_COMPILING_IN_PYPY
  0, /*nb_hex*/
  #endif
  __pyx_pw_7PyTorch_13_DoubleTensor_107__iadd__, /*nb_inplace_add*/
  __pyx_pw_7PyTorch_13_DoubleTensor_109__isub__, /*nb_inplace_subtract*/
  __pyx_pw_7PyTorch_13_DoubleTensor_111__imul__, /*nb_inplace_multiply*/
  #if PY_MAJOR_VERSION < 3 || CYTHON_COMPILING_IN_PYPY
  0, /*nb_inplace_divide*/
  #endif
  0, /*nb_inplace_remainder*/
  0, /*nb_inplace_power*/
  0, /*nb_inplace_lshift*/
  0, /*nb_inplace_rshift*/
  0, /*nb_inplace_and*/
  0, /*nb_inplace_xor*/
  0, /*nb_inplace_or*/
  0, /*nb_floor_divide*/
  __pyx_pw_7PyTorch_13_DoubleTensor_103__truediv__, /*nb_true_divide*/
  0, /*nb_inplace_floor_divide*/
  __pyx_pw_7PyTorch_13_DoubleTensor_105__itruediv__, /*nb_inplace_true_divide*/
  0, /*nb_index*/
  #if PY_VERSION_HEX >= 0x03050000
  0, /*nb_matrix_multiply*/
  #endif
  #if PY_VERSION_HEX >= 0x03050000
  0, /*nb_inplace_matrix_multiply*/
  #endif
};

static PySequenceMethods __pyx_tp_as_sequence__DoubleTensor = {
  0, /*sq_length*/
  0, /*sq_concat*/
  0, /*sq_repeat*/
  __pyx_sq_item_7PyTorch__DoubleTensor, /*sq_item*/
  0, /*sq_slice*/
  0, /*sq_ass_item*/
  0, /*sq_ass_slice*/
  0, /*sq_contains*/
  0, /*sq_inplace_concat*/
  0, /*sq_inplace_repeat*/
};

static PyMappingMethods __pyx_tp_as_mapping__DoubleTensor = {
  0, /*mp_length*/
  __pyx_pw_7PyTorch_13_DoubleTensor_29__getitem__, /*mp_subscript*/
  __pyx_mp_ass_subscript_7PyTorch__DoubleTensor, /*mp_ass_subscript*/
};

static PyTypeObject __pyx_type_7PyTorch__DoubleTensor = {
  PyVarObject_HEAD_INIT(0, 0)
  "PyTorch._DoubleTensor", /*tp_name*/
  sizeof(struct __pyx_obj_7PyTorch__DoubleTensor), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_7PyTorch__DoubleTensor, /*tp_dealloc*/
  0, /*tp_print*/
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  __pyx_pw_7PyTorch_13_DoubleTensor_25__repr__, /*tp_repr*/
  &__pyx_tp_as_number__DoubleTensor, /*tp_as_number*/
  &__pyx_tp_as_sequence__DoubleTensor, /*tp_as_sequence*/
  &__pyx_tp_as_mapping__DoubleTensor, /*tp_as_mapping*/
  0, /*tp_hash*/
  0, /*tp_call*/
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_BASETYPE, /*tp_flags*/
  0, /*tp_doc*/
  0, /*tp_traverse*/
  0, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  0, /*tp_iter*/
  0, /*tp_iternext*/
  __pyx_methods_7PyTorch__DoubleTensor, /*tp_methods*/
  0, /*tp_members*/
  __pyx_getsets_7PyTorch__DoubleTensor, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  0, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_7PyTorch__DoubleTensor, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
};
static struct __pyx_vtabstruct_7PyTorch__ByteTensor __pyx_vtable_7PyTorch__ByteTensor;

static PyObject *__pyx_tp_new_7PyTorch__ByteTensor(PyTypeObject *t, PyObject *a, PyObject *k) {
  struct __pyx_obj_7PyTorch__ByteTensor *p;
  PyObject *o;
  if (likely((t->tp_flags & Py_TPFLAGS_IS_ABSTRACT) == 0)) {
    o = (*t->tp_alloc)(t, 0);
  } else {
    o = (PyObject *) PyBaseObject_Type.tp_new(t, __pyx_empty_tuple, 0);
  }
  if (unlikely(!o)) return 0;
  p = ((struct __pyx_obj_7PyTorch__ByteTensor *)o);
  p->__pyx_vtab = __pyx_vtabptr_7PyTorch__ByteTensor;
  if (unlikely(__pyx_pw_7PyTorch_11_ByteTensor_1__cinit__(o, a, k) < 0)) goto bad;
  return o;
  bad:
  Py_DECREF(o); o = 0;
  return NULL;
}

static void __pyx_tp_dealloc_7PyTorch__ByteTensor(PyObject *o) {
  #if PY_VERSION_HEX >= 0x030400a1
  if (unlikely(Py_TYPE(o)->tp_finalize) && (!PyType_IS_GC(Py_TYPE(o)) || !_PyGC_FINALIZED(o))) {
    if (PyObject_CallFinalizerFromDealloc(o)) return;
  }
  #endif
  {
    PyObject *etype, *eval, *etb;
    PyErr_Fetch(&etype, &eval, &etb);
    ++Py_REFCNT(o);
    __pyx_pw_7PyTorch_11_ByteTensor_3__dealloc__(o);
    --Py_REFCNT(o);
    PyErr_Restore(etype, eval, etb);
  }
  (*Py_TYPE(o)->tp_free)(o);
}
static PyObject *__pyx_sq_item_7PyTorch__ByteTensor(PyObject *o, Py_ssize_t i) {
  PyObject *r;
  PyObject *x = PyInt_FromSsize_t(i); if(!x) return 0;
  r = Py_TYPE(o)->tp_as_mapping->mp_subscript(o, x);
  Py_DECREF(x);
  return r;
}

static int __pyx_mp_ass_subscript_7PyTorch__ByteTensor(PyObject *o, PyObject *i, PyObject *v) {
  if (v) {
    return __pyx_pw_7PyTorch_11_ByteTensor_31__setitem__(o, i, v);
  }
  else {
    PyErr_Format(PyExc_NotImplementedError,
      "Subscript deletion not supported by %.200s", Py_TYPE(o)->tp_name);
    return -1;
  }
}

static PyObject *__pyx_getprop_7PyTorch_11_ByteTensor_refCount(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_7PyTorch_11_ByteTensor_8refCount_1__get__(o);
}

static PyMethodDef __pyx_methods_7PyTorch__ByteTensor[] = {
  {"nElement", (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_5nElement, METH_NOARGS, 0},
  {"asNumpyTensor", (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_7asNumpyTensor, METH_NOARGS, 0},
  {"dims", (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_9dims, METH_NOARGS, 0},
  {"set1d", (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_11set1d, METH_VARARGS|METH_KEYWORDS, 0},
  {"set2d", (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_13set2d, METH_VARARGS|METH_KEYWORDS, 0},
  {"get1d", (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_15get1d, METH_O, 0},
  {"get2d", (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_17get2d, METH_VARARGS|METH_KEYWORDS, 0},
  {"isContiguous", (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_19isContiguous, METH_NOARGS, 0},
  {"max", (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_21max, METH_NOARGS, 0},
  {"min", (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_23min, METH_NOARGS, 0},
  {"as_string", (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_27as_string, METH_VARARGS|METH_KEYWORDS, 0},
  {"fill", (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_33fill, METH_O, 0},
  {"sum", (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_35sum, METH_NOARGS, 0},
  {"size", (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_37size, METH_NOARGS, 0},
  {"new", (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_39new, METH_VARARGS|METH_KEYWORDS, 0},
  {"narrow", (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_41narrow, METH_VARARGS|METH_KEYWORDS, 0},
  {"contiguous", (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_43contiguous, METH_NOARGS, 0},
  {"resize1d", (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_45resize1d, METH_O, 0},
  {"resize2d", (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_47resize2d, METH_VARARGS|METH_KEYWORDS, 0},
  {"resize3d", (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_49resize3d, METH_VARARGS|METH_KEYWORDS, 0},
  {"resize4d", (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_51resize4d, METH_VARARGS|METH_KEYWORDS, 0},
  {"resizeAs", (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_53resizeAs, METH_O, 0},
  {"resize", (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_55resize, METH_O, 0},
  {"newWithStorage", (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_57newWithStorage, METH_VARARGS|METH_KEYWORDS, 0},
  {"newWithStorage1d", (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_59newWithStorage1d, METH_VARARGS|METH_KEYWORDS, 0},
  {"newWithStorage2d", (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_61newWithStorage2d, METH_VARARGS|METH_KEYWORDS, 0},
  {"newWithStorage3d", (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_63newWithStorage3d, METH_VARARGS|METH_KEYWORDS, 0},
  {"newWithStorage4d", (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_65newWithStorage4d, METH_VARARGS|METH_KEYWORDS, 0},
  {"clone", (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_67clone, METH_NOARGS, 0},
  {"storage", (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_69storage, METH_NOARGS, 0},
  {"cmul", (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_73cmul, METH_O, 0},
  {"eq", (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_77eq, METH_O, 0},
  {"icmin", (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_79icmin, METH_O, 0},
  {"icmax", (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_81icmax, METH_O, 0},
  {"bernoulli", (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_95bernoulli, METH_VARARGS|METH_KEYWORDS, 0},
  {"geometric", (PyCFunction)__pyx_pw_7PyTorch_11_ByteTensor_97geometric, METH_VARARGS|METH_KEYWORDS, 0},
  {0, 0, 0, 0}
};

static struct PyGetSetDef __pyx_getsets_7PyTorch__ByteTensor[] = {
  {(char *)"refCount", __pyx_getprop_7PyTorch_11_ByteTensor_refCount, 0, (char *)0, 0},
  {0, 0, 0, 0, 0}
};

static PyNumberMethods __pyx_tp_as_number__ByteTensor = {
  __pyx_pw_7PyTorch_11_ByteTensor_71__add__, /*nb_add*/
  __pyx_pw_7PyTorch_11_ByteTensor_75__sub__, /*nb_subtract*/
  __pyx_pw_7PyTorch_11_ByteTensor_93__mul__, /*nb_multiply*/
  #if PY_MAJOR_VERSION < 3 || CYTHON_COMPILING_IN_PYPY
  0, /*nb_divide*/
  #endif
  0, /*nb_remainder*/
  0, /*nb_divmod*/
  0, /*nb_power*/
  0, /*nb_negative*/
  0, /*nb_positive*/
  0, /*nb_absolute*/
  0, /*nb_nonzero*/
  0, /*nb_invert*/
  0, /*nb_lshift*/
  0, /*nb_rshift*/
  0, /*nb_and*/
  0, /*nb_xor*/
  0, /*nb_or*/
  #if PY_MAJOR_VERSION < 3 || CYTHON_COMPILING_IN_PYPY
  0, /*nb_coerce*/
  #endif
  0, /*nb_int*/
  #if PY_MAJOR_VERSION < 3
  0, /*nb_long*/
  #else
  0, /*reserved*/
  #endif
  0, /*nb_float*/
  #if PY_MAJOR_VERSION < 3 || CYTHON_COMPILING_IN_PYPY
  0, /*nb_oct*/
  #endif
  #if PY_MAJOR_VERSION < 3 || CYTHON_COMPILING_IN_PYPY
  0, /*nb_hex*/
  #endif
  __pyx_pw_7PyTorch_11_ByteTensor_87__iadd__, /*nb_inplace_add*/
  __pyx_pw_7PyTorch_11_ByteTensor_89__isub__, /*nb_inplace_subtract*/
  __pyx_pw_7PyTorch_11_ByteTensor_91__imul__, /*nb_inplace_multiply*/
  #if PY_MAJOR_VERSION < 3 || CYTHON_COMPILING_IN_PYPY
  0, /*nb_inplace_divide*/
  #endif
  0, /*nb_inplace_remainder*/
  0, /*nb_inplace_power*/
  0, /*nb_inplace_lshift*/
  0, /*nb_inplace_rshift*/
  0, /*nb_inplace_and*/
  0, /*nb_inplace_xor*/
  0, /*nb_inplace_or*/
  __pyx_pw_7PyTorch_11_ByteTensor_83__floordiv__, /*nb_floor_divide*/
  0, /*nb_true_divide*/
  __pyx_pw_7PyTorch_11_ByteTensor_85__ifloordiv__, /*nb_inplace_floor_divide*/
  0, /*nb_inplace_true_divide*/
  0, /*nb_index*/
  #if PY_VERSION_HEX >= 0x03050000
  0, /*nb_matrix_multiply*/
  #endif
  #if PY_VERSION_HEX >= 0x03050000
  0, /*nb_inplace_matrix_multiply*/
  #endif
};

static PySequenceMethods __pyx_tp_as_sequence__ByteTensor = {
  0, /*sq_length*/
  0, /*sq_concat*/
  0, /*sq_repeat*/
  __pyx_sq_item_7PyTorch__ByteTensor, /*sq_item*/
  0, /*sq_slice*/
  0, /*sq_ass_item*/
  0, /*sq_ass_slice*/
  0, /*sq_contains*/
  0, /*sq_inplace_concat*/
  0, /*sq_inplace_repeat*/
};

static PyMappingMethods __pyx_tp_as_mapping__ByteTensor = {
  0, /*mp_length*/
  __pyx_pw_7PyTorch_11_ByteTensor_29__getitem__, /*mp_subscript*/
  __pyx_mp_ass_subscript_7PyTorch__ByteTensor, /*mp_ass_subscript*/
};

static PyTypeObject __pyx_type_7PyTorch__ByteTensor = {
  PyVarObject_HEAD_INIT(0, 0)
  "PyTorch._ByteTensor", /*tp_name*/
  sizeof(struct __pyx_obj_7PyTorch__ByteTensor), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_7PyTorch__ByteTensor, /*tp_dealloc*/
  0, /*tp_print*/
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  __pyx_pw_7PyTorch_11_ByteTensor_25__repr__, /*tp_repr*/
  &__pyx_tp_as_number__ByteTensor, /*tp_as_number*/
  &__pyx_tp_as_sequence__ByteTensor, /*tp_as_sequence*/
  &__pyx_tp_as_mapping__ByteTensor, /*tp_as_mapping*/
  0, /*tp_hash*/
  0, /*tp_call*/
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_BASETYPE, /*tp_flags*/
  0, /*tp_doc*/
  0, /*tp_traverse*/
  0, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  0, /*tp_iter*/
  0, /*tp_iternext*/
  __pyx_methods_7PyTorch__ByteTensor, /*tp_methods*/
  0, /*tp_members*/
  __pyx_getsets_7PyTorch__ByteTensor, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  0, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_7PyTorch__ByteTensor, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
};

static PyObject *__pyx_tp_new_7PyTorch_GlobalState(PyTypeObject *t, CYTHON_UNUSED PyObject *a, CYTHON_UNUSED PyObject *k) {
  PyObject *o;
  if (likely((t->tp_flags & Py_TPFLAGS_IS_ABSTRACT) == 0)) {
    o = (*t->tp_alloc)(t, 0);
  } else {
    o = (PyObject *) PyBaseObject_Type.tp_new(t, __pyx_empty_tuple, 0);
  }
  if (unlikely(!o)) return 0;
  if (unlikely(__pyx_pw_7PyTorch_11GlobalState_1__cinit__(o, __pyx_empty_tuple, NULL) < 0)) goto bad;
  return o;
  bad:
  Py_DECREF(o); o = 0;
  return NULL;
}

static void __pyx_tp_dealloc_7PyTorch_GlobalState(PyObject *o) {
  #if PY_VERSION_HEX >= 0x030400a1
  if (unlikely(Py_TYPE(o)->tp_finalize) && (!PyType_IS_GC(Py_TYPE(o)) || !_PyGC_FINALIZED(o))) {
    if (PyObject_CallFinalizerFromDealloc(o)) return;
  }
  #endif
  {
    PyObject *etype, *eval, *etb;
    PyErr_Fetch(&etype, &eval, &etb);
    ++Py_REFCNT(o);
    __pyx_pw_7PyTorch_11GlobalState_3__dealloc__(o);
    --Py_REFCNT(o);
    PyErr_Restore(etype, eval, etb);
  }
  (*Py_TYPE(o)->tp_free)(o);
}

static PyMethodDef __pyx_methods_7PyTorch_GlobalState[] = {
  {"getLua", (PyCFunction)__pyx_pw_7PyTorch_11GlobalState_5getLua, METH_NOARGS, 0},
  {0, 0, 0, 0}
};

static PyTypeObject __pyx_type_7PyTorch_GlobalState = {
  PyVarObject_HEAD_INIT(0, 0)
  "PyTorch.GlobalState", /*tp_name*/
  sizeof(struct __pyx_obj_7PyTorch_GlobalState), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_7PyTorch_GlobalState, /*tp_dealloc*/
  0, /*tp_print*/
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  0, /*tp_repr*/
  0, /*tp_as_number*/
  0, /*tp_as_sequence*/
  0, /*tp_as_mapping*/
  0, /*tp_hash*/
  0, /*tp_call*/
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_BASETYPE, /*tp_flags*/
  0, /*tp_doc*/
  0, /*tp_traverse*/
  0, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  0, /*tp_iter*/
  0, /*tp_iternext*/
  __pyx_methods_7PyTorch_GlobalState, /*tp_methods*/
  0, /*tp_members*/
  0, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  0, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_7PyTorch_GlobalState, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
};

static PyObject *__pyx_tp_new_7PyTorch_Nn(PyTypeObject *t, CYTHON_UNUSED PyObject *a, CYTHON_UNUSED PyObject *k) {
  PyObject *o;
  if (likely((t->tp_flags & Py_TPFLAGS_IS_ABSTRACT) == 0)) {
    o = (*t->tp_alloc)(t, 0);
  } else {
    o = (PyObject *) PyBaseObject_Type.tp_new(t, __pyx_empty_tuple, 0);
  }
  if (unlikely(!o)) return 0;
  return o;
}

static void __pyx_tp_dealloc_7PyTorch_Nn(PyObject *o) {
  #if PY_VERSION_HEX >= 0x030400a1
  if (unlikely(Py_TYPE(o)->tp_finalize) && (!PyType_IS_GC(Py_TYPE(o)) || !_PyGC_FINALIZED(o))) {
    if (PyObject_CallFinalizerFromDealloc(o)) return;
  }
  #endif
  (*Py_TYPE(o)->tp_free)(o);
}

static PyMethodDef __pyx_methods_7PyTorch_Nn[] = {
  {"collectgarbage", (PyCFunction)__pyx_pw_7PyTorch_2Nn_1collectgarbage, METH_NOARGS, 0},
  {0, 0, 0, 0}
};

static PyTypeObject __pyx_type_7PyTorch_Nn = {
  PyVarObject_HEAD_INIT(0, 0)
  "PyTorch.Nn", /*tp_name*/
  sizeof(struct __pyx_obj_7PyTorch_Nn), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_7PyTorch_Nn, /*tp_dealloc*/
  0, /*tp_print*/
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  0, /*tp_repr*/
  0, /*tp_as_number*/
  0, /*tp_as_sequence*/
  0, /*tp_as_mapping*/
  0, /*tp_hash*/
  0, /*tp_call*/
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_BASETYPE, /*tp_flags*/
  0, /*tp_doc*/
  0, /*tp_traverse*/
  0, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  0, /*tp_iter*/
  0, /*tp_iternext*/
  __pyx_methods_7PyTorch_Nn, /*tp_methods*/
  0, /*tp_members*/
  0, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  0, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_7PyTorch_Nn, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
};
static struct __pyx_vtabstruct_array __pyx_vtable_array;

static PyObject *__pyx_tp_new_array(PyTypeObject *t, PyObject *a, PyObject *k) {
  struct __pyx_array_obj *p;
  PyObject *o;
  if (likely((t->tp_flags & Py_TPFLAGS_IS_ABSTRACT) == 0)) {
    o = (*t->tp_alloc)(t, 0);
  } else {
    o = (PyObject *) PyBaseObject_Type.tp_new(t, __pyx_empty_tuple, 0);
  }
  if (unlikely(!o)) return 0;
  p = ((struct __pyx_array_obj *)o);
  p->__pyx_vtab = __pyx_vtabptr_array;
  p->mode = ((PyObject*)Py_None); Py_INCREF(Py_None);
  p->_format = ((PyObject*)Py_None); Py_INCREF(Py_None);
  if (unlikely(__pyx_array___cinit__(o, a, k) < 0)) goto bad;
  return o;
  bad:
  Py_DECREF(o); o = 0;
  return NULL;
}

static void __pyx_tp_dealloc_array(PyObject *o) {
  struct __pyx_array_obj *p = (struct __pyx_array_obj *)o;
  #if PY_VERSION_HEX >= 0x030400a1
  if (unlikely(Py_TYPE(o)->tp_finalize) && (!PyType_IS_GC(Py_TYPE(o)) || !_PyGC_FINALIZED(o))) {
    if (PyObject_CallFinalizerFromDealloc(o)) return;
  }
  #endif
  {
    PyObject *etype, *eval, *etb;
    PyErr_Fetch(&etype, &eval, &etb);
    ++Py_REFCNT(o);
    __pyx_array___dealloc__(o);
    --Py_REFCNT(o);
    PyErr_Restore(etype, eval, etb);
  }
  Py_CLEAR(p->mode);
  Py_CLEAR(p->_format);
  (*Py_TYPE(o)->tp_free)(o);
}
static PyObject *__pyx_sq_item_array(PyObject *o, Py_ssize_t i) {
  PyObject *r;
  PyObject *x = PyInt_FromSsize_t(i); if(!x) return 0;
  r = Py_TYPE(o)->tp_as_mapping->mp_subscript(o, x);
  Py_DECREF(x);
  return r;
}

static int __pyx_mp_ass_subscript_array(PyObject *o, PyObject *i, PyObject *v) {
  if (v) {
    return __pyx_array___setitem__(o, i, v);
  }
  else {
    PyErr_Format(PyExc_NotImplementedError,
      "Subscript deletion not supported by %.200s", Py_TYPE(o)->tp_name);
    return -1;
  }
}

static PyObject *__pyx_tp_getattro_array(PyObject *o, PyObject *n) {
  PyObject *v = PyObject_GenericGetAttr(o, n);
  if (!v && PyErr_ExceptionMatches(PyExc_AttributeError)) {
    PyErr_Clear();
    v = __pyx_array___getattr__(o, n);
  }
  return v;
}

static PyObject *__pyx_getprop___pyx_array_memview(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_15View_dot_MemoryView_5array_7memview_1__get__(o);
}

static PyMethodDef __pyx_methods_array[] = {
  {"__getattr__", (PyCFunction)__pyx_array___getattr__, METH_O|METH_COEXIST, 0},
  {0, 0, 0, 0}
};

static struct PyGetSetDef __pyx_getsets_array[] = {
  {(char *)"memview", __pyx_getprop___pyx_array_memview, 0, (char *)0, 0},
  {0, 0, 0, 0, 0}
};

static PySequenceMethods __pyx_tp_as_sequence_array = {
  0, /*sq_length*/
  0, /*sq_concat*/
  0, /*sq_repeat*/
  __pyx_sq_item_array, /*sq_item*/
  0, /*sq_slice*/
  0, /*sq_ass_item*/
  0, /*sq_ass_slice*/
  0, /*sq_contains*/
  0, /*sq_inplace_concat*/
  0, /*sq_inplace_repeat*/
};

static PyMappingMethods __pyx_tp_as_mapping_array = {
  0, /*mp_length*/
  __pyx_array___getitem__, /*mp_subscript*/
  __pyx_mp_ass_subscript_array, /*mp_ass_subscript*/
};

static PyBufferProcs __pyx_tp_as_buffer_array = {
  #if PY_MAJOR_VERSION < 3
  0, /*bf_getreadbuffer*/
  #endif
  #if PY_MAJOR_VERSION < 3
  0, /*bf_getwritebuffer*/
  #endif
  #if PY_MAJOR_VERSION < 3
  0, /*bf_getsegcount*/
  #endif
  #if PY_MAJOR_VERSION < 3
  0, /*bf_getcharbuffer*/
  #endif
  __pyx_array_getbuffer, /*bf_getbuffer*/
  0, /*bf_releasebuffer*/
};

static PyTypeObject __pyx_type___pyx_array = {
  PyVarObject_HEAD_INIT(0, 0)
  "PyTorch.array", /*tp_name*/
  sizeof(struct __pyx_array_obj), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_array, /*tp_dealloc*/
  0, /*tp_print*/
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  0, /*tp_repr*/
  0, /*tp_as_number*/
  &__pyx_tp_as_sequence_array, /*tp_as_sequence*/
  &__pyx_tp_as_mapping_array, /*tp_as_mapping*/
  0, /*tp_hash*/
  0, /*tp_call*/
  0, /*tp_str*/
  __pyx_tp_getattro_array, /*tp_getattro*/
  0, /*tp_setattro*/
  &__pyx_tp_as_buffer_array, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_BASETYPE, /*tp_flags*/
  0, /*tp_doc*/
  0, /*tp_traverse*/
  0, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  0, /*tp_iter*/
  0, /*tp_iternext*/
  __pyx_methods_array, /*tp_methods*/
  0, /*tp_members*/
  __pyx_getsets_array, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  0, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_array, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
};

static PyObject *__pyx_tp_new_Enum(PyTypeObject *t, CYTHON_UNUSED PyObject *a, CYTHON_UNUSED PyObject *k) {
  struct __pyx_MemviewEnum_obj *p;
  PyObject *o;
  if (likely((t->tp_flags & Py_TPFLAGS_IS_ABSTRACT) == 0)) {
    o = (*t->tp_alloc)(t, 0);
  } else {
    o = (PyObject *) PyBaseObject_Type.tp_new(t, __pyx_empty_tuple, 0);
  }
  if (unlikely(!o)) return 0;
  p = ((struct __pyx_MemviewEnum_obj *)o);
  p->name = Py_None; Py_INCREF(Py_None);
  return o;
}

static void __pyx_tp_dealloc_Enum(PyObject *o) {
  struct __pyx_MemviewEnum_obj *p = (struct __pyx_MemviewEnum_obj *)o;
  #if PY_VERSION_HEX >= 0x030400a1
  if (unlikely(Py_TYPE(o)->tp_finalize) && !_PyGC_FINALIZED(o)) {
    if (PyObject_CallFinalizerFromDealloc(o)) return;
  }
  #endif
  PyObject_GC_UnTrack(o);
  Py_CLEAR(p->name);
  (*Py_TYPE(o)->tp_free)(o);
}

static int __pyx_tp_traverse_Enum(PyObject *o, visitproc v, void *a) {
  int e;
  struct __pyx_MemviewEnum_obj *p = (struct __pyx_MemviewEnum_obj *)o;
  if (p->name) {
    e = (*v)(p->name, a); if (e) return e;
  }
  return 0;
}

static int __pyx_tp_clear_Enum(PyObject *o) {
  PyObject* tmp;
  struct __pyx_MemviewEnum_obj *p = (struct __pyx_MemviewEnum_obj *)o;
  tmp = ((PyObject*)p->name);
  p->name = Py_None; Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  return 0;
}

static PyMethodDef __pyx_methods_Enum[] = {
  {0, 0, 0, 0}
};

static PyTypeObject __pyx_type___pyx_MemviewEnum = {
  PyVarObject_HEAD_INIT(0, 0)
  "PyTorch.Enum", /*tp_name*/
  sizeof(struct __pyx_MemviewEnum_obj), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_Enum, /*tp_dealloc*/
  0, /*tp_print*/
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  __pyx_MemviewEnum___repr__, /*tp_repr*/
  0, /*tp_as_number*/
  0, /*tp_as_sequence*/
  0, /*tp_as_mapping*/
  0, /*tp_hash*/
  0, /*tp_call*/
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_BASETYPE|Py_TPFLAGS_HAVE_GC, /*tp_flags*/
  0, /*tp_doc*/
  __pyx_tp_traverse_Enum, /*tp_traverse*/
  __pyx_tp_clear_Enum, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  0, /*tp_iter*/
  0, /*tp_iternext*/
  __pyx_methods_Enum, /*tp_methods*/
  0, /*tp_members*/
  0, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  __pyx_MemviewEnum___init__, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_Enum, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
};
static struct __pyx_vtabstruct_memoryview __pyx_vtable_memoryview;

static PyObject *__pyx_tp_new_memoryview(PyTypeObject *t, PyObject *a, PyObject *k) {
  struct __pyx_memoryview_obj *p;
  PyObject *o;
  if (likely((t->tp_flags & Py_TPFLAGS_IS_ABSTRACT) == 0)) {
    o = (*t->tp_alloc)(t, 0);
  } else {
    o = (PyObject *) PyBaseObject_Type.tp_new(t, __pyx_empty_tuple, 0);
  }
  if (unlikely(!o)) return 0;
  p = ((struct __pyx_memoryview_obj *)o);
  p->__pyx_vtab = __pyx_vtabptr_memoryview;
  p->obj = Py_None; Py_INCREF(Py_None);
  p->_size = Py_None; Py_INCREF(Py_None);
  p->_array_interface = Py_None; Py_INCREF(Py_None);
  p->view.obj = NULL;
  if (unlikely(__pyx_memoryview___cinit__(o, a, k) < 0)) goto bad;
  return o;
  bad:
  Py_DECREF(o); o = 0;
  return NULL;
}

static void __pyx_tp_dealloc_memoryview(PyObject *o) {
  struct __pyx_memoryview_obj *p = (struct __pyx_memoryview_obj *)o;
  #if PY_VERSION_HEX >= 0x030400a1
  if (unlikely(Py_TYPE(o)->tp_finalize) && !_PyGC_FINALIZED(o)) {
    if (PyObject_CallFinalizerFromDealloc(o)) return;
  }
  #endif
  PyObject_GC_UnTrack(o);
  {
    PyObject *etype, *eval, *etb;
    PyErr_Fetch(&etype, &eval, &etb);
    ++Py_REFCNT(o);
    __pyx_memoryview___dealloc__(o);
    --Py_REFCNT(o);
    PyErr_Restore(etype, eval, etb);
  }
  Py_CLEAR(p->obj);
  Py_CLEAR(p->_size);
  Py_CLEAR(p->_array_interface);
  (*Py_TYPE(o)->tp_free)(o);
}

static int __pyx_tp_traverse_memoryview(PyObject *o, visitproc v, void *a) {
  int e;
  struct __pyx_memoryview_obj *p = (struct __pyx_memoryview_obj *)o;
  if (p->obj) {
    e = (*v)(p->obj, a); if (e) return e;
  }
  if (p->_size) {
    e = (*v)(p->_size, a); if (e) return e;
  }
  if (p->_array_interface) {
    e = (*v)(p->_array_interface, a); if (e) return e;
  }
  if (p->view.obj) {
    e = (*v)(p->view.obj, a); if (e) return e;
  }
  return 0;
}

static int __pyx_tp_clear_memoryview(PyObject *o) {
  PyObject* tmp;
  struct __pyx_memoryview_obj *p = (struct __pyx_memoryview_obj *)o;
  tmp = ((PyObject*)p->obj);
  p->obj = Py_None; Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  tmp = ((PyObject*)p->_size);
  p->_size = Py_None; Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  tmp = ((PyObject*)p->_array_interface);
  p->_array_interface = Py_None; Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  Py_CLEAR(p->view.obj);
  return 0;
}
static PyObject *__pyx_sq_item_memoryview(PyObject *o, Py_ssize_t i) {
  PyObject *r;
  PyObject *x = PyInt_FromSsize_t(i); if(!x) return 0;
  r = Py_TYPE(o)->tp_as_mapping->mp_subscript(o, x);
  Py_DECREF(x);
  return r;
}

static int __pyx_mp_ass_subscript_memoryview(PyObject *o, PyObject *i, PyObject *v) {
  if (v) {
    return __pyx_memoryview___setitem__(o, i, v);
  }
  else {
    PyErr_Format(PyExc_NotImplementedError,
      "Subscript deletion not supported by %.200s", Py_TYPE(o)->tp_name);
    return -1;
  }
}

static PyObject *__pyx_getprop___pyx_memoryview_T(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_15View_dot_MemoryView_10memoryview_1T_1__get__(o);
}

static PyObject *__pyx_getprop___pyx_memoryview_base(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_15View_dot_MemoryView_10memoryview_4base_1__get__(o);
}

static PyObject *__pyx_getprop___pyx_memoryview_shape(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_15View_dot_MemoryView_10memoryview_5shape_1__get__(o);
}

static PyObject *__pyx_getprop___pyx_memoryview_strides(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_15View_dot_MemoryView_10memoryview_7strides_1__get__(o);
}

static PyObject *__pyx_getprop___pyx_memoryview_suboffsets(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_15View_dot_MemoryView_10memoryview_10suboffsets_1__get__(o);
}

static PyObject *__pyx_getprop___pyx_memoryview_ndim(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_15View_dot_MemoryView_10memoryview_4ndim_1__get__(o);
}

static PyObject *__pyx_getprop___pyx_memoryview_itemsize(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_15View_dot_MemoryView_10memoryview_8itemsize_1__get__(o);
}

static PyObject *__pyx_getprop___pyx_memoryview_nbytes(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_15View_dot_MemoryView_10memoryview_6nbytes_1__get__(o);
}

static PyObject *__pyx_getprop___pyx_memoryview_size(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_15View_dot_MemoryView_10memoryview_4size_1__get__(o);
}

static PyMethodDef __pyx_methods_memoryview[] = {
  {"is_c_contig", (PyCFunction)__pyx_memoryview_is_c_contig, METH_NOARGS, 0},
  {"is_f_contig", (PyCFunction)__pyx_memoryview_is_f_contig, METH_NOARGS, 0},
  {"copy", (PyCFunction)__pyx_memoryview_copy, METH_NOARGS, 0},
  {"copy_fortran", (PyCFunction)__pyx_memoryview_copy_fortran, METH_NOARGS, 0},
  {0, 0, 0, 0}
};

static struct PyGetSetDef __pyx_getsets_memoryview[] = {
  {(char *)"T", __pyx_getprop___pyx_memoryview_T, 0, (char *)0, 0},
  {(char *)"base", __pyx_getprop___pyx_memoryview_base, 0, (char *)0, 0},
  {(char *)"shape", __pyx_getprop___pyx_memoryview_shape, 0, (char *)0, 0},
  {(char *)"strides", __pyx_getprop___pyx_memoryview_strides, 0, (char *)0, 0},
  {(char *)"suboffsets", __pyx_getprop___pyx_memoryview_suboffsets, 0, (char *)0, 0},
  {(char *)"ndim", __pyx_getprop___pyx_memoryview_ndim, 0, (char *)0, 0},
  {(char *)"itemsize", __pyx_getprop___pyx_memoryview_itemsize, 0, (char *)0, 0},
  {(char *)"nbytes", __pyx_getprop___pyx_memoryview_nbytes, 0, (char *)0, 0},
  {(char *)"size", __pyx_getprop___pyx_memoryview_size, 0, (char *)0, 0},
  {0, 0, 0, 0, 0}
};

static PySequenceMethods __pyx_tp_as_sequence_memoryview = {
  __pyx_memoryview___len__, /*sq_length*/
  0, /*sq_concat*/
  0, /*sq_repeat*/
  __pyx_sq_item_memoryview, /*sq_item*/
  0, /*sq_slice*/
  0, /*sq_ass_item*/
  0, /*sq_ass_slice*/
  0, /*sq_contains*/
  0, /*sq_inplace_concat*/
  0, /*sq_inplace_repeat*/
};

static PyMappingMethods __pyx_tp_as_mapping_memoryview = {
  __pyx_memoryview___len__, /*mp_length*/
  __pyx_memoryview___getitem__, /*mp_subscript*/
  __pyx_mp_ass_subscript_memoryview, /*mp_ass_subscript*/
};

static PyBufferProcs __pyx_tp_as_buffer_memoryview = {
  #if PY_MAJOR_VERSION < 3
  0, /*bf_getreadbuffer*/
  #endif
  #if PY_MAJOR_VERSION < 3
  0, /*bf_getwritebuffer*/
  #endif
  #if PY_MAJOR_VERSION < 3
  0, /*bf_getsegcount*/
  #endif
  #if PY_MAJOR_VERSION < 3
  0, /*bf_getcharbuffer*/
  #endif
  __pyx_memoryview_getbuffer, /*bf_getbuffer*/
  0, /*bf_releasebuffer*/
};

static PyTypeObject __pyx_type___pyx_memoryview = {
  PyVarObject_HEAD_INIT(0, 0)
  "PyTorch.memoryview", /*tp_name*/
  sizeof(struct __pyx_memoryview_obj), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_memoryview, /*tp_dealloc*/
  0, /*tp_print*/
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  __pyx_memoryview___repr__, /*tp_repr*/
  0, /*tp_as_number*/
  &__pyx_tp_as_sequence_memoryview, /*tp_as_sequence*/
  &__pyx_tp_as_mapping_memoryview, /*tp_as_mapping*/
  0, /*tp_hash*/
  0, /*tp_call*/
  __pyx_memoryview___str__, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  &__pyx_tp_as_buffer_memoryview, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_BASETYPE|Py_TPFLAGS_HAVE_GC, /*tp_flags*/
  0, /*tp_doc*/
  __pyx_tp_traverse_memoryview, /*tp_traverse*/
  __pyx_tp_clear_memoryview, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  0, /*tp_iter*/
  0, /*tp_iternext*/
  __pyx_methods_memoryview, /*tp_methods*/
  0, /*tp_members*/
  __pyx_getsets_memoryview, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  0, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_memoryview, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
};
static struct __pyx_vtabstruct__memoryviewslice __pyx_vtable__memoryviewslice;

static PyObject *__pyx_tp_new__memoryviewslice(PyTypeObject *t, PyObject *a, PyObject *k) {
  struct __pyx_memoryviewslice_obj *p;
  PyObject *o = __pyx_tp_new_memoryview(t, a, k);
  if (unlikely(!o)) return 0;
  p = ((struct __pyx_memoryviewslice_obj *)o);
  p->__pyx_base.__pyx_vtab = (struct __pyx_vtabstruct_memoryview*)__pyx_vtabptr__memoryviewslice;
  p->from_object = Py_None; Py_INCREF(Py_None);
  p->from_slice.memview = NULL;
  return o;
}

static void __pyx_tp_dealloc__memoryviewslice(PyObject *o) {
  struct __pyx_memoryviewslice_obj *p = (struct __pyx_memoryviewslice_obj *)o;
  #if PY_VERSION_HEX >= 0x030400a1
  if (unlikely(Py_TYPE(o)->tp_finalize) && !_PyGC_FINALIZED(o)) {
    if (PyObject_CallFinalizerFromDealloc(o)) return;
  }
  #endif
  PyObject_GC_UnTrack(o);
  {
    PyObject *etype, *eval, *etb;
    PyErr_Fetch(&etype, &eval, &etb);
    ++Py_REFCNT(o);
    __pyx_memoryviewslice___dealloc__(o);
    --Py_REFCNT(o);
    PyErr_Restore(etype, eval, etb);
  }
  Py_CLEAR(p->from_object);
  PyObject_GC_Track(o);
  __pyx_tp_dealloc_memoryview(o);
}

static int __pyx_tp_traverse__memoryviewslice(PyObject *o, visitproc v, void *a) {
  int e;
  struct __pyx_memoryviewslice_obj *p = (struct __pyx_memoryviewslice_obj *)o;
  e = __pyx_tp_traverse_memoryview(o, v, a); if (e) return e;
  if (p->from_object) {
    e = (*v)(p->from_object, a); if (e) return e;
  }
  return 0;
}

static int __pyx_tp_clear__memoryviewslice(PyObject *o) {
  PyObject* tmp;
  struct __pyx_memoryviewslice_obj *p = (struct __pyx_memoryviewslice_obj *)o;
  __pyx_tp_clear_memoryview(o);
  tmp = ((PyObject*)p->from_object);
  p->from_object = Py_None; Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  __PYX_XDEC_MEMVIEW(&p->from_slice, 1);
  return 0;
}

static PyObject *__pyx_getprop___pyx_memoryviewslice_base(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_15View_dot_MemoryView_16_memoryviewslice_4base_1__get__(o);
}

static PyMethodDef __pyx_methods__memoryviewslice[] = {
  {0, 0, 0, 0}
};

static struct PyGetSetDef __pyx_getsets__memoryviewslice[] = {
  {(char *)"base", __pyx_getprop___pyx_memoryviewslice_base, 0, (char *)0, 0},
  {0, 0, 0, 0, 0}
};

static PyTypeObject __pyx_type___pyx_memoryviewslice = {
  PyVarObject_HEAD_INIT(0, 0)
  "PyTorch._memoryviewslice", /*tp_name*/
  sizeof(struct __pyx_memoryviewslice_obj), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc__memoryviewslice, /*tp_dealloc*/
  0, /*tp_print*/
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  #if CYTHON_COMPILING_IN_PYPY
  __pyx_memoryview___repr__, /*tp_repr*/
  #else
  0, /*tp_repr*/
  #endif
  0, /*tp_as_number*/
  0, /*tp_as_sequence*/
  0, /*tp_as_mapping*/
  0, /*tp_hash*/
  0, /*tp_call*/
  #if CYTHON_COMPILING_IN_PYPY
  __pyx_memoryview___str__, /*tp_str*/
  #else
  0, /*tp_str*/
  #endif
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_BASETYPE|Py_TPFLAGS_HAVE_GC, /*tp_flags*/
  "Internal class for passing memoryview slices to Python", /*tp_doc*/
  __pyx_tp_traverse__memoryviewslice, /*tp_traverse*/
  __pyx_tp_clear__memoryviewslice, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  0, /*tp_iter*/
  0, /*tp_iternext*/
  __pyx_methods__memoryviewslice, /*tp_methods*/
  0, /*tp_members*/
  __pyx_getsets__memoryviewslice, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  0, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new__memoryviewslice, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
};

static PyMethodDef __pyx_methods[] = {
  {"getFloatPrediction", (PyCFunction)__pyx_pw_7PyTorch_23getFloatPrediction, METH_O, 0},
  {"getDoublePrediction", (PyCFunction)__pyx_pw_7PyTorch_25getDoublePrediction, METH_O, 0},
  {0, 0, 0, 0}
};

static int __pyx_import_star_set(PyObject *o, PyObject* py_name, char *name) {
  static const char* internal_type_names[] = {
    "Enum",
    "FILE",
    "GlobalState",
    "LuaState",
    "Nn",
    "PyObject",
    "PyThread_type_lock",
    "Py_intptr_t",
    "THByteTensor",
    "THDoubleTensor",
    "THFloatTensor",
    "THGenerator",
    "THLongTensor",
    "_ByteTensor",
    "_DoubleTensor",
    "_FloatTensor",
    "_LongTensor",
    "__Pyx_TypeInfo",
    "__Pyx_memviewslice",
    "__pyx_atomic_int",
    "__pyx_buffer",
    "__pyx_ctuple_Py_ssize_t",
    "__pyx_ctuple_Py_ssize_t_struct",
    "__pyx_ctuple___dunderPyx_memviewslice",
    "__pyx_ctuple___dunderPyx_memviewslice_struct",
    "__pyx_ctuple_char__ptr",
    "__pyx_ctuple_char__ptr_struct",
    "__pyx_ctuple_double",
    "__pyx_ctuple_double_struct",
    "__pyx_ctuple_int",
    "__pyx_ctuple_int__and_Py_ssize_t",
    "__pyx_ctuple_int__and_Py_ssize_t__and_Py_ssize_t",
    "__pyx_ctuple_int__and_Py_ssize_t__and_Py_ssize_t_struct",
    "__pyx_ctuple_int__and_Py_ssize_t_struct",
    "__pyx_ctuple_int__and_double",
    "__pyx_ctuple_int__and_double_struct",
    "__pyx_ctuple_int__and_float",
    "__pyx_ctuple_int__and_float_struct",
    "__pyx_ctuple_int__and_int",
    "__pyx_ctuple_int__and_int__and_double",
    "__pyx_ctuple_int__and_int__and_double_struct",
    "__pyx_ctuple_int__and_int__and_float",
    "__pyx_ctuple_int__and_int__and_float_struct",
    "__pyx_ctuple_int__and_int__and_long",
    "__pyx_ctuple_int__and_int__and_long_struct",
    "__pyx_ctuple_int__and_int__and_unsigned__space_char",
    "__pyx_ctuple_int__and_int__and_unsigned__space_char_struct",
    "__pyx_ctuple_int__and_int_struct",
    "__pyx_ctuple_int__and_long",
    "__pyx_ctuple_int__and_long_struct",
    "__pyx_ctuple_int__and_unsigned__space_char",
    "__pyx_ctuple_int__and_unsigned__space_char_struct",
    "__pyx_ctuple_int_struct",
    "__pyx_ctuple_long",
    "__pyx_ctuple_long__and_long__and_long",
    "__pyx_ctuple_long__and_long__and_long_struct",
    "__pyx_ctuple_long_struct",
    "__pyx_ctuple_unsigned__space_char",
    "__pyx_ctuple_unsigned__space_char_struct",
    "__pyx_memoryview",
    "__pyx_opt_args_7PyTorch__ByteTensor_fromNative",
    "__pyx_opt_args_7PyTorch__DoubleTensor_fromNative",
    "__pyx_opt_args_7PyTorch__FloatTensor_fromNative",
    "__pyx_opt_args_7PyTorch__LongTensor_fromNative",
    "_memoryviewslice",
    "array",
    "lua_State",
    "memoryview",
    0
  };
  const char** type_name = internal_type_names;
  while (*type_name) {
    if (__Pyx_StrEq(name, *type_name)) {
      PyErr_Format(PyExc_TypeError, "Cannot overwrite C type %s", name);
      goto bad;
    }
    type_name++;
  }
  if (0);
  else if (__Pyx_StrEq(name, "Py_None")) {
    PyErr_Format(PyExc_TypeError, "Cannot convert Python object Py_None to PyObject *");
    __PYX_ERR(2, 57, __pyx_L2_error)
  }
  else if (__Pyx_StrEq(name, "__pyx_memoryview_thread_locks")) {
    PyErr_Format(PyExc_TypeError, "Cannot convert Python object __pyx_memoryview_thread_locks to PyThread_type_lock [8]");
    __PYX_ERR(2, 313, __pyx_L2_error)
  }
  else if (__Pyx_StrEq(name, "__pyx_memoryview_thread_locks_used")) {
    __pyx_memoryview_thread_locks_used = __Pyx_PyInt_As_int(o); if (unlikely((__pyx_memoryview_thread_locks_used == (int)-1) && PyErr_Occurred())) __PYX_ERR(2, 312, __pyx_L2_error)
  }
  else if (__Pyx_StrEq(name, "contiguous")) {
    Py_INCREF(o);
    Py_DECREF(contiguous);
    contiguous = o;
  }
  else if (__Pyx_StrEq(name, "generic")) {
    Py_INCREF(o);
    Py_DECREF(generic);
    generic = o;
  }
  else if (__Pyx_StrEq(name, "globalState")) {
    if (!(likely(((o) == Py_None) || likely(__Pyx_TypeTest(o, __pyx_ptype_7PyTorch_GlobalState))))) __PYX_ERR(0, 2600, __pyx_L2_error);
    Py_INCREF(o);
    Py_DECREF(((PyObject *)__pyx_v_7PyTorch_globalState));
    __pyx_v_7PyTorch_globalState = ((struct __pyx_obj_7PyTorch_GlobalState *)o);
  }
  else if (__Pyx_StrEq(name, "indirect")) {
    Py_INCREF(o);
    Py_DECREF(indirect);
    indirect = o;
  }
  else if (__Pyx_StrEq(name, "indirect_contiguous")) {
    Py_INCREF(o);
    Py_DECREF(indirect_contiguous);
    indirect_contiguous = o;
  }
  else if (__Pyx_StrEq(name, "strided")) {
    Py_INCREF(o);
    Py_DECREF(strided);
    strided = o;
  }
  else {
    if (PyObject_SetAttr(__pyx_m, py_name, o) < 0) goto bad;
  }
  return 0;
  __pyx_L2_error:;
  __Pyx_AddTraceback("PyTorch", __pyx_clineno, __pyx_lineno, __pyx_filename);
  bad:
  return -1;
}

























































































































static int
__Pyx_import_all_from(PyObject *locals, PyObject *v)
{
    PyObject *all = PyObject_GetAttrString(v, "__all__");
    PyObject *dict, *name, *value;
    int skip_leading_underscores = 0;
    int pos, err;

    if (all == NULL) {
        if (!PyErr_ExceptionMatches(PyExc_AttributeError))
            return -1;
        PyErr_Clear();
        dict = PyObject_GetAttrString(v, "__dict__");
        if (dict == NULL) {
            if (!PyErr_ExceptionMatches(PyExc_AttributeError))
                return -1;
            PyErr_SetString(PyExc_ImportError,
            "from-import-* object has no __dict__ and no __all__");
            return -1;
        }
#if PY_MAJOR_VERSION < 3
        all = PyObject_CallMethod(dict, (char *)"keys", NULL);
#else
        all = PyMapping_Keys(dict);
#endif
        Py_DECREF(dict);
        if (all == NULL)
            return -1;
        skip_leading_underscores = 1;
    }

    for (pos = 0, err = 0; ; pos++) {
        name = PySequence_GetItem(all, pos);
        if (name == NULL) {
            if (!PyErr_ExceptionMatches(PyExc_IndexError))
                err = -1;
            else
                PyErr_Clear();
            break;
        }
        if (skip_leading_underscores &&
#if PY_MAJOR_VERSION < 3
            PyString_Check(name) &&
            PyString_AS_STRING(name)[0] == '_')
#else
            PyUnicode_Check(name) &&
            PyUnicode_AS_UNICODE(name)[0] == '_')
#endif
        {
            Py_DECREF(name);
            continue;
        }
        value = PyObject_GetAttr(v, name);
        if (value == NULL)
            err = -1;
        else if (PyDict_CheckExact(locals))
            err = PyDict_SetItem(locals, name, value);
        else
            err = PyObject_SetItem(locals, name, value);
        Py_DECREF(name);
        Py_XDECREF(value);
        if (err != 0)
            break;
    }
    Py_DECREF(all);
    return err;
}


static int __pyx_import_star(PyObject* m) {

    int i;
    int ret = -1;
    char* s;
    PyObject *locals = 0;
    PyObject *list = 0;
#if PY_MAJOR_VERSION >= 3
    PyObject *utf8_name = 0;
#endif
    PyObject *name;
    PyObject *item;

    locals = PyDict_New();              if (!locals) goto bad;
    if (__Pyx_import_all_from(locals, m) < 0) goto bad;
    list = PyDict_Items(locals);        if (!list) goto bad;

    for(i=0; i<PyList_GET_SIZE(list); i++) {
        name = PyTuple_GET_ITEM(PyList_GET_ITEM(list, i), 0);
        item = PyTuple_GET_ITEM(PyList_GET_ITEM(list, i), 1);
#if PY_MAJOR_VERSION >= 3
        utf8_name = PyUnicode_AsUTF8String(name);
        if (!utf8_name) goto bad;
        s = PyBytes_AS_STRING(utf8_name);
        if (__pyx_import_star_set(item, name, s) < 0) goto bad;
        Py_DECREF(utf8_name); utf8_name = 0;
#else
        s = PyString_AsString(name);
        if (!s) goto bad;
        if (__pyx_import_star_set(item, name, s) < 0) goto bad;
#endif
    }
    ret = 0;

bad:
    Py_XDECREF(locals);
    Py_XDECREF(list);
#if PY_MAJOR_VERSION >= 3
    Py_XDECREF(utf8_name);
#endif
    return ret;
}



#if PY_MAJOR_VERSION >= 3
static struct PyModuleDef __pyx_moduledef = {
  #if PY_VERSION_HEX < 0x03020000
    { PyObject_HEAD_INIT(NULL) NULL, 0, NULL },
  #else
    PyModuleDef_HEAD_INIT,
  #endif
    "PyTorch",
    0, /* m_doc */
    -1, /* m_size */
    __pyx_methods /* m_methods */,
    NULL, /* m_reload */
    NULL, /* m_traverse */
    NULL, /* m_clear */
    NULL /* m_free */
};
#endif

static __Pyx_StringTabEntry __pyx_string_tab[] = {
  {&__pyx_kp_s_0f, __pyx_k_0f, sizeof(__pyx_k_0f), 0, 0, 1, 0},
  {&__pyx_kp_s_6g, __pyx_k_6g, sizeof(__pyx_k_6g), 0, 0, 1, 0},
  {&__pyx_n_s_ASCII, __pyx_k_ASCII, sizeof(__pyx_k_ASCII), 0, 0, 1, 1},
  {&__pyx_kp_s_Buffer_view_does_not_expose_stri, __pyx_k_Buffer_view_does_not_expose_stri, sizeof(__pyx_k_Buffer_view_does_not_expose_stri), 0, 0, 1, 0},
  {&__pyx_n_s_ByteStorage, __pyx_k_ByteStorage, sizeof(__pyx_k_ByteStorage), 0, 0, 1, 1},
  {&__pyx_kp_s_ByteTensor___cinit, __pyx_k_ByteTensor___cinit, sizeof(__pyx_k_ByteTensor___cinit), 0, 0, 1, 0},
  {&__pyx_kp_s_Can_only_create_a_buffer_that_is, __pyx_k_Can_only_create_a_buffer_that_is, sizeof(__pyx_k_Can_only_create_a_buffer_that_is), 0, 0, 1, 0},
  {&__pyx_kp_s_Cannot_index_with_type_s, __pyx_k_Cannot_index_with_type_s, sizeof(__pyx_k_Cannot_index_with_type_s), 0, 0, 1, 0},
  {&__pyx_n_s_DoubleStorage, __pyx_k_DoubleStorage, sizeof(__pyx_k_DoubleStorage), 0, 0, 1, 1},
  {&__pyx_kp_s_DoubleTensor___cinit, __pyx_k_DoubleTensor___cinit, sizeof(__pyx_k_DoubleTensor___cinit), 0, 0, 1, 0},
  {&__pyx_n_s_Ellipsis, __pyx_k_Ellipsis, sizeof(__pyx_k_Ellipsis), 0, 0, 1, 1},
  {&__pyx_kp_s_Empty_shape_tuple_for_cython_arr, __pyx_k_Empty_shape_tuple_for_cython_arr, sizeof(__pyx_k_Empty_shape_tuple_for_cython_arr), 0, 0, 1, 0},
  {&__pyx_n_s_FloatStorage, __pyx_k_FloatStorage, sizeof(__pyx_k_FloatStorage), 0, 0, 1, 1},
  {&__pyx_kp_s_FloatTensor___cinit, __pyx_k_FloatTensor___cinit, sizeof(__pyx_k_FloatTensor___cinit), 0, 0, 1, 0},
  {&__pyx_n_s_IndexError, __pyx_k_IndexError, sizeof(__pyx_k_IndexError), 0, 0, 1, 1},
  {&__pyx_kp_s_Indirect_dimensions_not_supporte, __pyx_k_Indirect_dimensions_not_supporte, sizeof(__pyx_k_Indirect_dimensions_not_supporte), 0, 0, 1, 0},
  {&__pyx_kp_s_Invalid_arg_type_for_second, __pyx_k_Invalid_arg_type_for_second, sizeof(__pyx_k_Invalid_arg_type_for_second), 0, 0, 1, 0},
  {&__pyx_kp_s_Invalid_mode_expected_c_or_fortr, __pyx_k_Invalid_mode_expected_c_or_fortr, sizeof(__pyx_k_Invalid_mode_expected_c_or_fortr), 0, 0, 1, 0},
  {&__pyx_kp_s_Invalid_shape_in_axis_d_d, __pyx_k_Invalid_shape_in_axis_d_d, sizeof(__pyx_k_Invalid_shape_in_axis_d_d), 0, 0, 1, 0},
  {&__pyx_n_s_L, __pyx_k_L, sizeof(__pyx_k_L), 0, 0, 1, 1},
  {&__pyx_n_s_LongStorage, __pyx_k_LongStorage, sizeof(__pyx_k_LongStorage), 0, 0, 1, 1},
  {&__pyx_kp_s_LongTensor___cinit, __pyx_k_LongTensor___cinit, sizeof(__pyx_k_LongTensor___cinit), 0, 0, 1, 0},
  {&__pyx_n_s_MemoryError, __pyx_k_MemoryError, sizeof(__pyx_k_MemoryError), 0, 0, 1, 1},
  {&__pyx_kp_s_MemoryView_of_r_at_0x_x, __pyx_k_MemoryView_of_r_at_0x_x, sizeof(__pyx_k_MemoryView_of_r_at_0x_x), 0, 0, 1, 0},
  {&__pyx_kp_s_MemoryView_of_r_object, __pyx_k_MemoryView_of_r_object, sizeof(__pyx_k_MemoryView_of_r_object), 0, 0, 1, 0},
  {&__pyx_kp_s_Not_implemented_dims_2, __pyx_k_Not_implemented_dims_2, sizeof(__pyx_k_Not_implemented_dims_2), 0, 0, 1, 0},
  {&__pyx_kp_s_Not_implemented_for_dims, __pyx_k_Not_implemented_for_dims, sizeof(__pyx_k_Not_implemented_for_dims), 0, 0, 1, 0},
  {&__pyx_kp_s_Not_implemented_for_dims_dims, __pyx_k_Not_implemented_for_dims_dims, sizeof(__pyx_k_Not_implemented_for_dims_dims), 0, 0, 1, 0},
  {&__pyx_kp_s_Not_implemented_len_args, __pyx_k_Not_implemented_len_args, sizeof(__pyx_k_Not_implemented_len_args), 0, 0, 1, 0},
  {&__pyx_n_s_Number, __pyx_k_Number, sizeof(__pyx_k_Number), 0, 0, 1, 1},
  {&__pyx_n_b_O, __pyx_k_O, sizeof(__pyx_k_O), 0, 0, 0, 1},
  {&__pyx_kp_s_Out_of_bounds_on_buffer_access_a, __pyx_k_Out_of_bounds_on_buffer_access_a, sizeof(__pyx_k_Out_of_bounds_on_buffer_access_a), 0, 0, 1, 0},
  {&__pyx_n_s_PyTorch, __pyx_k_PyTorch, sizeof(__pyx_k_PyTorch), 0, 0, 1, 1},
  {&__pyx_kp_s_Raising_exception, __pyx_k_Raising_exception, sizeof(__pyx_k_Raising_exception), 0, 0, 1, 0},
  {&__pyx_n_s_Storage, __pyx_k_Storage, sizeof(__pyx_k_Storage), 0, 0, 1, 1},
  {&__pyx_n_s_TypeError, __pyx_k_TypeError, sizeof(__pyx_k_TypeError), 0, 0, 1, 1},
  {&__pyx_kp_s_Unable_to_convert_item_to_object, __pyx_k_Unable_to_convert_item_to_object, sizeof(__pyx_k_Unable_to_convert_item_to_object), 0, 0, 1, 0},
  {&__pyx_kp_s_Unallocated_an_already_deallocat, __pyx_k_Unallocated_an_already_deallocat, sizeof(__pyx_k_Unallocated_an_already_deallocat), 0, 0, 1, 0},
  {&__pyx_n_s_ValueError, __pyx_k_ValueError, sizeof(__pyx_k_ValueError), 0, 0, 1, 1},
  {&__pyx_kp_s__10, __pyx_k__10, sizeof(__pyx_k__10), 0, 0, 1, 0},
  {&__pyx_kp_s__11, __pyx_k__11, sizeof(__pyx_k__11), 0, 0, 1, 0},
  {&__pyx_kp_s__12, __pyx_k__12, sizeof(__pyx_k__12), 0, 0, 1, 0},
  {&__pyx_n_s__129, __pyx_k__129, sizeof(__pyx_k__129), 0, 0, 1, 1},
  {&__pyx_kp_s__13, __pyx_k__13, sizeof(__pyx_k__13), 0, 0, 1, 0},
  {&__pyx_kp_s__7, __pyx_k__7, sizeof(__pyx_k__7), 0, 0, 1, 0},
  {&__pyx_kp_s__8, __pyx_k__8, sizeof(__pyx_k__8), 0, 0, 1, 0},
  {&__pyx_kp_s__9, __pyx_k__9, sizeof(__pyx_k__9), 0, 0, 1, 0},
  {&__pyx_n_s_a, __pyx_k_a, sizeof(__pyx_k_a), 0, 0, 1, 1},
  {&__pyx_n_s_allocate, __pyx_k_allocate, sizeof(__pyx_k_allocate), 0, 0, 1, 1},
  {&__pyx_n_s_allocate_buffer, __pyx_k_allocate_buffer, sizeof(__pyx_k_allocate_buffer), 0, 0, 1, 1},
  {&__pyx_n_s_array, __pyx_k_array, sizeof(__pyx_k_array), 0, 0, 1, 1},
  {&__pyx_n_s_asByteTensor, __pyx_k_asByteTensor, sizeof(__pyx_k_asByteTensor), 0, 0, 1, 1},
  {&__pyx_n_s_asDoubleTensor, __pyx_k_asDoubleTensor, sizeof(__pyx_k_asDoubleTensor), 0, 0, 1, 1},
  {&__pyx_n_s_asFloatTensor, __pyx_k_asFloatTensor, sizeof(__pyx_k_asFloatTensor), 0, 0, 1, 1},
  {&__pyx_n_s_as_string, __pyx_k_as_string, sizeof(__pyx_k_as_string), 0, 0, 1, 1},
  {&__pyx_n_s_b, __pyx_k_b, sizeof(__pyx_k_b), 0, 0, 1, 1},
  {&__pyx_n_s_base, __pyx_k_base, sizeof(__pyx_k_base), 0, 0, 1, 1},
  {&__pyx_n_s_basicConfig, __pyx_k_basicConfig, sizeof(__pyx_k_basicConfig), 0, 0, 1, 1},
  {&__pyx_n_s_c, __pyx_k_c, sizeof(__pyx_k_c), 0, 0, 1, 1},
  {&__pyx_n_u_c, __pyx_k_c, sizeof(__pyx_k_c), 0, 1, 0, 1},
  {&__pyx_kp_s_cannot_provide_arguments_to_init, __pyx_k_cannot_provide_arguments_to_init, sizeof(__pyx_k_cannot_provide_arguments_to_init), 0, 0, 1, 0},
  {&__pyx_n_s_class, __pyx_k_class, sizeof(__pyx_k_class), 0, 0, 1, 1},
  {&__pyx_kp_s_class_numpy_ndarray, __pyx_k_class_numpy_ndarray, sizeof(__pyx_k_class_numpy_ndarray), 0, 0, 1, 0},
  {&__pyx_n_s_contiguous, __pyx_k_contiguous, sizeof(__pyx_k_contiguous), 0, 0, 1, 1},
  {&__pyx_kp_s_contiguous_and_direct, __pyx_k_contiguous_and_direct, sizeof(__pyx_k_contiguous_and_direct), 0, 0, 1, 0},
  {&__pyx_kp_s_contiguous_and_indirect, __pyx_k_contiguous_and_indirect, sizeof(__pyx_k_contiguous_and_indirect), 0, 0, 1, 0},
  {&__pyx_n_s_d, __pyx_k_d, sizeof(__pyx_k_d), 0, 0, 1, 1},
  {&__pyx_kp_s_dealloc___tensor_never_allocat, __pyx_k_dealloc___tensor_never_allocat, sizeof(__pyx_k_dealloc___tensor_never_allocat), 0, 0, 1, 0},
  {&__pyx_n_s_debug, __pyx_k_debug, sizeof(__pyx_k_debug), 0, 0, 1, 1},
  {&__pyx_n_s_dimension, __pyx_k_dimension, sizeof(__pyx_k_dimension), 0, 0, 1, 1},
  {&__pyx_n_s_dims, __pyx_k_dims, sizeof(__pyx_k_dims), 0, 0, 1, 1},
  {&__pyx_kp_s_dims_dims_not_implemented_please, __pyx_k_dims_dims_not_implemented_please, sizeof(__pyx_k_dims_dims_not_implemented_please), 0, 0, 1, 0},
  {&__pyx_n_s_dtype, __pyx_k_dtype, sizeof(__pyx_k_dtype), 0, 0, 1, 1},
  {&__pyx_n_s_dtype_is_object, __pyx_k_dtype_is_object, sizeof(__pyx_k_dtype_is_object), 0, 0, 1, 1},
  {&__pyx_n_s_encode, __pyx_k_encode, sizeof(__pyx_k_encode), 0, 0, 1, 1},
  {&__pyx_n_s_enumerate, __pyx_k_enumerate, sizeof(__pyx_k_enumerate), 0, 0, 1, 1},
  {&__pyx_n_s_error, __pyx_k_error, sizeof(__pyx_k_error), 0, 0, 1, 1},
  {&__pyx_n_s_firstIndex, __pyx_k_firstIndex, sizeof(__pyx_k_firstIndex), 0, 0, 1, 1},
  {&__pyx_n_s_flags, __pyx_k_flags, sizeof(__pyx_k_flags), 0, 0, 1, 1},
  {&__pyx_n_s_float32, __pyx_k_float32, sizeof(__pyx_k_float32), 0, 0, 1, 1},
  {&__pyx_n_s_float64, __pyx_k_float64, sizeof(__pyx_k_float64), 0, 0, 1, 1},
  {&__pyx_n_s_floattensor, __pyx_k_floattensor, sizeof(__pyx_k_floattensor), 0, 0, 1, 1},
  {&__pyx_n_s_floor, __pyx_k_floor, sizeof(__pyx_k_floor), 0, 0, 1, 1},
  {&__pyx_n_s_format, __pyx_k_format, sizeof(__pyx_k_format), 0, 0, 1, 1},
  {&__pyx_n_s_fortran, __pyx_k_fortran, sizeof(__pyx_k_fortran), 0, 0, 1, 1},
  {&__pyx_n_u_fortran, __pyx_k_fortran, sizeof(__pyx_k_fortran), 0, 1, 0, 1},
  {&__pyx_n_s_get1d, __pyx_k_get1d, sizeof(__pyx_k_get1d), 0, 0, 1, 1},
  {&__pyx_n_s_get2d, __pyx_k_get2d, sizeof(__pyx_k_get2d), 0, 0, 1, 1},
  {&__pyx_n_s_getGlobal, __pyx_k_getGlobal, sizeof(__pyx_k_getGlobal), 0, 0, 1, 1},
  {&__pyx_n_s_getGlobalState, __pyx_k_getGlobalState, sizeof(__pyx_k_getGlobalState), 0, 0, 1, 1},
  {&__pyx_n_s_getLogger, __pyx_k_getLogger, sizeof(__pyx_k_getLogger), 0, 0, 1, 1},
  {&__pyx_kp_s_got_differing_extents_in_dimensi, __pyx_k_got_differing_extents_in_dimensi, sizeof(__pyx_k_got_differing_extents_in_dimensi), 0, 0, 1, 0},
  {&__pyx_kp_s_home_steb_inst_pytorch_src_PyTo, __pyx_k_home_steb_inst_pytorch_src_PyTo, sizeof(__pyx_k_home_steb_inst_pytorch_src_PyTo), 0, 0, 1, 0},
  {&__pyx_n_s_id, __pyx_k_id, sizeof(__pyx_k_id), 0, 0, 1, 1},
  {&__pyx_n_s_import, __pyx_k_import, sizeof(__pyx_k_import), 0, 0, 1, 1},
  {&__pyx_n_s_init, __pyx_k_init, sizeof(__pyx_k_init), 0, 0, 1, 1},
  {&__pyx_n_s_isContiguous, __pyx_k_isContiguous, sizeof(__pyx_k_isContiguous), 0, 0, 1, 1},
  {&__pyx_n_s_itemsize, __pyx_k_itemsize, sizeof(__pyx_k_itemsize), 0, 0, 1, 1},
  {&__pyx_kp_s_itemsize_0_for_cython_array, __pyx_k_itemsize_0_for_cython_array, sizeof(__pyx_k_itemsize_0_for_cython_array), 0, 0, 1, 0},
  {&__pyx_n_s_lambda, __pyx_k_lambda, sizeof(__pyx_k_lambda), 0, 0, 1, 1},
  {&__pyx_n_s_libName, __pyx_k_libName, sizeof(__pyx_k_libName), 0, 0, 1, 1},
  {&__pyx_n_s_log10, __pyx_k_log10, sizeof(__pyx_k_log10), 0, 0, 1, 1},
  {&__pyx_n_s_logger, __pyx_k_logger, sizeof(__pyx_k_logger), 0, 0, 1, 1},
  {&__pyx_n_s_logging, __pyx_k_logging, sizeof(__pyx_k_logging), 0, 0, 1, 1},
  {&__pyx_n_s_main, __pyx_k_main, sizeof(__pyx_k_main), 0, 0, 1, 1},
  {&__pyx_n_s_manualSeed, __pyx_k_manualSeed, sizeof(__pyx_k_manualSeed), 0, 0, 1, 1},
  {&__pyx_n_s_math, __pyx_k_math, sizeof(__pyx_k_math), 0, 0, 1, 1},
  {&__pyx_n_s_max, __pyx_k_max, sizeof(__pyx_k_max), 0, 0, 1, 1},
  {&__pyx_n_s_mean, __pyx_k_mean, sizeof(__pyx_k_mean), 0, 0, 1, 1},
  {&__pyx_n_s_median, __pyx_k_median, sizeof(__pyx_k_median), 0, 0, 1, 1},
  {&__pyx_n_s_memview, __pyx_k_memview, sizeof(__pyx_k_memview), 0, 0, 1, 1},
  {&__pyx_n_s_min, __pyx_k_min, sizeof(__pyx_k_min), 0, 0, 1, 1},
  {&__pyx_n_s_mode, __pyx_k_mode, sizeof(__pyx_k_mode), 0, 0, 1, 1},
  {&__pyx_n_s_myarray, __pyx_k_myarray, sizeof(__pyx_k_myarray), 0, 0, 1, 1},
  {&__pyx_n_s_myarraymv, __pyx_k_myarraymv, sizeof(__pyx_k_myarraymv), 0, 0, 1, 1},
  {&__pyx_n_s_name, __pyx_k_name, sizeof(__pyx_k_name), 0, 0, 1, 1},
  {&__pyx_n_s_name_2, __pyx_k_name_2, sizeof(__pyx_k_name_2), 0, 0, 1, 1},
  {&__pyx_n_s_ndim, __pyx_k_ndim, sizeof(__pyx_k_ndim), 0, 0, 1, 1},
  {&__pyx_n_s_new, __pyx_k_new, sizeof(__pyx_k_new), 0, 0, 1, 1},
  {&__pyx_n_s_newTensorC, __pyx_k_newTensorC, sizeof(__pyx_k_newTensorC), 0, 0, 1, 1},
  {&__pyx_n_s_newWithData, __pyx_k_newWithData, sizeof(__pyx_k_newWithData), 0, 0, 1, 1},
  {&__pyx_n_s_newWithSize, __pyx_k_newWithSize, sizeof(__pyx_k_newWithSize), 0, 0, 1, 1},
  {&__pyx_n_s_newWithStorage, __pyx_k_newWithStorage, sizeof(__pyx_k_newWithStorage), 0, 0, 1, 1},
  {&__pyx_n_s_newWithStorage1d, __pyx_k_newWithStorage1d, sizeof(__pyx_k_newWithStorage1d), 0, 0, 1, 1},
  {&__pyx_n_s_newWithStorage2d, __pyx_k_newWithStorage2d, sizeof(__pyx_k_newWithStorage2d), 0, 0, 1, 1},
  {&__pyx_n_s_newWithStorage3d, __pyx_k_newWithStorage3d, sizeof(__pyx_k_newWithStorage3d), 0, 0, 1, 1},
  {&__pyx_n_s_newWithStorage4d, __pyx_k_newWithStorage4d, sizeof(__pyx_k_newWithStorage4d), 0, 0, 1, 1},
  {&__pyx_kp_s_not_implemented, __pyx_k_not_implemented, sizeof(__pyx_k_not_implemented), 0, 0, 1, 0},
  {&__pyx_kp_s_not_implemented_for_Byte, __pyx_k_not_implemented_for_Byte, sizeof(__pyx_k_not_implemented_for_Byte), 0, 0, 1, 0},
  {&__pyx_kp_s_not_implemented_for_Double, __pyx_k_not_implemented_for_Double, sizeof(__pyx_k_not_implemented_for_Double), 0, 0, 1, 0},
  {&__pyx_kp_s_not_implemented_for_Float, __pyx_k_not_implemented_for_Float, sizeof(__pyx_k_not_implemented_for_Float), 0, 0, 1, 0},
  {&__pyx_kp_s_not_implemented_for_Long, __pyx_k_not_implemented_for_Long, sizeof(__pyx_k_not_implemented_for_Long), 0, 0, 1, 0},
  {&__pyx_n_s_np, __pyx_k_np, sizeof(__pyx_k_np), 0, 0, 1, 1},
  {&__pyx_n_s_numbers, __pyx_k_numbers, sizeof(__pyx_k_numbers), 0, 0, 1, 1},
  {&__pyx_n_s_numpy, __pyx_k_numpy, sizeof(__pyx_k_numpy), 0, 0, 1, 1},
  {&__pyx_n_s_obj, __pyx_k_obj, sizeof(__pyx_k_obj), 0, 0, 1, 1},
  {&__pyx_n_s_offset, __pyx_k_offset, sizeof(__pyx_k_offset), 0, 0, 1, 1},
  {&__pyx_n_s_p, __pyx_k_p, sizeof(__pyx_k_p), 0, 0, 1, 1},
  {&__pyx_n_s_pack, __pyx_k_pack, sizeof(__pyx_k_pack), 0, 0, 1, 1},
  {&__pyx_n_s_popByteTensor, __pyx_k_popByteTensor, sizeof(__pyx_k_popByteTensor), 0, 0, 1, 1},
  {&__pyx_n_s_popDoubleTensor, __pyx_k_popDoubleTensor, sizeof(__pyx_k_popDoubleTensor), 0, 0, 1, 1},
  {&__pyx_n_s_popFloatTensor, __pyx_k_popFloatTensor, sizeof(__pyx_k_popFloatTensor), 0, 0, 1, 1},
  {&__pyx_n_s_pushByteTensor, __pyx_k_pushByteTensor, sizeof(__pyx_k_pushByteTensor), 0, 0, 1, 1},
  {&__pyx_n_s_pushDoubleTensor, __pyx_k_pushDoubleTensor, sizeof(__pyx_k_pushDoubleTensor), 0, 0, 1, 1},
  {&__pyx_n_s_pushFloatTensor, __pyx_k_pushFloatTensor, sizeof(__pyx_k_pushFloatTensor), 0, 0, 1, 1},
  {&__pyx_n_s_pyx_getbuffer, __pyx_k_pyx_getbuffer, sizeof(__pyx_k_pyx_getbuffer), 0, 0, 1, 1},
  {&__pyx_n_s_pyx_vtable, __pyx_k_pyx_vtable, sizeof(__pyx_k_pyx_vtable), 0, 0, 1, 1},
  {&__pyx_n_s_range, __pyx_k_range, sizeof(__pyx_k_range), 0, 0, 1, 1},
  {&__pyx_n_s_require, __pyx_k_require, sizeof(__pyx_k_require), 0, 0, 1, 1},
  {&__pyx_n_s_reshape, __pyx_k_reshape, sizeof(__pyx_k_reshape), 0, 0, 1, 1},
  {&__pyx_n_s_resize, __pyx_k_resize, sizeof(__pyx_k_resize), 0, 0, 1, 1},
  {&__pyx_n_s_resize2d, __pyx_k_resize2d, sizeof(__pyx_k_resize2d), 0, 0, 1, 1},
  {&__pyx_n_s_round, __pyx_k_round, sizeof(__pyx_k_round), 0, 0, 1, 1},
  {&__pyx_n_s_round_sig, __pyx_k_round_sig, sizeof(__pyx_k_round_sig), 0, 0, 1, 1},
  {&__pyx_n_s_seed, __pyx_k_seed, sizeof(__pyx_k_seed), 0, 0, 1, 1},
  {&__pyx_n_s_set1d, __pyx_k_set1d, sizeof(__pyx_k_set1d), 0, 0, 1, 1},
  {&__pyx_n_s_set2d, __pyx_k_set2d, sizeof(__pyx_k_set2d), 0, 0, 1, 1},
  {&__pyx_n_s_shape, __pyx_k_shape, sizeof(__pyx_k_shape), 0, 0, 1, 1},
  {&__pyx_n_s_show_size, __pyx_k_show_size, sizeof(__pyx_k_show_size), 0, 0, 1, 1},
  {&__pyx_n_s_sig, __pyx_k_sig, sizeof(__pyx_k_sig), 0, 0, 1, 1},
  {&__pyx_n_s_sigma, __pyx_k_sigma, sizeof(__pyx_k_sigma), 0, 0, 1, 1},
  {&__pyx_n_s_size, __pyx_k_size, sizeof(__pyx_k_size), 0, 0, 1, 1},
  {&__pyx_n_s_size0, __pyx_k_size0, sizeof(__pyx_k_size0), 0, 0, 1, 1},
  {&__pyx_n_s_size1, __pyx_k_size1, sizeof(__pyx_k_size1), 0, 0, 1, 1},
  {&__pyx_n_s_size2, __pyx_k_size2, sizeof(__pyx_k_size2), 0, 0, 1, 1},
  {&__pyx_n_s_size3, __pyx_k_size3, sizeof(__pyx_k_size3), 0, 0, 1, 1},
  {&__pyx_n_s_start, __pyx_k_start, sizeof(__pyx_k_start), 0, 0, 1, 1},
  {&__pyx_n_s_staticmethod, __pyx_k_staticmethod, sizeof(__pyx_k_staticmethod), 0, 0, 1, 1},
  {&__pyx_n_s_stdv, __pyx_k_stdv, sizeof(__pyx_k_stdv), 0, 0, 1, 1},
  {&__pyx_n_s_step, __pyx_k_step, sizeof(__pyx_k_step), 0, 0, 1, 1},
  {&__pyx_n_s_stop, __pyx_k_stop, sizeof(__pyx_k_stop), 0, 0, 1, 1},
  {&__pyx_n_s_storage, __pyx_k_storage, sizeof(__pyx_k_storage), 0, 0, 1, 1},
  {&__pyx_n_s_stride, __pyx_k_stride, sizeof(__pyx_k_stride), 0, 0, 1, 1},
  {&__pyx_n_s_stride0, __pyx_k_stride0, sizeof(__pyx_k_stride0), 0, 0, 1, 1},
  {&__pyx_n_s_stride1, __pyx_k_stride1, sizeof(__pyx_k_stride1), 0, 0, 1, 1},
  {&__pyx_n_s_stride2, __pyx_k_stride2, sizeof(__pyx_k_stride2), 0, 0, 1, 1},
  {&__pyx_n_s_stride3, __pyx_k_stride3, sizeof(__pyx_k_stride3), 0, 0, 1, 1},
  {&__pyx_n_s_strideSoFar, __pyx_k_strideSoFar, sizeof(__pyx_k_strideSoFar), 0, 0, 1, 1},
  {&__pyx_kp_s_strided_and_direct, __pyx_k_strided_and_direct, sizeof(__pyx_k_strided_and_direct), 0, 0, 1, 0},
  {&__pyx_kp_s_strided_and_direct_or_indirect, __pyx_k_strided_and_direct_or_indirect, sizeof(__pyx_k_strided_and_direct_or_indirect), 0, 0, 1, 0},
  {&__pyx_kp_s_strided_and_indirect, __pyx_k_strided_and_indirect, sizeof(__pyx_k_strided_and_indirect), 0, 0, 1, 0},
  {&__pyx_n_s_struct, __pyx_k_struct, sizeof(__pyx_k_struct), 0, 0, 1, 1},
  {&__pyx_n_s_tensor, __pyx_k_tensor, sizeof(__pyx_k_tensor), 0, 0, 1, 1},
  {&__pyx_n_s_tensorC, __pyx_k_tensorC, sizeof(__pyx_k_tensorC), 0, 0, 1, 1},
  {&__pyx_n_s_test, __pyx_k_test, sizeof(__pyx_k_test), 0, 0, 1, 1},
  {&__pyx_kp_s_torch_ByteTensor_of_size, __pyx_k_torch_ByteTensor_of_size, sizeof(__pyx_k_torch_ByteTensor_of_size), 0, 0, 1, 0},
  {&__pyx_kp_s_torch_ByteTensor_of_size_2, __pyx_k_torch_ByteTensor_of_size_2, sizeof(__pyx_k_torch_ByteTensor_of_size_2), 0, 0, 1, 0},
  {&__pyx_kp_s_torch_ByteTensor_with_no_dimens, __pyx_k_torch_ByteTensor_with_no_dimens, sizeof(__pyx_k_torch_ByteTensor_with_no_dimens), 0, 0, 1, 0},
  {&__pyx_kp_s_torch_DoubleTensor_of_size, __pyx_k_torch_DoubleTensor_of_size, sizeof(__pyx_k_torch_DoubleTensor_of_size), 0, 0, 1, 0},
  {&__pyx_kp_s_torch_DoubleTensor_of_size_2, __pyx_k_torch_DoubleTensor_of_size_2, sizeof(__pyx_k_torch_DoubleTensor_of_size_2), 0, 0, 1, 0},
  {&__pyx_kp_s_torch_DoubleTensor_with_no_dime, __pyx_k_torch_DoubleTensor_with_no_dime, sizeof(__pyx_k_torch_DoubleTensor_with_no_dime), 0, 0, 1, 0},
  {&__pyx_kp_s_torch_FloatTensor_of_size, __pyx_k_torch_FloatTensor_of_size, sizeof(__pyx_k_torch_FloatTensor_of_size), 0, 0, 1, 0},
  {&__pyx_kp_s_torch_FloatTensor_of_size_2, __pyx_k_torch_FloatTensor_of_size_2, sizeof(__pyx_k_torch_FloatTensor_of_size_2), 0, 0, 1, 0},
  {&__pyx_kp_s_torch_FloatTensor_with_no_dimen, __pyx_k_torch_FloatTensor_with_no_dimen, sizeof(__pyx_k_torch_FloatTensor_with_no_dimen), 0, 0, 1, 0},
  {&__pyx_kp_s_torch_LongTensor_of_size, __pyx_k_torch_LongTensor_of_size, sizeof(__pyx_k_torch_LongTensor_of_size), 0, 0, 1, 0},
  {&__pyx_kp_s_torch_LongTensor_of_size_2, __pyx_k_torch_LongTensor_of_size_2, sizeof(__pyx_k_torch_LongTensor_of_size_2), 0, 0, 1, 0},
  {&__pyx_kp_s_torch_LongTensor_with_no_dimens, __pyx_k_torch_LongTensor_with_no_dimens, sizeof(__pyx_k_torch_LongTensor_with_no_dimens), 0, 0, 1, 0},
  {&__pyx_n_s_totalSize, __pyx_k_totalSize, sizeof(__pyx_k_totalSize), 0, 0, 1, 1},
  {&__pyx_kp_s_type_numpy_ndarray, __pyx_k_type_numpy_ndarray, sizeof(__pyx_k_type_numpy_ndarray), 0, 0, 1, 0},
  {&__pyx_n_s_uint8, __pyx_k_uint8, sizeof(__pyx_k_uint8), 0, 0, 1, 1},
  {&__pyx_kp_s_unable_to_allocate_array_data, __pyx_k_unable_to_allocate_array_data, sizeof(__pyx_k_unable_to_allocate_array_data), 0, 0, 1, 0},
  {&__pyx_kp_s_unable_to_allocate_shape_and_str, __pyx_k_unable_to_allocate_shape_and_str, sizeof(__pyx_k_unable_to_allocate_shape_and_str), 0, 0, 1, 0},
  {&__pyx_n_s_unpack, __pyx_k_unpack, sizeof(__pyx_k_unpack), 0, 0, 1, 1},
  {&__pyx_kp_s_utf_8, __pyx_k_utf_8, sizeof(__pyx_k_utf_8), 0, 0, 1, 0},
  {&__pyx_n_s_value, __pyx_k_value, sizeof(__pyx_k_value), 0, 0, 1, 1},
  {&__pyx_n_s_x, __pyx_k_x, sizeof(__pyx_k_x), 0, 0, 1, 1},
  {&__pyx_n_s_x0, __pyx_k_x0, sizeof(__pyx_k_x0), 0, 0, 1, 1},
  {&__pyx_n_s_x1, __pyx_k_x1, sizeof(__pyx_k_x1), 0, 0, 1, 1},
  {&__pyx_n_s_zeros, __pyx_k_zeros, sizeof(__pyx_k_zeros), 0, 0, 1, 1},
  {0, 0, 0, 0, 0, 0, 0}
};
static int __Pyx_InitCachedBuiltins(void) {
  __pyx_builtin_staticmethod = __Pyx_GetBuiltinName(__pyx_n_s_staticmethod); if (!__pyx_builtin_staticmethod) __PYX_ERR(0, 628, __pyx_L1_error)
  __pyx_builtin_round = __Pyx_GetBuiltinName(__pyx_n_s_round); if (!__pyx_builtin_round) __PYX_ERR(0, 31, __pyx_L1_error)
  __pyx_builtin_range = __Pyx_GetBuiltinName(__pyx_n_s_range); if (!__pyx_builtin_range) __PYX_ERR(0, 481, __pyx_L1_error)
  __pyx_builtin_MemoryError = __Pyx_GetBuiltinName(__pyx_n_s_MemoryError); if (!__pyx_builtin_MemoryError) __PYX_ERR(1, 107, __pyx_L1_error)
  __pyx_builtin_ValueError = __Pyx_GetBuiltinName(__pyx_n_s_ValueError); if (!__pyx_builtin_ValueError) __PYX_ERR(2, 131, __pyx_L1_error)
  __pyx_builtin_enumerate = __Pyx_GetBuiltinName(__pyx_n_s_enumerate); if (!__pyx_builtin_enumerate) __PYX_ERR(2, 149, __pyx_L1_error)
  __pyx_builtin_Ellipsis = __Pyx_GetBuiltinName(__pyx_n_s_Ellipsis); if (!__pyx_builtin_Ellipsis) __PYX_ERR(2, 396, __pyx_L1_error)
  __pyx_builtin_TypeError = __Pyx_GetBuiltinName(__pyx_n_s_TypeError); if (!__pyx_builtin_TypeError) __PYX_ERR(2, 425, __pyx_L1_error)
  __pyx_builtin_id = __Pyx_GetBuiltinName(__pyx_n_s_id); if (!__pyx_builtin_id) __PYX_ERR(2, 599, __pyx_L1_error)
  __pyx_builtin_IndexError = __Pyx_GetBuiltinName(__pyx_n_s_IndexError); if (!__pyx_builtin_IndexError) __PYX_ERR(2, 818, __pyx_L1_error)
  return 0;
  __pyx_L1_error:;
  return -1;
}

static int __Pyx_InitCachedConstants(void) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__Pyx_InitCachedConstants", 0);

  /* "PyTorch.pyx":384
 *         cdef THLongTensor *newTensorC
 *         cdef _LongTensor templateObject
 *         logger.debug('LongTensor.__cinit__')             # <<<<<<<<<<<<<<
 * #        cdef THLongStorage *storageC
 * #        cdef long addr
 */
  __pyx_tuple_ = PyTuple_Pack(1, __pyx_kp_s_LongTensor___cinit); if (unlikely(!__pyx_tuple_)) __PYX_ERR(0, 384, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple_);
  __Pyx_GIVEREF(__pyx_tuple_);

  /* "PyTorch.pyx":401
 *             for arg in args:
 *                 if not isinstance(arg, int):
 *                     raise Exception('cannot provide arguments to initializer')             # <<<<<<<<<<<<<<
 *             if len(args) == 0:
 *                 # print('no args, calling THLongTensor_new()')
 */
  __pyx_tuple__2 = PyTuple_Pack(1, __pyx_kp_s_cannot_provide_arguments_to_init); if (unlikely(!__pyx_tuple__2)) __PYX_ERR(0, 401, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__2);
  __Pyx_GIVEREF(__pyx_tuple__2);

  /* "PyTorch.pyx":418
 *                 self.native = THLongTensor_newWithSize4d(args[0], args[1], args[2], args[3])
 *             else:
 *                 logger.error('Raising exception...')             # <<<<<<<<<<<<<<
 *                 raise Exception('Not implemented, len(args)=' + str(len(args)))
 * #        else:
 */
  __pyx_tuple__3 = PyTuple_Pack(1, __pyx_kp_s_Raising_exception); if (unlikely(!__pyx_tuple__3)) __PYX_ERR(0, 418, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__3);
  __Pyx_GIVEREF(__pyx_tuple__3);

  /* "PyTorch.pyx":458
 *    #            # print('   size[', i, ']', THFloatTensor_size(self.thFloatTensor, i))
 *             if refCount < 1:
 *                 raise Exception('Unallocated an already deallocated tensor... :-O')  # Hmmm, seems this exceptoin wont go anywhere useful... :-P             # <<<<<<<<<<<<<<
 *             THLongTensor_free(self.native)
 *         else:
 */
  __pyx_tuple__4 = PyTuple_Pack(1, __pyx_kp_s_Unallocated_an_already_deallocat); if (unlikely(!__pyx_tuple__4)) __PYX_ERR(0, 458, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__4);
  __Pyx_GIVEREF(__pyx_tuple__4);

  /* "PyTorch.pyx":461
 *             THLongTensor_free(self.native)
 *         else:
 *             logger.debug('__dealloc__ tensor never allocated')             # <<<<<<<<<<<<<<
 * 
 *     def nElement(_LongTensor self):
 */
  __pyx_tuple__5 = PyTuple_Pack(1, __pyx_kp_s_dealloc___tensor_never_allocat); if (unlikely(!__pyx_tuple__5)) __PYX_ERR(0, 461, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__5);
  __Pyx_GIVEREF(__pyx_tuple__5);

  /* "PyTorch.pyx":477
 * 
 *         if dtype is None:
 *           raise Exception("not implemented for Long")             # <<<<<<<<<<<<<<
 * #        print('dtype', dtype)
 *         if dims >= 1:
 */
  __pyx_tuple__6 = PyTuple_Pack(1, __pyx_kp_s_not_implemented_for_Long); if (unlikely(!__pyx_tuple__6)) __PYX_ERR(0, 477, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__6);
  __Pyx_GIVEREF(__pyx_tuple__6);

  /* "PyTorch.pyx":581
 *             return res
 *         else:
 *             raise Exception("Not implemented: dims > 2")             # <<<<<<<<<<<<<<
 * 
 *     def __getitem__(_LongTensor self, int index):
 */
  __pyx_tuple__14 = PyTuple_Pack(1, __pyx_kp_s_Not_implemented_dims_2); if (unlikely(!__pyx_tuple__14)) __PYX_ERR(0, 581, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__14);
  __Pyx_GIVEREF(__pyx_tuple__14);

  /* "PyTorch.pyx":593
 *             self.set1d(index, value)
 *         else:
 *             raise Exception("not implemented")             # <<<<<<<<<<<<<<
 * 
 *     def fill(_LongTensor self, long value):
 */
  __pyx_tuple__15 = PyTuple_Pack(1, __pyx_kp_s_not_implemented); if (unlikely(!__pyx_tuple__15)) __PYX_ERR(0, 593, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__15);
  __Pyx_GIVEREF(__pyx_tuple__15);

  /* "PyTorch.pyx":861
 *         cdef THFloatTensor *newTensorC
 *         cdef _FloatTensor templateObject
 *         logger.debug('FloatTensor.__cinit__')             # <<<<<<<<<<<<<<
 * #        cdef THFloatStorage *storageC
 * #        cdef long addr
 */
  __pyx_tuple__16 = PyTuple_Pack(1, __pyx_kp_s_FloatTensor___cinit); if (unlikely(!__pyx_tuple__16)) __PYX_ERR(0, 861, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__16);
  __Pyx_GIVEREF(__pyx_tuple__16);

  /* "PyTorch.pyx":878
 *             for arg in args:
 *                 if not isinstance(arg, int):
 *                     raise Exception('cannot provide arguments to initializer')             # <<<<<<<<<<<<<<
 *             if len(args) == 0:
 *                 # print('no args, calling THFloatTensor_new()')
 */
  __pyx_tuple__17 = PyTuple_Pack(1, __pyx_kp_s_cannot_provide_arguments_to_init); if (unlikely(!__pyx_tuple__17)) __PYX_ERR(0, 878, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__17);
  __Pyx_GIVEREF(__pyx_tuple__17);

  /* "PyTorch.pyx":895
 *                 self.native = THFloatTensor_newWithSize4d(args[0], args[1], args[2], args[3])
 *             else:
 *                 logger.error('Raising exception...')             # <<<<<<<<<<<<<<
 *                 raise Exception('Not implemented, len(args)=' + str(len(args)))
 * #        else:
 */
  __pyx_tuple__18 = PyTuple_Pack(1, __pyx_kp_s_Raising_exception); if (unlikely(!__pyx_tuple__18)) __PYX_ERR(0, 895, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__18);
  __Pyx_GIVEREF(__pyx_tuple__18);

  /* "PyTorch.pyx":935
 *    #            # print('   size[', i, ']', THFloatTensor_size(self.thFloatTensor, i))
 *             if refCount < 1:
 *                 raise Exception('Unallocated an already deallocated tensor... :-O')  # Hmmm, seems this exceptoin wont go anywhere useful... :-P             # <<<<<<<<<<<<<<
 *             THFloatTensor_free(self.native)
 *         else:
 */
  __pyx_tuple__19 = PyTuple_Pack(1, __pyx_kp_s_Unallocated_an_already_deallocat); if (unlikely(!__pyx_tuple__19)) __PYX_ERR(0, 935, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__19);
  __Pyx_GIVEREF(__pyx_tuple__19);

  /* "PyTorch.pyx":938
 *             THFloatTensor_free(self.native)
 *         else:
 *             logger.debug('__dealloc__ tensor never allocated')             # <<<<<<<<<<<<<<
 * 
 *     def nElement(_FloatTensor self):
 */
  __pyx_tuple__20 = PyTuple_Pack(1, __pyx_kp_s_dealloc___tensor_never_allocat); if (unlikely(!__pyx_tuple__20)) __PYX_ERR(0, 938, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__20);
  __Pyx_GIVEREF(__pyx_tuple__20);

  /* "PyTorch.pyx":954
 * 
 *         if dtype is None:
 *           raise Exception("not implemented for Float")             # <<<<<<<<<<<<<<
 * #        print('dtype', dtype)
 *         if dims >= 1:
 */
  __pyx_tuple__21 = PyTuple_Pack(1, __pyx_kp_s_not_implemented_for_Float); if (unlikely(!__pyx_tuple__21)) __PYX_ERR(0, 954, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__21);
  __Pyx_GIVEREF(__pyx_tuple__21);

  /* "PyTorch.pyx":1058
 *             return res
 *         else:
 *             raise Exception("Not implemented: dims > 2")             # <<<<<<<<<<<<<<
 * 
 *     def __getitem__(_FloatTensor self, int index):
 */
  __pyx_tuple__22 = PyTuple_Pack(1, __pyx_kp_s_Not_implemented_dims_2); if (unlikely(!__pyx_tuple__22)) __PYX_ERR(0, 1058, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__22);
  __Pyx_GIVEREF(__pyx_tuple__22);

  /* "PyTorch.pyx":1070
 *             self.set1d(index, value)
 *         else:
 *             raise Exception("not implemented")             # <<<<<<<<<<<<<<
 * 
 *     def fill(_FloatTensor self, float value):
 */
  __pyx_tuple__23 = PyTuple_Pack(1, __pyx_kp_s_not_implemented); if (unlikely(!__pyx_tuple__23)) __PYX_ERR(0, 1070, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__23);
  __Pyx_GIVEREF(__pyx_tuple__23);

  /* "PyTorch.pyx":1421
 *         return tensor
 *     else:
 *         raise Exception("not implemented")             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_tuple__24 = PyTuple_Pack(1, __pyx_kp_s_not_implemented); if (unlikely(!__pyx_tuple__24)) __PYX_ERR(0, 1421, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__24);
  __Pyx_GIVEREF(__pyx_tuple__24);

  /* "PyTorch.pyx":1437
 *         cdef THDoubleTensor *newTensorC
 *         cdef _DoubleTensor templateObject
 *         logger.debug('DoubleTensor.__cinit__')             # <<<<<<<<<<<<<<
 * #        cdef THDoubleStorage *storageC
 * #        cdef long addr
 */
  __pyx_tuple__25 = PyTuple_Pack(1, __pyx_kp_s_DoubleTensor___cinit); if (unlikely(!__pyx_tuple__25)) __PYX_ERR(0, 1437, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__25);
  __Pyx_GIVEREF(__pyx_tuple__25);

  /* "PyTorch.pyx":1454
 *             for arg in args:
 *                 if not isinstance(arg, int):
 *                     raise Exception('cannot provide arguments to initializer')             # <<<<<<<<<<<<<<
 *             if len(args) == 0:
 *                 # print('no args, calling THDoubleTensor_new()')
 */
  __pyx_tuple__26 = PyTuple_Pack(1, __pyx_kp_s_cannot_provide_arguments_to_init); if (unlikely(!__pyx_tuple__26)) __PYX_ERR(0, 1454, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__26);
  __Pyx_GIVEREF(__pyx_tuple__26);

  /* "PyTorch.pyx":1471
 *                 self.native = THDoubleTensor_newWithSize4d(args[0], args[1], args[2], args[3])
 *             else:
 *                 logger.error('Raising exception...')             # <<<<<<<<<<<<<<
 *                 raise Exception('Not implemented, len(args)=' + str(len(args)))
 * #        else:
 */
  __pyx_tuple__27 = PyTuple_Pack(1, __pyx_kp_s_Raising_exception); if (unlikely(!__pyx_tuple__27)) __PYX_ERR(0, 1471, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__27);
  __Pyx_GIVEREF(__pyx_tuple__27);

  /* "PyTorch.pyx":1511
 *    #            # print('   size[', i, ']', THFloatTensor_size(self.thFloatTensor, i))
 *             if refCount < 1:
 *                 raise Exception('Unallocated an already deallocated tensor... :-O')  # Hmmm, seems this exceptoin wont go anywhere useful... :-P             # <<<<<<<<<<<<<<
 *             THDoubleTensor_free(self.native)
 *         else:
 */
  __pyx_tuple__28 = PyTuple_Pack(1, __pyx_kp_s_Unallocated_an_already_deallocat); if (unlikely(!__pyx_tuple__28)) __PYX_ERR(0, 1511, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__28);
  __Pyx_GIVEREF(__pyx_tuple__28);

  /* "PyTorch.pyx":1514
 *             THDoubleTensor_free(self.native)
 *         else:
 *             logger.debug('__dealloc__ tensor never allocated')             # <<<<<<<<<<<<<<
 * 
 *     def nElement(_DoubleTensor self):
 */
  __pyx_tuple__29 = PyTuple_Pack(1, __pyx_kp_s_dealloc___tensor_never_allocat); if (unlikely(!__pyx_tuple__29)) __PYX_ERR(0, 1514, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__29);
  __Pyx_GIVEREF(__pyx_tuple__29);

  /* "PyTorch.pyx":1530
 * 
 *         if dtype is None:
 *           raise Exception("not implemented for Double")             # <<<<<<<<<<<<<<
 * #        print('dtype', dtype)
 *         if dims >= 1:
 */
  __pyx_tuple__30 = PyTuple_Pack(1, __pyx_kp_s_not_implemented_for_Double); if (unlikely(!__pyx_tuple__30)) __PYX_ERR(0, 1530, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__30);
  __Pyx_GIVEREF(__pyx_tuple__30);

  /* "PyTorch.pyx":1634
 *             return res
 *         else:
 *             raise Exception("Not implemented: dims > 2")             # <<<<<<<<<<<<<<
 * 
 *     def __getitem__(_DoubleTensor self, int index):
 */
  __pyx_tuple__31 = PyTuple_Pack(1, __pyx_kp_s_Not_implemented_dims_2); if (unlikely(!__pyx_tuple__31)) __PYX_ERR(0, 1634, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__31);
  __Pyx_GIVEREF(__pyx_tuple__31);

  /* "PyTorch.pyx":1646
 *             self.set1d(index, value)
 *         else:
 *             raise Exception("not implemented")             # <<<<<<<<<<<<<<
 * 
 *     def fill(_DoubleTensor self, double value):
 */
  __pyx_tuple__32 = PyTuple_Pack(1, __pyx_kp_s_not_implemented); if (unlikely(!__pyx_tuple__32)) __PYX_ERR(0, 1646, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__32);
  __Pyx_GIVEREF(__pyx_tuple__32);

  /* "PyTorch.pyx":1997
 *         return tensor
 *     else:
 *         raise Exception("not implemented")             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_tuple__33 = PyTuple_Pack(1, __pyx_kp_s_not_implemented); if (unlikely(!__pyx_tuple__33)) __PYX_ERR(0, 1997, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__33);
  __Pyx_GIVEREF(__pyx_tuple__33);

  /* "PyTorch.pyx":2013
 *         cdef THByteTensor *newTensorC
 *         cdef _ByteTensor templateObject
 *         logger.debug('ByteTensor.__cinit__')             # <<<<<<<<<<<<<<
 * #        cdef THByteStorage *storageC
 * #        cdef long addr
 */
  __pyx_tuple__34 = PyTuple_Pack(1, __pyx_kp_s_ByteTensor___cinit); if (unlikely(!__pyx_tuple__34)) __PYX_ERR(0, 2013, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__34);
  __Pyx_GIVEREF(__pyx_tuple__34);

  /* "PyTorch.pyx":2030
 *             for arg in args:
 *                 if not isinstance(arg, int):
 *                     raise Exception('cannot provide arguments to initializer')             # <<<<<<<<<<<<<<
 *             if len(args) == 0:
 *                 # print('no args, calling THByteTensor_new()')
 */
  __pyx_tuple__35 = PyTuple_Pack(1, __pyx_kp_s_cannot_provide_arguments_to_init); if (unlikely(!__pyx_tuple__35)) __PYX_ERR(0, 2030, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__35);
  __Pyx_GIVEREF(__pyx_tuple__35);

  /* "PyTorch.pyx":2047
 *                 self.native = THByteTensor_newWithSize4d(args[0], args[1], args[2], args[3])
 *             else:
 *                 logger.error('Raising exception...')             # <<<<<<<<<<<<<<
 *                 raise Exception('Not implemented, len(args)=' + str(len(args)))
 * #        else:
 */
  __pyx_tuple__36 = PyTuple_Pack(1, __pyx_kp_s_Raising_exception); if (unlikely(!__pyx_tuple__36)) __PYX_ERR(0, 2047, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__36);
  __Pyx_GIVEREF(__pyx_tuple__36);

  /* "PyTorch.pyx":2087
 *    #            # print('   size[', i, ']', THFloatTensor_size(self.thFloatTensor, i))
 *             if refCount < 1:
 *                 raise Exception('Unallocated an already deallocated tensor... :-O')  # Hmmm, seems this exceptoin wont go anywhere useful... :-P             # <<<<<<<<<<<<<<
 *             THByteTensor_free(self.native)
 *         else:
 */
  __pyx_tuple__37 = PyTuple_Pack(1, __pyx_kp_s_Unallocated_an_already_deallocat); if (unlikely(!__pyx_tuple__37)) __PYX_ERR(0, 2087, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__37);
  __Pyx_GIVEREF(__pyx_tuple__37);

  /* "PyTorch.pyx":2090
 *             THByteTensor_free(self.native)
 *         else:
 *             logger.debug('__dealloc__ tensor never allocated')             # <<<<<<<<<<<<<<
 * 
 *     def nElement(_ByteTensor self):
 */
  __pyx_tuple__38 = PyTuple_Pack(1, __pyx_kp_s_dealloc___tensor_never_allocat); if (unlikely(!__pyx_tuple__38)) __PYX_ERR(0, 2090, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__38);
  __Pyx_GIVEREF(__pyx_tuple__38);

  /* "PyTorch.pyx":2106
 *         dtype=np.uint8
 *         if dtype is None:
 *           raise Exception("not implemented for Byte")             # <<<<<<<<<<<<<<
 * #        print('dtype', dtype)
 *         if dims >= 1:
 */
  __pyx_tuple__39 = PyTuple_Pack(1, __pyx_kp_s_not_implemented_for_Byte); if (unlikely(!__pyx_tuple__39)) __PYX_ERR(0, 2106, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__39);
  __Pyx_GIVEREF(__pyx_tuple__39);

  /* "PyTorch.pyx":2210
 *             return res
 *         else:
 *             raise Exception("Not implemented: dims > 2")             # <<<<<<<<<<<<<<
 * 
 *     def __getitem__(_ByteTensor self, int index):
 */
  __pyx_tuple__40 = PyTuple_Pack(1, __pyx_kp_s_Not_implemented_dims_2); if (unlikely(!__pyx_tuple__40)) __PYX_ERR(0, 2210, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__40);
  __Pyx_GIVEREF(__pyx_tuple__40);

  /* "PyTorch.pyx":2222
 *             self.set1d(index, value)
 *         else:
 *             raise Exception("not implemented")             # <<<<<<<<<<<<<<
 * 
 *     def fill(_ByteTensor self, unsigned char value):
 */
  __pyx_tuple__41 = PyTuple_Pack(1, __pyx_kp_s_not_implemented); if (unlikely(!__pyx_tuple__41)) __PYX_ERR(0, 2222, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__41);
  __Pyx_GIVEREF(__pyx_tuple__41);

  /* "PyTorch.pyx":2497
 *         return tensor
 *     else:
 *         raise Exception("not implemented")             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_tuple__42 = PyTuple_Pack(1, __pyx_kp_s_not_implemented); if (unlikely(!__pyx_tuple__42)) __PYX_ERR(0, 2497, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__42);
  __Pyx_GIVEREF(__pyx_tuple__42);

  /* "PyTorch.pyx":2610
 *     cdef lua_State *L
 *     L = globalState.L
 *     luaRequire(L, libName.encode('utf-8'))             # <<<<<<<<<<<<<<
 * 
 * def getGlobal(name):
 */
  __pyx_tuple__43 = PyTuple_Pack(1, __pyx_kp_s_utf_8); if (unlikely(!__pyx_tuple__43)) __PYX_ERR(0, 2610, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__43);
  __Pyx_GIVEREF(__pyx_tuple__43);

  /* "View.MemoryView":131
 * 
 *         if not self.ndim:
 *             raise ValueError("Empty shape tuple for cython.array")             # <<<<<<<<<<<<<<
 * 
 *         if itemsize <= 0:
 */
  __pyx_tuple__44 = PyTuple_Pack(1, __pyx_kp_s_Empty_shape_tuple_for_cython_arr); if (unlikely(!__pyx_tuple__44)) __PYX_ERR(2, 131, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__44);
  __Pyx_GIVEREF(__pyx_tuple__44);

  /* "View.MemoryView":134
 * 
 *         if itemsize <= 0:
 *             raise ValueError("itemsize <= 0 for cython.array")             # <<<<<<<<<<<<<<
 * 
 *         if not isinstance(format, bytes):
 */
  __pyx_tuple__45 = PyTuple_Pack(1, __pyx_kp_s_itemsize_0_for_cython_array); if (unlikely(!__pyx_tuple__45)) __PYX_ERR(2, 134, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__45);
  __Pyx_GIVEREF(__pyx_tuple__45);

  /* "View.MemoryView":137
 * 
 *         if not isinstance(format, bytes):
 *             format = format.encode('ASCII')             # <<<<<<<<<<<<<<
 *         self._format = format  # keep a reference to the byte string
 *         self.format = self._format
 */
  __pyx_tuple__46 = PyTuple_Pack(1, __pyx_n_s_ASCII); if (unlikely(!__pyx_tuple__46)) __PYX_ERR(2, 137, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__46);
  __Pyx_GIVEREF(__pyx_tuple__46);

  /* "View.MemoryView":146
 * 
 *         if not self._shape:
 *             raise MemoryError("unable to allocate shape and strides.")             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_tuple__47 = PyTuple_Pack(1, __pyx_kp_s_unable_to_allocate_shape_and_str); if (unlikely(!__pyx_tuple__47)) __PYX_ERR(2, 146, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__47);
  __Pyx_GIVEREF(__pyx_tuple__47);

  /* "View.MemoryView":174
 *             self.data = <char *>malloc(self.len)
 *             if not self.data:
 *                 raise MemoryError("unable to allocate array data.")             # <<<<<<<<<<<<<<
 * 
 *             if self.dtype_is_object:
 */
  __pyx_tuple__48 = PyTuple_Pack(1, __pyx_kp_s_unable_to_allocate_array_data); if (unlikely(!__pyx_tuple__48)) __PYX_ERR(2, 174, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__48);
  __Pyx_GIVEREF(__pyx_tuple__48);

  /* "View.MemoryView":190
 *             bufmode = PyBUF_F_CONTIGUOUS | PyBUF_ANY_CONTIGUOUS
 *         if not (flags & bufmode):
 *             raise ValueError("Can only create a buffer that is contiguous in memory.")             # <<<<<<<<<<<<<<
 *         info.buf = self.data
 *         info.len = self.len
 */
  __pyx_tuple__49 = PyTuple_Pack(1, __pyx_kp_s_Can_only_create_a_buffer_that_is); if (unlikely(!__pyx_tuple__49)) __PYX_ERR(2, 190, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__49);
  __Pyx_GIVEREF(__pyx_tuple__49);

  /* "View.MemoryView":484
 *             result = struct.unpack(self.view.format, bytesitem)
 *         except struct.error:
 *             raise ValueError("Unable to convert item to object")             # <<<<<<<<<<<<<<
 *         else:
 *             if len(self.view.format) == 1:
 */
  __pyx_tuple__50 = PyTuple_Pack(1, __pyx_kp_s_Unable_to_convert_item_to_object); if (unlikely(!__pyx_tuple__50)) __PYX_ERR(2, 484, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__50);
  __Pyx_GIVEREF(__pyx_tuple__50);

  /* "View.MemoryView":556
 *         if self.view.strides == NULL:
 * 
 *             raise ValueError("Buffer view does not expose strides")             # <<<<<<<<<<<<<<
 * 
 *         return tuple([stride for stride in self.view.strides[:self.view.ndim]])
 */
  __pyx_tuple__51 = PyTuple_Pack(1, __pyx_kp_s_Buffer_view_does_not_expose_stri); if (unlikely(!__pyx_tuple__51)) __PYX_ERR(2, 556, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__51);
  __Pyx_GIVEREF(__pyx_tuple__51);

  /* "View.MemoryView":563
 *     def suboffsets(self):
 *         if self.view.suboffsets == NULL:
 *             return (-1,) * self.view.ndim             # <<<<<<<<<<<<<<
 * 
 *         return tuple([suboffset for suboffset in self.view.suboffsets[:self.view.ndim]])
 */
  __pyx_tuple__52 = PyTuple_New(1); if (unlikely(!__pyx_tuple__52)) __PYX_ERR(2, 563, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__52);
  __Pyx_INCREF(__pyx_int_neg_1);
  __Pyx_GIVEREF(__pyx_int_neg_1);
  PyTuple_SET_ITEM(__pyx_tuple__52, 0, __pyx_int_neg_1);
  __Pyx_GIVEREF(__pyx_tuple__52);

  /* "View.MemoryView":668
 *         if item is Ellipsis:
 *             if not seen_ellipsis:
 *                 result.extend([slice(None)] * (ndim - len(tup) + 1))             # <<<<<<<<<<<<<<
 *                 seen_ellipsis = True
 *             else:
 */
  __pyx_slice__53 = PySlice_New(Py_None, Py_None, Py_None); if (unlikely(!__pyx_slice__53)) __PYX_ERR(2, 668, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_slice__53);
  __Pyx_GIVEREF(__pyx_slice__53);

  /* "View.MemoryView":671
 *                 seen_ellipsis = True
 *             else:
 *                 result.append(slice(None))             # <<<<<<<<<<<<<<
 *             have_slices = True
 *         else:
 */
  __pyx_slice__54 = PySlice_New(Py_None, Py_None, Py_None); if (unlikely(!__pyx_slice__54)) __PYX_ERR(2, 671, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_slice__54);
  __Pyx_GIVEREF(__pyx_slice__54);

  /* "View.MemoryView":682
 *     nslices = ndim - len(result)
 *     if nslices:
 *         result.extend([slice(None)] * nslices)             # <<<<<<<<<<<<<<
 * 
 *     return have_slices or nslices, tuple(result)
 */
  __pyx_slice__55 = PySlice_New(Py_None, Py_None, Py_None); if (unlikely(!__pyx_slice__55)) __PYX_ERR(2, 682, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_slice__55);
  __Pyx_GIVEREF(__pyx_slice__55);

  /* "View.MemoryView":689
 *     for suboffset in suboffsets[:ndim]:
 *         if suboffset >= 0:
 *             raise ValueError("Indirect dimensions not supported")             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_tuple__56 = PyTuple_Pack(1, __pyx_kp_s_Indirect_dimensions_not_supporte); if (unlikely(!__pyx_tuple__56)) __PYX_ERR(2, 689, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__56);
  __Pyx_GIVEREF(__pyx_tuple__56);

  /* "PyTorch.pyx":30
 * 
 * # from http://stackoverflow.com/questions/3410976/how-to-round-a-number-to-significant-figures-in-python
 * def round_sig(x, sig=2):             # <<<<<<<<<<<<<<
 *     return round(x, sig-int(floor(log10(abs(x))))-1)
 * 
 */
  __pyx_tuple__57 = PyTuple_Pack(2, __pyx_n_s_x, __pyx_n_s_sig); if (unlikely(!__pyx_tuple__57)) __PYX_ERR(0, 30, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__57);
  __Pyx_GIVEREF(__pyx_tuple__57);
  __pyx_codeobj__58 = (PyObject*)__Pyx_PyCode_New(2, 0, 2, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__57, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_home_steb_inst_pytorch_src_PyTo, __pyx_n_s_round_sig, 30, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__58)) __PYX_ERR(0, 30, __pyx_L1_error)

  /* "PyTorch.pyx":37
 *     void THRandom_manualSeed(THGenerator *_generator, unsigned long the_seed_)
 * 
 * def manualSeed(long seed):             # <<<<<<<<<<<<<<
 *     THRandom_manualSeed(globalState.generator, seed)
 * 
 */
  __pyx_tuple__59 = PyTuple_Pack(2, __pyx_n_s_seed, __pyx_n_s_seed); if (unlikely(!__pyx_tuple__59)) __PYX_ERR(0, 37, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__59);
  __Pyx_GIVEREF(__pyx_tuple__59);
  __pyx_codeobj__60 = (PyObject*)__Pyx_PyCode_New(1, 0, 2, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__59, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_home_steb_inst_pytorch_src_PyTo, __pyx_n_s_manualSeed, 37, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__60)) __PYX_ERR(0, 37, __pyx_L1_error)

  /* "PyTorch.pyx":629
 * 
 *     @staticmethod
 *     def new():             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         return _LongTensor()
 */
  __pyx_codeobj__61 = (PyObject*)__Pyx_PyCode_New(0, 0, 0, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_home_steb_inst_pytorch_src_PyTo, __pyx_n_s_new, 629, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__61)) __PYX_ERR(0, 629, __pyx_L1_error)

  /* "PyTorch.pyx":682
 * 
 *     @staticmethod
 *     def newWithStorage(Storage._LongStorage storage, offset, Storage._LongStorage size, Storage._LongStorage stride):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THLongTensor *newTensorC = THLongTensor_newWithStorage(storage.native, offset, size.native, stride.native)
 */
  __pyx_tuple__62 = PyTuple_Pack(5, __pyx_n_s_storage, __pyx_n_s_offset, __pyx_n_s_size, __pyx_n_s_stride, __pyx_n_s_newTensorC); if (unlikely(!__pyx_tuple__62)) __PYX_ERR(0, 682, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__62);
  __Pyx_GIVEREF(__pyx_tuple__62);
  __pyx_codeobj__63 = (PyObject*)__Pyx_PyCode_New(4, 0, 5, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__62, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_home_steb_inst_pytorch_src_PyTo, __pyx_n_s_newWithStorage, 682, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__63)) __PYX_ERR(0, 682, __pyx_L1_error)

  /* "PyTorch.pyx":688
 * 
 *     @staticmethod
 *     def newWithStorage1d(Storage._LongStorage storage, offset, size0, stride0):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THLongTensor *newTensorC = THLongTensor_newWithStorage1d(storage.native, offset, size0, stride0)
 */
  __pyx_tuple__64 = PyTuple_Pack(5, __pyx_n_s_storage, __pyx_n_s_offset, __pyx_n_s_size0, __pyx_n_s_stride0, __pyx_n_s_newTensorC); if (unlikely(!__pyx_tuple__64)) __PYX_ERR(0, 688, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__64);
  __Pyx_GIVEREF(__pyx_tuple__64);
  __pyx_codeobj__65 = (PyObject*)__Pyx_PyCode_New(4, 0, 5, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__64, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_home_steb_inst_pytorch_src_PyTo, __pyx_n_s_newWithStorage1d, 688, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__65)) __PYX_ERR(0, 688, __pyx_L1_error)

  /* "PyTorch.pyx":694
 * 
 *     @staticmethod
 *     def newWithStorage2d(Storage._LongStorage storage, offset, size0, stride0, size1, stride1):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THLongTensor *newTensorC = THLongTensor_newWithStorage2d(storage.native, offset, size0, stride0, size1, stride1)
 */
  __pyx_tuple__66 = PyTuple_Pack(7, __pyx_n_s_storage, __pyx_n_s_offset, __pyx_n_s_size0, __pyx_n_s_stride0, __pyx_n_s_size1, __pyx_n_s_stride1, __pyx_n_s_newTensorC); if (unlikely(!__pyx_tuple__66)) __PYX_ERR(0, 694, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__66);
  __Pyx_GIVEREF(__pyx_tuple__66);
  __pyx_codeobj__67 = (PyObject*)__Pyx_PyCode_New(6, 0, 7, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__66, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_home_steb_inst_pytorch_src_PyTo, __pyx_n_s_newWithStorage2d, 694, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__67)) __PYX_ERR(0, 694, __pyx_L1_error)

  /* "PyTorch.pyx":700
 * 
 *     @staticmethod
 *     def newWithStorage3d(Storage._LongStorage storage, offset, size0, stride0, size1, stride1, size2, stride2):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THLongTensor *newTensorC = THLongTensor_newWithStorage3d(storage.native, offset, size0, stride0, size1, stride1,
 */
  __pyx_tuple__68 = PyTuple_Pack(9, __pyx_n_s_storage, __pyx_n_s_offset, __pyx_n_s_size0, __pyx_n_s_stride0, __pyx_n_s_size1, __pyx_n_s_stride1, __pyx_n_s_size2, __pyx_n_s_stride2, __pyx_n_s_newTensorC); if (unlikely(!__pyx_tuple__68)) __PYX_ERR(0, 700, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__68);
  __Pyx_GIVEREF(__pyx_tuple__68);
  __pyx_codeobj__69 = (PyObject*)__Pyx_PyCode_New(8, 0, 9, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__68, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_home_steb_inst_pytorch_src_PyTo, __pyx_n_s_newWithStorage3d, 700, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__69)) __PYX_ERR(0, 700, __pyx_L1_error)

  /* "PyTorch.pyx":707
 * 
 *     @staticmethod
 *     def newWithStorage4d(Storage._LongStorage storage, offset, size0, stride0, size1, stride1, size2, stride2,             # <<<<<<<<<<<<<<
 *             size3, stride3):
 * #        # print('allocate tensor')
 */
  __pyx_tuple__70 = PyTuple_Pack(11, __pyx_n_s_storage, __pyx_n_s_offset, __pyx_n_s_size0, __pyx_n_s_stride0, __pyx_n_s_size1, __pyx_n_s_stride1, __pyx_n_s_size2, __pyx_n_s_stride2, __pyx_n_s_size3, __pyx_n_s_stride3, __pyx_n_s_newTensorC); if (unlikely(!__pyx_tuple__70)) __PYX_ERR(0, 707, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__70);
  __Pyx_GIVEREF(__pyx_tuple__70);
  __pyx_codeobj__71 = (PyObject*)__Pyx_PyCode_New(10, 0, 11, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__70, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_home_steb_inst_pytorch_src_PyTo, __pyx_n_s_newWithStorage4d, 707, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__71)) __PYX_ERR(0, 707, __pyx_L1_error)

  /* "PyTorch.pyx":1145
 * 
 *     @staticmethod
 *     def new():             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         return _FloatTensor()
 */
  __pyx_codeobj__72 = (PyObject*)__Pyx_PyCode_New(0, 0, 0, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_home_steb_inst_pytorch_src_PyTo, __pyx_n_s_new, 1145, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__72)) __PYX_ERR(0, 1145, __pyx_L1_error)

  /* "PyTorch.pyx":1198
 * 
 *     @staticmethod
 *     def newWithStorage(Storage._FloatStorage storage, offset, Storage._LongStorage size, Storage._LongStorage stride):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THFloatTensor *newTensorC = THFloatTensor_newWithStorage(storage.native, offset, size.native, stride.native)
 */
  __pyx_tuple__73 = PyTuple_Pack(5, __pyx_n_s_storage, __pyx_n_s_offset, __pyx_n_s_size, __pyx_n_s_stride, __pyx_n_s_newTensorC); if (unlikely(!__pyx_tuple__73)) __PYX_ERR(0, 1198, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__73);
  __Pyx_GIVEREF(__pyx_tuple__73);
  __pyx_codeobj__74 = (PyObject*)__Pyx_PyCode_New(4, 0, 5, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__73, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_home_steb_inst_pytorch_src_PyTo, __pyx_n_s_newWithStorage, 1198, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__74)) __PYX_ERR(0, 1198, __pyx_L1_error)

  /* "PyTorch.pyx":1204
 * 
 *     @staticmethod
 *     def newWithStorage1d(Storage._FloatStorage storage, offset, size0, stride0):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THFloatTensor *newTensorC = THFloatTensor_newWithStorage1d(storage.native, offset, size0, stride0)
 */
  __pyx_tuple__75 = PyTuple_Pack(5, __pyx_n_s_storage, __pyx_n_s_offset, __pyx_n_s_size0, __pyx_n_s_stride0, __pyx_n_s_newTensorC); if (unlikely(!__pyx_tuple__75)) __PYX_ERR(0, 1204, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__75);
  __Pyx_GIVEREF(__pyx_tuple__75);
  __pyx_codeobj__76 = (PyObject*)__Pyx_PyCode_New(4, 0, 5, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__75, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_home_steb_inst_pytorch_src_PyTo, __pyx_n_s_newWithStorage1d, 1204, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__76)) __PYX_ERR(0, 1204, __pyx_L1_error)

  /* "PyTorch.pyx":1210
 * 
 *     @staticmethod
 *     def newWithStorage2d(Storage._FloatStorage storage, offset, size0, stride0, size1, stride1):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THFloatTensor *newTensorC = THFloatTensor_newWithStorage2d(storage.native, offset, size0, stride0, size1, stride1)
 */
  __pyx_tuple__77 = PyTuple_Pack(7, __pyx_n_s_storage, __pyx_n_s_offset, __pyx_n_s_size0, __pyx_n_s_stride0, __pyx_n_s_size1, __pyx_n_s_stride1, __pyx_n_s_newTensorC); if (unlikely(!__pyx_tuple__77)) __PYX_ERR(0, 1210, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__77);
  __Pyx_GIVEREF(__pyx_tuple__77);
  __pyx_codeobj__78 = (PyObject*)__Pyx_PyCode_New(6, 0, 7, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__77, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_home_steb_inst_pytorch_src_PyTo, __pyx_n_s_newWithStorage2d, 1210, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__78)) __PYX_ERR(0, 1210, __pyx_L1_error)

  /* "PyTorch.pyx":1216
 * 
 *     @staticmethod
 *     def newWithStorage3d(Storage._FloatStorage storage, offset, size0, stride0, size1, stride1, size2, stride2):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THFloatTensor *newTensorC = THFloatTensor_newWithStorage3d(storage.native, offset, size0, stride0, size1, stride1,
 */
  __pyx_tuple__79 = PyTuple_Pack(9, __pyx_n_s_storage, __pyx_n_s_offset, __pyx_n_s_size0, __pyx_n_s_stride0, __pyx_n_s_size1, __pyx_n_s_stride1, __pyx_n_s_size2, __pyx_n_s_stride2, __pyx_n_s_newTensorC); if (unlikely(!__pyx_tuple__79)) __PYX_ERR(0, 1216, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__79);
  __Pyx_GIVEREF(__pyx_tuple__79);
  __pyx_codeobj__80 = (PyObject*)__Pyx_PyCode_New(8, 0, 9, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__79, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_home_steb_inst_pytorch_src_PyTo, __pyx_n_s_newWithStorage3d, 1216, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__80)) __PYX_ERR(0, 1216, __pyx_L1_error)

  /* "PyTorch.pyx":1223
 * 
 *     @staticmethod
 *     def newWithStorage4d(Storage._FloatStorage storage, offset, size0, stride0, size1, stride1, size2, stride2,             # <<<<<<<<<<<<<<
 *             size3, stride3):
 * #        # print('allocate tensor')
 */
  __pyx_tuple__81 = PyTuple_Pack(11, __pyx_n_s_storage, __pyx_n_s_offset, __pyx_n_s_size0, __pyx_n_s_stride0, __pyx_n_s_size1, __pyx_n_s_stride1, __pyx_n_s_size2, __pyx_n_s_stride2, __pyx_n_s_size3, __pyx_n_s_stride3, __pyx_n_s_newTensorC); if (unlikely(!__pyx_tuple__81)) __PYX_ERR(0, 1223, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__81);
  __Pyx_GIVEREF(__pyx_tuple__81);
  __pyx_codeobj__82 = (PyObject*)__Pyx_PyCode_New(10, 0, 11, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__81, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_home_steb_inst_pytorch_src_PyTo, __pyx_n_s_newWithStorage4d, 1223, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__82)) __PYX_ERR(0, 1223, __pyx_L1_error)

  /* "PyTorch.pyx":1390
 * 
 * 
 * def _asFloatTensor(myarray):             # <<<<<<<<<<<<<<
 *     cdef float[:] myarraymv
 *     cdef Storage._FloatStorage storage
 */
  __pyx_tuple__83 = PyTuple_Pack(10, __pyx_n_s_myarray, __pyx_n_s_myarraymv, __pyx_n_s_storage, __pyx_n_s_dims, __pyx_n_s_totalSize, __pyx_n_s_size, __pyx_n_s_stride, __pyx_n_s_strideSoFar, __pyx_n_s_d, __pyx_n_s_tensor); if (unlikely(!__pyx_tuple__83)) __PYX_ERR(0, 1390, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__83);
  __Pyx_GIVEREF(__pyx_tuple__83);
  __pyx_codeobj__84 = (PyObject*)__Pyx_PyCode_New(1, 0, 10, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__83, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_home_steb_inst_pytorch_src_PyTo, __pyx_n_s_asFloatTensor, 1390, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__84)) __PYX_ERR(0, 1390, __pyx_L1_error)

  /* "PyTorch.pyx":1721
 * 
 *     @staticmethod
 *     def new():             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         return _DoubleTensor()
 */
  __pyx_codeobj__85 = (PyObject*)__Pyx_PyCode_New(0, 0, 0, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_home_steb_inst_pytorch_src_PyTo, __pyx_n_s_new, 1721, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__85)) __PYX_ERR(0, 1721, __pyx_L1_error)

  /* "PyTorch.pyx":1774
 * 
 *     @staticmethod
 *     def newWithStorage(Storage._DoubleStorage storage, offset, Storage._LongStorage size, Storage._LongStorage stride):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THDoubleTensor *newTensorC = THDoubleTensor_newWithStorage(storage.native, offset, size.native, stride.native)
 */
  __pyx_tuple__86 = PyTuple_Pack(5, __pyx_n_s_storage, __pyx_n_s_offset, __pyx_n_s_size, __pyx_n_s_stride, __pyx_n_s_newTensorC); if (unlikely(!__pyx_tuple__86)) __PYX_ERR(0, 1774, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__86);
  __Pyx_GIVEREF(__pyx_tuple__86);
  __pyx_codeobj__87 = (PyObject*)__Pyx_PyCode_New(4, 0, 5, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__86, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_home_steb_inst_pytorch_src_PyTo, __pyx_n_s_newWithStorage, 1774, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__87)) __PYX_ERR(0, 1774, __pyx_L1_error)

  /* "PyTorch.pyx":1780
 * 
 *     @staticmethod
 *     def newWithStorage1d(Storage._DoubleStorage storage, offset, size0, stride0):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THDoubleTensor *newTensorC = THDoubleTensor_newWithStorage1d(storage.native, offset, size0, stride0)
 */
  __pyx_tuple__88 = PyTuple_Pack(5, __pyx_n_s_storage, __pyx_n_s_offset, __pyx_n_s_size0, __pyx_n_s_stride0, __pyx_n_s_newTensorC); if (unlikely(!__pyx_tuple__88)) __PYX_ERR(0, 1780, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__88);
  __Pyx_GIVEREF(__pyx_tuple__88);
  __pyx_codeobj__89 = (PyObject*)__Pyx_PyCode_New(4, 0, 5, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__88, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_home_steb_inst_pytorch_src_PyTo, __pyx_n_s_newWithStorage1d, 1780, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__89)) __PYX_ERR(0, 1780, __pyx_L1_error)

  /* "PyTorch.pyx":1786
 * 
 *     @staticmethod
 *     def newWithStorage2d(Storage._DoubleStorage storage, offset, size0, stride0, size1, stride1):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THDoubleTensor *newTensorC = THDoubleTensor_newWithStorage2d(storage.native, offset, size0, stride0, size1, stride1)
 */
  __pyx_tuple__90 = PyTuple_Pack(7, __pyx_n_s_storage, __pyx_n_s_offset, __pyx_n_s_size0, __pyx_n_s_stride0, __pyx_n_s_size1, __pyx_n_s_stride1, __pyx_n_s_newTensorC); if (unlikely(!__pyx_tuple__90)) __PYX_ERR(0, 1786, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__90);
  __Pyx_GIVEREF(__pyx_tuple__90);
  __pyx_codeobj__91 = (PyObject*)__Pyx_PyCode_New(6, 0, 7, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__90, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_home_steb_inst_pytorch_src_PyTo, __pyx_n_s_newWithStorage2d, 1786, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__91)) __PYX_ERR(0, 1786, __pyx_L1_error)

  /* "PyTorch.pyx":1792
 * 
 *     @staticmethod
 *     def newWithStorage3d(Storage._DoubleStorage storage, offset, size0, stride0, size1, stride1, size2, stride2):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THDoubleTensor *newTensorC = THDoubleTensor_newWithStorage3d(storage.native, offset, size0, stride0, size1, stride1,
 */
  __pyx_tuple__92 = PyTuple_Pack(9, __pyx_n_s_storage, __pyx_n_s_offset, __pyx_n_s_size0, __pyx_n_s_stride0, __pyx_n_s_size1, __pyx_n_s_stride1, __pyx_n_s_size2, __pyx_n_s_stride2, __pyx_n_s_newTensorC); if (unlikely(!__pyx_tuple__92)) __PYX_ERR(0, 1792, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__92);
  __Pyx_GIVEREF(__pyx_tuple__92);
  __pyx_codeobj__93 = (PyObject*)__Pyx_PyCode_New(8, 0, 9, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__92, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_home_steb_inst_pytorch_src_PyTo, __pyx_n_s_newWithStorage3d, 1792, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__93)) __PYX_ERR(0, 1792, __pyx_L1_error)

  /* "PyTorch.pyx":1799
 * 
 *     @staticmethod
 *     def newWithStorage4d(Storage._DoubleStorage storage, offset, size0, stride0, size1, stride1, size2, stride2,             # <<<<<<<<<<<<<<
 *             size3, stride3):
 * #        # print('allocate tensor')
 */
  __pyx_tuple__94 = PyTuple_Pack(11, __pyx_n_s_storage, __pyx_n_s_offset, __pyx_n_s_size0, __pyx_n_s_stride0, __pyx_n_s_size1, __pyx_n_s_stride1, __pyx_n_s_size2, __pyx_n_s_stride2, __pyx_n_s_size3, __pyx_n_s_stride3, __pyx_n_s_newTensorC); if (unlikely(!__pyx_tuple__94)) __PYX_ERR(0, 1799, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__94);
  __Pyx_GIVEREF(__pyx_tuple__94);
  __pyx_codeobj__95 = (PyObject*)__Pyx_PyCode_New(10, 0, 11, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__94, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_home_steb_inst_pytorch_src_PyTo, __pyx_n_s_newWithStorage4d, 1799, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__95)) __PYX_ERR(0, 1799, __pyx_L1_error)

  /* "PyTorch.pyx":1966
 * 
 * 
 * def _asDoubleTensor(myarray):             # <<<<<<<<<<<<<<
 *     cdef double[:] myarraymv
 *     cdef Storage._DoubleStorage storage
 */
  __pyx_tuple__96 = PyTuple_Pack(10, __pyx_n_s_myarray, __pyx_n_s_myarraymv, __pyx_n_s_storage, __pyx_n_s_dims, __pyx_n_s_totalSize, __pyx_n_s_size, __pyx_n_s_stride, __pyx_n_s_strideSoFar, __pyx_n_s_d, __pyx_n_s_tensor); if (unlikely(!__pyx_tuple__96)) __PYX_ERR(0, 1966, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__96);
  __Pyx_GIVEREF(__pyx_tuple__96);
  __pyx_codeobj__97 = (PyObject*)__Pyx_PyCode_New(1, 0, 10, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__96, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_home_steb_inst_pytorch_src_PyTo, __pyx_n_s_asDoubleTensor, 1966, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__97)) __PYX_ERR(0, 1966, __pyx_L1_error)

  /* "PyTorch.pyx":2248
 * 
 *     @staticmethod
 *     def new():             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         return _ByteTensor()
 */
  __pyx_codeobj__98 = (PyObject*)__Pyx_PyCode_New(0, 0, 0, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_home_steb_inst_pytorch_src_PyTo, __pyx_n_s_new, 2248, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__98)) __PYX_ERR(0, 2248, __pyx_L1_error)

  /* "PyTorch.pyx":2301
 * 
 *     @staticmethod
 *     def newWithStorage(Storage._ByteStorage storage, offset, Storage._LongStorage size, Storage._LongStorage stride):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THByteTensor *newTensorC = THByteTensor_newWithStorage(storage.native, offset, size.native, stride.native)
 */
  __pyx_tuple__99 = PyTuple_Pack(5, __pyx_n_s_storage, __pyx_n_s_offset, __pyx_n_s_size, __pyx_n_s_stride, __pyx_n_s_newTensorC); if (unlikely(!__pyx_tuple__99)) __PYX_ERR(0, 2301, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__99);
  __Pyx_GIVEREF(__pyx_tuple__99);
  __pyx_codeobj__100 = (PyObject*)__Pyx_PyCode_New(4, 0, 5, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__99, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_home_steb_inst_pytorch_src_PyTo, __pyx_n_s_newWithStorage, 2301, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__100)) __PYX_ERR(0, 2301, __pyx_L1_error)

  /* "PyTorch.pyx":2307
 * 
 *     @staticmethod
 *     def newWithStorage1d(Storage._ByteStorage storage, offset, size0, stride0):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THByteTensor *newTensorC = THByteTensor_newWithStorage1d(storage.native, offset, size0, stride0)
 */
  __pyx_tuple__101 = PyTuple_Pack(5, __pyx_n_s_storage, __pyx_n_s_offset, __pyx_n_s_size0, __pyx_n_s_stride0, __pyx_n_s_newTensorC); if (unlikely(!__pyx_tuple__101)) __PYX_ERR(0, 2307, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__101);
  __Pyx_GIVEREF(__pyx_tuple__101);
  __pyx_codeobj__102 = (PyObject*)__Pyx_PyCode_New(4, 0, 5, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__101, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_home_steb_inst_pytorch_src_PyTo, __pyx_n_s_newWithStorage1d, 2307, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__102)) __PYX_ERR(0, 2307, __pyx_L1_error)

  /* "PyTorch.pyx":2313
 * 
 *     @staticmethod
 *     def newWithStorage2d(Storage._ByteStorage storage, offset, size0, stride0, size1, stride1):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THByteTensor *newTensorC = THByteTensor_newWithStorage2d(storage.native, offset, size0, stride0, size1, stride1)
 */
  __pyx_tuple__103 = PyTuple_Pack(7, __pyx_n_s_storage, __pyx_n_s_offset, __pyx_n_s_size0, __pyx_n_s_stride0, __pyx_n_s_size1, __pyx_n_s_stride1, __pyx_n_s_newTensorC); if (unlikely(!__pyx_tuple__103)) __PYX_ERR(0, 2313, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__103);
  __Pyx_GIVEREF(__pyx_tuple__103);
  __pyx_codeobj__104 = (PyObject*)__Pyx_PyCode_New(6, 0, 7, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__103, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_home_steb_inst_pytorch_src_PyTo, __pyx_n_s_newWithStorage2d, 2313, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__104)) __PYX_ERR(0, 2313, __pyx_L1_error)

  /* "PyTorch.pyx":2319
 * 
 *     @staticmethod
 *     def newWithStorage3d(Storage._ByteStorage storage, offset, size0, stride0, size1, stride1, size2, stride2):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THByteTensor *newTensorC = THByteTensor_newWithStorage3d(storage.native, offset, size0, stride0, size1, stride1,
 */
  __pyx_tuple__105 = PyTuple_Pack(9, __pyx_n_s_storage, __pyx_n_s_offset, __pyx_n_s_size0, __pyx_n_s_stride0, __pyx_n_s_size1, __pyx_n_s_stride1, __pyx_n_s_size2, __pyx_n_s_stride2, __pyx_n_s_newTensorC); if (unlikely(!__pyx_tuple__105)) __PYX_ERR(0, 2319, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__105);
  __Pyx_GIVEREF(__pyx_tuple__105);
  __pyx_codeobj__106 = (PyObject*)__Pyx_PyCode_New(8, 0, 9, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__105, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_home_steb_inst_pytorch_src_PyTo, __pyx_n_s_newWithStorage3d, 2319, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__106)) __PYX_ERR(0, 2319, __pyx_L1_error)

  /* "PyTorch.pyx":2326
 * 
 *     @staticmethod
 *     def newWithStorage4d(Storage._ByteStorage storage, offset, size0, stride0, size1, stride1, size2, stride2,             # <<<<<<<<<<<<<<
 *             size3, stride3):
 * #        # print('allocate tensor')
 */
  __pyx_tuple__107 = PyTuple_Pack(11, __pyx_n_s_storage, __pyx_n_s_offset, __pyx_n_s_size0, __pyx_n_s_stride0, __pyx_n_s_size1, __pyx_n_s_stride1, __pyx_n_s_size2, __pyx_n_s_stride2, __pyx_n_s_size3, __pyx_n_s_stride3, __pyx_n_s_newTensorC); if (unlikely(!__pyx_tuple__107)) __PYX_ERR(0, 2326, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__107);
  __Pyx_GIVEREF(__pyx_tuple__107);
  __pyx_codeobj__108 = (PyObject*)__Pyx_PyCode_New(10, 0, 11, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__107, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_home_steb_inst_pytorch_src_PyTo, __pyx_n_s_newWithStorage4d, 2326, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__108)) __PYX_ERR(0, 2326, __pyx_L1_error)

  /* "PyTorch.pyx":2466
 * 
 * 
 * def _asByteTensor(myarray):             # <<<<<<<<<<<<<<
 *     cdef unsigned char[:] myarraymv
 *     cdef Storage._ByteStorage storage
 */
  __pyx_tuple__109 = PyTuple_Pack(10, __pyx_n_s_myarray, __pyx_n_s_myarraymv, __pyx_n_s_storage, __pyx_n_s_dims, __pyx_n_s_totalSize, __pyx_n_s_size, __pyx_n_s_stride, __pyx_n_s_strideSoFar, __pyx_n_s_d, __pyx_n_s_tensor); if (unlikely(!__pyx_tuple__109)) __PYX_ERR(0, 2466, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__109);
  __Pyx_GIVEREF(__pyx_tuple__109);
  __pyx_codeobj__110 = (PyObject*)__Pyx_PyCode_New(1, 0, 10, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__109, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_home_steb_inst_pytorch_src_PyTo, __pyx_n_s_asByteTensor, 2466, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__110)) __PYX_ERR(0, 2466, __pyx_L1_error)

  /* "PyTorch.pyx":2520
 * 
 * 
 * def _popFloatTensor():             # <<<<<<<<<<<<<<
 *     global globalState
 *     cdef THFloatTensor *tensorC = popFloatTensor(globalState.L)
 */
  __pyx_tuple__111 = PyTuple_Pack(1, __pyx_n_s_tensorC); if (unlikely(!__pyx_tuple__111)) __PYX_ERR(0, 2520, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__111);
  __Pyx_GIVEREF(__pyx_tuple__111);
  __pyx_codeobj__112 = (PyObject*)__Pyx_PyCode_New(0, 0, 1, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__111, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_home_steb_inst_pytorch_src_PyTo, __pyx_n_s_popFloatTensor, 2520, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__112)) __PYX_ERR(0, 2520, __pyx_L1_error)

  /* "PyTorch.pyx":2525
 *     return _FloatTensor_fromNative(tensorC)
 * 
 * def _pushFloatTensor(_FloatTensor tensor):             # <<<<<<<<<<<<<<
 *     global globalState
 *     pushFloatTensor(globalState.L, tensor.native)
 */
  __pyx_tuple__113 = PyTuple_Pack(1, __pyx_n_s_tensor); if (unlikely(!__pyx_tuple__113)) __PYX_ERR(0, 2525, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__113);
  __Pyx_GIVEREF(__pyx_tuple__113);
  __pyx_codeobj__114 = (PyObject*)__Pyx_PyCode_New(1, 0, 1, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__113, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_home_steb_inst_pytorch_src_PyTo, __pyx_n_s_pushFloatTensor, 2525, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__114)) __PYX_ERR(0, 2525, __pyx_L1_error)

  /* "PyTorch.pyx":2533
 * 
 * 
 * def _popDoubleTensor():             # <<<<<<<<<<<<<<
 *     global globalState
 *     cdef THDoubleTensor *tensorC = popDoubleTensor(globalState.L)
 */
  __pyx_tuple__115 = PyTuple_Pack(1, __pyx_n_s_tensorC); if (unlikely(!__pyx_tuple__115)) __PYX_ERR(0, 2533, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__115);
  __Pyx_GIVEREF(__pyx_tuple__115);
  __pyx_codeobj__116 = (PyObject*)__Pyx_PyCode_New(0, 0, 1, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__115, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_home_steb_inst_pytorch_src_PyTo, __pyx_n_s_popDoubleTensor, 2533, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__116)) __PYX_ERR(0, 2533, __pyx_L1_error)

  /* "PyTorch.pyx":2538
 *     return _DoubleTensor_fromNative(tensorC)
 * 
 * def _pushDoubleTensor(_DoubleTensor tensor):             # <<<<<<<<<<<<<<
 *     global globalState
 *     pushDoubleTensor(globalState.L, tensor.native)
 */
  __pyx_tuple__117 = PyTuple_Pack(1, __pyx_n_s_tensor); if (unlikely(!__pyx_tuple__117)) __PYX_ERR(0, 2538, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__117);
  __Pyx_GIVEREF(__pyx_tuple__117);
  __pyx_codeobj__118 = (PyObject*)__Pyx_PyCode_New(1, 0, 1, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__117, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_home_steb_inst_pytorch_src_PyTo, __pyx_n_s_pushDoubleTensor, 2538, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__118)) __PYX_ERR(0, 2538, __pyx_L1_error)

  /* "PyTorch.pyx":2546
 * 
 * 
 * def _popByteTensor():             # <<<<<<<<<<<<<<
 *     global globalState
 *     cdef THByteTensor *tensorC = popByteTensor(globalState.L)
 */
  __pyx_tuple__119 = PyTuple_Pack(1, __pyx_n_s_tensorC); if (unlikely(!__pyx_tuple__119)) __PYX_ERR(0, 2546, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__119);
  __Pyx_GIVEREF(__pyx_tuple__119);
  __pyx_codeobj__120 = (PyObject*)__Pyx_PyCode_New(0, 0, 1, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__119, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_home_steb_inst_pytorch_src_PyTo, __pyx_n_s_popByteTensor, 2546, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__120)) __PYX_ERR(0, 2546, __pyx_L1_error)

  /* "PyTorch.pyx":2551
 *     return _ByteTensor_fromNative(tensorC)
 * 
 * def _pushByteTensor(_ByteTensor tensor):             # <<<<<<<<<<<<<<
 *     global globalState
 *     pushByteTensor(globalState.L, tensor.native)
 */
  __pyx_tuple__121 = PyTuple_Pack(1, __pyx_n_s_tensor); if (unlikely(!__pyx_tuple__121)) __PYX_ERR(0, 2551, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__121);
  __Pyx_GIVEREF(__pyx_tuple__121);
  __pyx_codeobj__122 = (PyObject*)__Pyx_PyCode_New(1, 0, 1, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__121, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_home_steb_inst_pytorch_src_PyTo, __pyx_n_s_pushByteTensor, 2551, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__122)) __PYX_ERR(0, 2551, __pyx_L1_error)

  /* "PyTorch.pyx":2602
 * cdef GlobalState globalState
 * 
 * def getGlobalState():             # <<<<<<<<<<<<<<
 *     global globalState
 *     return globalState
 */
  __pyx_codeobj__123 = (PyObject*)__Pyx_PyCode_New(0, 0, 0, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_home_steb_inst_pytorch_src_PyTo, __pyx_n_s_getGlobalState, 2602, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__123)) __PYX_ERR(0, 2602, __pyx_L1_error)

  /* "PyTorch.pyx":2606
 *     return globalState
 * 
 * def require(libName):             # <<<<<<<<<<<<<<
 *     global globalState
 *     cdef lua_State *L
 */
  __pyx_tuple__124 = PyTuple_Pack(2, __pyx_n_s_libName, __pyx_n_s_L); if (unlikely(!__pyx_tuple__124)) __PYX_ERR(0, 2606, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__124);
  __Pyx_GIVEREF(__pyx_tuple__124);
  __pyx_codeobj__125 = (PyObject*)__Pyx_PyCode_New(1, 0, 2, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__124, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_home_steb_inst_pytorch_src_PyTo, __pyx_n_s_require, 2606, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__125)) __PYX_ERR(0, 2606, __pyx_L1_error)

  /* "PyTorch.pyx":2612
 *     luaRequire(L, libName.encode('utf-8'))
 * 
 * def getGlobal(name):             # <<<<<<<<<<<<<<
 *     global globalState
 *     cdef lua_State *L
 */
  __pyx_tuple__126 = PyTuple_Pack(2, __pyx_n_s_name, __pyx_n_s_L); if (unlikely(!__pyx_tuple__126)) __PYX_ERR(0, 2612, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__126);
  __Pyx_GIVEREF(__pyx_tuple__126);
  __pyx_codeobj__127 = (PyObject*)__Pyx_PyCode_New(1, 0, 2, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__126, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_home_steb_inst_pytorch_src_PyTo, __pyx_n_s_getGlobal, 2612, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__127)) __PYX_ERR(0, 2612, __pyx_L1_error)

  /* "PyTorch.pyx":2618
 * 
 * 
 * def init():             # <<<<<<<<<<<<<<
 *     global globalState
 *     # print('initializing PyTorch...')
 */
  __pyx_codeobj__128 = (PyObject*)__Pyx_PyCode_New(0, 0, 0, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_home_steb_inst_pytorch_src_PyTo, __pyx_n_s_init, 2618, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__128)) __PYX_ERR(0, 2618, __pyx_L1_error)

  /* "View.MemoryView":282
 *         return self.name
 * 
 * cdef generic = Enum("<strided and direct or indirect>")             # <<<<<<<<<<<<<<
 * cdef strided = Enum("<strided and direct>") # default
 * cdef indirect = Enum("<strided and indirect>")
 */
  __pyx_tuple__130 = PyTuple_Pack(1, __pyx_kp_s_strided_and_direct_or_indirect); if (unlikely(!__pyx_tuple__130)) __PYX_ERR(2, 282, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__130);
  __Pyx_GIVEREF(__pyx_tuple__130);

  /* "View.MemoryView":283
 * 
 * cdef generic = Enum("<strided and direct or indirect>")
 * cdef strided = Enum("<strided and direct>") # default             # <<<<<<<<<<<<<<
 * cdef indirect = Enum("<strided and indirect>")
 * 
 */
  __pyx_tuple__131 = PyTuple_Pack(1, __pyx_kp_s_strided_and_direct); if (unlikely(!__pyx_tuple__131)) __PYX_ERR(2, 283, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__131);
  __Pyx_GIVEREF(__pyx_tuple__131);

  /* "View.MemoryView":284
 * cdef generic = Enum("<strided and direct or indirect>")
 * cdef strided = Enum("<strided and direct>") # default
 * cdef indirect = Enum("<strided and indirect>")             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_tuple__132 = PyTuple_Pack(1, __pyx_kp_s_strided_and_indirect); if (unlikely(!__pyx_tuple__132)) __PYX_ERR(2, 284, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__132);
  __Pyx_GIVEREF(__pyx_tuple__132);

  /* "View.MemoryView":287
 * 
 * 
 * cdef contiguous = Enum("<contiguous and direct>")             # <<<<<<<<<<<<<<
 * cdef indirect_contiguous = Enum("<contiguous and indirect>")
 * 
 */
  __pyx_tuple__133 = PyTuple_Pack(1, __pyx_kp_s_contiguous_and_direct); if (unlikely(!__pyx_tuple__133)) __PYX_ERR(2, 287, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__133);
  __Pyx_GIVEREF(__pyx_tuple__133);

  /* "View.MemoryView":288
 * 
 * cdef contiguous = Enum("<contiguous and direct>")
 * cdef indirect_contiguous = Enum("<contiguous and indirect>")             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_tuple__134 = PyTuple_Pack(1, __pyx_kp_s_contiguous_and_indirect); if (unlikely(!__pyx_tuple__134)) __PYX_ERR(2, 288, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__134);
  __Pyx_GIVEREF(__pyx_tuple__134);
  __Pyx_RefNannyFinishContext();
  return 0;
  __pyx_L1_error:;
  __Pyx_RefNannyFinishContext();
  return -1;
}

static int __Pyx_InitGlobals(void) {
  if (__Pyx_InitStrings(__pyx_string_tab) < 0) __PYX_ERR(0, 1, __pyx_L1_error);
  __pyx_int_0 = PyInt_FromLong(0); if (unlikely(!__pyx_int_0)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_int_1 = PyInt_FromLong(1); if (unlikely(!__pyx_int_1)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_int_2 = PyInt_FromLong(2); if (unlikely(!__pyx_int_2)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_int_neg_1 = PyInt_FromLong(-1); if (unlikely(!__pyx_int_neg_1)) __PYX_ERR(0, 1, __pyx_L1_error)
  return 0;
  __pyx_L1_error:;
  return -1;
}

#if PY_MAJOR_VERSION < 3
PyMODINIT_FUNC initPyTorch(void); /*proto*/
PyMODINIT_FUNC initPyTorch(void)
#else
PyMODINIT_FUNC PyInit_PyTorch(void); /*proto*/
PyMODINIT_FUNC PyInit_PyTorch(void)
#endif
{
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  static PyThread_type_lock __pyx_t_8[8];
  __Pyx_RefNannyDeclarations
  #if CYTHON_REFNANNY
  __Pyx_RefNanny = __Pyx_RefNannyImportAPI("refnanny");
  if (!__Pyx_RefNanny) {
      PyErr_Clear();
      __Pyx_RefNanny = __Pyx_RefNannyImportAPI("Cython.Runtime.refnanny");
      if (!__Pyx_RefNanny)
          Py_FatalError("failed to import 'refnanny' module");
  }
  #endif
  __Pyx_RefNannySetupContext("PyMODINIT_FUNC PyInit_PyTorch(void)", 0);
  if (__Pyx_check_binary_version() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_empty_tuple = PyTuple_New(0); if (unlikely(!__pyx_empty_tuple)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_empty_bytes = PyBytes_FromStringAndSize("", 0); if (unlikely(!__pyx_empty_bytes)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_empty_unicode = PyUnicode_FromStringAndSize("", 0); if (unlikely(!__pyx_empty_unicode)) __PYX_ERR(0, 1, __pyx_L1_error)
  #ifdef __Pyx_CyFunction_USED
  if (__pyx_CyFunction_init() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_FusedFunction_USED
  if (__pyx_FusedFunction_init() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_Coroutine_USED
  if (__pyx_Coroutine_init() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_Generator_USED
  if (__pyx_Generator_init() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_StopAsyncIteration_USED
  if (__pyx_StopAsyncIteration_init() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  /*--- Library function declarations ---*/
  /*--- Threads initialization code ---*/
  #if defined(__PYX_FORCE_INIT_THREADS) && __PYX_FORCE_INIT_THREADS
  #ifdef WITH_THREAD /* Python build with threading support? */
  PyEval_InitThreads();
  #endif
  #endif
  /*--- Module creation code ---*/
  #if PY_MAJOR_VERSION < 3
  __pyx_m = Py_InitModule4("PyTorch", __pyx_methods, 0, 0, PYTHON_API_VERSION); Py_XINCREF(__pyx_m);
  #else
  __pyx_m = PyModule_Create(&__pyx_moduledef);
  #endif
  if (unlikely(!__pyx_m)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_d = PyModule_GetDict(__pyx_m); if (unlikely(!__pyx_d)) __PYX_ERR(0, 1, __pyx_L1_error)
  Py_INCREF(__pyx_d);
  __pyx_b = PyImport_AddModule(__Pyx_BUILTIN_MODULE_NAME); if (unlikely(!__pyx_b)) __PYX_ERR(0, 1, __pyx_L1_error)
  #if CYTHON_COMPILING_IN_PYPY
  Py_INCREF(__pyx_b);
  #endif
  if (PyObject_SetAttrString(__pyx_m, "__builtins__", __pyx_b) < 0) __PYX_ERR(0, 1, __pyx_L1_error);
  /*--- Initialize various global constants etc. ---*/
  if (__Pyx_InitGlobals() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #if PY_MAJOR_VERSION < 3 && (__PYX_DEFAULT_STRING_ENCODING_IS_ASCII || __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT)
  if (__Pyx_init_sys_getdefaultencoding_params() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  if (__pyx_module_is_main_PyTorch) {
    if (PyObject_SetAttrString(__pyx_m, "__name__", __pyx_n_s_main) < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  }
  #if PY_MAJOR_VERSION >= 3
  {
    PyObject *modules = PyImport_GetModuleDict(); if (unlikely(!modules)) __PYX_ERR(0, 1, __pyx_L1_error)
    if (!PyDict_GetItemString(modules, "PyTorch")) {
      if (unlikely(PyDict_SetItemString(modules, "PyTorch", __pyx_m) < 0)) __PYX_ERR(0, 1, __pyx_L1_error)
    }
  }
  #endif
  /*--- Builtin init code ---*/
  if (__Pyx_InitCachedBuiltins() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  /*--- Constants init code ---*/
  if (__Pyx_InitCachedConstants() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  /*--- Global init code ---*/
  __pyx_v_7PyTorch_globalState = ((struct __pyx_obj_7PyTorch_GlobalState *)Py_None); Py_INCREF(Py_None);
  generic = Py_None; Py_INCREF(Py_None);
  strided = Py_None; Py_INCREF(Py_None);
  indirect = Py_None; Py_INCREF(Py_None);
  contiguous = Py_None; Py_INCREF(Py_None);
  indirect_contiguous = Py_None; Py_INCREF(Py_None);
  /*--- Variable export code ---*/
  /*--- Function export code ---*/
  /*--- Type init code ---*/
  __pyx_vtabptr_7PyTorch__LongTensor = &__pyx_vtable_7PyTorch__LongTensor;
  __pyx_vtable_7PyTorch__LongTensor.data = (long *(*)(struct __pyx_obj_7PyTorch__LongTensor *))__pyx_f_7PyTorch_11_LongTensor_data;
  __pyx_vtable_7PyTorch__LongTensor.dims = (int (*)(struct __pyx_obj_7PyTorch__LongTensor *, int __pyx_skip_dispatch))__pyx_f_7PyTorch_11_LongTensor_dims;
  __pyx_vtable_7PyTorch__LongTensor.set1d = (PyObject *(*)(struct __pyx_obj_7PyTorch__LongTensor *, int, long, int __pyx_skip_dispatch))__pyx_f_7PyTorch_11_LongTensor_set1d;
  __pyx_vtable_7PyTorch__LongTensor.set2d = (PyObject *(*)(struct __pyx_obj_7PyTorch__LongTensor *, int, int, long, int __pyx_skip_dispatch))__pyx_f_7PyTorch_11_LongTensor_set2d;
  __pyx_vtable_7PyTorch__LongTensor.get1d = (long (*)(struct __pyx_obj_7PyTorch__LongTensor *, int, int __pyx_skip_dispatch))__pyx_f_7PyTorch_11_LongTensor_get1d;
  __pyx_vtable_7PyTorch__LongTensor.get2d = (long (*)(struct __pyx_obj_7PyTorch__LongTensor *, int, int, int __pyx_skip_dispatch))__pyx_f_7PyTorch_11_LongTensor_get2d;
  __pyx_vtable_7PyTorch__LongTensor.isContiguous = (int (*)(struct __pyx_obj_7PyTorch__LongTensor *, int __pyx_skip_dispatch))__pyx_f_7PyTorch_11_LongTensor_isContiguous;
  __pyx_vtable_7PyTorch__LongTensor.max = (long (*)(struct __pyx_obj_7PyTorch__LongTensor *, int __pyx_skip_dispatch))__pyx_f_7PyTorch_11_LongTensor_max;
  __pyx_vtable_7PyTorch__LongTensor.min = (long (*)(struct __pyx_obj_7PyTorch__LongTensor *, int __pyx_skip_dispatch))__pyx_f_7PyTorch_11_LongTensor_min;
  if (PyType_Ready(&__pyx_type_7PyTorch__LongTensor) < 0) __PYX_ERR(0, 374, __pyx_L1_error)
  __pyx_type_7PyTorch__LongTensor.tp_print = 0;
  if (__Pyx_SetVtable(__pyx_type_7PyTorch__LongTensor.tp_dict, __pyx_vtabptr_7PyTorch__LongTensor) < 0) __PYX_ERR(0, 374, __pyx_L1_error)
  if (PyObject_SetAttrString(__pyx_m, "_LongTensor", (PyObject *)&__pyx_type_7PyTorch__LongTensor) < 0) __PYX_ERR(0, 374, __pyx_L1_error)
  __pyx_ptype_7PyTorch__LongTensor = &__pyx_type_7PyTorch__LongTensor;
  __pyx_vtabptr_7PyTorch__FloatTensor = &__pyx_vtable_7PyTorch__FloatTensor;
  __pyx_vtable_7PyTorch__FloatTensor.data = (float *(*)(struct __pyx_obj_7PyTorch__FloatTensor *))__pyx_f_7PyTorch_12_FloatTensor_data;
  __pyx_vtable_7PyTorch__FloatTensor.dims = (int (*)(struct __pyx_obj_7PyTorch__FloatTensor *, int __pyx_skip_dispatch))__pyx_f_7PyTorch_12_FloatTensor_dims;
  __pyx_vtable_7PyTorch__FloatTensor.set1d = (PyObject *(*)(struct __pyx_obj_7PyTorch__FloatTensor *, int, float, int __pyx_skip_dispatch))__pyx_f_7PyTorch_12_FloatTensor_set1d;
  __pyx_vtable_7PyTorch__FloatTensor.set2d = (PyObject *(*)(struct __pyx_obj_7PyTorch__FloatTensor *, int, int, float, int __pyx_skip_dispatch))__pyx_f_7PyTorch_12_FloatTensor_set2d;
  __pyx_vtable_7PyTorch__FloatTensor.get1d = (float (*)(struct __pyx_obj_7PyTorch__FloatTensor *, int, int __pyx_skip_dispatch))__pyx_f_7PyTorch_12_FloatTensor_get1d;
  __pyx_vtable_7PyTorch__FloatTensor.get2d = (float (*)(struct __pyx_obj_7PyTorch__FloatTensor *, int, int, int __pyx_skip_dispatch))__pyx_f_7PyTorch_12_FloatTensor_get2d;
  __pyx_vtable_7PyTorch__FloatTensor.isContiguous = (int (*)(struct __pyx_obj_7PyTorch__FloatTensor *, int __pyx_skip_dispatch))__pyx_f_7PyTorch_12_FloatTensor_isContiguous;
  __pyx_vtable_7PyTorch__FloatTensor.max = (float (*)(struct __pyx_obj_7PyTorch__FloatTensor *, int __pyx_skip_dispatch))__pyx_f_7PyTorch_12_FloatTensor_max;
  __pyx_vtable_7PyTorch__FloatTensor.min = (float (*)(struct __pyx_obj_7PyTorch__FloatTensor *, int __pyx_skip_dispatch))__pyx_f_7PyTorch_12_FloatTensor_min;
  if (PyType_Ready(&__pyx_type_7PyTorch__FloatTensor) < 0) __PYX_ERR(0, 851, __pyx_L1_error)
  __pyx_type_7PyTorch__FloatTensor.tp_print = 0;
  if (__Pyx_SetVtable(__pyx_type_7PyTorch__FloatTensor.tp_dict, __pyx_vtabptr_7PyTorch__FloatTensor) < 0) __PYX_ERR(0, 851, __pyx_L1_error)
  if (PyObject_SetAttrString(__pyx_m, "_FloatTensor", (PyObject *)&__pyx_type_7PyTorch__FloatTensor) < 0) __PYX_ERR(0, 851, __pyx_L1_error)
  __pyx_ptype_7PyTorch__FloatTensor = &__pyx_type_7PyTorch__FloatTensor;
  __pyx_vtabptr_7PyTorch__DoubleTensor = &__pyx_vtable_7PyTorch__DoubleTensor;
  __pyx_vtable_7PyTorch__DoubleTensor.data = (double *(*)(struct __pyx_obj_7PyTorch__DoubleTensor *))__pyx_f_7PyTorch_13_DoubleTensor_data;
  __pyx_vtable_7PyTorch__DoubleTensor.dims = (int (*)(struct __pyx_obj_7PyTorch__DoubleTensor *, int __pyx_skip_dispatch))__pyx_f_7PyTorch_13_DoubleTensor_dims;
  __pyx_vtable_7PyTorch__DoubleTensor.set1d = (PyObject *(*)(struct __pyx_obj_7PyTorch__DoubleTensor *, int, double, int __pyx_skip_dispatch))__pyx_f_7PyTorch_13_DoubleTensor_set1d;
  __pyx_vtable_7PyTorch__DoubleTensor.set2d = (PyObject *(*)(struct __pyx_obj_7PyTorch__DoubleTensor *, int, int, double, int __pyx_skip_dispatch))__pyx_f_7PyTorch_13_DoubleTensor_set2d;
  __pyx_vtable_7PyTorch__DoubleTensor.get1d = (double (*)(struct __pyx_obj_7PyTorch__DoubleTensor *, int, int __pyx_skip_dispatch))__pyx_f_7PyTorch_13_DoubleTensor_get1d;
  __pyx_vtable_7PyTorch__DoubleTensor.get2d = (double (*)(struct __pyx_obj_7PyTorch__DoubleTensor *, int, int, int __pyx_skip_dispatch))__pyx_f_7PyTorch_13_DoubleTensor_get2d;
  __pyx_vtable_7PyTorch__DoubleTensor.isContiguous = (int (*)(struct __pyx_obj_7PyTorch__DoubleTensor *, int __pyx_skip_dispatch))__pyx_f_7PyTorch_13_DoubleTensor_isContiguous;
  __pyx_vtable_7PyTorch__DoubleTensor.max = (double (*)(struct __pyx_obj_7PyTorch__DoubleTensor *, int __pyx_skip_dispatch))__pyx_f_7PyTorch_13_DoubleTensor_max;
  __pyx_vtable_7PyTorch__DoubleTensor.min = (double (*)(struct __pyx_obj_7PyTorch__DoubleTensor *, int __pyx_skip_dispatch))__pyx_f_7PyTorch_13_DoubleTensor_min;
  if (PyType_Ready(&__pyx_type_7PyTorch__DoubleTensor) < 0) __PYX_ERR(0, 1427, __pyx_L1_error)
  __pyx_type_7PyTorch__DoubleTensor.tp_print = 0;
  if (__Pyx_SetVtable(__pyx_type_7PyTorch__DoubleTensor.tp_dict, __pyx_vtabptr_7PyTorch__DoubleTensor) < 0) __PYX_ERR(0, 1427, __pyx_L1_error)
  if (PyObject_SetAttrString(__pyx_m, "_DoubleTensor", (PyObject *)&__pyx_type_7PyTorch__DoubleTensor) < 0) __PYX_ERR(0, 1427, __pyx_L1_error)
  __pyx_ptype_7PyTorch__DoubleTensor = &__pyx_type_7PyTorch__DoubleTensor;
  __pyx_vtabptr_7PyTorch__ByteTensor = &__pyx_vtable_7PyTorch__ByteTensor;
  __pyx_vtable_7PyTorch__ByteTensor.data = (unsigned char *(*)(struct __pyx_obj_7PyTorch__ByteTensor *))__pyx_f_7PyTorch_11_ByteTensor_data;
  __pyx_vtable_7PyTorch__ByteTensor.dims = (int (*)(struct __pyx_obj_7PyTorch__ByteTensor *, int __pyx_skip_dispatch))__pyx_f_7PyTorch_11_ByteTensor_dims;
  __pyx_vtable_7PyTorch__ByteTensor.set1d = (PyObject *(*)(struct __pyx_obj_7PyTorch__ByteTensor *, int, unsigned char, int __pyx_skip_dispatch))__pyx_f_7PyTorch_11_ByteTensor_set1d;
  __pyx_vtable_7PyTorch__ByteTensor.set2d = (PyObject *(*)(struct __pyx_obj_7PyTorch__ByteTensor *, int, int, unsigned char, int __pyx_skip_dispatch))__pyx_f_7PyTorch_11_ByteTensor_set2d;
  __pyx_vtable_7PyTorch__ByteTensor.get1d = (unsigned char (*)(struct __pyx_obj_7PyTorch__ByteTensor *, int, int __pyx_skip_dispatch))__pyx_f_7PyTorch_11_ByteTensor_get1d;
  __pyx_vtable_7PyTorch__ByteTensor.get2d = (unsigned char (*)(struct __pyx_obj_7PyTorch__ByteTensor *, int, int, int __pyx_skip_dispatch))__pyx_f_7PyTorch_11_ByteTensor_get2d;
  __pyx_vtable_7PyTorch__ByteTensor.isContiguous = (int (*)(struct __pyx_obj_7PyTorch__ByteTensor *, int __pyx_skip_dispatch))__pyx_f_7PyTorch_11_ByteTensor_isContiguous;
  __pyx_vtable_7PyTorch__ByteTensor.max = (unsigned char (*)(struct __pyx_obj_7PyTorch__ByteTensor *, int __pyx_skip_dispatch))__pyx_f_7PyTorch_11_ByteTensor_max;
  __pyx_vtable_7PyTorch__ByteTensor.min = (unsigned char (*)(struct __pyx_obj_7PyTorch__ByteTensor *, int __pyx_skip_dispatch))__pyx_f_7PyTorch_11_ByteTensor_min;
  if (PyType_Ready(&__pyx_type_7PyTorch__ByteTensor) < 0) __PYX_ERR(0, 2003, __pyx_L1_error)
  __pyx_type_7PyTorch__ByteTensor.tp_print = 0;
  if (__Pyx_SetVtable(__pyx_type_7PyTorch__ByteTensor.tp_dict, __pyx_vtabptr_7PyTorch__ByteTensor) < 0) __PYX_ERR(0, 2003, __pyx_L1_error)
  if (PyObject_SetAttrString(__pyx_m, "_ByteTensor", (PyObject *)&__pyx_type_7PyTorch__ByteTensor) < 0) __PYX_ERR(0, 2003, __pyx_L1_error)
  __pyx_ptype_7PyTorch__ByteTensor = &__pyx_type_7PyTorch__ByteTensor;
  if (PyType_Ready(&__pyx_type_7PyTorch_GlobalState) < 0) __PYX_ERR(0, 2502, __pyx_L1_error)
  __pyx_type_7PyTorch_GlobalState.tp_print = 0;
  if (PyObject_SetAttrString(__pyx_m, "GlobalState", (PyObject *)&__pyx_type_7PyTorch_GlobalState) < 0) __PYX_ERR(0, 2502, __pyx_L1_error)
  __pyx_ptype_7PyTorch_GlobalState = &__pyx_type_7PyTorch_GlobalState;
  if (PyType_Ready(&__pyx_type_7PyTorch_Nn) < 0) __PYX_ERR(0, 2632, __pyx_L1_error)
  __pyx_type_7PyTorch_Nn.tp_print = 0;
  if (PyObject_SetAttrString(__pyx_m, "Nn", (PyObject *)&__pyx_type_7PyTorch_Nn) < 0) __PYX_ERR(0, 2632, __pyx_L1_error)
  __pyx_ptype_7PyTorch_Nn = &__pyx_type_7PyTorch_Nn;
  __pyx_vtabptr_array = &__pyx_vtable_array;
  __pyx_vtable_array.get_memview = (PyObject *(*)(struct __pyx_array_obj *))__pyx_array_get_memview;
  if (PyType_Ready(&__pyx_type___pyx_array) < 0) __PYX_ERR(2, 103, __pyx_L1_error)
  __pyx_type___pyx_array.tp_print = 0;
  if (__Pyx_SetVtable(__pyx_type___pyx_array.tp_dict, __pyx_vtabptr_array) < 0) __PYX_ERR(2, 103, __pyx_L1_error)
  __pyx_array_type = &__pyx_type___pyx_array;
  if (PyType_Ready(&__pyx_type___pyx_MemviewEnum) < 0) __PYX_ERR(2, 275, __pyx_L1_error)
  __pyx_type___pyx_MemviewEnum.tp_print = 0;
  __pyx_MemviewEnum_type = &__pyx_type___pyx_MemviewEnum;
  __pyx_vtabptr_memoryview = &__pyx_vtable_memoryview;
  __pyx_vtable_memoryview.get_item_pointer = (char *(*)(struct __pyx_memoryview_obj *, PyObject *))__pyx_memoryview_get_item_pointer;
  __pyx_vtable_memoryview.is_slice = (PyObject *(*)(struct __pyx_memoryview_obj *, PyObject *))__pyx_memoryview_is_slice;
  __pyx_vtable_memoryview.setitem_slice_assignment = (PyObject *(*)(struct __pyx_memoryview_obj *, PyObject *, PyObject *))__pyx_memoryview_setitem_slice_assignment;
  __pyx_vtable_memoryview.setitem_slice_assign_scalar = (PyObject *(*)(struct __pyx_memoryview_obj *, struct __pyx_memoryview_obj *, PyObject *))__pyx_memoryview_setitem_slice_assign_scalar;
  __pyx_vtable_memoryview.setitem_indexed = (PyObject *(*)(struct __pyx_memoryview_obj *, PyObject *, PyObject *))__pyx_memoryview_setitem_indexed;
  __pyx_vtable_memoryview.convert_item_to_object = (PyObject *(*)(struct __pyx_memoryview_obj *, char *))__pyx_memoryview_convert_item_to_object;
  __pyx_vtable_memoryview.assign_item_from_object = (PyObject *(*)(struct __pyx_memoryview_obj *, char *, PyObject *))__pyx_memoryview_assign_item_from_object;
  if (PyType_Ready(&__pyx_type___pyx_memoryview) < 0) __PYX_ERR(2, 326, __pyx_L1_error)
  __pyx_type___pyx_memoryview.tp_print = 0;
  if (__Pyx_SetVtable(__pyx_type___pyx_memoryview.tp_dict, __pyx_vtabptr_memoryview) < 0) __PYX_ERR(2, 326, __pyx_L1_error)
  __pyx_memoryview_type = &__pyx_type___pyx_memoryview;
  __pyx_vtabptr__memoryviewslice = &__pyx_vtable__memoryviewslice;
  __pyx_vtable__memoryviewslice.__pyx_base = *__pyx_vtabptr_memoryview;
  __pyx_vtable__memoryviewslice.__pyx_base.convert_item_to_object = (PyObject *(*)(struct __pyx_memoryview_obj *, char *))__pyx_memoryviewslice_convert_item_to_object;
  __pyx_vtable__memoryviewslice.__pyx_base.assign_item_from_object = (PyObject *(*)(struct __pyx_memoryview_obj *, char *, PyObject *))__pyx_memoryviewslice_assign_item_from_object;
  __pyx_type___pyx_memoryviewslice.tp_base = __pyx_memoryview_type;
  if (PyType_Ready(&__pyx_type___pyx_memoryviewslice) < 0) __PYX_ERR(2, 951, __pyx_L1_error)
  __pyx_type___pyx_memoryviewslice.tp_print = 0;
  if (__Pyx_SetVtable(__pyx_type___pyx_memoryviewslice.tp_dict, __pyx_vtabptr__memoryviewslice) < 0) __PYX_ERR(2, 951, __pyx_L1_error)
  __pyx_memoryviewslice_type = &__pyx_type___pyx_memoryviewslice;
  /*--- Type import code ---*/
  __pyx_ptype_7cpython_4type_type = __Pyx_ImportType(__Pyx_BUILTIN_MODULE_NAME, "type", 
  #if CYTHON_COMPILING_IN_PYPY
  sizeof(PyTypeObject),
  #else
  sizeof(PyHeapTypeObject),
  #endif
  0); if (unlikely(!__pyx_ptype_7cpython_4type_type)) __PYX_ERR(3, 9, __pyx_L1_error)
  __pyx_ptype_7cpython_5array_array = __Pyx_ImportType("array", "array", sizeof(arrayobject), 0); if (unlikely(!__pyx_ptype_7cpython_5array_array)) __PYX_ERR(1, 58, __pyx_L1_error)
  __pyx_ptype_7Storage__LongStorage = __Pyx_ImportType("Storage", "_LongStorage", sizeof(struct __pyx_obj_7Storage__LongStorage), 1); if (unlikely(!__pyx_ptype_7Storage__LongStorage)) __PYX_ERR(4, 91, __pyx_L1_error)
  __pyx_vtabptr_7Storage__LongStorage = (struct __pyx_vtabstruct_7Storage__LongStorage*)__Pyx_GetVtable(__pyx_ptype_7Storage__LongStorage->tp_dict); if (unlikely(!__pyx_vtabptr_7Storage__LongStorage)) __PYX_ERR(4, 91, __pyx_L1_error)
  __pyx_ptype_7Storage__FloatStorage = __Pyx_ImportType("Storage", "_FloatStorage", sizeof(struct __pyx_obj_7Storage__FloatStorage), 1); if (unlikely(!__pyx_ptype_7Storage__FloatStorage)) __PYX_ERR(4, 99, __pyx_L1_error)
  __pyx_vtabptr_7Storage__FloatStorage = (struct __pyx_vtabstruct_7Storage__FloatStorage*)__Pyx_GetVtable(__pyx_ptype_7Storage__FloatStorage->tp_dict); if (unlikely(!__pyx_vtabptr_7Storage__FloatStorage)) __PYX_ERR(4, 99, __pyx_L1_error)
  __pyx_ptype_7Storage__DoubleStorage = __Pyx_ImportType("Storage", "_DoubleStorage", sizeof(struct __pyx_obj_7Storage__DoubleStorage), 1); if (unlikely(!__pyx_ptype_7Storage__DoubleStorage)) __PYX_ERR(4, 107, __pyx_L1_error)
  __pyx_vtabptr_7Storage__DoubleStorage = (struct __pyx_vtabstruct_7Storage__DoubleStorage*)__Pyx_GetVtable(__pyx_ptype_7Storage__DoubleStorage->tp_dict); if (unlikely(!__pyx_vtabptr_7Storage__DoubleStorage)) __PYX_ERR(4, 107, __pyx_L1_error)
  __pyx_ptype_7Storage__ByteStorage = __Pyx_ImportType("Storage", "_ByteStorage", sizeof(struct __pyx_obj_7Storage__ByteStorage), 1); if (unlikely(!__pyx_ptype_7Storage__ByteStorage)) __PYX_ERR(4, 115, __pyx_L1_error)
  __pyx_vtabptr_7Storage__ByteStorage = (struct __pyx_vtabstruct_7Storage__ByteStorage*)__Pyx_GetVtable(__pyx_ptype_7Storage__ByteStorage->tp_dict); if (unlikely(!__pyx_vtabptr_7Storage__ByteStorage)) __PYX_ERR(4, 115, __pyx_L1_error)
  __pyx_ptype_3lua_LuaState = __Pyx_ImportType("lua", "LuaState", sizeof(struct __pyx_obj_3lua_LuaState), 1); if (unlikely(!__pyx_ptype_3lua_LuaState)) __PYX_ERR(5, 67, __pyx_L1_error)
  /*--- Variable import code ---*/
  /*--- Function import code ---*/
  __pyx_t_1 = __Pyx_ImportModule("Storage"); if (!__pyx_t_1) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ImportFunction(__pyx_t_1, "_LongStorage_fromNative", (void (**)(void))&__pyx_f_7Storage__LongStorage_fromNative, "PyObject *(struct THLongStorage *, struct __pyx_opt_args_7Storage__LongStorage_fromNative *__pyx_optional_args)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ImportFunction(__pyx_t_1, "_FloatStorage_fromNative", (void (**)(void))&__pyx_f_7Storage__FloatStorage_fromNative, "PyObject *(struct THFloatStorage *, struct __pyx_opt_args_7Storage__FloatStorage_fromNative *__pyx_optional_args)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ImportFunction(__pyx_t_1, "_DoubleStorage_fromNative", (void (**)(void))&__pyx_f_7Storage__DoubleStorage_fromNative, "PyObject *(struct THDoubleStorage *, struct __pyx_opt_args_7Storage__DoubleStorage_fromNative *__pyx_optional_args)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ImportFunction(__pyx_t_1, "_ByteStorage_fromNative", (void (**)(void))&__pyx_f_7Storage__ByteStorage_fromNative, "PyObject *(struct THByteStorage *, struct __pyx_opt_args_7Storage__ByteStorage_fromNative *__pyx_optional_args)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  Py_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_2 = __Pyx_ImportModule("lua"); if (!__pyx_t_2) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ImportFunction(__pyx_t_2, "LuaState_fromNative", (void (**)(void))&__pyx_f_3lua_LuaState_fromNative, "PyObject *(struct lua_State *)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  Py_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  /*--- Execution code ---*/
  #if defined(__Pyx_Generator_USED) || defined(__Pyx_Coroutine_USED)
  if (__Pyx_patch_abc() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif

  /* "PyTorch.pyx":5
 * 
 * from __future__ import print_function, division
 * import numbers             # <<<<<<<<<<<<<<
 * import cython
 * cimport cython
 */
  __pyx_t_3 = __Pyx_Import(__pyx_n_s_numbers, 0, -1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 5, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_numbers, __pyx_t_3) < 0) __PYX_ERR(0, 5, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "PyTorch.pyx":9
 * cimport cython
 * 
 * import numpy as np             # <<<<<<<<<<<<<<
 * 
 * cimport cpython.array
 */
  __pyx_t_3 = __Pyx_Import(__pyx_n_s_numpy, 0, -1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 9, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_np, __pyx_t_3) < 0) __PYX_ERR(0, 9, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "PyTorch.pyx":12
 * 
 * cimport cpython.array
 * import array             # <<<<<<<<<<<<<<
 * 
 * from math import log10, floor
 */
  __pyx_t_3 = __Pyx_Import(__pyx_n_s_array, 0, -1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 12, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_array, __pyx_t_3) < 0) __PYX_ERR(0, 12, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "PyTorch.pyx":14
 * import array
 * 
 * from math import log10, floor             # <<<<<<<<<<<<<<
 * 
 * cimport Storage
 */
  __pyx_t_3 = PyList_New(2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 14, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_INCREF(__pyx_n_s_log10);
  __Pyx_GIVEREF(__pyx_n_s_log10);
  PyList_SET_ITEM(__pyx_t_3, 0, __pyx_n_s_log10);
  __Pyx_INCREF(__pyx_n_s_floor);
  __Pyx_GIVEREF(__pyx_n_s_floor);
  PyList_SET_ITEM(__pyx_t_3, 1, __pyx_n_s_floor);
  __pyx_t_4 = __Pyx_Import(__pyx_n_s_math, __pyx_t_3, -1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 14, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = __Pyx_ImportFrom(__pyx_t_4, __pyx_n_s_log10); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 14, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_log10, __pyx_t_3) < 0) __PYX_ERR(0, 14, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = __Pyx_ImportFrom(__pyx_t_4, __pyx_n_s_floor); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 14, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_floor, __pyx_t_3) < 0) __PYX_ERR(0, 14, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "PyTorch.pyx":17
 * 
 * cimport Storage
 * import Storage             # <<<<<<<<<<<<<<
 * from lua cimport *
 * from nnWrapper cimport *
 */
  __pyx_t_4 = __Pyx_Import(__pyx_n_s_Storage, 0, -1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 17, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_Storage, __pyx_t_4) < 0) __PYX_ERR(0, 17, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "PyTorch.pyx":24
 * # from Storage cimport *
 * 
 * import logging             # <<<<<<<<<<<<<<
 * logging.basicConfig()
 * logger = logging.getLogger(__name__)
 */
  __pyx_t_4 = __Pyx_Import(__pyx_n_s_logging, 0, -1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 24, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_logging, __pyx_t_4) < 0) __PYX_ERR(0, 24, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "PyTorch.pyx":25
 * 
 * import logging
 * logging.basicConfig()             # <<<<<<<<<<<<<<
 * logger = logging.getLogger(__name__)
 * # logger.setLevel(logging.DEBUG)
 */
  __pyx_t_3 = __Pyx_GetModuleGlobalName(__pyx_n_s_logging); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 25, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_basicConfig); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 25, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_5);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_5, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_4 = __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_t_3); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 25, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_4 = __Pyx_PyObject_CallNoArg(__pyx_t_5); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 25, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "PyTorch.pyx":26
 * import logging
 * logging.basicConfig()
 * logger = logging.getLogger(__name__)             # <<<<<<<<<<<<<<
 * # logger.setLevel(logging.DEBUG)
 * 
 */
  __pyx_t_5 = __Pyx_GetModuleGlobalName(__pyx_n_s_logging); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 26, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_getLogger); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 26, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = __Pyx_GetModuleGlobalName(__pyx_n_s_name_2); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 26, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_6 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_6)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_6);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
    }
  }
  if (!__pyx_t_6) {
    __pyx_t_4 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_5); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 26, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_GOTREF(__pyx_t_4);
  } else {
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_3)) {
      PyObject *__pyx_temp[2] = {__pyx_t_6, __pyx_t_5};
      __pyx_t_4 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 26, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
      PyObject *__pyx_temp[2] = {__pyx_t_6, __pyx_t_5};
      __pyx_t_4 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 26, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    } else
    #endif
    {
      __pyx_t_7 = PyTuple_New(1+1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 26, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_GIVEREF(__pyx_t_6); PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_6); __pyx_t_6 = NULL;
      __Pyx_GIVEREF(__pyx_t_5);
      PyTuple_SET_ITEM(__pyx_t_7, 0+1, __pyx_t_5);
      __pyx_t_5 = 0;
      __pyx_t_4 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_7, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 26, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    }
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_logger, __pyx_t_4) < 0) __PYX_ERR(0, 26, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "PyTorch.pyx":30
 * 
 * # from http://stackoverflow.com/questions/3410976/how-to-round-a-number-to-significant-figures-in-python
 * def round_sig(x, sig=2):             # <<<<<<<<<<<<<<
 *     return round(x, sig-int(floor(log10(abs(x))))-1)
 * 
 */
  __pyx_t_4 = PyCFunction_NewEx(&__pyx_mdef_7PyTorch_1round_sig, NULL, __pyx_n_s_PyTorch); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 30, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_round_sig, __pyx_t_4) < 0) __PYX_ERR(0, 30, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "PyTorch.pyx":37
 *     void THRandom_manualSeed(THGenerator *_generator, unsigned long the_seed_)
 * 
 * def manualSeed(long seed):             # <<<<<<<<<<<<<<
 *     THRandom_manualSeed(globalState.generator, seed)
 * 
 */
  __pyx_t_4 = PyCFunction_NewEx(&__pyx_mdef_7PyTorch_3manualSeed, NULL, __pyx_n_s_PyTorch); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 37, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_manualSeed, __pyx_t_4) < 0) __PYX_ERR(0, 37, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "PyTorch.pyx":46
 * 
 * 
 * _LongStorage = Storage._LongStorage             # <<<<<<<<<<<<<<
 * 
 * 
 */
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_LongStorage, ((PyObject *)__pyx_ptype_7Storage__LongStorage)) < 0) __PYX_ERR(0, 46, __pyx_L1_error)

  /* "PyTorch.pyx":50
 * 
 * 
 * _FloatStorage = Storage._FloatStorage             # <<<<<<<<<<<<<<
 * 
 * 
 */
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_FloatStorage, ((PyObject *)__pyx_ptype_7Storage__FloatStorage)) < 0) __PYX_ERR(0, 50, __pyx_L1_error)

  /* "PyTorch.pyx":54
 * 
 * 
 * _DoubleStorage = Storage._DoubleStorage             # <<<<<<<<<<<<<<
 * 
 * 
 */
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_DoubleStorage, ((PyObject *)__pyx_ptype_7Storage__DoubleStorage)) < 0) __PYX_ERR(0, 54, __pyx_L1_error)

  /* "PyTorch.pyx":58
 * 
 * 
 * _ByteStorage = Storage._ByteStorage             # <<<<<<<<<<<<<<
 * 
 * 
 */
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_ByteStorage, ((PyObject *)__pyx_ptype_7Storage__ByteStorage)) < 0) __PYX_ERR(0, 58, __pyx_L1_error)

  /* "PyTorch.pyx":629
 * 
 *     @staticmethod
 *     def new():             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         return _LongTensor()
 */
  __pyx_t_4 = PyCFunction_NewEx(&__pyx_mdef_7PyTorch_11_LongTensor_43new, NULL, __pyx_n_s_PyTorch); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 629, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":628
 *             return None  # not sure how to handle this yet
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def new():
 * #        # print('allocate tensor')
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 628, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 628, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__LongTensor->tp_dict, __pyx_n_s_new, __pyx_t_4) < 0) __PYX_ERR(0, 629, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__LongTensor);

  /* "PyTorch.pyx":629
 * 
 *     @staticmethod
 *     def new():             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         return _LongTensor()
 */
  __pyx_t_4 = __Pyx_GetNameInClass((PyObject *)__pyx_ptype_7PyTorch__LongTensor, __pyx_n_s_new); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 629, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":628
 *             return None  # not sure how to handle this yet
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def new():
 * #        # print('allocate tensor')
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 628, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 628, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__LongTensor->tp_dict, __pyx_n_s_new, __pyx_t_4) < 0) __PYX_ERR(0, 629, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__LongTensor);

  /* "PyTorch.pyx":682
 * 
 *     @staticmethod
 *     def newWithStorage(Storage._LongStorage storage, offset, Storage._LongStorage size, Storage._LongStorage stride):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THLongTensor *newTensorC = THLongTensor_newWithStorage(storage.native, offset, size.native, stride.native)
 */
  __pyx_t_4 = PyCFunction_NewEx(&__pyx_mdef_7PyTorch_11_LongTensor_61newWithStorage, NULL, __pyx_n_s_PyTorch); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 682, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":681
 *         return self
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def newWithStorage(Storage._LongStorage storage, offset, Storage._LongStorage size, Storage._LongStorage stride):
 * #        # print('allocate tensor')
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 681, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 681, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__LongTensor->tp_dict, __pyx_n_s_newWithStorage, __pyx_t_4) < 0) __PYX_ERR(0, 682, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__LongTensor);

  /* "PyTorch.pyx":682
 * 
 *     @staticmethod
 *     def newWithStorage(Storage._LongStorage storage, offset, Storage._LongStorage size, Storage._LongStorage stride):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THLongTensor *newTensorC = THLongTensor_newWithStorage(storage.native, offset, size.native, stride.native)
 */
  __pyx_t_4 = __Pyx_GetNameInClass((PyObject *)__pyx_ptype_7PyTorch__LongTensor, __pyx_n_s_newWithStorage); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 682, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":681
 *         return self
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def newWithStorage(Storage._LongStorage storage, offset, Storage._LongStorage size, Storage._LongStorage stride):
 * #        # print('allocate tensor')
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 681, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 681, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__LongTensor->tp_dict, __pyx_n_s_newWithStorage, __pyx_t_4) < 0) __PYX_ERR(0, 682, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__LongTensor);

  /* "PyTorch.pyx":688
 * 
 *     @staticmethod
 *     def newWithStorage1d(Storage._LongStorage storage, offset, size0, stride0):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THLongTensor *newTensorC = THLongTensor_newWithStorage1d(storage.native, offset, size0, stride0)
 */
  __pyx_t_4 = PyCFunction_NewEx(&__pyx_mdef_7PyTorch_11_LongTensor_63newWithStorage1d, NULL, __pyx_n_s_PyTorch); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 688, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":687
 *         return _LongTensor_fromNative(newTensorC, False)
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def newWithStorage1d(Storage._LongStorage storage, offset, size0, stride0):
 * #        # print('allocate tensor')
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 687, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 687, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__LongTensor->tp_dict, __pyx_n_s_newWithStorage1d, __pyx_t_4) < 0) __PYX_ERR(0, 688, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__LongTensor);

  /* "PyTorch.pyx":688
 * 
 *     @staticmethod
 *     def newWithStorage1d(Storage._LongStorage storage, offset, size0, stride0):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THLongTensor *newTensorC = THLongTensor_newWithStorage1d(storage.native, offset, size0, stride0)
 */
  __pyx_t_4 = __Pyx_GetNameInClass((PyObject *)__pyx_ptype_7PyTorch__LongTensor, __pyx_n_s_newWithStorage1d); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 688, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":687
 *         return _LongTensor_fromNative(newTensorC, False)
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def newWithStorage1d(Storage._LongStorage storage, offset, size0, stride0):
 * #        # print('allocate tensor')
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 687, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 687, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__LongTensor->tp_dict, __pyx_n_s_newWithStorage1d, __pyx_t_4) < 0) __PYX_ERR(0, 688, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__LongTensor);

  /* "PyTorch.pyx":694
 * 
 *     @staticmethod
 *     def newWithStorage2d(Storage._LongStorage storage, offset, size0, stride0, size1, stride1):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THLongTensor *newTensorC = THLongTensor_newWithStorage2d(storage.native, offset, size0, stride0, size1, stride1)
 */
  __pyx_t_4 = PyCFunction_NewEx(&__pyx_mdef_7PyTorch_11_LongTensor_65newWithStorage2d, NULL, __pyx_n_s_PyTorch); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 694, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":693
 *         return _LongTensor_fromNative(newTensorC, False)
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def newWithStorage2d(Storage._LongStorage storage, offset, size0, stride0, size1, stride1):
 * #        # print('allocate tensor')
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 693, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 693, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__LongTensor->tp_dict, __pyx_n_s_newWithStorage2d, __pyx_t_4) < 0) __PYX_ERR(0, 694, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__LongTensor);

  /* "PyTorch.pyx":694
 * 
 *     @staticmethod
 *     def newWithStorage2d(Storage._LongStorage storage, offset, size0, stride0, size1, stride1):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THLongTensor *newTensorC = THLongTensor_newWithStorage2d(storage.native, offset, size0, stride0, size1, stride1)
 */
  __pyx_t_4 = __Pyx_GetNameInClass((PyObject *)__pyx_ptype_7PyTorch__LongTensor, __pyx_n_s_newWithStorage2d); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 694, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":693
 *         return _LongTensor_fromNative(newTensorC, False)
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def newWithStorage2d(Storage._LongStorage storage, offset, size0, stride0, size1, stride1):
 * #        # print('allocate tensor')
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 693, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 693, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__LongTensor->tp_dict, __pyx_n_s_newWithStorage2d, __pyx_t_4) < 0) __PYX_ERR(0, 694, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__LongTensor);

  /* "PyTorch.pyx":700
 * 
 *     @staticmethod
 *     def newWithStorage3d(Storage._LongStorage storage, offset, size0, stride0, size1, stride1, size2, stride2):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THLongTensor *newTensorC = THLongTensor_newWithStorage3d(storage.native, offset, size0, stride0, size1, stride1,
 */
  __pyx_t_4 = PyCFunction_NewEx(&__pyx_mdef_7PyTorch_11_LongTensor_67newWithStorage3d, NULL, __pyx_n_s_PyTorch); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 700, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":699
 *         return _LongTensor_fromNative(newTensorC, False)
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def newWithStorage3d(Storage._LongStorage storage, offset, size0, stride0, size1, stride1, size2, stride2):
 * #        # print('allocate tensor')
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 699, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 699, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__LongTensor->tp_dict, __pyx_n_s_newWithStorage3d, __pyx_t_4) < 0) __PYX_ERR(0, 700, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__LongTensor);

  /* "PyTorch.pyx":700
 * 
 *     @staticmethod
 *     def newWithStorage3d(Storage._LongStorage storage, offset, size0, stride0, size1, stride1, size2, stride2):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THLongTensor *newTensorC = THLongTensor_newWithStorage3d(storage.native, offset, size0, stride0, size1, stride1,
 */
  __pyx_t_4 = __Pyx_GetNameInClass((PyObject *)__pyx_ptype_7PyTorch__LongTensor, __pyx_n_s_newWithStorage3d); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 700, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":699
 *         return _LongTensor_fromNative(newTensorC, False)
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def newWithStorage3d(Storage._LongStorage storage, offset, size0, stride0, size1, stride1, size2, stride2):
 * #        # print('allocate tensor')
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 699, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 699, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__LongTensor->tp_dict, __pyx_n_s_newWithStorage3d, __pyx_t_4) < 0) __PYX_ERR(0, 700, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__LongTensor);

  /* "PyTorch.pyx":707
 * 
 *     @staticmethod
 *     def newWithStorage4d(Storage._LongStorage storage, offset, size0, stride0, size1, stride1, size2, stride2,             # <<<<<<<<<<<<<<
 *             size3, stride3):
 * #        # print('allocate tensor')
 */
  __pyx_t_4 = PyCFunction_NewEx(&__pyx_mdef_7PyTorch_11_LongTensor_69newWithStorage4d, NULL, __pyx_n_s_PyTorch); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 707, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":706
 *         return _LongTensor_fromNative(newTensorC, False)
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def newWithStorage4d(Storage._LongStorage storage, offset, size0, stride0, size1, stride1, size2, stride2,
 *             size3, stride3):
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 706, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 706, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__LongTensor->tp_dict, __pyx_n_s_newWithStorage4d, __pyx_t_4) < 0) __PYX_ERR(0, 707, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__LongTensor);

  /* "PyTorch.pyx":707
 * 
 *     @staticmethod
 *     def newWithStorage4d(Storage._LongStorage storage, offset, size0, stride0, size1, stride1, size2, stride2,             # <<<<<<<<<<<<<<
 *             size3, stride3):
 * #        # print('allocate tensor')
 */
  __pyx_t_4 = __Pyx_GetNameInClass((PyObject *)__pyx_ptype_7PyTorch__LongTensor, __pyx_n_s_newWithStorage4d); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 707, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":706
 *         return _LongTensor_fromNative(newTensorC, False)
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def newWithStorage4d(Storage._LongStorage storage, offset, size0, stride0, size1, stride1, size2, stride2,
 *             size3, stride3):
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 706, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 706, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__LongTensor->tp_dict, __pyx_n_s_newWithStorage4d, __pyx_t_4) < 0) __PYX_ERR(0, 707, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__LongTensor);

  /* "PyTorch.pyx":1145
 * 
 *     @staticmethod
 *     def new():             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         return _FloatTensor()
 */
  __pyx_t_4 = PyCFunction_NewEx(&__pyx_mdef_7PyTorch_12_FloatTensor_59new, NULL, __pyx_n_s_PyTorch); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1145, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":1144
 *             return None  # not sure how to handle this yet
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def new():
 * #        # print('allocate tensor')
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1144, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1144, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__FloatTensor->tp_dict, __pyx_n_s_new, __pyx_t_4) < 0) __PYX_ERR(0, 1145, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__FloatTensor);

  /* "PyTorch.pyx":1145
 * 
 *     @staticmethod
 *     def new():             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         return _FloatTensor()
 */
  __pyx_t_4 = __Pyx_GetNameInClass((PyObject *)__pyx_ptype_7PyTorch__FloatTensor, __pyx_n_s_new); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1145, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":1144
 *             return None  # not sure how to handle this yet
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def new():
 * #        # print('allocate tensor')
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1144, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1144, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__FloatTensor->tp_dict, __pyx_n_s_new, __pyx_t_4) < 0) __PYX_ERR(0, 1145, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__FloatTensor);

  /* "PyTorch.pyx":1198
 * 
 *     @staticmethod
 *     def newWithStorage(Storage._FloatStorage storage, offset, Storage._LongStorage size, Storage._LongStorage stride):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THFloatTensor *newTensorC = THFloatTensor_newWithStorage(storage.native, offset, size.native, stride.native)
 */
  __pyx_t_4 = PyCFunction_NewEx(&__pyx_mdef_7PyTorch_12_FloatTensor_77newWithStorage, NULL, __pyx_n_s_PyTorch); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1198, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":1197
 *         return self
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def newWithStorage(Storage._FloatStorage storage, offset, Storage._LongStorage size, Storage._LongStorage stride):
 * #        # print('allocate tensor')
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1197, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1197, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__FloatTensor->tp_dict, __pyx_n_s_newWithStorage, __pyx_t_4) < 0) __PYX_ERR(0, 1198, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__FloatTensor);

  /* "PyTorch.pyx":1198
 * 
 *     @staticmethod
 *     def newWithStorage(Storage._FloatStorage storage, offset, Storage._LongStorage size, Storage._LongStorage stride):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THFloatTensor *newTensorC = THFloatTensor_newWithStorage(storage.native, offset, size.native, stride.native)
 */
  __pyx_t_4 = __Pyx_GetNameInClass((PyObject *)__pyx_ptype_7PyTorch__FloatTensor, __pyx_n_s_newWithStorage); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1198, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":1197
 *         return self
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def newWithStorage(Storage._FloatStorage storage, offset, Storage._LongStorage size, Storage._LongStorage stride):
 * #        # print('allocate tensor')
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1197, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1197, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__FloatTensor->tp_dict, __pyx_n_s_newWithStorage, __pyx_t_4) < 0) __PYX_ERR(0, 1198, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__FloatTensor);

  /* "PyTorch.pyx":1204
 * 
 *     @staticmethod
 *     def newWithStorage1d(Storage._FloatStorage storage, offset, size0, stride0):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THFloatTensor *newTensorC = THFloatTensor_newWithStorage1d(storage.native, offset, size0, stride0)
 */
  __pyx_t_4 = PyCFunction_NewEx(&__pyx_mdef_7PyTorch_12_FloatTensor_79newWithStorage1d, NULL, __pyx_n_s_PyTorch); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1204, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":1203
 *         return _FloatTensor_fromNative(newTensorC, False)
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def newWithStorage1d(Storage._FloatStorage storage, offset, size0, stride0):
 * #        # print('allocate tensor')
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1203, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1203, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__FloatTensor->tp_dict, __pyx_n_s_newWithStorage1d, __pyx_t_4) < 0) __PYX_ERR(0, 1204, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__FloatTensor);

  /* "PyTorch.pyx":1204
 * 
 *     @staticmethod
 *     def newWithStorage1d(Storage._FloatStorage storage, offset, size0, stride0):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THFloatTensor *newTensorC = THFloatTensor_newWithStorage1d(storage.native, offset, size0, stride0)
 */
  __pyx_t_4 = __Pyx_GetNameInClass((PyObject *)__pyx_ptype_7PyTorch__FloatTensor, __pyx_n_s_newWithStorage1d); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1204, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":1203
 *         return _FloatTensor_fromNative(newTensorC, False)
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def newWithStorage1d(Storage._FloatStorage storage, offset, size0, stride0):
 * #        # print('allocate tensor')
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1203, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1203, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__FloatTensor->tp_dict, __pyx_n_s_newWithStorage1d, __pyx_t_4) < 0) __PYX_ERR(0, 1204, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__FloatTensor);

  /* "PyTorch.pyx":1210
 * 
 *     @staticmethod
 *     def newWithStorage2d(Storage._FloatStorage storage, offset, size0, stride0, size1, stride1):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THFloatTensor *newTensorC = THFloatTensor_newWithStorage2d(storage.native, offset, size0, stride0, size1, stride1)
 */
  __pyx_t_4 = PyCFunction_NewEx(&__pyx_mdef_7PyTorch_12_FloatTensor_81newWithStorage2d, NULL, __pyx_n_s_PyTorch); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1210, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":1209
 *         return _FloatTensor_fromNative(newTensorC, False)
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def newWithStorage2d(Storage._FloatStorage storage, offset, size0, stride0, size1, stride1):
 * #        # print('allocate tensor')
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1209, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1209, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__FloatTensor->tp_dict, __pyx_n_s_newWithStorage2d, __pyx_t_4) < 0) __PYX_ERR(0, 1210, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__FloatTensor);

  /* "PyTorch.pyx":1210
 * 
 *     @staticmethod
 *     def newWithStorage2d(Storage._FloatStorage storage, offset, size0, stride0, size1, stride1):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THFloatTensor *newTensorC = THFloatTensor_newWithStorage2d(storage.native, offset, size0, stride0, size1, stride1)
 */
  __pyx_t_4 = __Pyx_GetNameInClass((PyObject *)__pyx_ptype_7PyTorch__FloatTensor, __pyx_n_s_newWithStorage2d); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1210, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":1209
 *         return _FloatTensor_fromNative(newTensorC, False)
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def newWithStorage2d(Storage._FloatStorage storage, offset, size0, stride0, size1, stride1):
 * #        # print('allocate tensor')
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1209, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1209, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__FloatTensor->tp_dict, __pyx_n_s_newWithStorage2d, __pyx_t_4) < 0) __PYX_ERR(0, 1210, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__FloatTensor);

  /* "PyTorch.pyx":1216
 * 
 *     @staticmethod
 *     def newWithStorage3d(Storage._FloatStorage storage, offset, size0, stride0, size1, stride1, size2, stride2):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THFloatTensor *newTensorC = THFloatTensor_newWithStorage3d(storage.native, offset, size0, stride0, size1, stride1,
 */
  __pyx_t_4 = PyCFunction_NewEx(&__pyx_mdef_7PyTorch_12_FloatTensor_83newWithStorage3d, NULL, __pyx_n_s_PyTorch); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1216, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":1215
 *         return _FloatTensor_fromNative(newTensorC, False)
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def newWithStorage3d(Storage._FloatStorage storage, offset, size0, stride0, size1, stride1, size2, stride2):
 * #        # print('allocate tensor')
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1215, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1215, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__FloatTensor->tp_dict, __pyx_n_s_newWithStorage3d, __pyx_t_4) < 0) __PYX_ERR(0, 1216, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__FloatTensor);

  /* "PyTorch.pyx":1216
 * 
 *     @staticmethod
 *     def newWithStorage3d(Storage._FloatStorage storage, offset, size0, stride0, size1, stride1, size2, stride2):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THFloatTensor *newTensorC = THFloatTensor_newWithStorage3d(storage.native, offset, size0, stride0, size1, stride1,
 */
  __pyx_t_4 = __Pyx_GetNameInClass((PyObject *)__pyx_ptype_7PyTorch__FloatTensor, __pyx_n_s_newWithStorage3d); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1216, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":1215
 *         return _FloatTensor_fromNative(newTensorC, False)
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def newWithStorage3d(Storage._FloatStorage storage, offset, size0, stride0, size1, stride1, size2, stride2):
 * #        # print('allocate tensor')
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1215, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1215, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__FloatTensor->tp_dict, __pyx_n_s_newWithStorage3d, __pyx_t_4) < 0) __PYX_ERR(0, 1216, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__FloatTensor);

  /* "PyTorch.pyx":1223
 * 
 *     @staticmethod
 *     def newWithStorage4d(Storage._FloatStorage storage, offset, size0, stride0, size1, stride1, size2, stride2,             # <<<<<<<<<<<<<<
 *             size3, stride3):
 * #        # print('allocate tensor')
 */
  __pyx_t_4 = PyCFunction_NewEx(&__pyx_mdef_7PyTorch_12_FloatTensor_85newWithStorage4d, NULL, __pyx_n_s_PyTorch); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1223, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":1222
 *         return _FloatTensor_fromNative(newTensorC, False)
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def newWithStorage4d(Storage._FloatStorage storage, offset, size0, stride0, size1, stride1, size2, stride2,
 *             size3, stride3):
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1222, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1222, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__FloatTensor->tp_dict, __pyx_n_s_newWithStorage4d, __pyx_t_4) < 0) __PYX_ERR(0, 1223, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__FloatTensor);

  /* "PyTorch.pyx":1223
 * 
 *     @staticmethod
 *     def newWithStorage4d(Storage._FloatStorage storage, offset, size0, stride0, size1, stride1, size2, stride2,             # <<<<<<<<<<<<<<
 *             size3, stride3):
 * #        # print('allocate tensor')
 */
  __pyx_t_4 = __Pyx_GetNameInClass((PyObject *)__pyx_ptype_7PyTorch__FloatTensor, __pyx_n_s_newWithStorage4d); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1223, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":1222
 *         return _FloatTensor_fromNative(newTensorC, False)
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def newWithStorage4d(Storage._FloatStorage storage, offset, size0, stride0, size1, stride1, size2, stride2,
 *             size3, stride3):
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1222, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1222, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__FloatTensor->tp_dict, __pyx_n_s_newWithStorage4d, __pyx_t_4) < 0) __PYX_ERR(0, 1223, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__FloatTensor);

  /* "PyTorch.pyx":1390
 * 
 * 
 * def _asFloatTensor(myarray):             # <<<<<<<<<<<<<<
 *     cdef float[:] myarraymv
 *     cdef Storage._FloatStorage storage
 */
  __pyx_t_4 = PyCFunction_NewEx(&__pyx_mdef_7PyTorch_5_asFloatTensor, NULL, __pyx_n_s_PyTorch); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1390, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_asFloatTensor, __pyx_t_4) < 0) __PYX_ERR(0, 1390, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "PyTorch.pyx":1721
 * 
 *     @staticmethod
 *     def new():             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         return _DoubleTensor()
 */
  __pyx_t_4 = PyCFunction_NewEx(&__pyx_mdef_7PyTorch_13_DoubleTensor_59new, NULL, __pyx_n_s_PyTorch); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1721, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":1720
 *             return None  # not sure how to handle this yet
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def new():
 * #        # print('allocate tensor')
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1720, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1720, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__DoubleTensor->tp_dict, __pyx_n_s_new, __pyx_t_4) < 0) __PYX_ERR(0, 1721, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__DoubleTensor);

  /* "PyTorch.pyx":1721
 * 
 *     @staticmethod
 *     def new():             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         return _DoubleTensor()
 */
  __pyx_t_4 = __Pyx_GetNameInClass((PyObject *)__pyx_ptype_7PyTorch__DoubleTensor, __pyx_n_s_new); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1721, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":1720
 *             return None  # not sure how to handle this yet
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def new():
 * #        # print('allocate tensor')
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1720, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1720, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__DoubleTensor->tp_dict, __pyx_n_s_new, __pyx_t_4) < 0) __PYX_ERR(0, 1721, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__DoubleTensor);

  /* "PyTorch.pyx":1774
 * 
 *     @staticmethod
 *     def newWithStorage(Storage._DoubleStorage storage, offset, Storage._LongStorage size, Storage._LongStorage stride):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THDoubleTensor *newTensorC = THDoubleTensor_newWithStorage(storage.native, offset, size.native, stride.native)
 */
  __pyx_t_4 = PyCFunction_NewEx(&__pyx_mdef_7PyTorch_13_DoubleTensor_77newWithStorage, NULL, __pyx_n_s_PyTorch); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1774, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":1773
 *         return self
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def newWithStorage(Storage._DoubleStorage storage, offset, Storage._LongStorage size, Storage._LongStorage stride):
 * #        # print('allocate tensor')
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1773, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1773, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__DoubleTensor->tp_dict, __pyx_n_s_newWithStorage, __pyx_t_4) < 0) __PYX_ERR(0, 1774, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__DoubleTensor);

  /* "PyTorch.pyx":1774
 * 
 *     @staticmethod
 *     def newWithStorage(Storage._DoubleStorage storage, offset, Storage._LongStorage size, Storage._LongStorage stride):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THDoubleTensor *newTensorC = THDoubleTensor_newWithStorage(storage.native, offset, size.native, stride.native)
 */
  __pyx_t_4 = __Pyx_GetNameInClass((PyObject *)__pyx_ptype_7PyTorch__DoubleTensor, __pyx_n_s_newWithStorage); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1774, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":1773
 *         return self
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def newWithStorage(Storage._DoubleStorage storage, offset, Storage._LongStorage size, Storage._LongStorage stride):
 * #        # print('allocate tensor')
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1773, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1773, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__DoubleTensor->tp_dict, __pyx_n_s_newWithStorage, __pyx_t_4) < 0) __PYX_ERR(0, 1774, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__DoubleTensor);

  /* "PyTorch.pyx":1780
 * 
 *     @staticmethod
 *     def newWithStorage1d(Storage._DoubleStorage storage, offset, size0, stride0):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THDoubleTensor *newTensorC = THDoubleTensor_newWithStorage1d(storage.native, offset, size0, stride0)
 */
  __pyx_t_4 = PyCFunction_NewEx(&__pyx_mdef_7PyTorch_13_DoubleTensor_79newWithStorage1d, NULL, __pyx_n_s_PyTorch); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1780, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":1779
 *         return _DoubleTensor_fromNative(newTensorC, False)
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def newWithStorage1d(Storage._DoubleStorage storage, offset, size0, stride0):
 * #        # print('allocate tensor')
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1779, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1779, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__DoubleTensor->tp_dict, __pyx_n_s_newWithStorage1d, __pyx_t_4) < 0) __PYX_ERR(0, 1780, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__DoubleTensor);

  /* "PyTorch.pyx":1780
 * 
 *     @staticmethod
 *     def newWithStorage1d(Storage._DoubleStorage storage, offset, size0, stride0):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THDoubleTensor *newTensorC = THDoubleTensor_newWithStorage1d(storage.native, offset, size0, stride0)
 */
  __pyx_t_4 = __Pyx_GetNameInClass((PyObject *)__pyx_ptype_7PyTorch__DoubleTensor, __pyx_n_s_newWithStorage1d); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1780, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":1779
 *         return _DoubleTensor_fromNative(newTensorC, False)
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def newWithStorage1d(Storage._DoubleStorage storage, offset, size0, stride0):
 * #        # print('allocate tensor')
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1779, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1779, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__DoubleTensor->tp_dict, __pyx_n_s_newWithStorage1d, __pyx_t_4) < 0) __PYX_ERR(0, 1780, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__DoubleTensor);

  /* "PyTorch.pyx":1786
 * 
 *     @staticmethod
 *     def newWithStorage2d(Storage._DoubleStorage storage, offset, size0, stride0, size1, stride1):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THDoubleTensor *newTensorC = THDoubleTensor_newWithStorage2d(storage.native, offset, size0, stride0, size1, stride1)
 */
  __pyx_t_4 = PyCFunction_NewEx(&__pyx_mdef_7PyTorch_13_DoubleTensor_81newWithStorage2d, NULL, __pyx_n_s_PyTorch); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1786, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":1785
 *         return _DoubleTensor_fromNative(newTensorC, False)
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def newWithStorage2d(Storage._DoubleStorage storage, offset, size0, stride0, size1, stride1):
 * #        # print('allocate tensor')
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1785, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1785, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__DoubleTensor->tp_dict, __pyx_n_s_newWithStorage2d, __pyx_t_4) < 0) __PYX_ERR(0, 1786, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__DoubleTensor);

  /* "PyTorch.pyx":1786
 * 
 *     @staticmethod
 *     def newWithStorage2d(Storage._DoubleStorage storage, offset, size0, stride0, size1, stride1):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THDoubleTensor *newTensorC = THDoubleTensor_newWithStorage2d(storage.native, offset, size0, stride0, size1, stride1)
 */
  __pyx_t_4 = __Pyx_GetNameInClass((PyObject *)__pyx_ptype_7PyTorch__DoubleTensor, __pyx_n_s_newWithStorage2d); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1786, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":1785
 *         return _DoubleTensor_fromNative(newTensorC, False)
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def newWithStorage2d(Storage._DoubleStorage storage, offset, size0, stride0, size1, stride1):
 * #        # print('allocate tensor')
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1785, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1785, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__DoubleTensor->tp_dict, __pyx_n_s_newWithStorage2d, __pyx_t_4) < 0) __PYX_ERR(0, 1786, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__DoubleTensor);

  /* "PyTorch.pyx":1792
 * 
 *     @staticmethod
 *     def newWithStorage3d(Storage._DoubleStorage storage, offset, size0, stride0, size1, stride1, size2, stride2):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THDoubleTensor *newTensorC = THDoubleTensor_newWithStorage3d(storage.native, offset, size0, stride0, size1, stride1,
 */
  __pyx_t_4 = PyCFunction_NewEx(&__pyx_mdef_7PyTorch_13_DoubleTensor_83newWithStorage3d, NULL, __pyx_n_s_PyTorch); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1792, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":1791
 *         return _DoubleTensor_fromNative(newTensorC, False)
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def newWithStorage3d(Storage._DoubleStorage storage, offset, size0, stride0, size1, stride1, size2, stride2):
 * #        # print('allocate tensor')
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1791, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1791, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__DoubleTensor->tp_dict, __pyx_n_s_newWithStorage3d, __pyx_t_4) < 0) __PYX_ERR(0, 1792, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__DoubleTensor);

  /* "PyTorch.pyx":1792
 * 
 *     @staticmethod
 *     def newWithStorage3d(Storage._DoubleStorage storage, offset, size0, stride0, size1, stride1, size2, stride2):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THDoubleTensor *newTensorC = THDoubleTensor_newWithStorage3d(storage.native, offset, size0, stride0, size1, stride1,
 */
  __pyx_t_4 = __Pyx_GetNameInClass((PyObject *)__pyx_ptype_7PyTorch__DoubleTensor, __pyx_n_s_newWithStorage3d); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1792, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":1791
 *         return _DoubleTensor_fromNative(newTensorC, False)
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def newWithStorage3d(Storage._DoubleStorage storage, offset, size0, stride0, size1, stride1, size2, stride2):
 * #        # print('allocate tensor')
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1791, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1791, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__DoubleTensor->tp_dict, __pyx_n_s_newWithStorage3d, __pyx_t_4) < 0) __PYX_ERR(0, 1792, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__DoubleTensor);

  /* "PyTorch.pyx":1799
 * 
 *     @staticmethod
 *     def newWithStorage4d(Storage._DoubleStorage storage, offset, size0, stride0, size1, stride1, size2, stride2,             # <<<<<<<<<<<<<<
 *             size3, stride3):
 * #        # print('allocate tensor')
 */
  __pyx_t_4 = PyCFunction_NewEx(&__pyx_mdef_7PyTorch_13_DoubleTensor_85newWithStorage4d, NULL, __pyx_n_s_PyTorch); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1799, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":1798
 *         return _DoubleTensor_fromNative(newTensorC, False)
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def newWithStorage4d(Storage._DoubleStorage storage, offset, size0, stride0, size1, stride1, size2, stride2,
 *             size3, stride3):
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1798, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1798, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__DoubleTensor->tp_dict, __pyx_n_s_newWithStorage4d, __pyx_t_4) < 0) __PYX_ERR(0, 1799, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__DoubleTensor);

  /* "PyTorch.pyx":1799
 * 
 *     @staticmethod
 *     def newWithStorage4d(Storage._DoubleStorage storage, offset, size0, stride0, size1, stride1, size2, stride2,             # <<<<<<<<<<<<<<
 *             size3, stride3):
 * #        # print('allocate tensor')
 */
  __pyx_t_4 = __Pyx_GetNameInClass((PyObject *)__pyx_ptype_7PyTorch__DoubleTensor, __pyx_n_s_newWithStorage4d); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1799, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":1798
 *         return _DoubleTensor_fromNative(newTensorC, False)
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def newWithStorage4d(Storage._DoubleStorage storage, offset, size0, stride0, size1, stride1, size2, stride2,
 *             size3, stride3):
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1798, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1798, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__DoubleTensor->tp_dict, __pyx_n_s_newWithStorage4d, __pyx_t_4) < 0) __PYX_ERR(0, 1799, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__DoubleTensor);

  /* "PyTorch.pyx":1966
 * 
 * 
 * def _asDoubleTensor(myarray):             # <<<<<<<<<<<<<<
 *     cdef double[:] myarraymv
 *     cdef Storage._DoubleStorage storage
 */
  __pyx_t_4 = PyCFunction_NewEx(&__pyx_mdef_7PyTorch_7_asDoubleTensor, NULL, __pyx_n_s_PyTorch); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1966, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_asDoubleTensor, __pyx_t_4) < 0) __PYX_ERR(0, 1966, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "PyTorch.pyx":2248
 * 
 *     @staticmethod
 *     def new():             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         return _ByteTensor()
 */
  __pyx_t_4 = PyCFunction_NewEx(&__pyx_mdef_7PyTorch_11_ByteTensor_39new, NULL, __pyx_n_s_PyTorch); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2248, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":2247
 *             return None  # not sure how to handle this yet
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def new():
 * #        # print('allocate tensor')
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2247, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2247, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__ByteTensor->tp_dict, __pyx_n_s_new, __pyx_t_4) < 0) __PYX_ERR(0, 2248, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__ByteTensor);

  /* "PyTorch.pyx":2248
 * 
 *     @staticmethod
 *     def new():             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         return _ByteTensor()
 */
  __pyx_t_4 = __Pyx_GetNameInClass((PyObject *)__pyx_ptype_7PyTorch__ByteTensor, __pyx_n_s_new); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2248, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":2247
 *             return None  # not sure how to handle this yet
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def new():
 * #        # print('allocate tensor')
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2247, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2247, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__ByteTensor->tp_dict, __pyx_n_s_new, __pyx_t_4) < 0) __PYX_ERR(0, 2248, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__ByteTensor);

  /* "PyTorch.pyx":2301
 * 
 *     @staticmethod
 *     def newWithStorage(Storage._ByteStorage storage, offset, Storage._LongStorage size, Storage._LongStorage stride):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THByteTensor *newTensorC = THByteTensor_newWithStorage(storage.native, offset, size.native, stride.native)
 */
  __pyx_t_4 = PyCFunction_NewEx(&__pyx_mdef_7PyTorch_11_ByteTensor_57newWithStorage, NULL, __pyx_n_s_PyTorch); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2301, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":2300
 *         return self
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def newWithStorage(Storage._ByteStorage storage, offset, Storage._LongStorage size, Storage._LongStorage stride):
 * #        # print('allocate tensor')
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2300, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2300, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__ByteTensor->tp_dict, __pyx_n_s_newWithStorage, __pyx_t_4) < 0) __PYX_ERR(0, 2301, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__ByteTensor);

  /* "PyTorch.pyx":2301
 * 
 *     @staticmethod
 *     def newWithStorage(Storage._ByteStorage storage, offset, Storage._LongStorage size, Storage._LongStorage stride):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THByteTensor *newTensorC = THByteTensor_newWithStorage(storage.native, offset, size.native, stride.native)
 */
  __pyx_t_4 = __Pyx_GetNameInClass((PyObject *)__pyx_ptype_7PyTorch__ByteTensor, __pyx_n_s_newWithStorage); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2301, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":2300
 *         return self
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def newWithStorage(Storage._ByteStorage storage, offset, Storage._LongStorage size, Storage._LongStorage stride):
 * #        # print('allocate tensor')
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2300, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2300, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__ByteTensor->tp_dict, __pyx_n_s_newWithStorage, __pyx_t_4) < 0) __PYX_ERR(0, 2301, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__ByteTensor);

  /* "PyTorch.pyx":2307
 * 
 *     @staticmethod
 *     def newWithStorage1d(Storage._ByteStorage storage, offset, size0, stride0):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THByteTensor *newTensorC = THByteTensor_newWithStorage1d(storage.native, offset, size0, stride0)
 */
  __pyx_t_4 = PyCFunction_NewEx(&__pyx_mdef_7PyTorch_11_ByteTensor_59newWithStorage1d, NULL, __pyx_n_s_PyTorch); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2307, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":2306
 *         return _ByteTensor_fromNative(newTensorC, False)
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def newWithStorage1d(Storage._ByteStorage storage, offset, size0, stride0):
 * #        # print('allocate tensor')
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2306, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2306, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__ByteTensor->tp_dict, __pyx_n_s_newWithStorage1d, __pyx_t_4) < 0) __PYX_ERR(0, 2307, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__ByteTensor);

  /* "PyTorch.pyx":2307
 * 
 *     @staticmethod
 *     def newWithStorage1d(Storage._ByteStorage storage, offset, size0, stride0):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THByteTensor *newTensorC = THByteTensor_newWithStorage1d(storage.native, offset, size0, stride0)
 */
  __pyx_t_4 = __Pyx_GetNameInClass((PyObject *)__pyx_ptype_7PyTorch__ByteTensor, __pyx_n_s_newWithStorage1d); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2307, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":2306
 *         return _ByteTensor_fromNative(newTensorC, False)
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def newWithStorage1d(Storage._ByteStorage storage, offset, size0, stride0):
 * #        # print('allocate tensor')
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2306, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2306, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__ByteTensor->tp_dict, __pyx_n_s_newWithStorage1d, __pyx_t_4) < 0) __PYX_ERR(0, 2307, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__ByteTensor);

  /* "PyTorch.pyx":2313
 * 
 *     @staticmethod
 *     def newWithStorage2d(Storage._ByteStorage storage, offset, size0, stride0, size1, stride1):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THByteTensor *newTensorC = THByteTensor_newWithStorage2d(storage.native, offset, size0, stride0, size1, stride1)
 */
  __pyx_t_4 = PyCFunction_NewEx(&__pyx_mdef_7PyTorch_11_ByteTensor_61newWithStorage2d, NULL, __pyx_n_s_PyTorch); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2313, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":2312
 *         return _ByteTensor_fromNative(newTensorC, False)
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def newWithStorage2d(Storage._ByteStorage storage, offset, size0, stride0, size1, stride1):
 * #        # print('allocate tensor')
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2312, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2312, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__ByteTensor->tp_dict, __pyx_n_s_newWithStorage2d, __pyx_t_4) < 0) __PYX_ERR(0, 2313, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__ByteTensor);

  /* "PyTorch.pyx":2313
 * 
 *     @staticmethod
 *     def newWithStorage2d(Storage._ByteStorage storage, offset, size0, stride0, size1, stride1):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THByteTensor *newTensorC = THByteTensor_newWithStorage2d(storage.native, offset, size0, stride0, size1, stride1)
 */
  __pyx_t_4 = __Pyx_GetNameInClass((PyObject *)__pyx_ptype_7PyTorch__ByteTensor, __pyx_n_s_newWithStorage2d); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2313, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":2312
 *         return _ByteTensor_fromNative(newTensorC, False)
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def newWithStorage2d(Storage._ByteStorage storage, offset, size0, stride0, size1, stride1):
 * #        # print('allocate tensor')
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2312, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2312, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__ByteTensor->tp_dict, __pyx_n_s_newWithStorage2d, __pyx_t_4) < 0) __PYX_ERR(0, 2313, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__ByteTensor);

  /* "PyTorch.pyx":2319
 * 
 *     @staticmethod
 *     def newWithStorage3d(Storage._ByteStorage storage, offset, size0, stride0, size1, stride1, size2, stride2):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THByteTensor *newTensorC = THByteTensor_newWithStorage3d(storage.native, offset, size0, stride0, size1, stride1,
 */
  __pyx_t_4 = PyCFunction_NewEx(&__pyx_mdef_7PyTorch_11_ByteTensor_63newWithStorage3d, NULL, __pyx_n_s_PyTorch); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2319, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":2318
 *         return _ByteTensor_fromNative(newTensorC, False)
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def newWithStorage3d(Storage._ByteStorage storage, offset, size0, stride0, size1, stride1, size2, stride2):
 * #        # print('allocate tensor')
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2318, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2318, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__ByteTensor->tp_dict, __pyx_n_s_newWithStorage3d, __pyx_t_4) < 0) __PYX_ERR(0, 2319, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__ByteTensor);

  /* "PyTorch.pyx":2319
 * 
 *     @staticmethod
 *     def newWithStorage3d(Storage._ByteStorage storage, offset, size0, stride0, size1, stride1, size2, stride2):             # <<<<<<<<<<<<<<
 * #        # print('allocate tensor')
 *         cdef THByteTensor *newTensorC = THByteTensor_newWithStorage3d(storage.native, offset, size0, stride0, size1, stride1,
 */
  __pyx_t_4 = __Pyx_GetNameInClass((PyObject *)__pyx_ptype_7PyTorch__ByteTensor, __pyx_n_s_newWithStorage3d); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2319, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":2318
 *         return _ByteTensor_fromNative(newTensorC, False)
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def newWithStorage3d(Storage._ByteStorage storage, offset, size0, stride0, size1, stride1, size2, stride2):
 * #        # print('allocate tensor')
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2318, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2318, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__ByteTensor->tp_dict, __pyx_n_s_newWithStorage3d, __pyx_t_4) < 0) __PYX_ERR(0, 2319, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__ByteTensor);

  /* "PyTorch.pyx":2326
 * 
 *     @staticmethod
 *     def newWithStorage4d(Storage._ByteStorage storage, offset, size0, stride0, size1, stride1, size2, stride2,             # <<<<<<<<<<<<<<
 *             size3, stride3):
 * #        # print('allocate tensor')
 */
  __pyx_t_4 = PyCFunction_NewEx(&__pyx_mdef_7PyTorch_11_ByteTensor_65newWithStorage4d, NULL, __pyx_n_s_PyTorch); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2326, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":2325
 *         return _ByteTensor_fromNative(newTensorC, False)
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def newWithStorage4d(Storage._ByteStorage storage, offset, size0, stride0, size1, stride1, size2, stride2,
 *             size3, stride3):
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2325, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2325, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__ByteTensor->tp_dict, __pyx_n_s_newWithStorage4d, __pyx_t_4) < 0) __PYX_ERR(0, 2326, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__ByteTensor);

  /* "PyTorch.pyx":2326
 * 
 *     @staticmethod
 *     def newWithStorage4d(Storage._ByteStorage storage, offset, size0, stride0, size1, stride1, size2, stride2,             # <<<<<<<<<<<<<<
 *             size3, stride3):
 * #        # print('allocate tensor')
 */
  __pyx_t_4 = __Pyx_GetNameInClass((PyObject *)__pyx_ptype_7PyTorch__ByteTensor, __pyx_n_s_newWithStorage4d); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2326, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "PyTorch.pyx":2325
 *         return _ByteTensor_fromNative(newTensorC, False)
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def newWithStorage4d(Storage._ByteStorage storage, offset, size0, stride0, size1, stride1, size2, stride2,
 *             size3, stride3):
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2325, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2325, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_7PyTorch__ByteTensor->tp_dict, __pyx_n_s_newWithStorage4d, __pyx_t_4) < 0) __PYX_ERR(0, 2326, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  PyType_Modified(__pyx_ptype_7PyTorch__ByteTensor);

  /* "PyTorch.pyx":2466
 * 
 * 
 * def _asByteTensor(myarray):             # <<<<<<<<<<<<<<
 *     cdef unsigned char[:] myarraymv
 *     cdef Storage._ByteStorage storage
 */
  __pyx_t_4 = PyCFunction_NewEx(&__pyx_mdef_7PyTorch_9_asByteTensor, NULL, __pyx_n_s_PyTorch); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2466, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_asByteTensor, __pyx_t_4) < 0) __PYX_ERR(0, 2466, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "PyTorch.pyx":2520
 * 
 * 
 * def _popFloatTensor():             # <<<<<<<<<<<<<<
 *     global globalState
 *     cdef THFloatTensor *tensorC = popFloatTensor(globalState.L)
 */
  __pyx_t_4 = PyCFunction_NewEx(&__pyx_mdef_7PyTorch_11_popFloatTensor, NULL, __pyx_n_s_PyTorch); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2520, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_popFloatTensor, __pyx_t_4) < 0) __PYX_ERR(0, 2520, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "PyTorch.pyx":2525
 *     return _FloatTensor_fromNative(tensorC)
 * 
 * def _pushFloatTensor(_FloatTensor tensor):             # <<<<<<<<<<<<<<
 *     global globalState
 *     pushFloatTensor(globalState.L, tensor.native)
 */
  __pyx_t_4 = PyCFunction_NewEx(&__pyx_mdef_7PyTorch_13_pushFloatTensor, NULL, __pyx_n_s_PyTorch); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2525, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_pushFloatTensor, __pyx_t_4) < 0) __PYX_ERR(0, 2525, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "PyTorch.pyx":2533
 * 
 * 
 * def _popDoubleTensor():             # <<<<<<<<<<<<<<
 *     global globalState
 *     cdef THDoubleTensor *tensorC = popDoubleTensor(globalState.L)
 */
  __pyx_t_4 = PyCFunction_NewEx(&__pyx_mdef_7PyTorch_15_popDoubleTensor, NULL, __pyx_n_s_PyTorch); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2533, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_popDoubleTensor, __pyx_t_4) < 0) __PYX_ERR(0, 2533, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "PyTorch.pyx":2538
 *     return _DoubleTensor_fromNative(tensorC)
 * 
 * def _pushDoubleTensor(_DoubleTensor tensor):             # <<<<<<<<<<<<<<
 *     global globalState
 *     pushDoubleTensor(globalState.L, tensor.native)
 */
  __pyx_t_4 = PyCFunction_NewEx(&__pyx_mdef_7PyTorch_17_pushDoubleTensor, NULL, __pyx_n_s_PyTorch); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2538, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_pushDoubleTensor, __pyx_t_4) < 0) __PYX_ERR(0, 2538, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "PyTorch.pyx":2546
 * 
 * 
 * def _popByteTensor():             # <<<<<<<<<<<<<<
 *     global globalState
 *     cdef THByteTensor *tensorC = popByteTensor(globalState.L)
 */
  __pyx_t_4 = PyCFunction_NewEx(&__pyx_mdef_7PyTorch_19_popByteTensor, NULL, __pyx_n_s_PyTorch); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2546, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_popByteTensor, __pyx_t_4) < 0) __PYX_ERR(0, 2546, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "PyTorch.pyx":2551
 *     return _ByteTensor_fromNative(tensorC)
 * 
 * def _pushByteTensor(_ByteTensor tensor):             # <<<<<<<<<<<<<<
 *     global globalState
 *     pushByteTensor(globalState.L, tensor.native)
 */
  __pyx_t_4 = PyCFunction_NewEx(&__pyx_mdef_7PyTorch_21_pushByteTensor, NULL, __pyx_n_s_PyTorch); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2551, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_pushByteTensor, __pyx_t_4) < 0) __PYX_ERR(0, 2551, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "PyTorch.pyx":2602
 * cdef GlobalState globalState
 * 
 * def getGlobalState():             # <<<<<<<<<<<<<<
 *     global globalState
 *     return globalState
 */
  __pyx_t_4 = PyCFunction_NewEx(&__pyx_mdef_7PyTorch_27getGlobalState, NULL, __pyx_n_s_PyTorch); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2602, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_getGlobalState, __pyx_t_4) < 0) __PYX_ERR(0, 2602, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "PyTorch.pyx":2606
 *     return globalState
 * 
 * def require(libName):             # <<<<<<<<<<<<<<
 *     global globalState
 *     cdef lua_State *L
 */
  __pyx_t_4 = PyCFunction_NewEx(&__pyx_mdef_7PyTorch_29require, NULL, __pyx_n_s_PyTorch); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2606, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_require, __pyx_t_4) < 0) __PYX_ERR(0, 2606, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "PyTorch.pyx":2612
 *     luaRequire(L, libName.encode('utf-8'))
 * 
 * def getGlobal(name):             # <<<<<<<<<<<<<<
 *     global globalState
 *     cdef lua_State *L
 */
  __pyx_t_4 = PyCFunction_NewEx(&__pyx_mdef_7PyTorch_31getGlobal, NULL, __pyx_n_s_PyTorch); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2612, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_getGlobal, __pyx_t_4) < 0) __PYX_ERR(0, 2612, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "PyTorch.pyx":2618
 * 
 * 
 * def init():             # <<<<<<<<<<<<<<
 *     global globalState
 *     # print('initializing PyTorch...')
 */
  __pyx_t_4 = PyCFunction_NewEx(&__pyx_mdef_7PyTorch_33init, NULL, __pyx_n_s_PyTorch); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2618, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_init, __pyx_t_4) < 0) __PYX_ERR(0, 2618, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "PyTorch.pyx":2627
 *     # print(' ... PyTorch initialized')
 * 
 * init()             # <<<<<<<<<<<<<<
 * 
 * from floattensor import *
 */
  __pyx_t_3 = __Pyx_GetModuleGlobalName(__pyx_n_s_init); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2627, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_7 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_7 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_7)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_7);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
    }
  }
  if (__pyx_t_7) {
    __pyx_t_4 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_7); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2627, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  } else {
    __pyx_t_4 = __Pyx_PyObject_CallNoArg(__pyx_t_3); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2627, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "PyTorch.pyx":2629
 * init()
 * 
 * from floattensor import *             # <<<<<<<<<<<<<<
 * 
 * # ==== Nn ==================================
 */
  __pyx_t_4 = PyList_New(1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2629, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_INCREF(__pyx_n_s__129);
  __Pyx_GIVEREF(__pyx_n_s__129);
  PyList_SET_ITEM(__pyx_t_4, 0, __pyx_n_s__129);
  __pyx_t_3 = __Pyx_Import(__pyx_n_s_floattensor, __pyx_t_4, -1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2629, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  if (__pyx_import_star(__pyx_t_3) < 0) __PYX_ERR(0, 2629, __pyx_L1_error);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "PyTorch.pyx":1
 * # GENERATED FILE, do not edit by hand             # <<<<<<<<<<<<<<
 * # Source: src/PyTorch.jinja2.pyx
 * 
 */
  __pyx_t_3 = PyDict_New(); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_test, __pyx_t_3) < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "View.MemoryView":207
 *         info.obj = self
 * 
 *     __pyx_getbuffer = capsule(<void *> &__pyx_array_getbuffer, "getbuffer(obj, view, flags)")             # <<<<<<<<<<<<<<
 * 
 *     def __dealloc__(array self):
 */
  __pyx_t_3 = __pyx_capsule_create(((void *)(&__pyx_array_getbuffer)), ((char *)"getbuffer(obj, view, flags)")); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 207, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_array_type->tp_dict, __pyx_n_s_pyx_getbuffer, __pyx_t_3) < 0) __PYX_ERR(2, 207, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  PyType_Modified(__pyx_array_type);

  /* "View.MemoryView":282
 *         return self.name
 * 
 * cdef generic = Enum("<strided and direct or indirect>")             # <<<<<<<<<<<<<<
 * cdef strided = Enum("<strided and direct>") # default
 * cdef indirect = Enum("<strided and indirect>")
 */
  __pyx_t_3 = __Pyx_PyObject_Call(((PyObject *)__pyx_MemviewEnum_type), __pyx_tuple__130, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 282, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_XGOTREF(generic);
  __Pyx_DECREF_SET(generic, __pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_3);
  __pyx_t_3 = 0;

  /* "View.MemoryView":283
 * 
 * cdef generic = Enum("<strided and direct or indirect>")
 * cdef strided = Enum("<strided and direct>") # default             # <<<<<<<<<<<<<<
 * cdef indirect = Enum("<strided and indirect>")
 * 
 */
  __pyx_t_3 = __Pyx_PyObject_Call(((PyObject *)__pyx_MemviewEnum_type), __pyx_tuple__131, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 283, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_XGOTREF(strided);
  __Pyx_DECREF_SET(strided, __pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_3);
  __pyx_t_3 = 0;

  /* "View.MemoryView":284
 * cdef generic = Enum("<strided and direct or indirect>")
 * cdef strided = Enum("<strided and direct>") # default
 * cdef indirect = Enum("<strided and indirect>")             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_3 = __Pyx_PyObject_Call(((PyObject *)__pyx_MemviewEnum_type), __pyx_tuple__132, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 284, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_XGOTREF(indirect);
  __Pyx_DECREF_SET(indirect, __pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_3);
  __pyx_t_3 = 0;

  /* "View.MemoryView":287
 * 
 * 
 * cdef contiguous = Enum("<contiguous and direct>")             # <<<<<<<<<<<<<<
 * cdef indirect_contiguous = Enum("<contiguous and indirect>")
 * 
 */
  __pyx_t_3 = __Pyx_PyObject_Call(((PyObject *)__pyx_MemviewEnum_type), __pyx_tuple__133, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 287, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_XGOTREF(contiguous);
  __Pyx_DECREF_SET(contiguous, __pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_3);
  __pyx_t_3 = 0;

  /* "View.MemoryView":288
 * 
 * cdef contiguous = Enum("<contiguous and direct>")
 * cdef indirect_contiguous = Enum("<contiguous and indirect>")             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_3 = __Pyx_PyObject_Call(((PyObject *)__pyx_MemviewEnum_type), __pyx_tuple__134, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 288, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_XGOTREF(indirect_contiguous);
  __Pyx_DECREF_SET(indirect_contiguous, __pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_3);
  __pyx_t_3 = 0;

  /* "View.MemoryView":312
 * 
 * DEF THREAD_LOCKS_PREALLOCATED = 8
 * cdef int __pyx_memoryview_thread_locks_used = 0             # <<<<<<<<<<<<<<
 * cdef PyThread_type_lock[THREAD_LOCKS_PREALLOCATED] __pyx_memoryview_thread_locks = [
 *     PyThread_allocate_lock(),
 */
  __pyx_memoryview_thread_locks_used = 0;

  /* "View.MemoryView":313
 * DEF THREAD_LOCKS_PREALLOCATED = 8
 * cdef int __pyx_memoryview_thread_locks_used = 0
 * cdef PyThread_type_lock[THREAD_LOCKS_PREALLOCATED] __pyx_memoryview_thread_locks = [             # <<<<<<<<<<<<<<
 *     PyThread_allocate_lock(),
 *     PyThread_allocate_lock(),
 */
  __pyx_t_8[0] = PyThread_allocate_lock();
  __pyx_t_8[1] = PyThread_allocate_lock();
  __pyx_t_8[2] = PyThread_allocate_lock();
  __pyx_t_8[3] = PyThread_allocate_lock();
  __pyx_t_8[4] = PyThread_allocate_lock();
  __pyx_t_8[5] = PyThread_allocate_lock();
  __pyx_t_8[6] = PyThread_allocate_lock();
  __pyx_t_8[7] = PyThread_allocate_lock();
  memcpy(&(__pyx_memoryview_thread_locks[0]), __pyx_t_8, sizeof(__pyx_memoryview_thread_locks[0]) * (8));

  /* "View.MemoryView":535
 *         info.obj = self
 * 
 *     __pyx_getbuffer = capsule(<void *> &__pyx_memoryview_getbuffer, "getbuffer(obj, view, flags)")             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_3 = __pyx_capsule_create(((void *)(&__pyx_memoryview_getbuffer)), ((char *)"getbuffer(obj, view, flags)")); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 535, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_memoryview_type->tp_dict, __pyx_n_s_pyx_getbuffer, __pyx_t_3) < 0) __PYX_ERR(2, 535, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  PyType_Modified(__pyx_memoryview_type);

  /* "View.MemoryView":981
 *         return self.from_object
 * 
 *     __pyx_getbuffer = capsule(<void *> &__pyx_memoryview_getbuffer, "getbuffer(obj, view, flags)")             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_3 = __pyx_capsule_create(((void *)(&__pyx_memoryview_getbuffer)), ((char *)"getbuffer(obj, view, flags)")); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 981, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_memoryviewslice_type->tp_dict, __pyx_n_s_pyx_getbuffer, __pyx_t_3) < 0) __PYX_ERR(2, 981, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  PyType_Modified(__pyx_memoryviewslice_type);

  /* "View.MemoryView":1391
 * 
 * @cname('__pyx_memoryview__slice_assign_scalar')
 * cdef void _slice_assign_scalar(char *data, Py_ssize_t *shape,             # <<<<<<<<<<<<<<
 *                               Py_ssize_t *strides, int ndim,
 *                               size_t itemsize, void *item) nogil:
 */

  /*--- Wrapped vars code ---*/

  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  if (__pyx_m) {
    if (__pyx_d) {
      __Pyx_AddTraceback("init PyTorch", __pyx_clineno, __pyx_lineno, __pyx_filename);
    }
    Py_DECREF(__pyx_m); __pyx_m = 0;
  } else if (!PyErr_Occurred()) {
    PyErr_SetString(PyExc_ImportError, "init PyTorch");
  }
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  #if PY_MAJOR_VERSION < 3
  return;
  #else
  return __pyx_m;
  #endif
}

/* --- Runtime support code --- */
/* Refnanny */
#if CYTHON_REFNANNY
static __Pyx_RefNannyAPIStruct *__Pyx_RefNannyImportAPI(const char *modname) {
    PyObject *m = NULL, *p = NULL;
    void *r = NULL;
    m = PyImport_ImportModule((char *)modname);
    if (!m) goto end;
    p = PyObject_GetAttrString(m, (char *)"RefNannyAPI");
    if (!p) goto end;
    r = PyLong_AsVoidPtr(p);
end:
    Py_XDECREF(p);
    Py_XDECREF(m);
    return (__Pyx_RefNannyAPIStruct *)r;
}
#endif

/* GetBuiltinName */
static PyObject *__Pyx_GetBuiltinName(PyObject *name) {
    PyObject* result = __Pyx_PyObject_GetAttrStr(__pyx_b, name);
    if (unlikely(!result)) {
        PyErr_Format(PyExc_NameError,
#if PY_MAJOR_VERSION >= 3
            "name '%U' is not defined", name);
#else
            "name '%.200s' is not defined", PyString_AS_STRING(name));
#endif
    }
    return result;
}

/* RaiseDoubleKeywords */
static void __Pyx_RaiseDoubleKeywordsError(
    const char* func_name,
    PyObject* kw_name)
{
    PyErr_Format(PyExc_TypeError,
        #if PY_MAJOR_VERSION >= 3
        "%s() got multiple values for keyword argument '%U'", func_name, kw_name);
        #else
        "%s() got multiple values for keyword argument '%s'", func_name,
        PyString_AsString(kw_name));
        #endif
}

/* ParseKeywords */
static int __Pyx_ParseOptionalKeywords(
    PyObject *kwds,
    PyObject **argnames[],
    PyObject *kwds2,
    PyObject *values[],
    Py_ssize_t num_pos_args,
    const char* function_name)
{
    PyObject *key = 0, *value = 0;
    Py_ssize_t pos = 0;
    PyObject*** name;
    PyObject*** first_kw_arg = argnames + num_pos_args;
    while (PyDict_Next(kwds, &pos, &key, &value)) {
        name = first_kw_arg;
        while (*name && (**name != key)) name++;
        if (*name) {
            values[name-argnames] = value;
            continue;
        }
        name = first_kw_arg;
        #if PY_MAJOR_VERSION < 3
        if (likely(PyString_CheckExact(key)) || likely(PyString_Check(key))) {
            while (*name) {
                if ((CYTHON_COMPILING_IN_PYPY || PyString_GET_SIZE(**name) == PyString_GET_SIZE(key))
                        && _PyString_Eq(**name, key)) {
                    values[name-argnames] = value;
                    break;
                }
                name++;
            }
            if (*name) continue;
            else {
                PyObject*** argname = argnames;
                while (argname != first_kw_arg) {
                    if ((**argname == key) || (
                            (CYTHON_COMPILING_IN_PYPY || PyString_GET_SIZE(**argname) == PyString_GET_SIZE(key))
                             && _PyString_Eq(**argname, key))) {
                        goto arg_passed_twice;
                    }
                    argname++;
                }
            }
        } else
        #endif
        if (likely(PyUnicode_Check(key))) {
            while (*name) {
                int cmp = (**name == key) ? 0 :
                #if !CYTHON_COMPILING_IN_PYPY && PY_MAJOR_VERSION >= 3
                    (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
                #endif
                    PyUnicode_Compare(**name, key);
                if (cmp < 0 && unlikely(PyErr_Occurred())) goto bad;
                if (cmp == 0) {
                    values[name-argnames] = value;
                    break;
                }
                name++;
            }
            if (*name) continue;
            else {
                PyObject*** argname = argnames;
                while (argname != first_kw_arg) {
                    int cmp = (**argname == key) ? 0 :
                    #if !CYTHON_COMPILING_IN_PYPY && PY_MAJOR_VERSION >= 3
                        (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
                    #endif
                        PyUnicode_Compare(**argname, key);
                    if (cmp < 0 && unlikely(PyErr_Occurred())) goto bad;
                    if (cmp == 0) goto arg_passed_twice;
                    argname++;
                }
            }
        } else
            goto invalid_keyword_type;
        if (kwds2) {
            if (unlikely(PyDict_SetItem(kwds2, key, value))) goto bad;
        } else {
            goto invalid_keyword;
        }
    }
    return 0;
arg_passed_twice:
    __Pyx_RaiseDoubleKeywordsError(function_name, key);
    goto bad;
invalid_keyword_type:
    PyErr_Format(PyExc_TypeError,
        "%.200s() keywords must be strings", function_name);
    goto bad;
invalid_keyword:
    PyErr_Format(PyExc_TypeError,
    #if PY_MAJOR_VERSION < 3
        "%.200s() got an unexpected keyword argument '%.200s'",
        function_name, PyString_AsString(key));
    #else
        "%s() got an unexpected keyword argument '%U'",
        function_name, key);
    #endif
bad:
    return -1;
}

/* RaiseArgTupleInvalid */
static void __Pyx_RaiseArgtupleInvalid(
    const char* func_name,
    int exact,
    Py_ssize_t num_min,
    Py_ssize_t num_max,
    Py_ssize_t num_found)
{
    Py_ssize_t num_expected;
    const char *more_or_less;
    if (num_found < num_min) {
        num_expected = num_min;
        more_or_less = "at least";
    } else {
        num_expected = num_max;
        more_or_less = "at most";
    }
    if (exact) {
        more_or_less = "exactly";
    }
    PyErr_Format(PyExc_TypeError,
                 "%.200s() takes %.8s %" CYTHON_FORMAT_SSIZE_T "d positional argument%.1s (%" CYTHON_FORMAT_SSIZE_T "d given)",
                 func_name, more_or_less, num_expected,
                 (num_expected == 1) ? "" : "s", num_found);
}

/* PyIntBinop */
#if !CYTHON_COMPILING_IN_PYPY
static PyObject* __Pyx_PyInt_SubtractObjC(PyObject *op1, PyObject *op2, CYTHON_UNUSED long intval, CYTHON_UNUSED int inplace) {
    #if PY_MAJOR_VERSION < 3
    if (likely(PyInt_CheckExact(op1))) {
        const long b = intval;
        long x;
        long a = PyInt_AS_LONG(op1);
            x = (long)((unsigned long)a - b);
            if (likely((x^a) >= 0 || (x^~b) >= 0))
                return PyInt_FromLong(x);
            return PyLong_Type.tp_as_number->nb_subtract(op1, op2);
    }
    #endif
    #if CYTHON_USE_PYLONG_INTERNALS
    if (likely(PyLong_CheckExact(op1))) {
        const long b = intval;
        long a, x;
#ifdef HAVE_LONG_LONG
        const PY_LONG_LONG llb = intval;
        PY_LONG_LONG lla, llx;
#endif
        const digit* digits = ((PyLongObject*)op1)->ob_digit;
        const Py_ssize_t size = Py_SIZE(op1);
        if (likely(__Pyx_sst_abs(size) <= 1)) {
            a = likely(size) ? digits[0] : 0;
            if (size == -1) a = -a;
        } else {
            switch (size) {
                case -2:
                    if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                        a = -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 2 * PyLong_SHIFT) {
                        lla = -(PY_LONG_LONG) (((((unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case 2:
                    if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                        a = (long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 2 * PyLong_SHIFT) {
                        lla = (PY_LONG_LONG) (((((unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case -3:
                    if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                        a = -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 3 * PyLong_SHIFT) {
                        lla = -(PY_LONG_LONG) (((((((unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case 3:
                    if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                        a = (long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 3 * PyLong_SHIFT) {
                        lla = (PY_LONG_LONG) (((((((unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case -4:
                    if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                        a = -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 4 * PyLong_SHIFT) {
                        lla = -(PY_LONG_LONG) (((((((((unsigned PY_LONG_LONG)digits[3]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case 4:
                    if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                        a = (long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 4 * PyLong_SHIFT) {
                        lla = (PY_LONG_LONG) (((((((((unsigned PY_LONG_LONG)digits[3]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                default: return PyLong_Type.tp_as_number->nb_subtract(op1, op2);
            }
        }
                x = a - b;
            return PyLong_FromLong(x);
#ifdef HAVE_LONG_LONG
        long_long:
                llx = lla - llb;
            return PyLong_FromLongLong(llx);
#endif
        
        
    }
    #endif
    if (PyFloat_CheckExact(op1)) {
        const long b = intval;
        double a = PyFloat_AS_DOUBLE(op1);
            double result;
            PyFPE_START_PROTECT("subtract", return NULL)
            result = ((double)a) - (double)b;
            PyFPE_END_PROTECT(result)
            return PyFloat_FromDouble(result);
    }
    return (inplace ? PyNumber_InPlaceSubtract : PyNumber_Subtract)(op1, op2);
}
#endif

/* GetModuleGlobalName */
static CYTHON_INLINE PyObject *__Pyx_GetModuleGlobalName(PyObject *name) {
    PyObject *result;
#if !CYTHON_AVOID_BORROWED_REFS
    result = PyDict_GetItem(__pyx_d, name);
    if (likely(result)) {
        Py_INCREF(result);
    } else {
#else
    result = PyObject_GetItem(__pyx_d, name);
    if (!result) {
        PyErr_Clear();
#endif
        result = __Pyx_GetBuiltinName(name);
    }
    return result;
}

/* PyCFunctionFastCall */
  #if CYTHON_FAST_PYCCALL
static CYTHON_INLINE PyObject * __Pyx_PyCFunction_FastCall(PyObject *func_obj, PyObject **args, Py_ssize_t nargs) {
    PyCFunctionObject *func = (PyCFunctionObject*)func_obj;
    PyCFunction meth = PyCFunction_GET_FUNCTION(func);
    PyObject *self = PyCFunction_GET_SELF(func);
    assert(PyCFunction_Check(func));
    assert(METH_FASTCALL == (PyCFunction_GET_FLAGS(func) & ~(METH_CLASS | METH_STATIC | METH_COEXIST)));
    assert(nargs >= 0);
    assert(nargs == 0 || args != NULL);
    /* _PyCFunction_FastCallDict() must not be called with an exception set,
       because it may clear it (directly or indirectly) and so the
       caller loses its exception */
    assert(!PyErr_Occurred());
    return (*((__Pyx_PyCFunctionFast)meth)) (self, args, nargs, NULL);
}
#endif  // CYTHON_FAST_PYCCALL

/* PyFunctionFastCall */
  #if CYTHON_FAST_PYCALL
#include "frameobject.h"
static PyObject* __Pyx_PyFunction_FastCallNoKw(PyCodeObject *co, PyObject **args, Py_ssize_t na,
                                               PyObject *globals) {
    PyFrameObject *f;
    PyThreadState *tstate = PyThreadState_GET();
    PyObject **fastlocals;
    Py_ssize_t i;
    PyObject *result;
    assert(globals != NULL);
    /* XXX Perhaps we should create a specialized
       PyFrame_New() that doesn't take locals, but does
       take builtins without sanity checking them.
       */
    assert(tstate != NULL);
    f = PyFrame_New(tstate, co, globals, NULL);
    if (f == NULL) {
        return NULL;
    }
    fastlocals = f->f_localsplus;
    for (i = 0; i < na; i++) {
        Py_INCREF(*args);
        fastlocals[i] = *args++;
    }
    result = PyEval_EvalFrameEx(f,0);
    ++tstate->recursion_depth;
    Py_DECREF(f);
    --tstate->recursion_depth;
    return result;
}
#if 1 || PY_VERSION_HEX < 0x030600B1
static PyObject *__Pyx_PyFunction_FastCallDict(PyObject *func, PyObject **args, int nargs, PyObject *kwargs) {
    PyCodeObject *co = (PyCodeObject *)PyFunction_GET_CODE(func);
    PyObject *globals = PyFunction_GET_GLOBALS(func);
    PyObject *argdefs = PyFunction_GET_DEFAULTS(func);
    PyObject *closure;
#if PY_MAJOR_VERSION >= 3
    PyObject *kwdefs;
#endif
    PyObject *kwtuple, **k;
    PyObject **d;
    Py_ssize_t nd;
    Py_ssize_t nk;
    PyObject *result;
    assert(kwargs == NULL || PyDict_Check(kwargs));
    nk = kwargs ? PyDict_Size(kwargs) : 0;
    if (Py_EnterRecursiveCall((char*)" while calling a Python object")) {
        return NULL;
    }
    if (
#if PY_MAJOR_VERSION >= 3
            co->co_kwonlyargcount == 0 &&
#endif
            likely(kwargs == NULL || nk == 0) &&
            co->co_flags == (CO_OPTIMIZED | CO_NEWLOCALS | CO_NOFREE)) {
        if (argdefs == NULL && co->co_argcount == nargs) {
            result = __Pyx_PyFunction_FastCallNoKw(co, args, nargs, globals);
            goto done;
        }
        else if (nargs == 0 && argdefs != NULL
                 && co->co_argcount == Py_SIZE(argdefs)) {
            /* function called with no arguments, but all parameters have
               a default value: use default values as arguments .*/
            args = &PyTuple_GET_ITEM(argdefs, 0);
            result =__Pyx_PyFunction_FastCallNoKw(co, args, Py_SIZE(argdefs), globals);
            goto done;
        }
    }
    if (kwargs != NULL) {
        Py_ssize_t pos, i;
        kwtuple = PyTuple_New(2 * nk);
        if (kwtuple == NULL) {
            result = NULL;
            goto done;
        }
        k = &PyTuple_GET_ITEM(kwtuple, 0);
        pos = i = 0;
        while (PyDict_Next(kwargs, &pos, &k[i], &k[i+1])) {
            Py_INCREF(k[i]);
            Py_INCREF(k[i+1]);
            i += 2;
        }
        nk = i / 2;
    }
    else {
        kwtuple = NULL;
        k = NULL;
    }
    closure = PyFunction_GET_CLOSURE(func);
#if PY_MAJOR_VERSION >= 3
    kwdefs = PyFunction_GET_KW_DEFAULTS(func);
#endif
    if (argdefs != NULL) {
        d = &PyTuple_GET_ITEM(argdefs, 0);
        nd = Py_SIZE(argdefs);
    }
    else {
        d = NULL;
        nd = 0;
    }
#if PY_MAJOR_VERSION >= 3
    result = PyEval_EvalCodeEx((PyObject*)co, globals, (PyObject *)NULL,
                               args, nargs,
                               k, (int)nk,
                               d, (int)nd, kwdefs, closure);
#else
    result = PyEval_EvalCodeEx(co, globals, (PyObject *)NULL,
                               args, nargs,
                               k, (int)nk,
                               d, (int)nd, closure);
#endif
    Py_XDECREF(kwtuple);
done:
    Py_LeaveRecursiveCall();
    return result;
}
#endif  // CPython < 3.6
#endif  // CYTHON_FAST_PYCALL

/* PyObjectCall */
  #if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_Call(PyObject *func, PyObject *arg, PyObject *kw) {
    PyObject *result;
    ternaryfunc call = func->ob_type->tp_call;
    if (unlikely(!call))
        return PyObject_Call(func, arg, kw);
    if (unlikely(Py_EnterRecursiveCall((char*)" while calling a Python object")))
        return NULL;
    result = (*call)(func, arg, kw);
    Py_LeaveRecursiveCall();
    if (unlikely(!result) && unlikely(!PyErr_Occurred())) {
        PyErr_SetString(
            PyExc_SystemError,
            "NULL result without error in PyObject_Call");
    }
    return result;
}
#endif

/* PyObjectCallMethO */
  #if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallMethO(PyObject *func, PyObject *arg) {
    PyObject *self, *result;
    PyCFunction cfunc;
    cfunc = PyCFunction_GET_FUNCTION(func);
    self = PyCFunction_GET_SELF(func);
    if (unlikely(Py_EnterRecursiveCall((char*)" while calling a Python object")))
        return NULL;
    result = cfunc(self, arg);
    Py_LeaveRecursiveCall();
    if (unlikely(!result) && unlikely(!PyErr_Occurred())) {
        PyErr_SetString(
            PyExc_SystemError,
            "NULL result without error in PyObject_Call");
    }
    return result;
}
#endif

/* PyObjectCallOneArg */
  #if CYTHON_COMPILING_IN_CPYTHON
static PyObject* __Pyx__PyObject_CallOneArg(PyObject *func, PyObject *arg) {
    PyObject *result;
    PyObject *args = PyTuple_New(1);
    if (unlikely(!args)) return NULL;
    Py_INCREF(arg);
    PyTuple_SET_ITEM(args, 0, arg);
    result = __Pyx_PyObject_Call(func, args, NULL);
    Py_DECREF(args);
    return result;
}
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallOneArg(PyObject *func, PyObject *arg) {
#if CYTHON_FAST_PYCALL
    if (PyFunction_Check(func)) {
        return __Pyx_PyFunction_FastCall(func, &arg, 1);
    }
#endif
#ifdef __Pyx_CyFunction_USED
    if (likely(PyCFunction_Check(func) || PyObject_TypeCheck(func, __pyx_CyFunctionType))) {
#else
    if (likely(PyCFunction_Check(func))) {
#endif
        if (likely(PyCFunction_GET_FLAGS(func) & METH_O)) {
            return __Pyx_PyObject_CallMethO(func, arg);
#if CYTHON_FAST_PYCCALL
        } else if (PyCFunction_GET_FLAGS(func) & METH_FASTCALL) {
            return __Pyx_PyCFunction_FastCall(func, &arg, 1);
#endif
        }
    }
    return __Pyx__PyObject_CallOneArg(func, arg);
}
#else
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallOneArg(PyObject *func, PyObject *arg) {
    PyObject *result;
    PyObject *args = PyTuple_Pack(1, arg);
    if (unlikely(!args)) return NULL;
    result = __Pyx_PyObject_Call(func, args, NULL);
    Py_DECREF(args);
    return result;
}
#endif

/* GetItemInt */
    static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Generic(PyObject *o, PyObject* j) {
    PyObject *r;
    if (!j) return NULL;
    r = PyObject_GetItem(o, j);
    Py_DECREF(j);
    return r;
}
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_List_Fast(PyObject *o, Py_ssize_t i,
                                                              CYTHON_NCP_UNUSED int wraparound,
                                                              CYTHON_NCP_UNUSED int boundscheck) {
#if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    if (wraparound & unlikely(i < 0)) i += PyList_GET_SIZE(o);
    if ((!boundscheck) || likely((0 <= i) & (i < PyList_GET_SIZE(o)))) {
        PyObject *r = PyList_GET_ITEM(o, i);
        Py_INCREF(r);
        return r;
    }
    return __Pyx_GetItemInt_Generic(o, PyInt_FromSsize_t(i));
#else
    return PySequence_GetItem(o, i);
#endif
}
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Tuple_Fast(PyObject *o, Py_ssize_t i,
                                                              CYTHON_NCP_UNUSED int wraparound,
                                                              CYTHON_NCP_UNUSED int boundscheck) {
#if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    if (wraparound & unlikely(i < 0)) i += PyTuple_GET_SIZE(o);
    if ((!boundscheck) || likely((0 <= i) & (i < PyTuple_GET_SIZE(o)))) {
        PyObject *r = PyTuple_GET_ITEM(o, i);
        Py_INCREF(r);
        return r;
    }
    return __Pyx_GetItemInt_Generic(o, PyInt_FromSsize_t(i));
#else
    return PySequence_GetItem(o, i);
#endif
}
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Fast(PyObject *o, Py_ssize_t i, int is_list,
                                                     CYTHON_NCP_UNUSED int wraparound,
                                                     CYTHON_NCP_UNUSED int boundscheck) {
#if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS && CYTHON_USE_TYPE_SLOTS
    if (is_list || PyList_CheckExact(o)) {
        Py_ssize_t n = ((!wraparound) | likely(i >= 0)) ? i : i + PyList_GET_SIZE(o);
        if ((!boundscheck) || (likely((n >= 0) & (n < PyList_GET_SIZE(o))))) {
            PyObject *r = PyList_GET_ITEM(o, n);
            Py_INCREF(r);
            return r;
        }
    }
    else if (PyTuple_CheckExact(o)) {
        Py_ssize_t n = ((!wraparound) | likely(i >= 0)) ? i : i + PyTuple_GET_SIZE(o);
        if ((!boundscheck) || likely((n >= 0) & (n < PyTuple_GET_SIZE(o)))) {
            PyObject *r = PyTuple_GET_ITEM(o, n);
            Py_INCREF(r);
            return r;
        }
    } else {
        PySequenceMethods *m = Py_TYPE(o)->tp_as_sequence;
        if (likely(m && m->sq_item)) {
            if (wraparound && unlikely(i < 0) && likely(m->sq_length)) {
                Py_ssize_t l = m->sq_length(o);
                if (likely(l >= 0)) {
                    i += l;
                } else {
                    if (!PyErr_ExceptionMatches(PyExc_OverflowError))
                        return NULL;
                    PyErr_Clear();
                }
            }
            return m->sq_item(o, i);
        }
    }
#else
    if (is_list || PySequence_Check(o)) {
        return PySequence_GetItem(o, i);
    }
#endif
    return __Pyx_GetItemInt_Generic(o, PyInt_FromSsize_t(i));
}

/* ExtTypeTest */
    static CYTHON_INLINE int __Pyx_TypeTest(PyObject *obj, PyTypeObject *type) {
    if (unlikely(!type)) {
        PyErr_SetString(PyExc_SystemError, "Missing type object");
        return 0;
    }
    if (likely(PyObject_TypeCheck(obj, type)))
        return 1;
    PyErr_Format(PyExc_TypeError, "Cannot convert %.200s to %.200s",
                 Py_TYPE(obj)->tp_name, type->tp_name);
    return 0;
}

/* PyErrFetchRestore */
    #if CYTHON_FAST_THREAD_STATE
static CYTHON_INLINE void __Pyx_ErrRestoreInState(PyThreadState *tstate, PyObject *type, PyObject *value, PyObject *tb) {
    PyObject *tmp_type, *tmp_value, *tmp_tb;
    tmp_type = tstate->curexc_type;
    tmp_value = tstate->curexc_value;
    tmp_tb = tstate->curexc_traceback;
    tstate->curexc_type = type;
    tstate->curexc_value = value;
    tstate->curexc_traceback = tb;
    Py_XDECREF(tmp_type);
    Py_XDECREF(tmp_value);
    Py_XDECREF(tmp_tb);
}
static CYTHON_INLINE void __Pyx_ErrFetchInState(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb) {
    *type = tstate->curexc_type;
    *value = tstate->curexc_value;
    *tb = tstate->curexc_traceback;
    tstate->curexc_type = 0;
    tstate->curexc_value = 0;
    tstate->curexc_traceback = 0;
}
#endif

/* RaiseException */
    #if PY_MAJOR_VERSION < 3
static void __Pyx_Raise(PyObject *type, PyObject *value, PyObject *tb,
                        CYTHON_UNUSED PyObject *cause) {
    __Pyx_PyThreadState_declare
    Py_XINCREF(type);
    if (!value || value == Py_None)
        value = NULL;
    else
        Py_INCREF(value);
    if (!tb || tb == Py_None)
        tb = NULL;
    else {
        Py_INCREF(tb);
        if (!PyTraceBack_Check(tb)) {
            PyErr_SetString(PyExc_TypeError,
                "raise: arg 3 must be a traceback or None");
            goto raise_error;
        }
    }
    if (PyType_Check(type)) {
#if CYTHON_COMPILING_IN_PYPY
        if (!value) {
            Py_INCREF(Py_None);
            value = Py_None;
        }
#endif
        PyErr_NormalizeException(&type, &value, &tb);
    } else {
        if (value) {
            PyErr_SetString(PyExc_TypeError,
                "instance exception may not have a separate value");
            goto raise_error;
        }
        value = type;
        type = (PyObject*) Py_TYPE(type);
        Py_INCREF(type);
        if (!PyType_IsSubtype((PyTypeObject *)type, (PyTypeObject *)PyExc_BaseException)) {
            PyErr_SetString(PyExc_TypeError,
                "raise: exception class must be a subclass of BaseException");
            goto raise_error;
        }
    }
    __Pyx_PyThreadState_assign
    __Pyx_ErrRestore(type, value, tb);
    return;
raise_error:
    Py_XDECREF(value);
    Py_XDECREF(type);
    Py_XDECREF(tb);
    return;
}
#else
static void __Pyx_Raise(PyObject *type, PyObject *value, PyObject *tb, PyObject *cause) {
    PyObject* owned_instance = NULL;
    if (tb == Py_None) {
        tb = 0;
    } else if (tb && !PyTraceBack_Check(tb)) {
        PyErr_SetString(PyExc_TypeError,
            "raise: arg 3 must be a traceback or None");
        goto bad;
    }
    if (value == Py_None)
        value = 0;
    if (PyExceptionInstance_Check(type)) {
        if (value) {
            PyErr_SetString(PyExc_TypeError,
                "instance exception may not have a separate value");
            goto bad;
        }
        value = type;
        type = (PyObject*) Py_TYPE(value);
    } else if (PyExceptionClass_Check(type)) {
        PyObject *instance_class = NULL;
        if (value && PyExceptionInstance_Check(value)) {
            instance_class = (PyObject*) Py_TYPE(value);
            if (instance_class != type) {
                int is_subclass = PyObject_IsSubclass(instance_class, type);
                if (!is_subclass) {
                    instance_class = NULL;
                } else if (unlikely(is_subclass == -1)) {
                    goto bad;
                } else {
                    type = instance_class;
                }
            }
        }
        if (!instance_class) {
            PyObject *args;
            if (!value)
                args = PyTuple_New(0);
            else if (PyTuple_Check(value)) {
                Py_INCREF(value);
                args = value;
            } else
                args = PyTuple_Pack(1, value);
            if (!args)
                goto bad;
            owned_instance = PyObject_Call(type, args, NULL);
            Py_DECREF(args);
            if (!owned_instance)
                goto bad;
            value = owned_instance;
            if (!PyExceptionInstance_Check(value)) {
                PyErr_Format(PyExc_TypeError,
                             "calling %R should have returned an instance of "
                             "BaseException, not %R",
                             type, Py_TYPE(value));
                goto bad;
            }
        }
    } else {
        PyErr_SetString(PyExc_TypeError,
            "raise: exception class must be a subclass of BaseException");
        goto bad;
    }
#if PY_VERSION_HEX >= 0x03030000
    if (cause) {
#else
    if (cause && cause != Py_None) {
#endif
        PyObject *fixed_cause;
        if (cause == Py_None) {
            fixed_cause = NULL;
        } else if (PyExceptionClass_Check(cause)) {
            fixed_cause = PyObject_CallObject(cause, NULL);
            if (fixed_cause == NULL)
                goto bad;
        } else if (PyExceptionInstance_Check(cause)) {
            fixed_cause = cause;
            Py_INCREF(fixed_cause);
        } else {
            PyErr_SetString(PyExc_TypeError,
                            "exception causes must derive from "
                            "BaseException");
            goto bad;
        }
        PyException_SetCause(value, fixed_cause);
    }
    PyErr_SetObject(type, value);
    if (tb) {
#if CYTHON_COMPILING_IN_PYPY
        PyObject *tmp_type, *tmp_value, *tmp_tb;
        PyErr_Fetch(&tmp_type, &tmp_value, &tmp_tb);
        Py_INCREF(tb);
        PyErr_Restore(tmp_type, tmp_value, tb);
        Py_XDECREF(tmp_tb);
#else
        PyThreadState *tstate = PyThreadState_GET();
        PyObject* tmp_tb = tstate->curexc_traceback;
        if (tb != tmp_tb) {
            Py_INCREF(tb);
            tstate->curexc_traceback = tb;
            Py_XDECREF(tmp_tb);
        }
#endif
    }
bad:
    Py_XDECREF(owned_instance);
    return;
}
#endif

/* WriteUnraisableException */
      static void __Pyx_WriteUnraisable(const char *name, CYTHON_UNUSED int clineno,
                                  CYTHON_UNUSED int lineno, CYTHON_UNUSED const char *filename,
                                  int full_traceback, CYTHON_UNUSED int nogil) {
    PyObject *old_exc, *old_val, *old_tb;
    PyObject *ctx;
    __Pyx_PyThreadState_declare
#ifdef WITH_THREAD
    PyGILState_STATE state;
    if (nogil)
        state = PyGILState_Ensure();
#ifdef _MSC_VER
    else state = (PyGILState_STATE)-1;
#endif
#endif
    __Pyx_PyThreadState_assign
    __Pyx_ErrFetch(&old_exc, &old_val, &old_tb);
    if (full_traceback) {
        Py_XINCREF(old_exc);
        Py_XINCREF(old_val);
        Py_XINCREF(old_tb);
        __Pyx_ErrRestore(old_exc, old_val, old_tb);
        PyErr_PrintEx(1);
    }
    #if PY_MAJOR_VERSION < 3
    ctx = PyString_FromString(name);
    #else
    ctx = PyUnicode_FromString(name);
    #endif
    __Pyx_ErrRestore(old_exc, old_val, old_tb);
    if (!ctx) {
        PyErr_WriteUnraisable(Py_None);
    } else {
        PyErr_WriteUnraisable(ctx);
        Py_DECREF(ctx);
    }
#ifdef WITH_THREAD
    if (nogil)
        PyGILState_Release(state);
#endif
}

/* PyObjectCallNoArg */
      #if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallNoArg(PyObject *func) {
#if CYTHON_FAST_PYCALL
    if (PyFunction_Check(func)) {
        return __Pyx_PyFunction_FastCall(func, NULL, 0);
    }
#endif
#ifdef __Pyx_CyFunction_USED
    if (likely(PyCFunction_Check(func) || PyObject_TypeCheck(func, __pyx_CyFunctionType))) {
#else
    if (likely(PyCFunction_Check(func))) {
#endif
        if (likely(PyCFunction_GET_FLAGS(func) & METH_NOARGS)) {
            return __Pyx_PyObject_CallMethO(func, NULL);
        }
    }
    return __Pyx_PyObject_Call(func, __pyx_empty_tuple, NULL);
}
#endif

/* SetItemInt */
        static CYTHON_INLINE int __Pyx_SetItemInt_Generic(PyObject *o, PyObject *j, PyObject *v) {
    int r;
    if (!j) return -1;
    r = PyObject_SetItem(o, j, v);
    Py_DECREF(j);
    return r;
}
static CYTHON_INLINE int __Pyx_SetItemInt_Fast(PyObject *o, Py_ssize_t i, PyObject *v, int is_list,
                                               CYTHON_NCP_UNUSED int wraparound, CYTHON_NCP_UNUSED int boundscheck) {
#if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS && CYTHON_USE_TYPE_SLOTS
    if (is_list || PyList_CheckExact(o)) {
        Py_ssize_t n = (!wraparound) ? i : ((likely(i >= 0)) ? i : i + PyList_GET_SIZE(o));
        if ((!boundscheck) || likely((n >= 0) & (n < PyList_GET_SIZE(o)))) {
            PyObject* old = PyList_GET_ITEM(o, n);
            Py_INCREF(v);
            PyList_SET_ITEM(o, n, v);
            Py_DECREF(old);
            return 1;
        }
    } else {
        PySequenceMethods *m = Py_TYPE(o)->tp_as_sequence;
        if (likely(m && m->sq_ass_item)) {
            if (wraparound && unlikely(i < 0) && likely(m->sq_length)) {
                Py_ssize_t l = m->sq_length(o);
                if (likely(l >= 0)) {
                    i += l;
                } else {
                    if (!PyErr_ExceptionMatches(PyExc_OverflowError))
                        return -1;
                    PyErr_Clear();
                }
            }
            return m->sq_ass_item(o, i, v);
        }
    }
#else
#if CYTHON_COMPILING_IN_PYPY
    if (is_list || (PySequence_Check(o) && !PyDict_Check(o))) {
#else
    if (is_list || PySequence_Check(o)) {
#endif
        return PySequence_SetItem(o, i, v);
    }
#endif
    return __Pyx_SetItemInt_Generic(o, PyInt_FromSsize_t(i), v);
}

/* KeywordStringCheck */
          static CYTHON_INLINE int __Pyx_CheckKeywordStrings(
    PyObject *kwdict,
    const char* function_name,
    int kw_allowed)
{
    PyObject* key = 0;
    Py_ssize_t pos = 0;
#if CYTHON_COMPILING_IN_PYPY
    if (!kw_allowed && PyDict_Next(kwdict, &pos, &key, 0))
        goto invalid_keyword;
    return 1;
#else
    while (PyDict_Next(kwdict, &pos, &key, 0)) {
        #if PY_MAJOR_VERSION < 3
        if (unlikely(!PyString_CheckExact(key)) && unlikely(!PyString_Check(key)))
        #endif
            if (unlikely(!PyUnicode_Check(key)))
                goto invalid_keyword_type;
    }
    if ((!kw_allowed) && unlikely(key))
        goto invalid_keyword;
    return 1;
invalid_keyword_type:
    PyErr_Format(PyExc_TypeError,
        "%.200s() keywords must be strings", function_name);
    return 0;
#endif
invalid_keyword:
    PyErr_Format(PyExc_TypeError,
    #if PY_MAJOR_VERSION < 3
        "%.200s() got an unexpected keyword argument '%.200s'",
        function_name, PyString_AsString(key));
    #else
        "%s() got an unexpected keyword argument '%U'",
        function_name, key);
    #endif
    return 0;
}

/* ArgTypeTest */
          static void __Pyx_RaiseArgumentTypeInvalid(const char* name, PyObject *obj, PyTypeObject *type) {
    PyErr_Format(PyExc_TypeError,
        "Argument '%.200s' has incorrect type (expected %.200s, got %.200s)",
        name, type->tp_name, Py_TYPE(obj)->tp_name);
}
static CYTHON_INLINE int __Pyx_ArgTypeTest(PyObject *obj, PyTypeObject *type, int none_allowed,
    const char *name, int exact)
{
    if (unlikely(!type)) {
        PyErr_SetString(PyExc_SystemError, "Missing type object");
        return 0;
    }
    if (none_allowed && obj == Py_None) return 1;
    else if (exact) {
        if (likely(Py_TYPE(obj) == type)) return 1;
        #if PY_MAJOR_VERSION == 2
        else if ((type == &PyBaseString_Type) && likely(__Pyx_PyBaseString_CheckExact(obj))) return 1;
        #endif
    }
    else {
        if (likely(PyObject_TypeCheck(obj, type))) return 1;
    }
    __Pyx_RaiseArgumentTypeInvalid(name, obj, type);
    return 0;
}

/* BytesEquals */
          static CYTHON_INLINE int __Pyx_PyBytes_Equals(PyObject* s1, PyObject* s2, int equals) {
#if CYTHON_COMPILING_IN_PYPY
    return PyObject_RichCompareBool(s1, s2, equals);
#else
    if (s1 == s2) {
        return (equals == Py_EQ);
    } else if (PyBytes_CheckExact(s1) & PyBytes_CheckExact(s2)) {
        const char *ps1, *ps2;
        Py_ssize_t length = PyBytes_GET_SIZE(s1);
        if (length != PyBytes_GET_SIZE(s2))
            return (equals == Py_NE);
        ps1 = PyBytes_AS_STRING(s1);
        ps2 = PyBytes_AS_STRING(s2);
        if (ps1[0] != ps2[0]) {
            return (equals == Py_NE);
        } else if (length == 1) {
            return (equals == Py_EQ);
        } else {
            int result = memcmp(ps1, ps2, (size_t)length);
            return (equals == Py_EQ) ? (result == 0) : (result != 0);
        }
    } else if ((s1 == Py_None) & PyBytes_CheckExact(s2)) {
        return (equals == Py_NE);
    } else if ((s2 == Py_None) & PyBytes_CheckExact(s1)) {
        return (equals == Py_NE);
    } else {
        int result;
        PyObject* py_result = PyObject_RichCompare(s1, s2, equals);
        if (!py_result)
            return -1;
        result = __Pyx_PyObject_IsTrue(py_result);
        Py_DECREF(py_result);
        return result;
    }
#endif
}

/* UnicodeEquals */
          static CYTHON_INLINE int __Pyx_PyUnicode_Equals(PyObject* s1, PyObject* s2, int equals) {
#if CYTHON_COMPILING_IN_PYPY
    return PyObject_RichCompareBool(s1, s2, equals);
#else
#if PY_MAJOR_VERSION < 3
    PyObject* owned_ref = NULL;
#endif
    int s1_is_unicode, s2_is_unicode;
    if (s1 == s2) {
        goto return_eq;
    }
    s1_is_unicode = PyUnicode_CheckExact(s1);
    s2_is_unicode = PyUnicode_CheckExact(s2);
#if PY_MAJOR_VERSION < 3
    if ((s1_is_unicode & (!s2_is_unicode)) && PyString_CheckExact(s2)) {
        owned_ref = PyUnicode_FromObject(s2);
        if (unlikely(!owned_ref))
            return -1;
        s2 = owned_ref;
        s2_is_unicode = 1;
    } else if ((s2_is_unicode & (!s1_is_unicode)) && PyString_CheckExact(s1)) {
        owned_ref = PyUnicode_FromObject(s1);
        if (unlikely(!owned_ref))
            return -1;
        s1 = owned_ref;
        s1_is_unicode = 1;
    } else if (((!s2_is_unicode) & (!s1_is_unicode))) {
        return __Pyx_PyBytes_Equals(s1, s2, equals);
    }
#endif
    if (s1_is_unicode & s2_is_unicode) {
        Py_ssize_t length;
        int kind;
        void *data1, *data2;
        if (unlikely(__Pyx_PyUnicode_READY(s1) < 0) || unlikely(__Pyx_PyUnicode_READY(s2) < 0))
            return -1;
        length = __Pyx_PyUnicode_GET_LENGTH(s1);
        if (length != __Pyx_PyUnicode_GET_LENGTH(s2)) {
            goto return_ne;
        }
        kind = __Pyx_PyUnicode_KIND(s1);
        if (kind != __Pyx_PyUnicode_KIND(s2)) {
            goto return_ne;
        }
        data1 = __Pyx_PyUnicode_DATA(s1);
        data2 = __Pyx_PyUnicode_DATA(s2);
        if (__Pyx_PyUnicode_READ(kind, data1, 0) != __Pyx_PyUnicode_READ(kind, data2, 0)) {
            goto return_ne;
        } else if (length == 1) {
            goto return_eq;
        } else {
            int result = memcmp(data1, data2, (size_t)(length * kind));
            #if PY_MAJOR_VERSION < 3
            Py_XDECREF(owned_ref);
            #endif
            return (equals == Py_EQ) ? (result == 0) : (result != 0);
        }
    } else if ((s1 == Py_None) & s2_is_unicode) {
        goto return_ne;
    } else if ((s2 == Py_None) & s1_is_unicode) {
        goto return_ne;
    } else {
        int result;
        PyObject* py_result = PyObject_RichCompare(s1, s2, equals);
        if (!py_result)
            return -1;
        result = __Pyx_PyObject_IsTrue(py_result);
        Py_DECREF(py_result);
        return result;
    }
return_eq:
    #if PY_MAJOR_VERSION < 3
    Py_XDECREF(owned_ref);
    #endif
    return (equals == Py_EQ);
return_ne:
    #if PY_MAJOR_VERSION < 3
    Py_XDECREF(owned_ref);
    #endif
    return (equals == Py_NE);
#endif
}

/* BufferFormatCheck */
          static CYTHON_INLINE int __Pyx_IsLittleEndian(void) {
  unsigned int n = 1;
  return *(unsigned char*)(&n) != 0;
}
static void __Pyx_BufFmt_Init(__Pyx_BufFmt_Context* ctx,
                              __Pyx_BufFmt_StackElem* stack,
                              __Pyx_TypeInfo* type) {
  stack[0].field = &ctx->root;
  stack[0].parent_offset = 0;
  ctx->root.type = type;
  ctx->root.name = "buffer dtype";
  ctx->root.offset = 0;
  ctx->head = stack;
  ctx->head->field = &ctx->root;
  ctx->fmt_offset = 0;
  ctx->head->parent_offset = 0;
  ctx->new_packmode = '@';
  ctx->enc_packmode = '@';
  ctx->new_count = 1;
  ctx->enc_count = 0;
  ctx->enc_type = 0;
  ctx->is_complex = 0;
  ctx->is_valid_array = 0;
  ctx->struct_alignment = 0;
  while (type->typegroup == 'S') {
    ++ctx->head;
    ctx->head->field = type->fields;
    ctx->head->parent_offset = 0;
    type = type->fields->type;
  }
}
static int __Pyx_BufFmt_ParseNumber(const char** ts) {
    int count;
    const char* t = *ts;
    if (*t < '0' || *t > '9') {
      return -1;
    } else {
        count = *t++ - '0';
        while (*t >= '0' && *t < '9') {
            count *= 10;
            count += *t++ - '0';
        }
    }
    *ts = t;
    return count;
}
static int __Pyx_BufFmt_ExpectNumber(const char **ts) {
    int number = __Pyx_BufFmt_ParseNumber(ts);
    if (number == -1)
        PyErr_Format(PyExc_ValueError,\
                     "Does not understand character buffer dtype format string ('%c')", **ts);
    return number;
}
static void __Pyx_BufFmt_RaiseUnexpectedChar(char ch) {
  PyErr_Format(PyExc_ValueError,
               "Unexpected format string character: '%c'", ch);
}
static const char* __Pyx_BufFmt_DescribeTypeChar(char ch, int is_complex) {
  switch (ch) {
    case 'c': return "'char'";
    case 'b': return "'signed char'";
    case 'B': return "'unsigned char'";
    case 'h': return "'short'";
    case 'H': return "'unsigned short'";
    case 'i': return "'int'";
    case 'I': return "'unsigned int'";
    case 'l': return "'long'";
    case 'L': return "'unsigned long'";
    case 'q': return "'long long'";
    case 'Q': return "'unsigned long long'";
    case 'f': return (is_complex ? "'complex float'" : "'float'");
    case 'd': return (is_complex ? "'complex double'" : "'double'");
    case 'g': return (is_complex ? "'complex long double'" : "'long double'");
    case 'T': return "a struct";
    case 'O': return "Python object";
    case 'P': return "a pointer";
    case 's': case 'p': return "a string";
    case 0: return "end";
    default: return "unparseable format string";
  }
}
static size_t __Pyx_BufFmt_TypeCharToStandardSize(char ch, int is_complex) {
  switch (ch) {
    case '?': case 'c': case 'b': case 'B': case 's': case 'p': return 1;
    case 'h': case 'H': return 2;
    case 'i': case 'I': case 'l': case 'L': return 4;
    case 'q': case 'Q': return 8;
    case 'f': return (is_complex ? 8 : 4);
    case 'd': return (is_complex ? 16 : 8);
    case 'g': {
      PyErr_SetString(PyExc_ValueError, "Python does not define a standard format string size for long double ('g')..");
      return 0;
    }
    case 'O': case 'P': return sizeof(void*);
    default:
      __Pyx_BufFmt_RaiseUnexpectedChar(ch);
      return 0;
    }
}
static size_t __Pyx_BufFmt_TypeCharToNativeSize(char ch, int is_complex) {
  switch (ch) {
    case 'c': case 'b': case 'B': case 's': case 'p': return 1;
    case 'h': case 'H': return sizeof(short);
    case 'i': case 'I': return sizeof(int);
    case 'l': case 'L': return sizeof(long);
    #ifdef HAVE_LONG_LONG
    case 'q': case 'Q': return sizeof(PY_LONG_LONG);
    #endif
    case 'f': return sizeof(float) * (is_complex ? 2 : 1);
    case 'd': return sizeof(double) * (is_complex ? 2 : 1);
    case 'g': return sizeof(long double) * (is_complex ? 2 : 1);
    case 'O': case 'P': return sizeof(void*);
    default: {
      __Pyx_BufFmt_RaiseUnexpectedChar(ch);
      return 0;
    }
  }
}
typedef struct { char c; short x; } __Pyx_st_short;
typedef struct { char c; int x; } __Pyx_st_int;
typedef struct { char c; long x; } __Pyx_st_long;
typedef struct { char c; float x; } __Pyx_st_float;
typedef struct { char c; double x; } __Pyx_st_double;
typedef struct { char c; long double x; } __Pyx_st_longdouble;
typedef struct { char c; void *x; } __Pyx_st_void_p;
#ifdef HAVE_LONG_LONG
typedef struct { char c; PY_LONG_LONG x; } __Pyx_st_longlong;
#endif
static size_t __Pyx_BufFmt_TypeCharToAlignment(char ch, CYTHON_UNUSED int is_complex) {
  switch (ch) {
    case '?': case 'c': case 'b': case 'B': case 's': case 'p': return 1;
    case 'h': case 'H': return sizeof(__Pyx_st_short) - sizeof(short);
    case 'i': case 'I': return sizeof(__Pyx_st_int) - sizeof(int);
    case 'l': case 'L': return sizeof(__Pyx_st_long) - sizeof(long);
#ifdef HAVE_LONG_LONG
    case 'q': case 'Q': return sizeof(__Pyx_st_longlong) - sizeof(PY_LONG_LONG);
#endif
    case 'f': return sizeof(__Pyx_st_float) - sizeof(float);
    case 'd': return sizeof(__Pyx_st_double) - sizeof(double);
    case 'g': return sizeof(__Pyx_st_longdouble) - sizeof(long double);
    case 'P': case 'O': return sizeof(__Pyx_st_void_p) - sizeof(void*);
    default:
      __Pyx_BufFmt_RaiseUnexpectedChar(ch);
      return 0;
    }
}
/* These are for computing the padding at the end of the struct to align
   on the first member of the struct. This will probably the same as above,
   but we don't have any guarantees.
 */
typedef struct { short x; char c; } __Pyx_pad_short;
typedef struct { int x; char c; } __Pyx_pad_int;
typedef struct { long x; char c; } __Pyx_pad_long;
typedef struct { float x; char c; } __Pyx_pad_float;
typedef struct { double x; char c; } __Pyx_pad_double;
typedef struct { long double x; char c; } __Pyx_pad_longdouble;
typedef struct { void *x; char c; } __Pyx_pad_void_p;
#ifdef HAVE_LONG_LONG
typedef struct { PY_LONG_LONG x; char c; } __Pyx_pad_longlong;
#endif
static size_t __Pyx_BufFmt_TypeCharToPadding(char ch, CYTHON_UNUSED int is_complex) {
  switch (ch) {
    case '?': case 'c': case 'b': case 'B': case 's': case 'p': return 1;
    case 'h': case 'H': return sizeof(__Pyx_pad_short) - sizeof(short);
    case 'i': case 'I': return sizeof(__Pyx_pad_int) - sizeof(int);
    case 'l': case 'L': return sizeof(__Pyx_pad_long) - sizeof(long);
#ifdef HAVE_LONG_LONG
    case 'q': case 'Q': return sizeof(__Pyx_pad_longlong) - sizeof(PY_LONG_LONG);
#endif
    case 'f': return sizeof(__Pyx_pad_float) - sizeof(float);
    case 'd': return sizeof(__Pyx_pad_double) - sizeof(double);
    case 'g': return sizeof(__Pyx_pad_longdouble) - sizeof(long double);
    case 'P': case 'O': return sizeof(__Pyx_pad_void_p) - sizeof(void*);
    default:
      __Pyx_BufFmt_RaiseUnexpectedChar(ch);
      return 0;
    }
}
static char __Pyx_BufFmt_TypeCharToGroup(char ch, int is_complex) {
  switch (ch) {
    case 'c':
        return 'H';
    case 'b': case 'h': case 'i':
    case 'l': case 'q': case 's': case 'p':
        return 'I';
    case 'B': case 'H': case 'I': case 'L': case 'Q':
        return 'U';
    case 'f': case 'd': case 'g':
        return (is_complex ? 'C' : 'R');
    case 'O':
        return 'O';
    case 'P':
        return 'P';
    default: {
      __Pyx_BufFmt_RaiseUnexpectedChar(ch);
      return 0;
    }
  }
}
static void __Pyx_BufFmt_RaiseExpected(__Pyx_BufFmt_Context* ctx) {
  if (ctx->head == NULL || ctx->head->field == &ctx->root) {
    const char* expected;
    const char* quote;
    if (ctx->head == NULL) {
      expected = "end";
      quote = "";
    } else {
      expected = ctx->head->field->type->name;
      quote = "'";
    }
    PyErr_Format(PyExc_ValueError,
                 "Buffer dtype mismatch, expected %s%s%s but got %s",
                 quote, expected, quote,
                 __Pyx_BufFmt_DescribeTypeChar(ctx->enc_type, ctx->is_complex));
  } else {
    __Pyx_StructField* field = ctx->head->field;
    __Pyx_StructField* parent = (ctx->head - 1)->field;
    PyErr_Format(PyExc_ValueError,
                 "Buffer dtype mismatch, expected '%s' but got %s in '%s.%s'",
                 field->type->name, __Pyx_BufFmt_DescribeTypeChar(ctx->enc_type, ctx->is_complex),
                 parent->type->name, field->name);
  }
}
static int __Pyx_BufFmt_ProcessTypeChunk(__Pyx_BufFmt_Context* ctx) {
  char group;
  size_t size, offset, arraysize = 1;
  if (ctx->enc_type == 0) return 0;
  if (ctx->head->field->type->arraysize[0]) {
    int i, ndim = 0;
    if (ctx->enc_type == 's' || ctx->enc_type == 'p') {
        ctx->is_valid_array = ctx->head->field->type->ndim == 1;
        ndim = 1;
        if (ctx->enc_count != ctx->head->field->type->arraysize[0]) {
            PyErr_Format(PyExc_ValueError,
                         "Expected a dimension of size %zu, got %zu",
                         ctx->head->field->type->arraysize[0], ctx->enc_count);
            return -1;
        }
    }
    if (!ctx->is_valid_array) {
      PyErr_Format(PyExc_ValueError, "Expected %d dimensions, got %d",
                   ctx->head->field->type->ndim, ndim);
      return -1;
    }
    for (i = 0; i < ctx->head->field->type->ndim; i++) {
      arraysize *= ctx->head->field->type->arraysize[i];
    }
    ctx->is_valid_array = 0;
    ctx->enc_count = 1;
  }
  group = __Pyx_BufFmt_TypeCharToGroup(ctx->enc_type, ctx->is_complex);
  do {
    __Pyx_StructField* field = ctx->head->field;
    __Pyx_TypeInfo* type = field->type;
    if (ctx->enc_packmode == '@' || ctx->enc_packmode == '^') {
      size = __Pyx_BufFmt_TypeCharToNativeSize(ctx->enc_type, ctx->is_complex);
    } else {
      size = __Pyx_BufFmt_TypeCharToStandardSize(ctx->enc_type, ctx->is_complex);
    }
    if (ctx->enc_packmode == '@') {
      size_t align_at = __Pyx_BufFmt_TypeCharToAlignment(ctx->enc_type, ctx->is_complex);
      size_t align_mod_offset;
      if (align_at == 0) return -1;
      align_mod_offset = ctx->fmt_offset % align_at;
      if (align_mod_offset > 0) ctx->fmt_offset += align_at - align_mod_offset;
      if (ctx->struct_alignment == 0)
          ctx->struct_alignment = __Pyx_BufFmt_TypeCharToPadding(ctx->enc_type,
                                                                 ctx->is_complex);
    }
    if (type->size != size || type->typegroup != group) {
      if (type->typegroup == 'C' && type->fields != NULL) {
        size_t parent_offset = ctx->head->parent_offset + field->offset;
        ++ctx->head;
        ctx->head->field = type->fields;
        ctx->head->parent_offset = parent_offset;
        continue;
      }
      if ((type->typegroup == 'H' || group == 'H') && type->size == size) {
      } else {
          __Pyx_BufFmt_RaiseExpected(ctx);
          return -1;
      }
    }
    offset = ctx->head->parent_offset + field->offset;
    if (ctx->fmt_offset != offset) {
      PyErr_Format(PyExc_ValueError,
                   "Buffer dtype mismatch; next field is at offset %" CYTHON_FORMAT_SSIZE_T "d but %" CYTHON_FORMAT_SSIZE_T "d expected",
                   (Py_ssize_t)ctx->fmt_offset, (Py_ssize_t)offset);
      return -1;
    }
    ctx->fmt_offset += size;
    if (arraysize)
      ctx->fmt_offset += (arraysize - 1) * size;
    --ctx->enc_count;
    while (1) {
      if (field == &ctx->root) {
        ctx->head = NULL;
        if (ctx->enc_count != 0) {
          __Pyx_BufFmt_RaiseExpected(ctx);
          return -1;
        }
        break;
      }
      ctx->head->field = ++field;
      if (field->type == NULL) {
        --ctx->head;
        field = ctx->head->field;
        continue;
      } else if (field->type->typegroup == 'S') {
        size_t parent_offset = ctx->head->parent_offset + field->offset;
        if (field->type->fields->type == NULL) continue;
        field = field->type->fields;
        ++ctx->head;
        ctx->head->field = field;
        ctx->head->parent_offset = parent_offset;
        break;
      } else {
        break;
      }
    }
  } while (ctx->enc_count);
  ctx->enc_type = 0;
  ctx->is_complex = 0;
  return 0;
}
static CYTHON_INLINE PyObject *
__pyx_buffmt_parse_array(__Pyx_BufFmt_Context* ctx, const char** tsp)
{
    const char *ts = *tsp;
    int i = 0, number;
    int ndim = ctx->head->field->type->ndim;
;
    ++ts;
    if (ctx->new_count != 1) {
        PyErr_SetString(PyExc_ValueError,
                        "Cannot handle repeated arrays in format string");
        return NULL;
    }
    if (__Pyx_BufFmt_ProcessTypeChunk(ctx) == -1) return NULL;
    while (*ts && *ts != ')') {
        switch (*ts) {
            case ' ': case '\f': case '\r': case '\n': case '\t': case '\v':  continue;
            default:  break;
        }
        number = __Pyx_BufFmt_ExpectNumber(&ts);
        if (number == -1) return NULL;
        if (i < ndim && (size_t) number != ctx->head->field->type->arraysize[i])
            return PyErr_Format(PyExc_ValueError,
                        "Expected a dimension of size %zu, got %d",
                        ctx->head->field->type->arraysize[i], number);
        if (*ts != ',' && *ts != ')')
            return PyErr_Format(PyExc_ValueError,
                                "Expected a comma in format string, got '%c'", *ts);
        if (*ts == ',') ts++;
        i++;
    }
    if (i != ndim)
        return PyErr_Format(PyExc_ValueError, "Expected %d dimension(s), got %d",
                            ctx->head->field->type->ndim, i);
    if (!*ts) {
        PyErr_SetString(PyExc_ValueError,
                        "Unexpected end of format string, expected ')'");
        return NULL;
    }
    ctx->is_valid_array = 1;
    ctx->new_count = 1;
    *tsp = ++ts;
    return Py_None;
}
static const char* __Pyx_BufFmt_CheckString(__Pyx_BufFmt_Context* ctx, const char* ts) {
  int got_Z = 0;
  while (1) {
    switch(*ts) {
      case 0:
        if (ctx->enc_type != 0 && ctx->head == NULL) {
          __Pyx_BufFmt_RaiseExpected(ctx);
          return NULL;
        }
        if (__Pyx_BufFmt_ProcessTypeChunk(ctx) == -1) return NULL;
        if (ctx->head != NULL) {
          __Pyx_BufFmt_RaiseExpected(ctx);
          return NULL;
        }
        return ts;
      case ' ':
      case '\r':
      case '\n':
        ++ts;
        break;
      case '<':
        if (!__Pyx_IsLittleEndian()) {
          PyErr_SetString(PyExc_ValueError, "Little-endian buffer not supported on big-endian compiler");
          return NULL;
        }
        ctx->new_packmode = '=';
        ++ts;
        break;
      case '>':
      case '!':
        if (__Pyx_IsLittleEndian()) {
          PyErr_SetString(PyExc_ValueError, "Big-endian buffer not supported on little-endian compiler");
          return NULL;
        }
        ctx->new_packmode = '=';
        ++ts;
        break;
      case '=':
      case '@':
      case '^':
        ctx->new_packmode = *ts++;
        break;
      case 'T':
        {
          const char* ts_after_sub;
          size_t i, struct_count = ctx->new_count;
          size_t struct_alignment = ctx->struct_alignment;
          ctx->new_count = 1;
          ++ts;
          if (*ts != '{') {
            PyErr_SetString(PyExc_ValueError, "Buffer acquisition: Expected '{' after 'T'");
            return NULL;
          }
          if (__Pyx_BufFmt_ProcessTypeChunk(ctx) == -1) return NULL;
          ctx->enc_type = 0;
          ctx->enc_count = 0;
          ctx->struct_alignment = 0;
          ++ts;
          ts_after_sub = ts;
          for (i = 0; i != struct_count; ++i) {
            ts_after_sub = __Pyx_BufFmt_CheckString(ctx, ts);
            if (!ts_after_sub) return NULL;
          }
          ts = ts_after_sub;
          if (struct_alignment) ctx->struct_alignment = struct_alignment;
        }
        break;
      case '}':
        {
          size_t alignment = ctx->struct_alignment;
          ++ts;
          if (__Pyx_BufFmt_ProcessTypeChunk(ctx) == -1) return NULL;
          ctx->enc_type = 0;
          if (alignment && ctx->fmt_offset % alignment) {
            ctx->fmt_offset += alignment - (ctx->fmt_offset % alignment);
          }
        }
        return ts;
      case 'x':
        if (__Pyx_BufFmt_ProcessTypeChunk(ctx) == -1) return NULL;
        ctx->fmt_offset += ctx->new_count;
        ctx->new_count = 1;
        ctx->enc_count = 0;
        ctx->enc_type = 0;
        ctx->enc_packmode = ctx->new_packmode;
        ++ts;
        break;
      case 'Z':
        got_Z = 1;
        ++ts;
        if (*ts != 'f' && *ts != 'd' && *ts != 'g') {
          __Pyx_BufFmt_RaiseUnexpectedChar('Z');
          return NULL;
        }
      case 'c': case 'b': case 'B': case 'h': case 'H': case 'i': case 'I':
      case 'l': case 'L': case 'q': case 'Q':
      case 'f': case 'd': case 'g':
      case 'O': case 'p':
        if (ctx->enc_type == *ts && got_Z == ctx->is_complex &&
            ctx->enc_packmode == ctx->new_packmode) {
          ctx->enc_count += ctx->new_count;
          ctx->new_count = 1;
          got_Z = 0;
          ++ts;
          break;
        }
      case 's':
        if (__Pyx_BufFmt_ProcessTypeChunk(ctx) == -1) return NULL;
        ctx->enc_count = ctx->new_count;
        ctx->enc_packmode = ctx->new_packmode;
        ctx->enc_type = *ts;
        ctx->is_complex = got_Z;
        ++ts;
        ctx->new_count = 1;
        got_Z = 0;
        break;
      case ':':
        ++ts;
        while(*ts != ':') ++ts;
        ++ts;
        break;
      case '(':
        if (!__pyx_buffmt_parse_array(ctx, &ts)) return NULL;
        break;
      default:
        {
          int number = __Pyx_BufFmt_ExpectNumber(&ts);
          if (number == -1) return NULL;
          ctx->new_count = (size_t)number;
        }
    }
  }
}
static CYTHON_INLINE void __Pyx_ZeroBuffer(Py_buffer* buf) {
  buf->buf = NULL;
  buf->obj = NULL;
  buf->strides = __Pyx_zeros;
  buf->shape = __Pyx_zeros;
  buf->suboffsets = __Pyx_minusones;
}
static CYTHON_INLINE int __Pyx_GetBufferAndValidate(
        Py_buffer* buf, PyObject* obj,  __Pyx_TypeInfo* dtype, int flags,
        int nd, int cast, __Pyx_BufFmt_StackElem* stack)
{
  if (obj == Py_None || obj == NULL) {
    __Pyx_ZeroBuffer(buf);
    return 0;
  }
  buf->buf = NULL;
  if (__Pyx_GetBuffer(obj, buf, flags) == -1) goto fail;
  if (buf->ndim != nd) {
    PyErr_Format(PyExc_ValueError,
                 "Buffer has wrong number of dimensions (expected %d, got %d)",
                 nd, buf->ndim);
    goto fail;
  }
  if (!cast) {
    __Pyx_BufFmt_Context ctx;
    __Pyx_BufFmt_Init(&ctx, stack, dtype);
    if (!__Pyx_BufFmt_CheckString(&ctx, buf->format)) goto fail;
  }
  if ((unsigned)buf->itemsize != dtype->size) {
    PyErr_Format(PyExc_ValueError,
      "Item size of buffer (%" CYTHON_FORMAT_SSIZE_T "d byte%s) does not match size of '%s' (%" CYTHON_FORMAT_SSIZE_T "d byte%s)",
      buf->itemsize, (buf->itemsize > 1) ? "s" : "",
      dtype->name, (Py_ssize_t)dtype->size, (dtype->size > 1) ? "s" : "");
    goto fail;
  }
  if (buf->suboffsets == NULL) buf->suboffsets = __Pyx_minusones;
  return 0;
fail:;
  __Pyx_ZeroBuffer(buf);
  return -1;
}
static CYTHON_INLINE void __Pyx_SafeReleaseBuffer(Py_buffer* info) {
  if (info->buf == NULL) return;
  if (info->suboffsets == __Pyx_minusones) info->suboffsets = NULL;
  __Pyx_ReleaseBuffer(info);
}

/* MemviewSliceInit */
            static int
__Pyx_init_memviewslice(struct __pyx_memoryview_obj *memview,
                        int ndim,
                        __Pyx_memviewslice *memviewslice,
                        int memview_is_new_reference)
{
    __Pyx_RefNannyDeclarations
    int i, retval=-1;
    Py_buffer *buf = &memview->view;
    __Pyx_RefNannySetupContext("init_memviewslice", 0);
    if (!buf) {
        PyErr_SetString(PyExc_ValueError,
            "buf is NULL.");
        goto fail;
    } else if (memviewslice->memview || memviewslice->data) {
        PyErr_SetString(PyExc_ValueError,
            "memviewslice is already initialized!");
        goto fail;
    }
    if (buf->strides) {
        for (i = 0; i < ndim; i++) {
            memviewslice->strides[i] = buf->strides[i];
        }
    } else {
        Py_ssize_t stride = buf->itemsize;
        for (i = ndim - 1; i >= 0; i--) {
            memviewslice->strides[i] = stride;
            stride *= buf->shape[i];
        }
    }
    for (i = 0; i < ndim; i++) {
        memviewslice->shape[i]   = buf->shape[i];
        if (buf->suboffsets) {
            memviewslice->suboffsets[i] = buf->suboffsets[i];
        } else {
            memviewslice->suboffsets[i] = -1;
        }
    }
    memviewslice->memview = memview;
    memviewslice->data = (char *)buf->buf;
    if (__pyx_add_acquisition_count(memview) == 0 && !memview_is_new_reference) {
        Py_INCREF(memview);
    }
    retval = 0;
    goto no_fail;
fail:
    memviewslice->memview = 0;
    memviewslice->data = 0;
    retval = -1;
no_fail:
    __Pyx_RefNannyFinishContext();
    return retval;
}
static CYTHON_INLINE void __pyx_fatalerror(const char *fmt, ...) {
    va_list vargs;
    char msg[200];
#ifdef HAVE_STDARG_PROTOTYPES
    va_start(vargs, fmt);
#else
    va_start(vargs);
#endif
    vsnprintf(msg, 200, fmt, vargs);
    Py_FatalError(msg);
    va_end(vargs);
}
static CYTHON_INLINE int
__pyx_add_acquisition_count_locked(__pyx_atomic_int *acquisition_count,
                                   PyThread_type_lock lock)
{
    int result;
    PyThread_acquire_lock(lock, 1);
    result = (*acquisition_count)++;
    PyThread_release_lock(lock);
    return result;
}
static CYTHON_INLINE int
__pyx_sub_acquisition_count_locked(__pyx_atomic_int *acquisition_count,
                                   PyThread_type_lock lock)
{
    int result;
    PyThread_acquire_lock(lock, 1);
    result = (*acquisition_count)--;
    PyThread_release_lock(lock);
    return result;
}
static CYTHON_INLINE void
__Pyx_INC_MEMVIEW(__Pyx_memviewslice *memslice, int have_gil, int lineno)
{
    int first_time;
    struct __pyx_memoryview_obj *memview = memslice->memview;
    if (!memview || (PyObject *) memview == Py_None)
        return;
    if (__pyx_get_slice_count(memview) < 0)
        __pyx_fatalerror("Acquisition count is %d (line %d)",
                         __pyx_get_slice_count(memview), lineno);
    first_time = __pyx_add_acquisition_count(memview) == 0;
    if (first_time) {
        if (have_gil) {
            Py_INCREF((PyObject *) memview);
        } else {
            PyGILState_STATE _gilstate = PyGILState_Ensure();
            Py_INCREF((PyObject *) memview);
            PyGILState_Release(_gilstate);
        }
    }
}
static CYTHON_INLINE void __Pyx_XDEC_MEMVIEW(__Pyx_memviewslice *memslice,
                                             int have_gil, int lineno) {
    int last_time;
    struct __pyx_memoryview_obj *memview = memslice->memview;
    if (!memview ) {
        return;
    } else if ((PyObject *) memview == Py_None) {
        memslice->memview = NULL;
        return;
    }
    if (__pyx_get_slice_count(memview) <= 0)
        __pyx_fatalerror("Acquisition count is %d (line %d)",
                         __pyx_get_slice_count(memview), lineno);
    last_time = __pyx_sub_acquisition_count(memview) == 1;
    memslice->data = NULL;
    if (last_time) {
        if (have_gil) {
            Py_CLEAR(memslice->memview);
        } else {
            PyGILState_STATE _gilstate = PyGILState_Ensure();
            Py_CLEAR(memslice->memview);
            PyGILState_Release(_gilstate);
        }
    } else {
        memslice->memview = NULL;
    }
}

/* None */
            static CYTHON_INLINE Py_ssize_t __Pyx_div_Py_ssize_t(Py_ssize_t a, Py_ssize_t b) {
    Py_ssize_t q = a / b;
    Py_ssize_t r = a - q*b;
    q -= ((r != 0) & ((r ^ b) < 0));
    return q;
}

/* GetAttr */
            static CYTHON_INLINE PyObject *__Pyx_GetAttr(PyObject *o, PyObject *n) {
#if CYTHON_COMPILING_IN_CPYTHON
#if PY_MAJOR_VERSION >= 3
    if (likely(PyUnicode_Check(n)))
#else
    if (likely(PyString_Check(n)))
#endif
        return __Pyx_PyObject_GetAttrStr(o, n);
#endif
    return PyObject_GetAttr(o, n);
}

/* decode_c_string */
            static CYTHON_INLINE PyObject* __Pyx_decode_c_string(
         const char* cstring, Py_ssize_t start, Py_ssize_t stop,
         const char* encoding, const char* errors,
         PyObject* (*decode_func)(const char *s, Py_ssize_t size, const char *errors)) {
    Py_ssize_t length;
    if (unlikely((start < 0) | (stop < 0))) {
        size_t slen = strlen(cstring);
        if (unlikely(slen > (size_t) PY_SSIZE_T_MAX)) {
            PyErr_SetString(PyExc_OverflowError,
                            "c-string too long to convert to Python");
            return NULL;
        }
        length = (Py_ssize_t) slen;
        if (start < 0) {
            start += length;
            if (start < 0)
                start = 0;
        }
        if (stop < 0)
            stop += length;
    }
    length = stop - start;
    if (unlikely(length <= 0))
        return PyUnicode_FromUnicode(NULL, 0);
    cstring += start;
    if (decode_func) {
        return decode_func(cstring, length, errors);
    } else {
        return PyUnicode_Decode(cstring, length, encoding, errors);
    }
}

/* RaiseTooManyValuesToUnpack */
            static CYTHON_INLINE void __Pyx_RaiseTooManyValuesError(Py_ssize_t expected) {
    PyErr_Format(PyExc_ValueError,
                 "too many values to unpack (expected %" CYTHON_FORMAT_SSIZE_T "d)", expected);
}

/* RaiseNeedMoreValuesToUnpack */
            static CYTHON_INLINE void __Pyx_RaiseNeedMoreValuesError(Py_ssize_t index) {
    PyErr_Format(PyExc_ValueError,
                 "need more than %" CYTHON_FORMAT_SSIZE_T "d value%.1s to unpack",
                 index, (index == 1) ? "" : "s");
}

/* RaiseNoneIterError */
            static CYTHON_INLINE void __Pyx_RaiseNoneNotIterableError(void) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not iterable");
}

/* SaveResetException */
            #if CYTHON_FAST_THREAD_STATE
static CYTHON_INLINE void __Pyx__ExceptionSave(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb) {
    *type = tstate->exc_type;
    *value = tstate->exc_value;
    *tb = tstate->exc_traceback;
    Py_XINCREF(*type);
    Py_XINCREF(*value);
    Py_XINCREF(*tb);
}
static CYTHON_INLINE void __Pyx__ExceptionReset(PyThreadState *tstate, PyObject *type, PyObject *value, PyObject *tb) {
    PyObject *tmp_type, *tmp_value, *tmp_tb;
    tmp_type = tstate->exc_type;
    tmp_value = tstate->exc_value;
    tmp_tb = tstate->exc_traceback;
    tstate->exc_type = type;
    tstate->exc_value = value;
    tstate->exc_traceback = tb;
    Py_XDECREF(tmp_type);
    Py_XDECREF(tmp_value);
    Py_XDECREF(tmp_tb);
}
#endif

/* PyErrExceptionMatches */
            #if CYTHON_FAST_THREAD_STATE
static CYTHON_INLINE int __Pyx_PyErr_ExceptionMatchesInState(PyThreadState* tstate, PyObject* err) {
    PyObject *exc_type = tstate->curexc_type;
    if (exc_type == err) return 1;
    if (unlikely(!exc_type)) return 0;
    return PyErr_GivenExceptionMatches(exc_type, err);
}
#endif

/* GetException */
            #if CYTHON_FAST_THREAD_STATE
static int __Pyx__GetException(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb) {
#else
static int __Pyx_GetException(PyObject **type, PyObject **value, PyObject **tb) {
#endif
    PyObject *local_type, *local_value, *local_tb;
#if CYTHON_FAST_THREAD_STATE
    PyObject *tmp_type, *tmp_value, *tmp_tb;
    local_type = tstate->curexc_type;
    local_value = tstate->curexc_value;
    local_tb = tstate->curexc_traceback;
    tstate->curexc_type = 0;
    tstate->curexc_value = 0;
    tstate->curexc_traceback = 0;
#else
    PyErr_Fetch(&local_type, &local_value, &local_tb);
#endif
    PyErr_NormalizeException(&local_type, &local_value, &local_tb);
#if CYTHON_FAST_THREAD_STATE
    if (unlikely(tstate->curexc_type))
#else
    if (unlikely(PyErr_Occurred()))
#endif
        goto bad;
    #if PY_MAJOR_VERSION >= 3
    if (local_tb) {
        if (unlikely(PyException_SetTraceback(local_value, local_tb) < 0))
            goto bad;
    }
    #endif
    Py_XINCREF(local_tb);
    Py_XINCREF(local_type);
    Py_XINCREF(local_value);
    *type = local_type;
    *value = local_value;
    *tb = local_tb;
#if CYTHON_FAST_THREAD_STATE
    tmp_type = tstate->exc_type;
    tmp_value = tstate->exc_value;
    tmp_tb = tstate->exc_traceback;
    tstate->exc_type = local_type;
    tstate->exc_value = local_value;
    tstate->exc_traceback = local_tb;
    Py_XDECREF(tmp_type);
    Py_XDECREF(tmp_value);
    Py_XDECREF(tmp_tb);
#else
    PyErr_SetExcInfo(local_type, local_value, local_tb);
#endif
    return 0;
bad:
    *type = 0;
    *value = 0;
    *tb = 0;
    Py_XDECREF(local_type);
    Py_XDECREF(local_value);
    Py_XDECREF(local_tb);
    return -1;
}

/* SwapException */
              #if CYTHON_FAST_THREAD_STATE
static CYTHON_INLINE void __Pyx__ExceptionSwap(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb) {
    PyObject *tmp_type, *tmp_value, *tmp_tb;
    tmp_type = tstate->exc_type;
    tmp_value = tstate->exc_value;
    tmp_tb = tstate->exc_traceback;
    tstate->exc_type = *type;
    tstate->exc_value = *value;
    tstate->exc_traceback = *tb;
    *type = tmp_type;
    *value = tmp_value;
    *tb = tmp_tb;
}
#else
static CYTHON_INLINE void __Pyx_ExceptionSwap(PyObject **type, PyObject **value, PyObject **tb) {
    PyObject *tmp_type, *tmp_value, *tmp_tb;
    PyErr_GetExcInfo(&tmp_type, &tmp_value, &tmp_tb);
    PyErr_SetExcInfo(*type, *value, *tb);
    *type = tmp_type;
    *value = tmp_value;
    *tb = tmp_tb;
}
#endif

/* Import */
              static PyObject *__Pyx_Import(PyObject *name, PyObject *from_list, int level) {
    PyObject *empty_list = 0;
    PyObject *module = 0;
    PyObject *global_dict = 0;
    PyObject *empty_dict = 0;
    PyObject *list;
    #if PY_VERSION_HEX < 0x03030000
    PyObject *py_import;
    py_import = __Pyx_PyObject_GetAttrStr(__pyx_b, __pyx_n_s_import);
    if (!py_import)
        goto bad;
    #endif
    if (from_list)
        list = from_list;
    else {
        empty_list = PyList_New(0);
        if (!empty_list)
            goto bad;
        list = empty_list;
    }
    global_dict = PyModule_GetDict(__pyx_m);
    if (!global_dict)
        goto bad;
    empty_dict = PyDict_New();
    if (!empty_dict)
        goto bad;
    {
        #if PY_MAJOR_VERSION >= 3
        if (level == -1) {
            if (strchr(__Pyx_MODULE_NAME, '.')) {
                #if PY_VERSION_HEX < 0x03030000
                PyObject *py_level = PyInt_FromLong(1);
                if (!py_level)
                    goto bad;
                module = PyObject_CallFunctionObjArgs(py_import,
                    name, global_dict, empty_dict, list, py_level, NULL);
                Py_DECREF(py_level);
                #else
                module = PyImport_ImportModuleLevelObject(
                    name, global_dict, empty_dict, list, 1);
                #endif
                if (!module) {
                    if (!PyErr_ExceptionMatches(PyExc_ImportError))
                        goto bad;
                    PyErr_Clear();
                }
            }
            level = 0;
        }
        #endif
        if (!module) {
            #if PY_VERSION_HEX < 0x03030000
            PyObject *py_level = PyInt_FromLong(level);
            if (!py_level)
                goto bad;
            module = PyObject_CallFunctionObjArgs(py_import,
                name, global_dict, empty_dict, list, py_level, NULL);
            Py_DECREF(py_level);
            #else
            module = PyImport_ImportModuleLevelObject(
                name, global_dict, empty_dict, list, level);
            #endif
        }
    }
bad:
    #if PY_VERSION_HEX < 0x03030000
    Py_XDECREF(py_import);
    #endif
    Py_XDECREF(empty_list);
    Py_XDECREF(empty_dict);
    return module;
}

/* PyIntBinop */
              #if !CYTHON_COMPILING_IN_PYPY
static PyObject* __Pyx_PyInt_AddObjC(PyObject *op1, PyObject *op2, CYTHON_UNUSED long intval, CYTHON_UNUSED int inplace) {
    #if PY_MAJOR_VERSION < 3
    if (likely(PyInt_CheckExact(op1))) {
        const long b = intval;
        long x;
        long a = PyInt_AS_LONG(op1);
            x = (long)((unsigned long)a + b);
            if (likely((x^a) >= 0 || (x^b) >= 0))
                return PyInt_FromLong(x);
            return PyLong_Type.tp_as_number->nb_add(op1, op2);
    }
    #endif
    #if CYTHON_USE_PYLONG_INTERNALS
    if (likely(PyLong_CheckExact(op1))) {
        const long b = intval;
        long a, x;
#ifdef HAVE_LONG_LONG
        const PY_LONG_LONG llb = intval;
        PY_LONG_LONG lla, llx;
#endif
        const digit* digits = ((PyLongObject*)op1)->ob_digit;
        const Py_ssize_t size = Py_SIZE(op1);
        if (likely(__Pyx_sst_abs(size) <= 1)) {
            a = likely(size) ? digits[0] : 0;
            if (size == -1) a = -a;
        } else {
            switch (size) {
                case -2:
                    if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                        a = -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 2 * PyLong_SHIFT) {
                        lla = -(PY_LONG_LONG) (((((unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case 2:
                    if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                        a = (long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 2 * PyLong_SHIFT) {
                        lla = (PY_LONG_LONG) (((((unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case -3:
                    if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                        a = -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 3 * PyLong_SHIFT) {
                        lla = -(PY_LONG_LONG) (((((((unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case 3:
                    if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                        a = (long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 3 * PyLong_SHIFT) {
                        lla = (PY_LONG_LONG) (((((((unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case -4:
                    if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                        a = -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 4 * PyLong_SHIFT) {
                        lla = -(PY_LONG_LONG) (((((((((unsigned PY_LONG_LONG)digits[3]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case 4:
                    if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                        a = (long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 4 * PyLong_SHIFT) {
                        lla = (PY_LONG_LONG) (((((((((unsigned PY_LONG_LONG)digits[3]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                default: return PyLong_Type.tp_as_number->nb_add(op1, op2);
            }
        }
                x = a + b;
            return PyLong_FromLong(x);
#ifdef HAVE_LONG_LONG
        long_long:
                llx = lla + llb;
            return PyLong_FromLongLong(llx);
#endif
        
        
    }
    #endif
    if (PyFloat_CheckExact(op1)) {
        const long b = intval;
        double a = PyFloat_AS_DOUBLE(op1);
            double result;
            PyFPE_START_PROTECT("add", return NULL)
            result = ((double)a) + (double)b;
            PyFPE_END_PROTECT(result)
            return PyFloat_FromDouble(result);
    }
    return (inplace ? PyNumber_InPlaceAdd : PyNumber_Add)(op1, op2);
}
#endif

/* None */
              static CYTHON_INLINE void __Pyx_RaiseUnboundLocalError(const char *varname) {
    PyErr_Format(PyExc_UnboundLocalError, "local variable '%s' referenced before assignment", varname);
}

/* None */
              static CYTHON_INLINE long __Pyx_div_long(long a, long b) {
    long q = a / b;
    long r = a - q*b;
    q -= ((r != 0) & ((r ^ b) < 0));
    return q;
}

/* SetVTable */
              static int __Pyx_SetVtable(PyObject *dict, void *vtable) {
#if PY_VERSION_HEX >= 0x02070000
    PyObject *ob = PyCapsule_New(vtable, 0, 0);
#else
    PyObject *ob = PyCObject_FromVoidPtr(vtable, 0);
#endif
    if (!ob)
        goto bad;
    if (PyDict_SetItem(dict, __pyx_n_s_pyx_vtable, ob) < 0)
        goto bad;
    Py_DECREF(ob);
    return 0;
bad:
    Py_XDECREF(ob);
    return -1;
}

/* GetVTable */
              static void* __Pyx_GetVtable(PyObject *dict) {
    void* ptr;
    PyObject *ob = PyObject_GetItem(dict, __pyx_n_s_pyx_vtable);
    if (!ob)
        goto bad;
#if PY_VERSION_HEX >= 0x02070000
    ptr = PyCapsule_GetPointer(ob, 0);
#else
    ptr = PyCObject_AsVoidPtr(ob);
#endif
    if (!ptr && !PyErr_Occurred())
        PyErr_SetString(PyExc_RuntimeError, "invalid vtable found for imported type");
    Py_DECREF(ob);
    return ptr;
bad:
    Py_XDECREF(ob);
    return NULL;
}

/* ImportFrom */
              static PyObject* __Pyx_ImportFrom(PyObject* module, PyObject* name) {
    PyObject* value = __Pyx_PyObject_GetAttrStr(module, name);
    if (unlikely(!value) && PyErr_ExceptionMatches(PyExc_AttributeError)) {
        PyErr_Format(PyExc_ImportError,
        #if PY_MAJOR_VERSION < 3
            "cannot import name %.230s", PyString_AS_STRING(name));
        #else
            "cannot import name %S", name);
        #endif
    }
    return value;
}

/* GetNameInClass */
              static PyObject *__Pyx_GetNameInClass(PyObject *nmspace, PyObject *name) {
    PyObject *result;
    result = __Pyx_PyObject_GetAttrStr(nmspace, name);
    if (!result)
        result = __Pyx_GetModuleGlobalName(name);
    return result;
}

/* CodeObjectCache */
              static int __pyx_bisect_code_objects(__Pyx_CodeObjectCacheEntry* entries, int count, int code_line) {
    int start = 0, mid = 0, end = count - 1;
    if (end >= 0 && code_line > entries[end].code_line) {
        return count;
    }
    while (start < end) {
        mid = start + (end - start) / 2;
        if (code_line < entries[mid].code_line) {
            end = mid;
        } else if (code_line > entries[mid].code_line) {
             start = mid + 1;
        } else {
            return mid;
        }
    }
    if (code_line <= entries[mid].code_line) {
        return mid;
    } else {
        return mid + 1;
    }
}
static PyCodeObject *__pyx_find_code_object(int code_line) {
    PyCodeObject* code_object;
    int pos;
    if (unlikely(!code_line) || unlikely(!__pyx_code_cache.entries)) {
        return NULL;
    }
    pos = __pyx_bisect_code_objects(__pyx_code_cache.entries, __pyx_code_cache.count, code_line);
    if (unlikely(pos >= __pyx_code_cache.count) || unlikely(__pyx_code_cache.entries[pos].code_line != code_line)) {
        return NULL;
    }
    code_object = __pyx_code_cache.entries[pos].code_object;
    Py_INCREF(code_object);
    return code_object;
}
static void __pyx_insert_code_object(int code_line, PyCodeObject* code_object) {
    int pos, i;
    __Pyx_CodeObjectCacheEntry* entries = __pyx_code_cache.entries;
    if (unlikely(!code_line)) {
        return;
    }
    if (unlikely(!entries)) {
        entries = (__Pyx_CodeObjectCacheEntry*)PyMem_Malloc(64*sizeof(__Pyx_CodeObjectCacheEntry));
        if (likely(entries)) {
            __pyx_code_cache.entries = entries;
            __pyx_code_cache.max_count = 64;
            __pyx_code_cache.count = 1;
            entries[0].code_line = code_line;
            entries[0].code_object = code_object;
            Py_INCREF(code_object);
        }
        return;
    }
    pos = __pyx_bisect_code_objects(__pyx_code_cache.entries, __pyx_code_cache.count, code_line);
    if ((pos < __pyx_code_cache.count) && unlikely(__pyx_code_cache.entries[pos].code_line == code_line)) {
        PyCodeObject* tmp = entries[pos].code_object;
        entries[pos].code_object = code_object;
        Py_DECREF(tmp);
        return;
    }
    if (__pyx_code_cache.count == __pyx_code_cache.max_count) {
        int new_max = __pyx_code_cache.max_count + 64;
        entries = (__Pyx_CodeObjectCacheEntry*)PyMem_Realloc(
            __pyx_code_cache.entries, (size_t)new_max*sizeof(__Pyx_CodeObjectCacheEntry));
        if (unlikely(!entries)) {
            return;
        }
        __pyx_code_cache.entries = entries;
        __pyx_code_cache.max_count = new_max;
    }
    for (i=__pyx_code_cache.count; i>pos; i--) {
        entries[i] = entries[i-1];
    }
    entries[pos].code_line = code_line;
    entries[pos].code_object = code_object;
    __pyx_code_cache.count++;
    Py_INCREF(code_object);
}

/* AddTraceback */
              #include "compile.h"
#include "frameobject.h"
#include "traceback.h"
static PyCodeObject* __Pyx_CreateCodeObjectForTraceback(
            const char *funcname, int c_line,
            int py_line, const char *filename) {
    PyCodeObject *py_code = 0;
    PyObject *py_srcfile = 0;
    PyObject *py_funcname = 0;
    #if PY_MAJOR_VERSION < 3
    py_srcfile = PyString_FromString(filename);
    #else
    py_srcfile = PyUnicode_FromString(filename);
    #endif
    if (!py_srcfile) goto bad;
    if (c_line) {
        #if PY_MAJOR_VERSION < 3
        py_funcname = PyString_FromFormat( "%s (%s:%d)", funcname, __pyx_cfilenm, c_line);
        #else
        py_funcname = PyUnicode_FromFormat( "%s (%s:%d)", funcname, __pyx_cfilenm, c_line);
        #endif
    }
    else {
        #if PY_MAJOR_VERSION < 3
        py_funcname = PyString_FromString(funcname);
        #else
        py_funcname = PyUnicode_FromString(funcname);
        #endif
    }
    if (!py_funcname) goto bad;
    py_code = __Pyx_PyCode_New(
        0,
        0,
        0,
        0,
        0,
        __pyx_empty_bytes, /*PyObject *code,*/
        __pyx_empty_tuple, /*PyObject *consts,*/
        __pyx_empty_tuple, /*PyObject *names,*/
        __pyx_empty_tuple, /*PyObject *varnames,*/
        __pyx_empty_tuple, /*PyObject *freevars,*/
        __pyx_empty_tuple, /*PyObject *cellvars,*/
        py_srcfile,   /*PyObject *filename,*/
        py_funcname,  /*PyObject *name,*/
        py_line,
        __pyx_empty_bytes  /*PyObject *lnotab*/
    );
    Py_DECREF(py_srcfile);
    Py_DECREF(py_funcname);
    return py_code;
bad:
    Py_XDECREF(py_srcfile);
    Py_XDECREF(py_funcname);
    return NULL;
}
static void __Pyx_AddTraceback(const char *funcname, int c_line,
                               int py_line, const char *filename) {
    PyCodeObject *py_code = 0;
    PyFrameObject *py_frame = 0;
    py_code = __pyx_find_code_object(c_line ? c_line : py_line);
    if (!py_code) {
        py_code = __Pyx_CreateCodeObjectForTraceback(
            funcname, c_line, py_line, filename);
        if (!py_code) goto bad;
        __pyx_insert_code_object(c_line ? c_line : py_line, py_code);
    }
    py_frame = PyFrame_New(
        PyThreadState_GET(), /*PyThreadState *tstate,*/
        py_code,             /*PyCodeObject *code,*/
        __pyx_d,      /*PyObject *globals,*/
        0                    /*PyObject *locals*/
    );
    if (!py_frame) goto bad;
    __Pyx_PyFrame_SetLineNumber(py_frame, py_line);
    PyTraceBack_Here(py_frame);
bad:
    Py_XDECREF(py_code);
    Py_XDECREF(py_frame);
}

#if PY_MAJOR_VERSION < 3
static int __Pyx_GetBuffer(PyObject *obj, Py_buffer *view, int flags) {
    if (PyObject_CheckBuffer(obj)) return PyObject_GetBuffer(obj, view, flags);
        if (PyObject_TypeCheck(obj, __pyx_ptype_7cpython_5array_array)) return __pyx_pw_7cpython_5array_5array_1__getbuffer__(obj, view, flags);
        if (PyObject_TypeCheck(obj, __pyx_array_type)) return __pyx_array_getbuffer(obj, view, flags);
        if (PyObject_TypeCheck(obj, __pyx_memoryview_type)) return __pyx_memoryview_getbuffer(obj, view, flags);
    PyErr_Format(PyExc_TypeError, "'%.200s' does not have the buffer interface", Py_TYPE(obj)->tp_name);
    return -1;
}
static void __Pyx_ReleaseBuffer(Py_buffer *view) {
    PyObject *obj = view->obj;
    if (!obj) return;
    if (PyObject_CheckBuffer(obj)) {
        PyBuffer_Release(view);
        return;
    }
        if (PyObject_TypeCheck(obj, __pyx_ptype_7cpython_5array_array)) { __pyx_pw_7cpython_5array_5array_3__releasebuffer__(obj, view); return; }
    Py_DECREF(obj);
    view->obj = NULL;
}
#endif


              /* MemviewSliceIsContig */
              static int
__pyx_memviewslice_is_contig(const __Pyx_memviewslice mvs,
                             char order, int ndim)
{
    int i, index, step, start;
    Py_ssize_t itemsize = mvs.memview->view.itemsize;
    if (order == 'F') {
        step = 1;
        start = 0;
    } else {
        step = -1;
        start = ndim - 1;
    }
    for (i = 0; i < ndim; i++) {
        index = start + step * i;
        if (mvs.suboffsets[index] >= 0 || mvs.strides[index] != itemsize)
            return 0;
        itemsize *= mvs.shape[index];
    }
    return 1;
}

/* OverlappingSlices */
              static void
__pyx_get_array_memory_extents(__Pyx_memviewslice *slice,
                               void **out_start, void **out_end,
                               int ndim, size_t itemsize)
{
    char *start, *end;
    int i;
    start = end = slice->data;
    for (i = 0; i < ndim; i++) {
        Py_ssize_t stride = slice->strides[i];
        Py_ssize_t extent = slice->shape[i];
        if (extent == 0) {
            *out_start = *out_end = start;
            return;
        } else {
            if (stride > 0)
                end += stride * (extent - 1);
            else
                start += stride * (extent - 1);
        }
    }
    *out_start = start;
    *out_end = end + itemsize;
}
static int
__pyx_slices_overlap(__Pyx_memviewslice *slice1,
                     __Pyx_memviewslice *slice2,
                     int ndim, size_t itemsize)
{
    void *start1, *end1, *start2, *end2;
    __pyx_get_array_memory_extents(slice1, &start1, &end1, ndim, itemsize);
    __pyx_get_array_memory_extents(slice2, &start2, &end2, ndim, itemsize);
    return (start1 < end2) && (start2 < end1);
}

/* Capsule */
              static CYTHON_INLINE PyObject *
__pyx_capsule_create(void *p, CYTHON_UNUSED const char *sig)
{
    PyObject *cobj;
#if PY_VERSION_HEX >= 0x02070000
    cobj = PyCapsule_New(p, sig, NULL);
#else
    cobj = PyCObject_FromVoidPtr(p, NULL);
#endif
    return cobj;
}

/* CIntFromPyVerify */
              #define __PYX_VERIFY_RETURN_INT(target_type, func_type, func_value)\
    __PYX__VERIFY_RETURN_INT(target_type, func_type, func_value, 0)
#define __PYX_VERIFY_RETURN_INT_EXC(target_type, func_type, func_value)\
    __PYX__VERIFY_RETURN_INT(target_type, func_type, func_value, 1)
#define __PYX__VERIFY_RETURN_INT(target_type, func_type, func_value, exc)\
    {\
        func_type value = func_value;\
        if (sizeof(target_type) < sizeof(func_type)) {\
            if (unlikely(value != (func_type) (target_type) value)) {\
                func_type zero = 0;\
                if (exc && unlikely(value == (func_type)-1 && PyErr_Occurred()))\
                    return (target_type) -1;\
                if (is_unsigned && unlikely(value < zero))\
                    goto raise_neg_overflow;\
                else\
                    goto raise_overflow;\
            }\
        }\
        return (target_type) value;\
    }

/* CIntToPy */
              static CYTHON_INLINE PyObject* __Pyx_PyInt_From_long(long value) {
    const long neg_one = (long) -1, const_zero = (long) 0;
    const int is_unsigned = neg_one > const_zero;
    if (is_unsigned) {
        if (sizeof(long) < sizeof(long)) {
            return PyInt_FromLong((long) value);
        } else if (sizeof(long) <= sizeof(unsigned long)) {
            return PyLong_FromUnsignedLong((unsigned long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(long) <= sizeof(unsigned PY_LONG_LONG)) {
            return PyLong_FromUnsignedLongLong((unsigned PY_LONG_LONG) value);
#endif
        }
    } else {
        if (sizeof(long) <= sizeof(long)) {
            return PyInt_FromLong((long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(long) <= sizeof(PY_LONG_LONG)) {
            return PyLong_FromLongLong((PY_LONG_LONG) value);
#endif
        }
    }
    {
        int one = 1; int little = (int)*(unsigned char *)&one;
        unsigned char *bytes = (unsigned char *)&value;
        return _PyLong_FromByteArray(bytes, sizeof(long),
                                     little, !is_unsigned);
    }
}

/* CIntToPy */
              static CYTHON_INLINE PyObject* __Pyx_PyInt_From_int(int value) {
    const int neg_one = (int) -1, const_zero = (int) 0;
    const int is_unsigned = neg_one > const_zero;
    if (is_unsigned) {
        if (sizeof(int) < sizeof(long)) {
            return PyInt_FromLong((long) value);
        } else if (sizeof(int) <= sizeof(unsigned long)) {
            return PyLong_FromUnsignedLong((unsigned long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(int) <= sizeof(unsigned PY_LONG_LONG)) {
            return PyLong_FromUnsignedLongLong((unsigned PY_LONG_LONG) value);
#endif
        }
    } else {
        if (sizeof(int) <= sizeof(long)) {
            return PyInt_FromLong((long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(int) <= sizeof(PY_LONG_LONG)) {
            return PyLong_FromLongLong((PY_LONG_LONG) value);
#endif
        }
    }
    {
        int one = 1; int little = (int)*(unsigned char *)&one;
        unsigned char *bytes = (unsigned char *)&value;
        return _PyLong_FromByteArray(bytes, sizeof(int),
                                     little, !is_unsigned);
    }
}

/* MemviewDtypeToObject */
              static CYTHON_INLINE PyObject *__pyx_memview_get_float(const char *itemp) {
    return (PyObject *) PyFloat_FromDouble(*(float *) itemp);
}
static CYTHON_INLINE int __pyx_memview_set_float(const char *itemp, PyObject *obj) {
    float value = __pyx_PyFloat_AsFloat(obj);
    if ((value == (float)-1) && PyErr_Occurred())
        return 0;
    *(float *) itemp = value;
    return 1;
}

/* MemviewDtypeToObject */
              static CYTHON_INLINE PyObject *__pyx_memview_get_double(const char *itemp) {
    return (PyObject *) PyFloat_FromDouble(*(double *) itemp);
}
static CYTHON_INLINE int __pyx_memview_set_double(const char *itemp, PyObject *obj) {
    double value = __pyx_PyFloat_AsDouble(obj);
    if ((value == (double)-1) && PyErr_Occurred())
        return 0;
    *(double *) itemp = value;
    return 1;
}

/* CIntToPy */
              static CYTHON_INLINE PyObject* __Pyx_PyInt_From_unsigned_char(unsigned char value) {
    const unsigned char neg_one = (unsigned char) -1, const_zero = (unsigned char) 0;
    const int is_unsigned = neg_one > const_zero;
    if (is_unsigned) {
        if (sizeof(unsigned char) < sizeof(long)) {
            return PyInt_FromLong((long) value);
        } else if (sizeof(unsigned char) <= sizeof(unsigned long)) {
            return PyLong_FromUnsignedLong((unsigned long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(unsigned char) <= sizeof(unsigned PY_LONG_LONG)) {
            return PyLong_FromUnsignedLongLong((unsigned PY_LONG_LONG) value);
#endif
        }
    } else {
        if (sizeof(unsigned char) <= sizeof(long)) {
            return PyInt_FromLong((long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(unsigned char) <= sizeof(PY_LONG_LONG)) {
            return PyLong_FromLongLong((PY_LONG_LONG) value);
#endif
        }
    }
    {
        int one = 1; int little = (int)*(unsigned char *)&one;
        unsigned char *bytes = (unsigned char *)&value;
        return _PyLong_FromByteArray(bytes, sizeof(unsigned char),
                                     little, !is_unsigned);
    }
}

/* MemviewDtypeToObject */
              static CYTHON_INLINE PyObject *__pyx_memview_get_unsigned_char(const char *itemp) {
    return (PyObject *) __Pyx_PyInt_From_unsigned_char(*(unsigned char *) itemp);
}
static CYTHON_INLINE int __pyx_memview_set_unsigned_char(const char *itemp, PyObject *obj) {
    unsigned char value = __Pyx_PyInt_As_unsigned_char(obj);
    if ((value == (unsigned char)-1) && PyErr_Occurred())
        return 0;
    *(unsigned char *) itemp = value;
    return 1;
}

/* MemviewSliceCopyTemplate */
              static __Pyx_memviewslice
__pyx_memoryview_copy_new_contig(const __Pyx_memviewslice *from_mvs,
                                 const char *mode, int ndim,
                                 size_t sizeof_dtype, int contig_flag,
                                 int dtype_is_object)
{
    __Pyx_RefNannyDeclarations
    int i;
    __Pyx_memviewslice new_mvs = { 0, 0, { 0 }, { 0 }, { 0 } };
    struct __pyx_memoryview_obj *from_memview = from_mvs->memview;
    Py_buffer *buf = &from_memview->view;
    PyObject *shape_tuple = NULL;
    PyObject *temp_int = NULL;
    struct __pyx_array_obj *array_obj = NULL;
    struct __pyx_memoryview_obj *memview_obj = NULL;
    __Pyx_RefNannySetupContext("__pyx_memoryview_copy_new_contig", 0);
    for (i = 0; i < ndim; i++) {
        if (from_mvs->suboffsets[i] >= 0) {
            PyErr_Format(PyExc_ValueError, "Cannot copy memoryview slice with "
                                           "indirect dimensions (axis %d)", i);
            goto fail;
        }
    }
    shape_tuple = PyTuple_New(ndim);
    if (unlikely(!shape_tuple)) {
        goto fail;
    }
    __Pyx_GOTREF(shape_tuple);
    for(i = 0; i < ndim; i++) {
        temp_int = PyInt_FromSsize_t(from_mvs->shape[i]);
        if(unlikely(!temp_int)) {
            goto fail;
        } else {
            PyTuple_SET_ITEM(shape_tuple, i, temp_int);
            temp_int = NULL;
        }
    }
    array_obj = __pyx_array_new(shape_tuple, sizeof_dtype, buf->format, (char *) mode, NULL);
    if (unlikely(!array_obj)) {
        goto fail;
    }
    __Pyx_GOTREF(array_obj);
    memview_obj = (struct __pyx_memoryview_obj *) __pyx_memoryview_new(
                                    (PyObject *) array_obj, contig_flag,
                                    dtype_is_object,
                                    from_mvs->memview->typeinfo);
    if (unlikely(!memview_obj))
        goto fail;
    if (unlikely(__Pyx_init_memviewslice(memview_obj, ndim, &new_mvs, 1) < 0))
        goto fail;
    if (unlikely(__pyx_memoryview_copy_contents(*from_mvs, new_mvs, ndim, ndim,
                                                dtype_is_object) < 0))
        goto fail;
    goto no_fail;
fail:
    __Pyx_XDECREF(new_mvs.memview);
    new_mvs.memview = NULL;
    new_mvs.data = NULL;
no_fail:
    __Pyx_XDECREF(shape_tuple);
    __Pyx_XDECREF(temp_int);
    __Pyx_XDECREF(array_obj);
    __Pyx_RefNannyFinishContext();
    return new_mvs;
}

/* CIntFromPy */
              static CYTHON_INLINE long __Pyx_PyInt_As_long(PyObject *x) {
    const long neg_one = (long) -1, const_zero = (long) 0;
    const int is_unsigned = neg_one > const_zero;
#if PY_MAJOR_VERSION < 3
    if (likely(PyInt_Check(x))) {
        if (sizeof(long) < sizeof(long)) {
            __PYX_VERIFY_RETURN_INT(long, long, PyInt_AS_LONG(x))
        } else {
            long val = PyInt_AS_LONG(x);
            if (is_unsigned && unlikely(val < 0)) {
                goto raise_neg_overflow;
            }
            return (long) val;
        }
    } else
#endif
    if (likely(PyLong_Check(x))) {
        if (is_unsigned) {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (long) 0;
                case  1: __PYX_VERIFY_RETURN_INT(long, digit, digits[0])
                case 2:
                    if (8 * sizeof(long) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) >= 2 * PyLong_SHIFT) {
                            return (long) (((((long)digits[1]) << PyLong_SHIFT) | (long)digits[0]));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(long) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) >= 3 * PyLong_SHIFT) {
                            return (long) (((((((long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0]));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(long) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) >= 4 * PyLong_SHIFT) {
                            return (long) (((((((((long)digits[3]) << PyLong_SHIFT) | (long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0]));
                        }
                    }
                    break;
            }
#endif
#if CYTHON_COMPILING_IN_CPYTHON
            if (unlikely(Py_SIZE(x) < 0)) {
                goto raise_neg_overflow;
            }
#else
            {
                int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
                if (unlikely(result < 0))
                    return (long) -1;
                if (unlikely(result == 1))
                    goto raise_neg_overflow;
            }
#endif
            if (sizeof(long) <= sizeof(unsigned long)) {
                __PYX_VERIFY_RETURN_INT_EXC(long, unsigned long, PyLong_AsUnsignedLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(long) <= sizeof(unsigned PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(long, unsigned PY_LONG_LONG, PyLong_AsUnsignedLongLong(x))
#endif
            }
        } else {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (long) 0;
                case -1: __PYX_VERIFY_RETURN_INT(long, sdigit, (sdigit) (-(sdigit)digits[0]))
                case  1: __PYX_VERIFY_RETURN_INT(long,  digit, +digits[0])
                case -2:
                    if (8 * sizeof(long) - 1 > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, long, -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                            return (long) (((long)-1)*(((((long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case 2:
                    if (8 * sizeof(long) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                            return (long) ((((((long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case -3:
                    if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, long, -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                            return (long) (((long)-1)*(((((((long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(long) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                            return (long) ((((((((long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case -4:
                    if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, long, -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                            return (long) (((long)-1)*(((((((((long)digits[3]) << PyLong_SHIFT) | (long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(long) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                            return (long) ((((((((((long)digits[3]) << PyLong_SHIFT) | (long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
            }
#endif
            if (sizeof(long) <= sizeof(long)) {
                __PYX_VERIFY_RETURN_INT_EXC(long, long, PyLong_AsLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(long) <= sizeof(PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(long, PY_LONG_LONG, PyLong_AsLongLong(x))
#endif
            }
        }
        {
#if CYTHON_COMPILING_IN_PYPY && !defined(_PyLong_AsByteArray)
            PyErr_SetString(PyExc_RuntimeError,
                            "_PyLong_AsByteArray() not available in PyPy, cannot convert large numbers");
#else
            long val;
            PyObject *v = __Pyx_PyNumber_IntOrLong(x);
 #if PY_MAJOR_VERSION < 3
            if (likely(v) && !PyLong_Check(v)) {
                PyObject *tmp = v;
                v = PyNumber_Long(tmp);
                Py_DECREF(tmp);
            }
 #endif
            if (likely(v)) {
                int one = 1; int is_little = (int)*(unsigned char *)&one;
                unsigned char *bytes = (unsigned char *)&val;
                int ret = _PyLong_AsByteArray((PyLongObject *)v,
                                              bytes, sizeof(val),
                                              is_little, !is_unsigned);
                Py_DECREF(v);
                if (likely(!ret))
                    return val;
            }
#endif
            return (long) -1;
        }
    } else {
        long val;
        PyObject *tmp = __Pyx_PyNumber_IntOrLong(x);
        if (!tmp) return (long) -1;
        val = __Pyx_PyInt_As_long(tmp);
        Py_DECREF(tmp);
        return val;
    }
raise_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "value too large to convert to long");
    return (long) -1;
raise_neg_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "can't convert negative value to long");
    return (long) -1;
}

/* CIntFromPy */
              static CYTHON_INLINE int __Pyx_PyInt_As_int(PyObject *x) {
    const int neg_one = (int) -1, const_zero = (int) 0;
    const int is_unsigned = neg_one > const_zero;
#if PY_MAJOR_VERSION < 3
    if (likely(PyInt_Check(x))) {
        if (sizeof(int) < sizeof(long)) {
            __PYX_VERIFY_RETURN_INT(int, long, PyInt_AS_LONG(x))
        } else {
            long val = PyInt_AS_LONG(x);
            if (is_unsigned && unlikely(val < 0)) {
                goto raise_neg_overflow;
            }
            return (int) val;
        }
    } else
#endif
    if (likely(PyLong_Check(x))) {
        if (is_unsigned) {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (int) 0;
                case  1: __PYX_VERIFY_RETURN_INT(int, digit, digits[0])
                case 2:
                    if (8 * sizeof(int) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) >= 2 * PyLong_SHIFT) {
                            return (int) (((((int)digits[1]) << PyLong_SHIFT) | (int)digits[0]));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(int) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) >= 3 * PyLong_SHIFT) {
                            return (int) (((((((int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0]));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(int) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) >= 4 * PyLong_SHIFT) {
                            return (int) (((((((((int)digits[3]) << PyLong_SHIFT) | (int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0]));
                        }
                    }
                    break;
            }
#endif
#if CYTHON_COMPILING_IN_CPYTHON
            if (unlikely(Py_SIZE(x) < 0)) {
                goto raise_neg_overflow;
            }
#else
            {
                int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
                if (unlikely(result < 0))
                    return (int) -1;
                if (unlikely(result == 1))
                    goto raise_neg_overflow;
            }
#endif
            if (sizeof(int) <= sizeof(unsigned long)) {
                __PYX_VERIFY_RETURN_INT_EXC(int, unsigned long, PyLong_AsUnsignedLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(int) <= sizeof(unsigned PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(int, unsigned PY_LONG_LONG, PyLong_AsUnsignedLongLong(x))
#endif
            }
        } else {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (int) 0;
                case -1: __PYX_VERIFY_RETURN_INT(int, sdigit, (sdigit) (-(sdigit)digits[0]))
                case  1: __PYX_VERIFY_RETURN_INT(int,  digit, +digits[0])
                case -2:
                    if (8 * sizeof(int) - 1 > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, long, -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 2 * PyLong_SHIFT) {
                            return (int) (((int)-1)*(((((int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case 2:
                    if (8 * sizeof(int) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 2 * PyLong_SHIFT) {
                            return (int) ((((((int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case -3:
                    if (8 * sizeof(int) - 1 > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, long, -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 3 * PyLong_SHIFT) {
                            return (int) (((int)-1)*(((((((int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(int) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 3 * PyLong_SHIFT) {
                            return (int) ((((((((int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case -4:
                    if (8 * sizeof(int) - 1 > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, long, -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 4 * PyLong_SHIFT) {
                            return (int) (((int)-1)*(((((((((int)digits[3]) << PyLong_SHIFT) | (int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(int) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 4 * PyLong_SHIFT) {
                            return (int) ((((((((((int)digits[3]) << PyLong_SHIFT) | (int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
            }
#endif
            if (sizeof(int) <= sizeof(long)) {
                __PYX_VERIFY_RETURN_INT_EXC(int, long, PyLong_AsLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(int) <= sizeof(PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(int, PY_LONG_LONG, PyLong_AsLongLong(x))
#endif
            }
        }
        {
#if CYTHON_COMPILING_IN_PYPY && !defined(_PyLong_AsByteArray)
            PyErr_SetString(PyExc_RuntimeError,
                            "_PyLong_AsByteArray() not available in PyPy, cannot convert large numbers");
#else
            int val;
            PyObject *v = __Pyx_PyNumber_IntOrLong(x);
 #if PY_MAJOR_VERSION < 3
            if (likely(v) && !PyLong_Check(v)) {
                PyObject *tmp = v;
                v = PyNumber_Long(tmp);
                Py_DECREF(tmp);
            }
 #endif
            if (likely(v)) {
                int one = 1; int is_little = (int)*(unsigned char *)&one;
                unsigned char *bytes = (unsigned char *)&val;
                int ret = _PyLong_AsByteArray((PyLongObject *)v,
                                              bytes, sizeof(val),
                                              is_little, !is_unsigned);
                Py_DECREF(v);
                if (likely(!ret))
                    return val;
            }
#endif
            return (int) -1;
        }
    } else {
        int val;
        PyObject *tmp = __Pyx_PyNumber_IntOrLong(x);
        if (!tmp) return (int) -1;
        val = __Pyx_PyInt_As_int(tmp);
        Py_DECREF(tmp);
        return val;
    }
raise_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "value too large to convert to int");
    return (int) -1;
raise_neg_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "can't convert negative value to int");
    return (int) -1;
}

/* CIntFromPy */
              static CYTHON_INLINE unsigned char __Pyx_PyInt_As_unsigned_char(PyObject *x) {
    const unsigned char neg_one = (unsigned char) -1, const_zero = (unsigned char) 0;
    const int is_unsigned = neg_one > const_zero;
#if PY_MAJOR_VERSION < 3
    if (likely(PyInt_Check(x))) {
        if (sizeof(unsigned char) < sizeof(long)) {
            __PYX_VERIFY_RETURN_INT(unsigned char, long, PyInt_AS_LONG(x))
        } else {
            long val = PyInt_AS_LONG(x);
            if (is_unsigned && unlikely(val < 0)) {
                goto raise_neg_overflow;
            }
            return (unsigned char) val;
        }
    } else
#endif
    if (likely(PyLong_Check(x))) {
        if (is_unsigned) {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (unsigned char) 0;
                case  1: __PYX_VERIFY_RETURN_INT(unsigned char, digit, digits[0])
                case 2:
                    if (8 * sizeof(unsigned char) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned char, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned char) >= 2 * PyLong_SHIFT) {
                            return (unsigned char) (((((unsigned char)digits[1]) << PyLong_SHIFT) | (unsigned char)digits[0]));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(unsigned char) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned char, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned char) >= 3 * PyLong_SHIFT) {
                            return (unsigned char) (((((((unsigned char)digits[2]) << PyLong_SHIFT) | (unsigned char)digits[1]) << PyLong_SHIFT) | (unsigned char)digits[0]));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(unsigned char) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned char, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned char) >= 4 * PyLong_SHIFT) {
                            return (unsigned char) (((((((((unsigned char)digits[3]) << PyLong_SHIFT) | (unsigned char)digits[2]) << PyLong_SHIFT) | (unsigned char)digits[1]) << PyLong_SHIFT) | (unsigned char)digits[0]));
                        }
                    }
                    break;
            }
#endif
#if CYTHON_COMPILING_IN_CPYTHON
            if (unlikely(Py_SIZE(x) < 0)) {
                goto raise_neg_overflow;
            }
#else
            {
                int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
                if (unlikely(result < 0))
                    return (unsigned char) -1;
                if (unlikely(result == 1))
                    goto raise_neg_overflow;
            }
#endif
            if (sizeof(unsigned char) <= sizeof(unsigned long)) {
                __PYX_VERIFY_RETURN_INT_EXC(unsigned char, unsigned long, PyLong_AsUnsignedLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(unsigned char) <= sizeof(unsigned PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(unsigned char, unsigned PY_LONG_LONG, PyLong_AsUnsignedLongLong(x))
#endif
            }
        } else {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (unsigned char) 0;
                case -1: __PYX_VERIFY_RETURN_INT(unsigned char, sdigit, (sdigit) (-(sdigit)digits[0]))
                case  1: __PYX_VERIFY_RETURN_INT(unsigned char,  digit, +digits[0])
                case -2:
                    if (8 * sizeof(unsigned char) - 1 > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned char, long, -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned char) - 1 > 2 * PyLong_SHIFT) {
                            return (unsigned char) (((unsigned char)-1)*(((((unsigned char)digits[1]) << PyLong_SHIFT) | (unsigned char)digits[0])));
                        }
                    }
                    break;
                case 2:
                    if (8 * sizeof(unsigned char) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned char, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned char) - 1 > 2 * PyLong_SHIFT) {
                            return (unsigned char) ((((((unsigned char)digits[1]) << PyLong_SHIFT) | (unsigned char)digits[0])));
                        }
                    }
                    break;
                case -3:
                    if (8 * sizeof(unsigned char) - 1 > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned char, long, -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned char) - 1 > 3 * PyLong_SHIFT) {
                            return (unsigned char) (((unsigned char)-1)*(((((((unsigned char)digits[2]) << PyLong_SHIFT) | (unsigned char)digits[1]) << PyLong_SHIFT) | (unsigned char)digits[0])));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(unsigned char) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned char, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned char) - 1 > 3 * PyLong_SHIFT) {
                            return (unsigned char) ((((((((unsigned char)digits[2]) << PyLong_SHIFT) | (unsigned char)digits[1]) << PyLong_SHIFT) | (unsigned char)digits[0])));
                        }
                    }
                    break;
                case -4:
                    if (8 * sizeof(unsigned char) - 1 > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned char, long, -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned char) - 1 > 4 * PyLong_SHIFT) {
                            return (unsigned char) (((unsigned char)-1)*(((((((((unsigned char)digits[3]) << PyLong_SHIFT) | (unsigned char)digits[2]) << PyLong_SHIFT) | (unsigned char)digits[1]) << PyLong_SHIFT) | (unsigned char)digits[0])));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(unsigned char) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned char, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned char) - 1 > 4 * PyLong_SHIFT) {
                            return (unsigned char) ((((((((((unsigned char)digits[3]) << PyLong_SHIFT) | (unsigned char)digits[2]) << PyLong_SHIFT) | (unsigned char)digits[1]) << PyLong_SHIFT) | (unsigned char)digits[0])));
                        }
                    }
                    break;
            }
#endif
            if (sizeof(unsigned char) <= sizeof(long)) {
                __PYX_VERIFY_RETURN_INT_EXC(unsigned char, long, PyLong_AsLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(unsigned char) <= sizeof(PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(unsigned char, PY_LONG_LONG, PyLong_AsLongLong(x))
#endif
            }
        }
        {
#if CYTHON_COMPILING_IN_PYPY && !defined(_PyLong_AsByteArray)
            PyErr_SetString(PyExc_RuntimeError,
                            "_PyLong_AsByteArray() not available in PyPy, cannot convert large numbers");
#else
            unsigned char val;
            PyObject *v = __Pyx_PyNumber_IntOrLong(x);
 #if PY_MAJOR_VERSION < 3
            if (likely(v) && !PyLong_Check(v)) {
                PyObject *tmp = v;
                v = PyNumber_Long(tmp);
                Py_DECREF(tmp);
            }
 #endif
            if (likely(v)) {
                int one = 1; int is_little = (int)*(unsigned char *)&one;
                unsigned char *bytes = (unsigned char *)&val;
                int ret = _PyLong_AsByteArray((PyLongObject *)v,
                                              bytes, sizeof(val),
                                              is_little, !is_unsigned);
                Py_DECREF(v);
                if (likely(!ret))
                    return val;
            }
#endif
            return (unsigned char) -1;
        }
    } else {
        unsigned char val;
        PyObject *tmp = __Pyx_PyNumber_IntOrLong(x);
        if (!tmp) return (unsigned char) -1;
        val = __Pyx_PyInt_As_unsigned_char(tmp);
        Py_DECREF(tmp);
        return val;
    }
raise_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "value too large to convert to unsigned char");
    return (unsigned char) -1;
raise_neg_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "can't convert negative value to unsigned char");
    return (unsigned char) -1;
}

/* CIntFromPy */
              static CYTHON_INLINE char __Pyx_PyInt_As_char(PyObject *x) {
    const char neg_one = (char) -1, const_zero = (char) 0;
    const int is_unsigned = neg_one > const_zero;
#if PY_MAJOR_VERSION < 3
    if (likely(PyInt_Check(x))) {
        if (sizeof(char) < sizeof(long)) {
            __PYX_VERIFY_RETURN_INT(char, long, PyInt_AS_LONG(x))
        } else {
            long val = PyInt_AS_LONG(x);
            if (is_unsigned && unlikely(val < 0)) {
                goto raise_neg_overflow;
            }
            return (char) val;
        }
    } else
#endif
    if (likely(PyLong_Check(x))) {
        if (is_unsigned) {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (char) 0;
                case  1: __PYX_VERIFY_RETURN_INT(char, digit, digits[0])
                case 2:
                    if (8 * sizeof(char) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(char, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(char) >= 2 * PyLong_SHIFT) {
                            return (char) (((((char)digits[1]) << PyLong_SHIFT) | (char)digits[0]));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(char) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(char, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(char) >= 3 * PyLong_SHIFT) {
                            return (char) (((((((char)digits[2]) << PyLong_SHIFT) | (char)digits[1]) << PyLong_SHIFT) | (char)digits[0]));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(char) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(char, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(char) >= 4 * PyLong_SHIFT) {
                            return (char) (((((((((char)digits[3]) << PyLong_SHIFT) | (char)digits[2]) << PyLong_SHIFT) | (char)digits[1]) << PyLong_SHIFT) | (char)digits[0]));
                        }
                    }
                    break;
            }
#endif
#if CYTHON_COMPILING_IN_CPYTHON
            if (unlikely(Py_SIZE(x) < 0)) {
                goto raise_neg_overflow;
            }
#else
            {
                int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
                if (unlikely(result < 0))
                    return (char) -1;
                if (unlikely(result == 1))
                    goto raise_neg_overflow;
            }
#endif
            if (sizeof(char) <= sizeof(unsigned long)) {
                __PYX_VERIFY_RETURN_INT_EXC(char, unsigned long, PyLong_AsUnsignedLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(char) <= sizeof(unsigned PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(char, unsigned PY_LONG_LONG, PyLong_AsUnsignedLongLong(x))
#endif
            }
        } else {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (char) 0;
                case -1: __PYX_VERIFY_RETURN_INT(char, sdigit, (sdigit) (-(sdigit)digits[0]))
                case  1: __PYX_VERIFY_RETURN_INT(char,  digit, +digits[0])
                case -2:
                    if (8 * sizeof(char) - 1 > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(char, long, -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(char) - 1 > 2 * PyLong_SHIFT) {
                            return (char) (((char)-1)*(((((char)digits[1]) << PyLong_SHIFT) | (char)digits[0])));
                        }
                    }
                    break;
                case 2:
                    if (8 * sizeof(char) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(char, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(char) - 1 > 2 * PyLong_SHIFT) {
                            return (char) ((((((char)digits[1]) << PyLong_SHIFT) | (char)digits[0])));
                        }
                    }
                    break;
                case -3:
                    if (8 * sizeof(char) - 1 > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(char, long, -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(char) - 1 > 3 * PyLong_SHIFT) {
                            return (char) (((char)-1)*(((((((char)digits[2]) << PyLong_SHIFT) | (char)digits[1]) << PyLong_SHIFT) | (char)digits[0])));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(char) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(char, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(char) - 1 > 3 * PyLong_SHIFT) {
                            return (char) ((((((((char)digits[2]) << PyLong_SHIFT) | (char)digits[1]) << PyLong_SHIFT) | (char)digits[0])));
                        }
                    }
                    break;
                case -4:
                    if (8 * sizeof(char) - 1 > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(char, long, -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(char) - 1 > 4 * PyLong_SHIFT) {
                            return (char) (((char)-1)*(((((((((char)digits[3]) << PyLong_SHIFT) | (char)digits[2]) << PyLong_SHIFT) | (char)digits[1]) << PyLong_SHIFT) | (char)digits[0])));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(char) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(char, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(char) - 1 > 4 * PyLong_SHIFT) {
                            return (char) ((((((((((char)digits[3]) << PyLong_SHIFT) | (char)digits[2]) << PyLong_SHIFT) | (char)digits[1]) << PyLong_SHIFT) | (char)digits[0])));
                        }
                    }
                    break;
            }
#endif
            if (sizeof(char) <= sizeof(long)) {
                __PYX_VERIFY_RETURN_INT_EXC(char, long, PyLong_AsLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(char) <= sizeof(PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(char, PY_LONG_LONG, PyLong_AsLongLong(x))
#endif
            }
        }
        {
#if CYTHON_COMPILING_IN_PYPY && !defined(_PyLong_AsByteArray)
            PyErr_SetString(PyExc_RuntimeError,
                            "_PyLong_AsByteArray() not available in PyPy, cannot convert large numbers");
#else
            char val;
            PyObject *v = __Pyx_PyNumber_IntOrLong(x);
 #if PY_MAJOR_VERSION < 3
            if (likely(v) && !PyLong_Check(v)) {
                PyObject *tmp = v;
                v = PyNumber_Long(tmp);
                Py_DECREF(tmp);
            }
 #endif
            if (likely(v)) {
                int one = 1; int is_little = (int)*(unsigned char *)&one;
                unsigned char *bytes = (unsigned char *)&val;
                int ret = _PyLong_AsByteArray((PyLongObject *)v,
                                              bytes, sizeof(val),
                                              is_little, !is_unsigned);
                Py_DECREF(v);
                if (likely(!ret))
                    return val;
            }
#endif
            return (char) -1;
        }
    } else {
        char val;
        PyObject *tmp = __Pyx_PyNumber_IntOrLong(x);
        if (!tmp) return (char) -1;
        val = __Pyx_PyInt_As_char(tmp);
        Py_DECREF(tmp);
        return val;
    }
raise_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "value too large to convert to char");
    return (char) -1;
raise_neg_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "can't convert negative value to char");
    return (char) -1;
}

/* TypeInfoCompare */
              static int
__pyx_typeinfo_cmp(__Pyx_TypeInfo *a, __Pyx_TypeInfo *b)
{
    int i;
    if (!a || !b)
        return 0;
    if (a == b)
        return 1;
    if (a->size != b->size || a->typegroup != b->typegroup ||
            a->is_unsigned != b->is_unsigned || a->ndim != b->ndim) {
        if (a->typegroup == 'H' || b->typegroup == 'H') {
            return a->size == b->size;
        } else {
            return 0;
        }
    }
    if (a->ndim) {
        for (i = 0; i < a->ndim; i++)
            if (a->arraysize[i] != b->arraysize[i])
                return 0;
    }
    if (a->typegroup == 'S') {
        if (a->flags != b->flags)
            return 0;
        if (a->fields || b->fields) {
            if (!(a->fields && b->fields))
                return 0;
            for (i = 0; a->fields[i].type && b->fields[i].type; i++) {
                __Pyx_StructField *field_a = a->fields + i;
                __Pyx_StructField *field_b = b->fields + i;
                if (field_a->offset != field_b->offset ||
                    !__pyx_typeinfo_cmp(field_a->type, field_b->type))
                    return 0;
            }
            return !a->fields[i].type && !b->fields[i].type;
        }
    }
    return 1;
}

/* MemviewSliceValidateAndInit */
              static int
__pyx_check_strides(Py_buffer *buf, int dim, int ndim, int spec)
{
    if (buf->shape[dim] <= 1)
        return 1;
    if (buf->strides) {
        if (spec & __Pyx_MEMVIEW_CONTIG) {
            if (spec & (__Pyx_MEMVIEW_PTR|__Pyx_MEMVIEW_FULL)) {
                if (buf->strides[dim] != sizeof(void *)) {
                    PyErr_Format(PyExc_ValueError,
                                 "Buffer is not indirectly contiguous "
                                 "in dimension %d.", dim);
                    goto fail;
                }
            } else if (buf->strides[dim] != buf->itemsize) {
                PyErr_SetString(PyExc_ValueError,
                                "Buffer and memoryview are not contiguous "
                                "in the same dimension.");
                goto fail;
            }
        }
        if (spec & __Pyx_MEMVIEW_FOLLOW) {
            Py_ssize_t stride = buf->strides[dim];
            if (stride < 0)
                stride = -stride;
            if (stride < buf->itemsize) {
                PyErr_SetString(PyExc_ValueError,
                                "Buffer and memoryview are not contiguous "
                                "in the same dimension.");
                goto fail;
            }
        }
    } else {
        if (spec & __Pyx_MEMVIEW_CONTIG && dim != ndim - 1) {
            PyErr_Format(PyExc_ValueError,
                         "C-contiguous buffer is not contiguous in "
                         "dimension %d", dim);
            goto fail;
        } else if (spec & (__Pyx_MEMVIEW_PTR)) {
            PyErr_Format(PyExc_ValueError,
                         "C-contiguous buffer is not indirect in "
                         "dimension %d", dim);
            goto fail;
        } else if (buf->suboffsets) {
            PyErr_SetString(PyExc_ValueError,
                            "Buffer exposes suboffsets but no strides");
            goto fail;
        }
    }
    return 1;
fail:
    return 0;
}
static int
__pyx_check_suboffsets(Py_buffer *buf, int dim, CYTHON_UNUSED int ndim, int spec)
{
    if (spec & __Pyx_MEMVIEW_DIRECT) {
        if (buf->suboffsets && buf->suboffsets[dim] >= 0) {
            PyErr_Format(PyExc_ValueError,
                         "Buffer not compatible with direct access "
                         "in dimension %d.", dim);
            goto fail;
        }
    }
    if (spec & __Pyx_MEMVIEW_PTR) {
        if (!buf->suboffsets || (buf->suboffsets && buf->suboffsets[dim] < 0)) {
            PyErr_Format(PyExc_ValueError,
                         "Buffer is not indirectly accessible "
                         "in dimension %d.", dim);
            goto fail;
        }
    }
    return 1;
fail:
    return 0;
}
static int
__pyx_verify_contig(Py_buffer *buf, int ndim, int c_or_f_flag)
{
    int i;
    if (c_or_f_flag & __Pyx_IS_F_CONTIG) {
        Py_ssize_t stride = 1;
        for (i = 0; i < ndim; i++) {
            if (stride * buf->itemsize != buf->strides[i] &&
                    buf->shape[i] > 1)
            {
                PyErr_SetString(PyExc_ValueError,
                    "Buffer not fortran contiguous.");
                goto fail;
            }
            stride = stride * buf->shape[i];
        }
    } else if (c_or_f_flag & __Pyx_IS_C_CONTIG) {
        Py_ssize_t stride = 1;
        for (i = ndim - 1; i >- 1; i--) {
            if (stride * buf->itemsize != buf->strides[i] &&
                    buf->shape[i] > 1) {
                PyErr_SetString(PyExc_ValueError,
                    "Buffer not C contiguous.");
                goto fail;
            }
            stride = stride * buf->shape[i];
        }
    }
    return 1;
fail:
    return 0;
}
static int __Pyx_ValidateAndInit_memviewslice(
                int *axes_specs,
                int c_or_f_flag,
                int buf_flags,
                int ndim,
                __Pyx_TypeInfo *dtype,
                __Pyx_BufFmt_StackElem stack[],
                __Pyx_memviewslice *memviewslice,
                PyObject *original_obj)
{
    struct __pyx_memoryview_obj *memview, *new_memview;
    __Pyx_RefNannyDeclarations
    Py_buffer *buf;
    int i, spec = 0, retval = -1;
    __Pyx_BufFmt_Context ctx;
    int from_memoryview = __pyx_memoryview_check(original_obj);
    __Pyx_RefNannySetupContext("ValidateAndInit_memviewslice", 0);
    if (from_memoryview && __pyx_typeinfo_cmp(dtype, ((struct __pyx_memoryview_obj *)
                                                            original_obj)->typeinfo)) {
        memview = (struct __pyx_memoryview_obj *) original_obj;
        new_memview = NULL;
    } else {
        memview = (struct __pyx_memoryview_obj *) __pyx_memoryview_new(
                                            original_obj, buf_flags, 0, dtype);
        new_memview = memview;
        if (unlikely(!memview))
            goto fail;
    }
    buf = &memview->view;
    if (buf->ndim != ndim) {
        PyErr_Format(PyExc_ValueError,
                "Buffer has wrong number of dimensions (expected %d, got %d)",
                ndim, buf->ndim);
        goto fail;
    }
    if (new_memview) {
        __Pyx_BufFmt_Init(&ctx, stack, dtype);
        if (!__Pyx_BufFmt_CheckString(&ctx, buf->format)) goto fail;
    }
    if ((unsigned) buf->itemsize != dtype->size) {
        PyErr_Format(PyExc_ValueError,
                     "Item size of buffer (%" CYTHON_FORMAT_SSIZE_T "u byte%s) "
                     "does not match size of '%s' (%" CYTHON_FORMAT_SSIZE_T "u byte%s)",
                     buf->itemsize,
                     (buf->itemsize > 1) ? "s" : "",
                     dtype->name,
                     dtype->size,
                     (dtype->size > 1) ? "s" : "");
        goto fail;
    }
    for (i = 0; i < ndim; i++) {
        spec = axes_specs[i];
        if (!__pyx_check_strides(buf, i, ndim, spec))
            goto fail;
        if (!__pyx_check_suboffsets(buf, i, ndim, spec))
            goto fail;
    }
    if (buf->strides && !__pyx_verify_contig(buf, ndim, c_or_f_flag))
        goto fail;
    if (unlikely(__Pyx_init_memviewslice(memview, ndim, memviewslice,
                                         new_memview != NULL) == -1)) {
        goto fail;
    }
    retval = 0;
    goto no_fail;
fail:
    Py_XDECREF(new_memview);
    retval = -1;
no_fail:
    __Pyx_RefNannyFinishContext();
    return retval;
}

/* ObjectToMemviewSlice */
              static CYTHON_INLINE __Pyx_memviewslice __Pyx_PyObject_to_MemoryviewSlice_ds_float(PyObject *obj) {
    __Pyx_memviewslice result = { 0, 0, { 0 }, { 0 }, { 0 } };
    __Pyx_BufFmt_StackElem stack[1];
    int axes_specs[] = { (__Pyx_MEMVIEW_DIRECT | __Pyx_MEMVIEW_STRIDED) };
    int retcode;
    if (obj == Py_None) {
        result.memview = (struct __pyx_memoryview_obj *) Py_None;
        return result;
    }
    retcode = __Pyx_ValidateAndInit_memviewslice(axes_specs, 0,
                                                 PyBUF_RECORDS, 1,
                                                 &__Pyx_TypeInfo_float, stack,
                                                 &result, obj);
    if (unlikely(retcode == -1))
        goto __pyx_fail;
    return result;
__pyx_fail:
    result.memview = NULL;
    result.data = NULL;
    return result;
}

/* ObjectToMemviewSlice */
              static CYTHON_INLINE __Pyx_memviewslice __Pyx_PyObject_to_MemoryviewSlice_ds_double(PyObject *obj) {
    __Pyx_memviewslice result = { 0, 0, { 0 }, { 0 }, { 0 } };
    __Pyx_BufFmt_StackElem stack[1];
    int axes_specs[] = { (__Pyx_MEMVIEW_DIRECT | __Pyx_MEMVIEW_STRIDED) };
    int retcode;
    if (obj == Py_None) {
        result.memview = (struct __pyx_memoryview_obj *) Py_None;
        return result;
    }
    retcode = __Pyx_ValidateAndInit_memviewslice(axes_specs, 0,
                                                 PyBUF_RECORDS, 1,
                                                 &__Pyx_TypeInfo_double, stack,
                                                 &result, obj);
    if (unlikely(retcode == -1))
        goto __pyx_fail;
    return result;
__pyx_fail:
    result.memview = NULL;
    result.data = NULL;
    return result;
}

/* ObjectToMemviewSlice */
              static CYTHON_INLINE __Pyx_memviewslice __Pyx_PyObject_to_MemoryviewSlice_ds_unsigned_char(PyObject *obj) {
    __Pyx_memviewslice result = { 0, 0, { 0 }, { 0 }, { 0 } };
    __Pyx_BufFmt_StackElem stack[1];
    int axes_specs[] = { (__Pyx_MEMVIEW_DIRECT | __Pyx_MEMVIEW_STRIDED) };
    int retcode;
    if (obj == Py_None) {
        result.memview = (struct __pyx_memoryview_obj *) Py_None;
        return result;
    }
    retcode = __Pyx_ValidateAndInit_memviewslice(axes_specs, 0,
                                                 PyBUF_RECORDS, 1,
                                                 &__Pyx_TypeInfo_unsigned_char, stack,
                                                 &result, obj);
    if (unlikely(retcode == -1))
        goto __pyx_fail;
    return result;
__pyx_fail:
    result.memview = NULL;
    result.data = NULL;
    return result;
}

/* CStringEquals */
              static CYTHON_INLINE int __Pyx_StrEq(const char *s1, const char *s2) {
    while (*s1 != '\0' && *s1 == *s2) { s1++; s2++; }
    return *s1 == *s2;
}

/* CheckBinaryVersion */
              static int __Pyx_check_binary_version(void) {
    char ctversion[4], rtversion[4];
    PyOS_snprintf(ctversion, 4, "%d.%d", PY_MAJOR_VERSION, PY_MINOR_VERSION);
    PyOS_snprintf(rtversion, 4, "%s", Py_GetVersion());
    if (ctversion[0] != rtversion[0] || ctversion[2] != rtversion[2]) {
        char message[200];
        PyOS_snprintf(message, sizeof(message),
                      "compiletime version %s of module '%.100s' "
                      "does not match runtime version %s",
                      ctversion, __Pyx_MODULE_NAME, rtversion);
        return PyErr_WarnEx(NULL, message, 1);
    }
    return 0;
}

/* ModuleImport */
              #ifndef __PYX_HAVE_RT_ImportModule
#define __PYX_HAVE_RT_ImportModule
static PyObject *__Pyx_ImportModule(const char *name) {
    PyObject *py_name = 0;
    PyObject *py_module = 0;
    py_name = __Pyx_PyIdentifier_FromString(name);
    if (!py_name)
        goto bad;
    py_module = PyImport_Import(py_name);
    Py_DECREF(py_name);
    return py_module;
bad:
    Py_XDECREF(py_name);
    return 0;
}
#endif

/* TypeImport */
              #ifndef __PYX_HAVE_RT_ImportType
#define __PYX_HAVE_RT_ImportType
static PyTypeObject *__Pyx_ImportType(const char *module_name, const char *class_name,
    size_t size, int strict)
{
    PyObject *py_module = 0;
    PyObject *result = 0;
    PyObject *py_name = 0;
    char warning[200];
    Py_ssize_t basicsize;
#ifdef Py_LIMITED_API
    PyObject *py_basicsize;
#endif
    py_module = __Pyx_ImportModule(module_name);
    if (!py_module)
        goto bad;
    py_name = __Pyx_PyIdentifier_FromString(class_name);
    if (!py_name)
        goto bad;
    result = PyObject_GetAttr(py_module, py_name);
    Py_DECREF(py_name);
    py_name = 0;
    Py_DECREF(py_module);
    py_module = 0;
    if (!result)
        goto bad;
    if (!PyType_Check(result)) {
        PyErr_Format(PyExc_TypeError,
            "%.200s.%.200s is not a type object",
            module_name, class_name);
        goto bad;
    }
#ifndef Py_LIMITED_API
    basicsize = ((PyTypeObject *)result)->tp_basicsize;
#else
    py_basicsize = PyObject_GetAttrString(result, "__basicsize__");
    if (!py_basicsize)
        goto bad;
    basicsize = PyLong_AsSsize_t(py_basicsize);
    Py_DECREF(py_basicsize);
    py_basicsize = 0;
    if (basicsize == (Py_ssize_t)-1 && PyErr_Occurred())
        goto bad;
#endif
    if (!strict && (size_t)basicsize > size) {
        PyOS_snprintf(warning, sizeof(warning),
            "%s.%s size changed, may indicate binary incompatibility. Expected %zd, got %zd",
            module_name, class_name, basicsize, size);
        if (PyErr_WarnEx(NULL, warning, 0) < 0) goto bad;
    }
    else if ((size_t)basicsize != size) {
        PyErr_Format(PyExc_ValueError,
            "%.200s.%.200s has the wrong size, try recompiling. Expected %zd, got %zd",
            module_name, class_name, basicsize, size);
        goto bad;
    }
    return (PyTypeObject *)result;
bad:
    Py_XDECREF(py_module);
    Py_XDECREF(result);
    return NULL;
}
#endif

/* FunctionImport */
              #ifndef __PYX_HAVE_RT_ImportFunction
#define __PYX_HAVE_RT_ImportFunction
static int __Pyx_ImportFunction(PyObject *module, const char *funcname, void (**f)(void), const char *sig) {
    PyObject *d = 0;
    PyObject *cobj = 0;
    union {
        void (*fp)(void);
        void *p;
    } tmp;
    d = PyObject_GetAttrString(module, (char *)"__pyx_capi__");
    if (!d)
        goto bad;
    cobj = PyDict_GetItemString(d, funcname);
    if (!cobj) {
        PyErr_Format(PyExc_ImportError,
            "%.200s does not export expected C function %.200s",
                PyModule_GetName(module), funcname);
        goto bad;
    }
#if PY_VERSION_HEX >= 0x02070000
    if (!PyCapsule_IsValid(cobj, sig)) {
        PyErr_Format(PyExc_TypeError,
            "C function %.200s.%.200s has wrong signature (expected %.500s, got %.500s)",
             PyModule_GetName(module), funcname, sig, PyCapsule_GetName(cobj));
        goto bad;
    }
    tmp.p = PyCapsule_GetPointer(cobj, sig);
#else
    {const char *desc, *s1, *s2;
    desc = (const char *)PyCObject_GetDesc(cobj);
    if (!desc)
        goto bad;
    s1 = desc; s2 = sig;
    while (*s1 != '\0' && *s1 == *s2) { s1++; s2++; }
    if (*s1 != *s2) {
        PyErr_Format(PyExc_TypeError,
            "C function %.200s.%.200s has wrong signature (expected %.500s, got %.500s)",
             PyModule_GetName(module), funcname, sig, desc);
        goto bad;
    }
    tmp.p = PyCObject_AsVoidPtr(cobj);}
#endif
    *f = tmp.fp;
    if (!(*f))
        goto bad;
    Py_DECREF(d);
    return 0;
bad:
    Py_XDECREF(d);
    return -1;
}
#endif

/* InitStrings */
              static int __Pyx_InitStrings(__Pyx_StringTabEntry *t) {
    while (t->p) {
        #if PY_MAJOR_VERSION < 3
        if (t->is_unicode) {
            *t->p = PyUnicode_DecodeUTF8(t->s, t->n - 1, NULL);
        } else if (t->intern) {
            *t->p = PyString_InternFromString(t->s);
        } else {
            *t->p = PyString_FromStringAndSize(t->s, t->n - 1);
        }
        #else
        if (t->is_unicode | t->is_str) {
            if (t->intern) {
                *t->p = PyUnicode_InternFromString(t->s);
            } else if (t->encoding) {
                *t->p = PyUnicode_Decode(t->s, t->n - 1, t->encoding, NULL);
            } else {
                *t->p = PyUnicode_FromStringAndSize(t->s, t->n - 1);
            }
        } else {
            *t->p = PyBytes_FromStringAndSize(t->s, t->n - 1);
        }
        #endif
        if (!*t->p)
            return -1;
        ++t;
    }
    return 0;
}

static CYTHON_INLINE PyObject* __Pyx_PyUnicode_FromString(const char* c_str) {
    return __Pyx_PyUnicode_FromStringAndSize(c_str, (Py_ssize_t)strlen(c_str));
}
static CYTHON_INLINE char* __Pyx_PyObject_AsString(PyObject* o) {
    Py_ssize_t ignore;
    return __Pyx_PyObject_AsStringAndSize(o, &ignore);
}
static CYTHON_INLINE char* __Pyx_PyObject_AsStringAndSize(PyObject* o, Py_ssize_t *length) {
#if CYTHON_COMPILING_IN_CPYTHON && (__PYX_DEFAULT_STRING_ENCODING_IS_ASCII || __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT)
    if (
#if PY_MAJOR_VERSION < 3 && __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
            __Pyx_sys_getdefaultencoding_not_ascii &&
#endif
            PyUnicode_Check(o)) {
#if PY_VERSION_HEX < 0x03030000
        char* defenc_c;
        PyObject* defenc = _PyUnicode_AsDefaultEncodedString(o, NULL);
        if (!defenc) return NULL;
        defenc_c = PyBytes_AS_STRING(defenc);
#if __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
        {
            char* end = defenc_c + PyBytes_GET_SIZE(defenc);
            char* c;
            for (c = defenc_c; c < end; c++) {
                if ((unsigned char) (*c) >= 128) {
                    PyUnicode_AsASCIIString(o);
                    return NULL;
                }
            }
        }
#endif
        *length = PyBytes_GET_SIZE(defenc);
        return defenc_c;
#else
        if (__Pyx_PyUnicode_READY(o) == -1) return NULL;
#if __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
        if (PyUnicode_IS_ASCII(o)) {
            *length = PyUnicode_GET_LENGTH(o);
            return PyUnicode_AsUTF8(o);
        } else {
            PyUnicode_AsASCIIString(o);
            return NULL;
        }
#else
        return PyUnicode_AsUTF8AndSize(o, length);
#endif
#endif
    } else
#endif
#if (!CYTHON_COMPILING_IN_PYPY) || (defined(PyByteArray_AS_STRING) && defined(PyByteArray_GET_SIZE))
    if (PyByteArray_Check(o)) {
        *length = PyByteArray_GET_SIZE(o);
        return PyByteArray_AS_STRING(o);
    } else
#endif
    {
        char* result;
        int r = PyBytes_AsStringAndSize(o, &result, length);
        if (unlikely(r < 0)) {
            return NULL;
        } else {
            return result;
        }
    }
}
static CYTHON_INLINE int __Pyx_PyObject_IsTrue(PyObject* x) {
   int is_true = x == Py_True;
   if (is_true | (x == Py_False) | (x == Py_None)) return is_true;
   else return PyObject_IsTrue(x);
}
static CYTHON_INLINE PyObject* __Pyx_PyNumber_IntOrLong(PyObject* x) {
#if CYTHON_USE_TYPE_SLOTS
  PyNumberMethods *m;
#endif
  const char *name = NULL;
  PyObject *res = NULL;
#if PY_MAJOR_VERSION < 3
  if (PyInt_Check(x) || PyLong_Check(x))
#else
  if (PyLong_Check(x))
#endif
    return __Pyx_NewRef(x);
#if CYTHON_USE_TYPE_SLOTS
  m = Py_TYPE(x)->tp_as_number;
  #if PY_MAJOR_VERSION < 3
  if (m && m->nb_int) {
    name = "int";
    res = PyNumber_Int(x);
  }
  else if (m && m->nb_long) {
    name = "long";
    res = PyNumber_Long(x);
  }
  #else
  if (m && m->nb_int) {
    name = "int";
    res = PyNumber_Long(x);
  }
  #endif
#else
  res = PyNumber_Int(x);
#endif
  if (res) {
#if PY_MAJOR_VERSION < 3
    if (!PyInt_Check(res) && !PyLong_Check(res)) {
#else
    if (!PyLong_Check(res)) {
#endif
      PyErr_Format(PyExc_TypeError,
                   "__%.4s__ returned non-%.4s (type %.200s)",
                   name, name, Py_TYPE(res)->tp_name);
      Py_DECREF(res);
      return NULL;
    }
  }
  else if (!PyErr_Occurred()) {
    PyErr_SetString(PyExc_TypeError,
                    "an integer is required");
  }
  return res;
}
static CYTHON_INLINE Py_ssize_t __Pyx_PyIndex_AsSsize_t(PyObject* b) {
  Py_ssize_t ival;
  PyObject *x;
#if PY_MAJOR_VERSION < 3
  if (likely(PyInt_CheckExact(b))) {
    if (sizeof(Py_ssize_t) >= sizeof(long))
        return PyInt_AS_LONG(b);
    else
        return PyInt_AsSsize_t(x);
  }
#endif
  if (likely(PyLong_CheckExact(b))) {
    #if CYTHON_USE_PYLONG_INTERNALS
    const digit* digits = ((PyLongObject*)b)->ob_digit;
    const Py_ssize_t size = Py_SIZE(b);
    if (likely(__Pyx_sst_abs(size) <= 1)) {
        ival = likely(size) ? digits[0] : 0;
        if (size == -1) ival = -ival;
        return ival;
    } else {
      switch (size) {
         case 2:
           if (8 * sizeof(Py_ssize_t) > 2 * PyLong_SHIFT) {
             return (Py_ssize_t) (((((size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case -2:
           if (8 * sizeof(Py_ssize_t) > 2 * PyLong_SHIFT) {
             return -(Py_ssize_t) (((((size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case 3:
           if (8 * sizeof(Py_ssize_t) > 3 * PyLong_SHIFT) {
             return (Py_ssize_t) (((((((size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case -3:
           if (8 * sizeof(Py_ssize_t) > 3 * PyLong_SHIFT) {
             return -(Py_ssize_t) (((((((size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case 4:
           if (8 * sizeof(Py_ssize_t) > 4 * PyLong_SHIFT) {
             return (Py_ssize_t) (((((((((size_t)digits[3]) << PyLong_SHIFT) | (size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case -4:
           if (8 * sizeof(Py_ssize_t) > 4 * PyLong_SHIFT) {
             return -(Py_ssize_t) (((((((((size_t)digits[3]) << PyLong_SHIFT) | (size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
      }
    }
    #endif
    return PyLong_AsSsize_t(b);
  }
  x = PyNumber_Index(b);
  if (!x) return -1;
  ival = PyInt_AsSsize_t(x);
  Py_DECREF(x);
  return ival;
}
static CYTHON_INLINE PyObject * __Pyx_PyInt_FromSize_t(size_t ival) {
    return PyInt_FromSize_t(ival);
}


#endif /* Py_PYTHON_H */
